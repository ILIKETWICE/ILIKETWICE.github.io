<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title>无法拉取 gcr.io 镜像？用魔法来打败魔法</title>
      <link href="/2022/02/06/2022-02-06-githubactions-pull-images/"/>
      <url>/2022/02/06/2022-02-06-githubactions-pull-images/</url>
      
        <content type="html"><![CDATA[<p>目前常用的 Docker Registry 公开服务有：</p><ul><li><code>docker.io</code> ：Docker Hub 官方镜像仓库，也是 Docker 默认的仓库</li><li><code>gcr.io</code>、<code>k8s.gcr.io</code> ：谷歌镜像仓库</li><li><code>quay.io</code> ：Red Hat 镜像仓库</li><li><code>ghcr.io</code> ：GitHub 镜像仓库</li></ul><p>当使用 <code>docker pull 仓库地址/用户名/仓库名:标签</code> 时，会前往对应的仓库地址拉取镜像，标签无声明时默认为 <code>latest</code>， 仓库地址无声明时默认为 <code>docker.io</code> 。</p><p>众所周知的原因，在国内访问这些服务异常的慢，甚至 <code>gcr.io</code> 和 <code>quay.io</code> 根本无法访问。</p><h2 id="解决方案：镜像加速器"><a href="#解决方案：镜像加速器" class="headerlink" title="解决方案：镜像加速器"></a>解决方案：镜像加速器</h2><p>针对 <code>Docker Hub</code> ，Docker 官方和国内各大云服务商均提供了 Docker 镜像加速服务。</p><p>你只需要简单配置一下（以 Linux 为例）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo mkdir -p /etc/docker</span><br><span class="line"></span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;镜像加速器&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure><p>便可以通过访问国内镜像加速器来加速 <code>Docker Hub</code> 的镜像下载。</p><p>!&gt; 不过这种办法也只能针对 <code>docker.io</code> ，其它的仓库地址并没有真正实际可用的加速器（至少我目前没找到）。</p><h2 id="解决方案：用魔法打败魔法"><a href="#解决方案：用魔法打败魔法" class="headerlink" title="解决方案：用魔法打败魔法"></a>解决方案：用魔法打败魔法</h2><p>既然无法治本，那治治标还是可以的吧。</p><p>若我们使用一台魔法机器从 <code>gcr.io</code> 或 <code>quay.io</code> 等仓库先把我们无法下载的镜像拉取下来，然后重新上传到 <code>docker.io</code> ，是不是就可以使用 <code>Docker Hub</code> 的镜像加速器来下载了。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>本篇的实现已放在 GitHub ：**<code>https://github.com/togettoyou/hub-mirror</code>**</p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Gitlab CI 在 Kubernetes 中的 Docker 缓存 </title>
      <link href="/2021/12/23/2021-12-23-k8s-gitlabci-layer/"/>
      <url>/2021/12/23/2021-12-23-k8s-gitlabci-layer/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Gitlab Runner的执行器有8个，常见的有Shell、Dcoker和Kubernetes。</p><p>Shell执行器配置简单，但是构建工具都需要手动安装，例如：JDK、Maven、Nodejs。如果此时有需求需要升级所有Shell执行器的JDK版本，还需要重新手动升级？(虽然可以写个脚本)</p><p>Docker和Kubernetes执行器比较灵活，缺点就是Docker执行器和Kubenetes执行器每次启动的容器或者Pod依赖包都是干净的，就需要重新拉取相关依赖包，比较耽误构建时间。</p><p>此时Shell执行器就比较占优势，因为是使用系统本机的构建工具，会在系统上留有构建缓存，例如：.mvn</p><p>那么怎么做，也能缓存Docker执行器的layer层呢？</p><p>这个问题的解决方法非常简单，与其为每个 Pod 运行一个 Docker DIND 服务的 sidecar 容器，不如让我们运行一个独立的 Docker DIND 容器，构建容器的所有 Docker CLI 都连接到这个一个 Docker 守护进程上，这个时候我们将 Docker layer 层进行持久化，也就起到了缓存的作用了。</p><h2 id="Docker-镜像说明"><a href="#Docker-镜像说明" class="headerlink" title="Docker 镜像说明"></a>Docker 镜像说明</h2><p>查看<a href="https://link.juejin.cn/?target=https://hub.docker.com/_/docker">官方的 docker 镜像</a></p><h3 id="docker-latest"><a href="#docker-latest" class="headerlink" title="docker:latest"></a>docker:latest</h3><p>该镜像只包含 Docker 客户端，需要有 Docker daemon 支持，可以使用 <code>docker:dind</code> 的，也可以挂载宿主机的 <code>/var/run/docker.sock</code>。</p><p>该镜像启动不需要 <code>--privileged</code> 参数。</p><h3 id="docker-dind"><a href="#docker-dind" class="headerlink" title="docker:dind"></a>docker:dind</h3><p>该镜像包含 Docker 客户端（命令行工具）和 Docker daemon。</p><p>通过 <code>docker history docker:dind</code> 命令我们发现 <code>docker:dind</code> 是在 <code>docker:latest</code> 基础上又安装了 Docker daemon</p><p>启动 <code>docker:dind</code> 容器时，参数 <code>--privileged</code> 必须加上，否则 Docker daemon 启动时会报错。</p><h2 id="正文开始"><a href="#正文开始" class="headerlink" title="正文开始"></a>正文开始</h2><p>首先创建一个 PVC 来存储 Docker 的持久化数据，为了性能考虑，这里我们使用的是一个 Local PV：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">local-volume</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/no-provisioner</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">WaitForFirstConsumer</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">docker-pv</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">local-volume</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/mnt/k8s/docker</span>  <span class="comment"># 数据存储的目录</span></span><br><span class="line">  <span class="attr">nodeAffinity:</span></span><br><span class="line">    <span class="attr">required:</span></span><br><span class="line">      <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">          <span class="attr">values:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">node1</span>  <span class="comment"># 运行在node1节点</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">docker-dind</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">docker-dind-data</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">local-volume</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">5Gi</span></span><br></pre></td></tr></table></figure><p>然后使用 Deployment 部署一个 Docker DIND 服务：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">docker-dind</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-ops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">docker-dind</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">docker-dind</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">docker-dind</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">docker:dind</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">docker-dind</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">--registry-mirror=https://ot2k4d59.mirror.aliyuncs.com/</span>  <span class="comment"># 指定一个镜像加速器地址</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DOCKER_DRIVER</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">overlay2</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DOCKER_HOST</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">tcp://0.0.0.0:2375</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DOCKER_TLS_CERTDIR</span>   <span class="comment"># 禁用 TLS </span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker-dind-data-vol</span> <span class="comment"># 持久化docker根目录</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/var/lib/docker/</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemon-port</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">2375</span></span><br><span class="line">          <span class="attr">securityContext:</span></span><br><span class="line">            <span class="attr">privileged:</span> <span class="literal">true</span> <span class="comment"># 需要设置成特权模式</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">docker-dind-data-vol</span></span><br><span class="line">          <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">            <span class="attr">claimName:</span> <span class="string">docker-dind-data</span></span><br></pre></td></tr></table></figure><p>然后创建一个 Service 以方便构建的 Docker CLI 与其连接：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">docker-dind</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-ops</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">docker-dind</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">2375</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">2375</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">docker-dind</span></span><br></pre></td></tr></table></figure><p>将 Docker DIND 服务部署完成后，我们就可以在 Gitlab CI 中使用这个守护程序来构建镜像了，如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tages:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">image</span></span><br><span class="line"></span><br><span class="line"><span class="attr">build_image:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">image</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">docker:latest</span></span><br><span class="line">  <span class="attr">variables:</span></span><br><span class="line">    <span class="attr">DOCKER_HOST:</span> <span class="string">tcp://docker-dind:2375</span>  <span class="comment"># 通过 service dns 形式连接 docker dind 服务</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">docker</span> <span class="string">info</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">docker</span> <span class="string">build</span> <span class="string">-t</span> <span class="string">xxxx</span> <span class="string">.</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">docker</span> <span class="string">push</span> <span class="string">xxxx</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">tags</span></span><br></pre></td></tr></table></figure><p>由于我们缓存了 Docker layer 层，这个时候构建的速度会明显提升。最后随着镜像的大量构建会产生很多镜像数据，我们可以写一个 Cronjob 用来定时清除缓存：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">docker-dind-clear-cache</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="number">0</span> <span class="number">0</span> <span class="string">*</span> <span class="string">*</span> <span class="number">0</span>  <span class="comment"># 每周清理一次</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">docker-dind</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">docker-dind-clear-cache</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">clear-cache</span></span><br><span class="line">              <span class="attr">image:</span> <span class="string">docker:latest</span></span><br><span class="line">              <span class="attr">command:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">docker</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">system</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">prune</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">-af</span></span><br><span class="line">              <span class="attr">env:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DOCKER_HOST</span></span><br><span class="line">                  <span class="attr">value:</span> <span class="string">tcp://docker-dind:2375</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Python下划线的5个潜规则 </title>
      <link href="/2021/12/23/2021-12-23-python-underline-rules/"/>
      <url>/2021/12/23/2021-12-23-python-underline-rules/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文将介绍 Python 中<strong>单下划线</strong>和<strong>双下划线</strong> (“dunder”) 的各种含义和命名约定，名称修饰 (name mangling) 的工作原理，以及它如何影响你自己的 Python 类。</p><p><strong>单下划线</strong>和<strong>双下划线</strong> 在 Python 变量和方法名称中都各有其含义。有一些含义仅仅是依照约定，被视作是对程序员的提示，而有一些含义是由 Python 解释器严格执行的。</p><p>在本文中，我将讨论以下五种下划线模式和命名约定，以及它们如何影响 Python 程序的行为：</p><ul><li>单前导下划线：**_var**</li><li>单末尾下划线：<strong>var_</strong></li><li>双前导下划线：**__var**</li><li>双前导和末尾下划线：**<strong>var</strong>**</li><li>单下划线：**_**</li></ul><p>在文章结尾处，你可以找到一个简短的<strong>速查表</strong>，总结了五种不同的下划线命名约定及其含义，让我们马上开始！</p><h2 id="1、单前导下划线-var"><a href="#1、单前导下划线-var" class="headerlink" title="1、单前导下划线 _var"></a>1、单前导下划线 <code>_var</code></h2><p>当涉及到变量和方法名称时，单个下划线前缀有一个约定俗成的含义。它是对程序员的一个提示：意味着 Python 社区一致认为它应该是什么意思，但程序的行为不受影响。</p><p>下划线前缀的含义是告知其他程序员：<strong>以单个下划线开头的变量或方法仅供内部使用</strong>。该约定在 PEP 8 中有定义。</p><p>这不是 Python 强制规定的。Python 不像 Java 那样在 “私有” 和 “公共” 变量之间有很强的区别。</p><p>看看下面的例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>:</span>   </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span>      </span><br><span class="line">    self.foo = <span class="number">11</span>       </span><br><span class="line">    self._bar = <span class="number">23</span></span><br></pre></td></tr></table></figure><p>如果你实例化此类，并尝试访问在__init__构造函数中定义的 foo 和_bar 属性，会发生什么情况？让我们来看看：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = Test()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t.foo</span><br><span class="line"><span class="number">11</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t._bar</span><br><span class="line"><span class="number">23</span></span><br></pre></td></tr></table></figure><p>你会看到_bar 中的单个下划线并没有阻止我们 “进入” 类并访问该变量的值。</p><p>这是因为 Python 中的单个下划线前缀仅仅是一个约定 - 至少相对于变量和方法名而言。</p><p>但是，前导下划线的确会影响从模块中导入名称的方式。</p><p>假设你在一个名为 my_module 的模块中有以下代码：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">external_func</span>():</span>   </span><br><span class="line"><span class="keyword">return</span> <span class="number">23</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_internal_func</span>():</span>   </span><br><span class="line"><span class="keyword">return</span> <span class="number">42</span></span><br></pre></td></tr></table></figure><p>现在，如果使用通配符从模块中导入所有名称，则 Python 不会导入带有前导下划线的名称（除非模块定义了覆盖此行为的__all__列表）：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> my_module <span class="keyword">import</span> *</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>external_func()</span><br><span class="line"><span class="number">23</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_internal_func()</span><br><span class="line">NameError: <span class="string">&quot;name &#x27;_internal_func&#x27; is not defined&quot;</span></span><br></pre></td></tr></table></figure><p>顺便说一下，应该避免通配符导入，因为它们使名称空间中存在哪些名称不清楚。为了清楚起见，坚持常规导入更好。</p><p>与通配符导入不同，常规导入不受前导单个下划线命名约定的影响：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> my_module</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_module.external_func()</span><br><span class="line"><span class="number">23</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_module._internal_func()</span><br><span class="line"><span class="number">42</span></span><br></pre></td></tr></table></figure><p>我知道这一点可能有点令人困惑。如果你遵循 PEP 8 推荐，避免通配符导入，那么你真正需要记住的只有这个：</p><p>单个下划线是一个 Python 命名约定，表示这个名称是供内部使用的。它通常不由 Python 解释器强制执行，仅仅作为一种对程序员的提示。</p><h2 id="2、单末尾下划线-var"><a href="#2、单末尾下划线-var" class="headerlink" title="2、单末尾下划线 var_"></a>2、单末尾下划线 <code>var_</code></h2><p>有时候，一个变量的最合适的名称已经被一个关键字所占用。因此，像 class 或 def 这样的名称不能用作 Python 中的变量名称。在这种情况下，你可以附加一个下划线来解决命名冲突：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">make_object</span>(<span class="params">name, <span class="keyword">class</span></span>):</span></span><br><span class="line">SyntaxError: <span class="string">&quot;invalid syntax&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">make_object</span>(<span class="params">name, class_</span>):</span></span><br><span class="line"><span class="meta">... </span>   <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p> 总之，单个末尾下划线（后缀）是一个约定，用来避免与 Python 关键字产生命名冲突。PEP 8 解释了这个约定。</p><h2 id="3、双前导下划线-var"><a href="#3、双前导下划线-var" class="headerlink" title="3、双前导下划线 __var"></a>3、双前导下划线 <code>__var</code></h2><p>到目前为止，我们所涉及的所有命名模式的含义，来自于已达成共识的约定。而对于以<strong>双下划线开头</strong>的 Python 类的属性 (包括变量和方法)，情况就有点不同了。</p><p>双下划线前缀会导致 Python 解释器重写属性名称，以避免子类中的命名冲突。</p><p>这也叫做<strong>名称修饰 (name mangling)</strong> - 解释器更改变量的名称，以便在类被扩展的时候不容易产生冲突。</p><p>我知道这听起来很抽象。因此，我组合了一个小小的代码示例来予以说明：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">       self.foo = <span class="number">11</span></span><br><span class="line">       self._bar = <span class="number">23</span></span><br><span class="line">       self.__baz = <span class="number">23</span></span><br></pre></td></tr></table></figure><p>让我们用内置的 dir () 函数来看看这个对象的属性：</p> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = Test()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">dir</span>(t)</span><br><span class="line">[<span class="string">&#x27;_Test__baz&#x27;</span>, <span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dict__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__weakref__&#x27;</span>, <span class="string">&#x27;_bar&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>]</span><br></pre></td></tr></table></figure><p>以上是这个对象属性的列表。让我们来看看这个列表，并寻找我们的原始变量名称 foo，_bar 和__baz , 我保证你会注意到一些有趣的变化。</p><ul><li>self.foo 变量在属性列表中显示为未修改为 foo。</li><li>self._bar 的行为方式相同 - 它以_bar 的形式显示在类上。就像我之前说过的，在这种情况下，前导下划线仅仅是一个约定。给程序员一个提示而已。</li><li>然而，对于 self.__baz 而言，情况看起来有点不同。当你在该列表中搜索__baz 时，你会看不到有这个名字的变量。</li></ul><p><strong>__baz 出什么情况了？</strong></p><p>如果你仔细观察，你会看到此对象上有一个名为_Test__baz 的属性。这就是 Python 解释器所做的名称修饰。它这样做是为了防止变量在子类中被重写。</p><p>让我们创建另一个扩展 Test 类的类，并尝试重写构造函数中添加的现有属性：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExtendedTest</span>(<span class="params">Test</span>):</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="built_in">super</span>().__init__()</span><br><span class="line">       self.foo = <span class="string">&#x27;overridden&#x27;</span></span><br><span class="line">       self._bar = <span class="string">&#x27;overridden&#x27;</span></span><br><span class="line">       self.__baz = <span class="string">&#x27;overridden&#x27;</span></span><br></pre></td></tr></table></figure><p>现在，你认为 foo，_bar 和__baz 的值会出现在这个 ExtendedTest 类的实例上吗？我们来看一看：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t2 = ExtendedTest()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t2.foo</span><br><span class="line"><span class="string">&#x27;overridden&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t2._bar</span><br><span class="line"><span class="string">&#x27;overridden&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t2.__baz</span><br><span class="line">AttributeError: <span class="string">&quot;&#x27;ExtendedTest&#x27; object has no attribute &#x27;__baz&#x27;&quot;</span></span><br></pre></td></tr></table></figure><p>等一下，当我们尝试查看 t2 .__ baz 的值时，为什么我们会得到 AttributeError？名称修饰被再次触发了！事实证明，这个对象甚至没有__baz 属性：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">dir</span>(t2)</span><br><span class="line">[<span class="string">&#x27;_ExtendedTest__baz&#x27;</span>, <span class="string">&#x27;_Test__baz&#x27;</span>, <span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__dict__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__getattribute__&#x27;</span>, <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>, <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>, <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;__subclasshook__&#x27;</span>, <span class="string">&#x27;__weakref__&#x27;</span>, <span class="string">&#x27;_bar&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;get_vars&#x27;</span>]</span><br></pre></td></tr></table></figure><p>正如你可以看到__baz 变成_ExtendedTest__baz 以防止意外修改：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t2._ExtendedTest__baz</span><br><span class="line"><span class="string">&#x27;overridden&#x27;</span></span><br></pre></td></tr></table></figure><p>但原来的_Test__baz 还在：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t2._Test__baz</span><br><span class="line"><span class="number">42</span></span><br></pre></td></tr></table></figure><p>双下划线名称修饰对程序员是完全透明的。下面的例子证实了这一点：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ManglingTest</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">       self.__mangled = <span class="string">&#x27;hello&#x27;</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">get_mangled</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="keyword">return</span> self.__mangled</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ManglingTest().get_mangled()</span><br><span class="line"><span class="string">&#x27;hello&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ManglingTest().__mangled</span><br><span class="line">AttributeError: <span class="string">&quot;&#x27;ManglingTest&#x27; object has no attribute &#x27;__mangled&#x27;&quot;</span></span><br></pre></td></tr></table></figure><p>名称修饰是否也适用于方法名称？是的，也适用。名称修饰会影响在一个类的上下文中，以两个下划线字符（”dunders”）开头的所有名称：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MangledMethod</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__method</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="keyword">return</span> <span class="number">42</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">call_it</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="keyword">return</span> self.__method()</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>MangledMethod().__method()</span><br><span class="line">AttributeError: <span class="string">&quot;&#x27;MangledMethod&#x27; object has no attribute &#x27;__method&#x27;&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>MangledMethod().call_it()</span><br><span class="line"><span class="number">42</span></span><br></pre></td></tr></table></figure><p>这是另一个也许令人惊讶的运用名称修饰的例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_MangledGlobal__mangled = <span class="number">23</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MangledGlobal</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="keyword">return</span> __mangled</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>MangledGlobal().test()</span><br><span class="line"><span class="number">23</span></span><br></pre></td></tr></table></figure><p>在这个例子中，我声明了一个名为_MangledGlobal__mangled 的全局变量。然后我在名为 MangledGlobal 的类的上下文中访问变量。由于名称修饰，我能够在类的 test () 方法内，以__mangled 来引用_MangledGlobal__mangled 全局变量。</p><p>Python 解释器自动将名称__mangled 扩展为_MangledGlobal__mangled，因为它以两个下划线字符开头。这表明名称修饰不是专门与类属性关联的。它适用于在类上下文中使用的两个下划线字符开头的任何名称。</p><p>有很多要吸收的内容吧。</p><p>老实说，这些例子和解释不是从我脑子里蹦出来的。我作了一些研究和加工才弄出来。我一直使用 Python，有很多年了，但是像这样的规则和特殊情况并不总是浮现在脑海里。</p><p>有时候程序员最重要的技能是 “模式识别”，而且知道在哪里查阅信息。如果您在这一点上感到有点不知所措，请不要担心。慢慢来，试试这篇文章中的一些例子。</p><p>让这些概念完全沉浸下来，以便你能够理解名称修饰的总体思路，以及我向您展示的一些其他的行为。如果有一天你和它们不期而遇，你会知道在文档中按什么来查。</p><h2 id="4、双前导和双末尾下划线-var"><a href="#4、双前导和双末尾下划线-var" class="headerlink" title="4、双前导和双末尾下划线__var__"></a>4、双前导和双末尾下划线<code>__var__</code></h2><p>也许令人惊讶的是，如果一个名字同时以双下划线开始和结束，则不会应用名称修饰。由双下划线前缀和后缀包围的变量不会被 Python 解释器修改：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrefixPostfixTest</span>:</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">       self.__bam__ = <span class="number">42</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>PrefixPostfixTest().__bam__</span><br><span class="line"><span class="number">42</span></span><br></pre></td></tr></table></figure><p>但是，Python 保留了有双前导和双末尾下划线的名称，用于特殊用途。这样的例子有，<strong>init__对象构造函数，或__call</strong> — 它使得一个对象可以被调用。</p><p>这些 dunder 方法通常被称为神奇方法 - 但 Python 社区中的许多人（包括我自己）都不喜欢这种方法。</p><p>最好避免在自己的程序中使用以双下划线（“dunders”）开头和结尾的名称，以避免与将来 Python 语言的变化产生冲突。</p><h2 id="5、单下划线"><a href="#5、单下划线" class="headerlink" title="5、单下划线_"></a>5、单下划线<code>_</code></h2><p>按照习惯，有时候单个独立下划线是用作一个名字，来表示某个变量是临时的或无关紧要的。</p><p>例如，在下面的循环中，我们不需要访问正在运行的索引，我们可以使用 “_” 来表示它只是一个临时值：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>):</span><br><span class="line"><span class="meta">... </span>   <span class="built_in">print</span>(<span class="string">&#x27;Hello, World.&#x27;</span>)</span><br></pre></td></tr></table></figure><p>你也可以在拆分 (unpacking) 表达式中将单个下划线用作 “不关心的” 变量，以忽略特定的值。同样，这个含义只是 “依照约定”，并不会在 Python 解释器中触发特殊的行为。单个下划线仅仅是一个有效的变量名称，会有这个用途而已。</p><p>在下面的代码示例中，我将汽车元组拆分为单独的变量，但我只对颜色和里程值感兴趣。但是，为了使拆分表达式成功运行，我需要将包含在元组中的所有值分配给变量。在这种情况下，“_” 作为占位符变量可以派上用场：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>car = (<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;auto&#x27;</span>, <span class="number">12</span>, <span class="number">3812.4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>color, _, _, mileage = car</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>color</span><br><span class="line"><span class="string">&#x27;red&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mileage</span><br><span class="line"><span class="number">3812.4</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_</span><br><span class="line"><span class="number">12</span></span><br></pre></td></tr></table></figure><p>除了用作临时变量之外，“_” 是大多数 Python REPL 中的一个特殊变量，它表示由解释器评估的最近一个表达式的结果。</p><p>这样就很方便了，比如你可以在一个解释器会话中访问先前计算的结果，或者，你是在动态构建多个对象并与它们交互，无需事先给这些对象分配名字：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">20</span> + <span class="number">3</span></span><br><span class="line"><span class="number">23</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_</span><br><span class="line"><span class="number">23</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(_)</span><br><span class="line"><span class="number">23</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>()</span><br><span class="line">[]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_.append(<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_.append(<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_.append(<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>_</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-12-22/640.jpg"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Linux History命令及其配置 </title>
      <link href="/2021/12/09/2021-12-09-linux-history/"/>
      <url>/2021/12/09/2021-12-09-linux-history/</url>
      
        <content type="html"><![CDATA[<p>当我们频繁使用 Linux 命令行时，有效地使用历史记录，可以大大提高工作效率。</p><p>在平时 Linux 操作过程中，很多命令是重复的，你一定不希望大量输入重复的命令。如果你是系统管理员，你可能需要对用户操作进行审计，管理好 Linux 命令历史记录显得非常重要。</p><p>今天我们来介绍一下，在 Linux 使用 history 来减少重复命令的几个实用技巧。</p><h2 id="1-基本原理"><a href="#1-基本原理" class="headerlink" title="1 基本原理"></a>1 基本原理</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-12-09/history.jpg"></p><p>Linux 命令的历史记录，会持久化存储，默认位置是当前用户家目录的 <code>.bash_history</code> 文件。</p><p>当 Linux 系统启动一个 Shell 时，Shell 会从 <code>.bash_history</code> 文件中，读取历史记录，存储在相应内存的缓冲区中。</p><p>我们平时所操作的 Linux 命令，都会记录在 <code>缓冲区</code> 中。包括 <code>history</code> 命令所执行的历史命令管理，都是在操作 <code>缓冲区</code> ，而不是直接操作 <code>.bash_history</code> 文件。</p><p>当我们退出 Shell，比如按下 <code>Ctrl+D</code> 时，Shell 进程会把历史记录缓冲区的内容，写回到 <code>.bash_history</code> 文件中去。</p><h2 id="2-使用详解"><a href="#2-使用详解" class="headerlink" title="2 使用详解"></a>2 使用详解</h2><p>清楚了 <code>history</code> 的基本原理，我们来具体学习一下如何使用它。</p><p><strong>（一）基础用法</strong></p><p>直接输入 history 命令，可以看到最近操作的所有命令都显示出来了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">history</span></span><br><span class="line">   1  bash</span><br><span class="line">   2  ls</span><br><span class="line">   3  vim .bash_history</span><br><span class="line">   4  cat .bash_history</span><br><span class="line">   5  <span class="built_in">history</span></span><br><span class="line">   6  bash</span><br></pre></td></tr></table></figure><p>有时候我不需要显示所有的历史命令，只显示最后的 10 条历史记录，可以在命令后加数字 <code>N</code> 即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">history</span> 10</span><br></pre></td></tr></table></figure><p>正常情况下，只有在 Shell 正常退出时，才会将缓冲区内容保存到文件。如果你想主动保存缓冲区的历史记录，执行 <code>-w</code> 选项即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">history</span> -w</span><br></pre></td></tr></table></figure><p>当然，如果你执行了一些敏感的命令操作，可以执行 <code>-c</code> 将缓冲区内容直接删除</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">history</span> -c</span><br></pre></td></tr></table></figure><p><strong>（二）重复执行命令</strong></p><p>如果要重复执行一些命令，可以使用 <code>!</code> 来快速执行重复的命令。</p><p>举个例子，重复执行第 1024 历史命令，可以执行如下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ !1024</span><br></pre></td></tr></table></figure><p><code>1024</code> 这个编号可以通过 <code>history</code> 查看哦</p><p>重复执行上一条命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ !!</span><br></pre></td></tr></table></figure><p>重复执行倒数第 6 条历史命令，可以通过 <code>负数</code> 表示， <code>-6</code> 表示倒数第 6 条记录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ !-6</span><br></pre></td></tr></table></figure><p><strong>（三）搜索历史命令</strong></p><p>有时候，需要重复执行某字符串开头的最后一个命令，同样可以通过 <code>!</code> 来操作，然后按 Enter 执行即可</p><p>比如，刚才执行了一个很长命令，只记录命令开头是 <code>curl</code> ，这时就可以通过 <code>!curl</code> 快速执行该命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ !curl</span><br></pre></td></tr></table></figure><p>这个用法很高效，但存在不安全因素，因为有可能执行的命令不是你想要执行的，那就坏事了。可以通过 <code>:p</code> 来安全地执行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ !curl:p</span><br><span class="line">curl www.sina.com.cn</span><br></pre></td></tr></table></figure><p>加上 <code>:p</code> 后，只是打印出了搜索到的命令，如果要执行，请按 <code>Up</code> 键，然后回车即可。</p><p>如果你只知道某条命令包含了 <code>x</code> 信息，不是以 <code>x</code> 开头，同样可以通过 <code>?</code> 来执行包含字符串的命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ !?sina</span><br></pre></td></tr></table></figure><p><strong>（四）交互式搜索历史命令</strong></p><p>在 Linux 搜索历史命令，还可以通过交互式的搜索方式，简直高效直接。在命令行输入 <code>Ctrl+R</code> 后，进入交互界面，键入需要搜索的关键字，如果匹配到多条命令，可以多次键入 <code>Ctrl+R</code> 来切换上一条匹配的命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(reverse-i-search)`sina<span class="string">&#x27;: echo sina</span></span><br></pre></td></tr></table></figure><p>可以看到，我输入了 sina 后，就自动匹配到最近一次和 sina 匹配的命令，这时按下回车就可以执行该命令。</p><p><strong>（五）重复执行上条命令</strong></p><p>在这里总结下多种重复执行上条命令的方式，你可以选择一种自己喜欢的就可以啦</p><ul><li><code>!!</code></li><li><code>!-1</code></li><li><code>Ctrl+p</code></li><li><code>Up</code></li><li><code>Ctrl+R</code></li></ul><p><strong>（六）显示时间戳</strong></p><p>有时候需要对 Linux 系统做审计，那为历史记录添加时间戳，显示非常有用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> HISTTIMEFORMAT=<span class="string">&#x27;%F %T &#x27;</span></span><br><span class="line">$ <span class="built_in">history</span> 3</span><br><span class="line">  46  2021-04-18 15:21:33 curl baidu.com</span><br><span class="line">  47  2021-04-18 15:21:35 <span class="built_in">pwd</span></span><br><span class="line">  48  2021-04-18 15:21:39 <span class="built_in">history</span> 3</span><br></pre></td></tr></table></figure><p>可以看到，历史记录已经显示了时间戳。其实这些对于审计需求，还不够，可以加上更详细的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> HISTTIMEFORMAT=<span class="string">&quot;%F %T `who -u am i 2&gt;/dev/null| awk &#x27;&#123;print <span class="variable">$NF</span>&#125;&#x27;|sed \-e &#x27;s/[()]//g&#x27;` `whoami` &quot;</span></span><br><span class="line">  6  2021-04-18 16:07:48 113.200.44.237 root ls</span><br><span class="line">  7  2021-04-18 16:07:59 113.200.44.237 root <span class="built_in">pwd</span></span><br><span class="line">  8  2021-04-18 16:08:14 113.200.44.237 root <span class="built_in">history</span></span><br></pre></td></tr></table></figure><p><strong>（七）控制历史记录总数</strong></p><p>默认情况下，Linux 系统最多存储 1000 条历史记录，可以通过 <code>HISTSIZE</code> 环境变量查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="variable">$HISTSIZE</span></span><br><span class="line">1000</span><br></pre></td></tr></table></figure><p>对于需要做审计的场景，1000 条历史记录可能会太少了，我们可以修改为合适的值</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> HISTSIZE=10000</span><br></pre></td></tr></table></figure><p>注意， <code>HISTSIZE</code> 变量只能控制缓冲区中的历史记录数量，如果需要控制 <code>.bash_history</code> 文件存储的最大记录数，可以通过 <code>HISTFILESIZE</code> 进行控制</p><p>上述命令行修改只在当前 Shell 环境生效，如果需要永久生效，需要写入配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;export HISTSIZE=10000&quot;</span> &gt;&gt; ~/.bash_profile</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;export HISTFILESIZE=200000&quot;</span> &gt;&gt; ~/.bash_profile</span><br><span class="line">$ <span class="built_in">source</span> ~/.bash_profile</span><br></pre></td></tr></table></figure><p><strong>（八）更改历史记录文件名</strong></p><p>有时，为了方便管理和备份，需要更改历史记录文件的路径和名称。简单，同样可以通过环境变量 <code>HISTFILE</code> 更改它的文件名称</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;export HISTFILE=/data/backup/chopin.bash_history&quot;</span> &gt;&gt; ~/.bash_profile</span><br><span class="line">$ souce ~/.bash_profile</span><br></pre></td></tr></table></figure><p><strong>（九）禁用历史记录</strong></p><p>处于某种特殊环境，我们需要禁用历史记录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;export HISTSIZE=0&quot;</span> &gt;&gt; ~/.bash_profile</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;export HISTFILESIZE=0&quot;</span> &gt;&gt; ~/.bash_profile</span><br><span class="line">$ <span class="built_in">source</span> ~/.bash_profile</span><br></pre></td></tr></table></figure><p>哈哈，直接把上述两个变量的值设置为 <code>0</code> ，就实现了禁用历史记录的功能</p><p><strong>（十）黑客必知的一个小技巧</strong></p><p>最后分享一个不为人知的，黑客必知的小技巧。</p><p>在命令前额外多加一个<em>空格</em>，这样的命令是不会被记录到历史记录的，感觉是不是很酷</p><p>这个技巧如果在你的系统不管用，请查看下环境变量 <code>HISTCONTROL</code> 是否包含 <code>ignorespace</code> ，貌似 centos 系统默认没有设置这个值。</p><h2 id="3-总结时间"><a href="#3-总结时间" class="headerlink" title="3 总结时间"></a>3 总结时间</h2><p>在 Linux 系统， <code>history</code> 命令可以非常方便，帮助我们管理历史命令，平时我们命令都会先记录在<em>缓存区</em>，在 Shell 退出时才会记录到文件中。</p><p>history 命令提供了很方便的管理功能，合理去配置和管理历史记录，可以让你的 Linux 系统更加健壮和安全。</p><p>好了，老规矩，贴心的肖哥还是来总结一下 <code>history</code> 命令常用方法</p><ul><li><code>history n</code>：只显示最近的 n 条历史记录</li><li><code>history -c</code>：清除缓存区中的历史记录</li><li><code>history -w</code>：将缓存区的历史记录保存到文件</li><li><code>history -d N</code>：删除第 N 条历史记录</li></ul><p>几种重复执行命令的方法： <code>!!</code> 、 <code>!-1</code> 、 <code>! N</code> 、 <code>!string</code> 等</p><p>交互式历史命令搜索，请使用 <code>Ctrl+R</code> 快捷键</p><p>合适使用几个相关的环境变量，让你的 Linux 系统更安全：</p><ul><li><code>HISTSIZE</code>：控制缓冲区历史记录的最大个数</li><li><code>HISTFILESIZE</code>：控制历史记录文件中的最大个数</li><li><code>HISTIGNORE</code>：设置哪些命令不记录到历史记录</li><li><code>HISTTIMEFORMAT</code>：设置历史命令显示的时间格式</li><li><code>HISTCONTROL</code>：扩展的控制选项</li></ul><p>如果在生产环境，这些环境变量需要持久化到配置文件 <em>~/.bash_profile</em></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HISTCONTROL=ignoreboth</span><br><span class="line"><span class="comment"># ignorespace: 忽略空格开头的命令</span></span><br><span class="line"><span class="comment"># ignoredups: 忽略连续重复命令</span></span><br><span class="line"><span class="comment"># ignoreboth: 表示上述两个参数都设置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置追加而不是覆盖</span></span><br><span class="line"><span class="built_in">shopt</span> -s histappend</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HISTSIZE=1000</span><br><span class="line"><span class="built_in">export</span> HISTFILESIZE=200000</span><br><span class="line"><span class="built_in">export</span> HISTTIMEFORMAT=<span class="string">&quot;%F %T &quot;</span></span><br><span class="line"><span class="built_in">export</span> HISTIGNORE=<span class="string">&quot;ls:history&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Redis 访问控制列表(ACL) </title>
      <link href="/2021/11/08/2021-11-08-redis-acl/"/>
      <url>/2021/11/08/2021-11-08-redis-acl/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在 Redis6.0 之前的版本中，登陆 Redis Server 只需要输入密码（前提配置了密码 requirepass ）即可，不需要输入用户名，而且密码也是明文配置到配置文件中，安全性不高。并且应用连接也使用该密码，导致应用有所有权限处理数据，风险也极高。在 Redis6.0 有了 <a href="https://redis.io/topics/acl">ACL</a> 之后，终于解决了这些不安全的因素，可以按照不同的需求设置相关的用户和权限。本文来介绍下 Redis 6.0 ACL 相关的配置和使用。具体的说明可以查看官方文档：**<a href="https://redis.io/topics/acl">ACL</a>** </p><h2 id="ACL介绍"><a href="#ACL介绍" class="headerlink" title="ACL介绍"></a>ACL介绍</h2><p>Redis ACL 是 Access Control List 的缩写，是一种特性，它可以限制某些连接的<strong>可执行命令</strong>和<strong>访问 key</strong> 的权限。它的工作方式是，在连接之后，客户端需要提供用户名和有效密码进行身份验证：如果身份验证阶段成功，则连接与给定用户相关联，并限制用户的权限。Redis 可以配置为已经使用 <strong>“default”</strong> 用户（这是默认配置）对新连接进行了身份验证，所以配置 <strong>default</strong> 的用户，作为一个副作用，仅提供一个特定功能的子集，没有明确身份验证的连接。</p><p>在默认配置下 ，Redis 6（第一个拥有 ACL 的版本）的工作原理与旧版本的 Redis 完全相同，也就是说，每一个新的连接都能够调用每一个可能的命令和访问每一个 key ，所以ACL功能是向后兼容的。另外，使用requirepass配置指令配置密码的旧方法仍然可以正常工作，但现在它所做的只是为default用户设置密码。</p><p>Redis <a href="https://redis.io/commands/auth">AUTH</a>命令在 Redis 6 中被扩展了，所以它现在可以在两个参数的形式使用它：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AUTH &lt;username&gt; &lt;password&gt;</span><br></pre></td></tr></table></figure><p>按旧形式使用时，即：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AUTH &lt;password&gt;</span><br></pre></td></tr></table></figure><p>实际情况是，用于身份验证的用户名是“default”，因此仅指定密码就意味着我们要针对默认用户进行身份验证。这提供了与过去完美的向后兼容性。</p><h2 id="ACL的作用"><a href="#ACL的作用" class="headerlink" title="ACL的作用"></a>ACL的作用</h2><p>在使用acl之前，您可能想问问自己，通过实现这一层保护，您希望实现什么目标。通常acl可以很好地实现两个主要目标:</p><ul><li><p>限制对命令和密钥的访问来：</p><p>以便不受信任的客户机没有访问权限，而受信任的客户机只有对数据库的最低访问级别，以便执行所需的工作。例如，某些客户端只能执行只读命令。</p></li><li><p>提高操作安全性：</p><p>以防止由于软件错误或人为错误而导致进程或人员访问 Redis，从而破坏数据或配置。例如，从Redis获取延迟作业的worker没有理由能够调用FLUSHALL命令。</p></li></ul><h2 id="ACL-规则"><a href="#ACL-规则" class="headerlink" title="ACL 规则"></a>ACL 规则</h2><p>以下是有效的ACL规则列表。某些规则只是单个单词，用于激活或删除标志，或执行对用户ACL的给定更改。其他规则是与命令或类别名称或键模式等连接的字符前缀。</p><h4 id="启用和禁用用户"><a href="#启用和禁用用户" class="headerlink" title="启用和禁用用户"></a>启用和禁用用户</h4><p><code>on</code>：启用用户，可以使用该用户进行身份验证。</p><p><code>off</code>：禁用用户，不再可能与该用户进行身份验证，但是已经通过身份验证的连接仍将工作。</p><p>注意，如果默认用户被标记为关闭，新的连接开始时将不经过身份验证，并且将要求用户发送带有AUTH选项的AUTH或HELLO以某种方式进行身份验证，而不管默认用户配置如何。</p><h4 id="允许和禁止命令"><a href="#允许和禁止命令" class="headerlink" title="允许和禁止命令"></a>允许和禁止命令</h4><p><code>+&lt;command&gt;</code>：将该命令添加到用户可以调用的命令列表中。可以与<code>|</code>一起使用以允许子命令(例如“+config|get”)。</p><p><code>—&lt;command&gt;</code>：将命令从用户可以调用的命令列表中移除。可以与<code>|</code>一起用于阻塞子命令(例如“-config|set”)。</p><p><code>+@&lt;category&gt;</code>：为用户添加一类命令的权限，有效的类如@admin， @set， @sortedset，…等等，通过调用ACL CAT命令查看完整的列表。特殊类别@all表示所有命令，包括当前在服务器中存在的命令和将来将通过模块加载的命令。</p><p><code>-@&lt;category&gt;</code>：类似**+@&lt;category&gt;**，从客户端可以调用的命令列表中删除命令</p><p><code>+\&lt;command&gt;|first-arg</code>：允许一个特定的第一个参数，否则禁用命令。注意，这个表单不允许是负数，比如-SELECT|1，而只能是以“+”开头的加法。</p><p><code>allcommands</code>：+@all的别名。注意，它意味着能够执行通过模块系统加载的所有未来命令。</p><p><code>nocommands</code>： -@all的别名。</p><h4 id="允许和禁止某些-key"><a href="#允许和禁止某些-key" class="headerlink" title="允许和禁止某些 key"></a>允许和禁止某些 key</h4><p><code>~&lt;pattern&gt;</code>：添加可以作为命令的一部分提到的键模式。例如~*允许所有的键。该模式是一个全局样式的模式，类似于KEYS模式。可以指定多个模式。</p><p><code>allkeys</code>:  也就是~*。</p><p><code>resetkeys</code>：刷新允许的键模式列表。例如ACL ~foo:* ~bar:* resetkeys ~objects:*，将导致客户端只能访问匹配模式对象:*的键。</p><h4 id="允许和禁止发布-订阅频道"><a href="#允许和禁止发布-订阅频道" class="headerlink" title="允许和禁止发布/订阅频道"></a>允许和禁止发布/订阅频道</h4><p><code>&amp;&lt;pattern&gt;</code>：添加一个用户可以访问的发布/订阅通道的glob样式模式。可以指定多个通道模式。注意，模式匹配只对PUBLISH和SUBSCRIBE提到的通道进行，而PSUBSCRIBE要求在其通道模式和用户允许的通道模式之间进行文字匹配。</p><p><code>allchannels</code>：&amp;*别名，允许用户访问所有发布/订阅通道</p><p><code>resetchannels</code>：刷新允许的通道模式列表，如果用户的发布/订阅客户端不再能够访问各自的通道和/或通道模式，则断开这些客户端。</p><h4 id="为用户配置有效的密码"><a href="#为用户配置有效的密码" class="headerlink" title="为用户配置有效的密码"></a>为用户配置有效的密码</h4><p><code>&gt;&lt;password&gt;</code>：将此密码添加到用户的有效密码列表中。例如，&gt;mypass将把“mypass”添加到有效密码列表中。该指令清除nopass标志(参见后面的内容)。每个用户可以有任意数量的密码。</p><p><code>&lt;&lt;password&gt;</code>：从有效密码列表中删除此密码。如果删除的密码实际上没有设置，则将发出错误。</p><p><code>#&lt;hash&gt;</code>：将此SHA-256哈希值添加到该用户的有效密码列表中。此hash值将与为ACL用户输入的密码的hash值进行比较。这允许用户将hash值存储在acl.conf文件中，而不是存储明文密码。只能接受SHA-256哈希值，因为密码hash值必须为64个字符，且只能包含小写的十六进制字符。</p><p><code>!&lt;hash&gt;</code>：从有效密码列表中删除此hash值。当您不知道由hash值指定的密码，但希望从用户中删除密码时，这是非常有用的。</p><p><code>nopass</code>：用户设置的所有密码都被删除，用户被标记为不需要密码:这意味着每个密码都适用于该用户。如果将此指令用于默认用户，则每个新连接都将立即使用默认用户进行身份验证，而不需要任何显式的AUTH命令。注意，resetpass指令将清除这个条件。</p><p><code>resetpass</code>：清除允许的密码列表。此外，还删除了nopass状态。重置后，用户没有相关的密码，如果不添加一些密码(或稍后设置为nopass)，就无法进行身份验证。</p><h4 id="重置用户"><a href="#重置用户" class="headerlink" title="重置用户"></a>重置用户</h4><p><code>rest</code>：执行以下操作:resetpass, resetkeys, resetchannels, off， -@all。用户在创建后立即返回到相同的状态。</p><h2 id="使用-ACL-命令配置-ACL"><a href="#使用-ACL-命令配置-ACL" class="headerlink" title="使用 ACL 命令配置 ACL"></a>使用 ACL 命令配置 ACL</h2><p>acl是使用DSL(领域特定语言)定义的，DSL描述了给定用户能够做什么或不能做什么。这样的规则总是从第一个到最后一个，从左到右实现，因为有时规则的顺序对理解用户真正能够做什么很重要。</p><p>首先看 ACL 的 help，了解大致的使用方法：ACL help</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; ACL <span class="built_in">help</span></span><br><span class="line"> 1) ACL &lt;subcommand&gt; arg arg ... arg. Subcommands are:</span><br><span class="line"> 2) LOAD                             -- 从ACL文件中重新载入用户信息.</span><br><span class="line"> 3) SAVE                             -- 保存当前的用户配置信息到ACL文件.</span><br><span class="line"> 4) LIST                             -- 以配置文件格式显示用户详细信息.</span><br><span class="line"> 5) USERS                            -- 列出所有注册的用户名.</span><br><span class="line"> 6) SETUSER &lt;username&gt; [attribs ...] -- 创建或则修改一个用户.</span><br><span class="line"> 7) GETUSER &lt;username&gt;               -- 得到一个用户的详细信息.</span><br><span class="line"> 8) DELUSER &lt;username&gt; [...]         -- 删除列表中的用户.</span><br><span class="line"> 9) CAT                              -- 列出可用的类别.</span><br><span class="line">10) CAT &lt;category&gt;                   -- 列出指定类别中的命令.</span><br><span class="line">11) GENPASS [&lt;bits&gt;]                 -- 生成一个安全的用户密码.</span><br><span class="line">12) WHOAMI                           -- 返回当前的连接用户.</span><br><span class="line">13) LOG [&lt;count&gt; | RESET]            -- 显示ACL日志条目.</span><br></pre></td></tr></table></figure><p>默认情况下，redis只定义了一个用户，称为<strong>default</strong>。</p><p>我们可以使用<strong>ACL LIST</strong>命令来检查当前启用的ACL，并验证一个刚启动的、默认配置的Redis实例的配置是什么:</p><p>默认 default 用户，没有配置密码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; acl list</span><br><span class="line">1) <span class="string">&quot;user default on nopass ~* &amp;* +@all&quot;</span></span><br></pre></td></tr></table></figure><p>配置密码的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; acl list</span><br><span class="line">1) <span class="string">&quot;user onlyread on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>参 数</th><th>说明</th></tr></thead><tbody><tr><td>user</td><td>用户</td></tr><tr><td>default</td><td>表示默认用户名，或则自己定义的用户名</td></tr><tr><td>on</td><td>表示是否启用该用户，默认为 off（禁用）</td></tr><tr><td>#…</td><td>表示用户密码，nopass 表示不需要密码</td></tr><tr><td>~*</td><td>表示可以访问的 Key（正则匹配）</td></tr><tr><td>&amp;*</td><td>Pub/Sub通道(发布/订阅)</td></tr><tr><td>+@</td><td>表示用户的权限，+/- 表示授权还是销权； @为权限类。+@all 表示所有权限</td></tr></tbody></table><p>权限对 key 的类型和命令的类型进行了分类，如有对数据类型进行分类：string、hash、list、set、sortedset，和对命令类型进行分类：connection、admin、dangerous。</p><h2 id="配置实例"><a href="#配置实例" class="headerlink" title="配置实例"></a>配置实例</h2><h4 id="密码相关"><a href="#密码相关" class="headerlink" title="密码相关"></a>密码相关</h4><p>1、配置密码：一个用户可以设置不同的密码，即一个用户可以有多个密码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">-- 添加密码 </span><br><span class="line">## &gt;开头: &gt;password，明文密码；</span><br><span class="line">&gt; ACL SETUSER zhoujy on &gt;abc</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"># 获取哈希值密码 echo -n &quot;cba&quot; | shasum -a 256</span><br><span class="line">6d970874d0db767a7058798973f22cf6589601edab57996312f2ef7b56e5584d</span><br><span class="line"></span><br><span class="line">## #开头: #hash，SHA-256哈希值</span><br><span class="line">&gt; ACL SETUSER zhoujy on #6d970874d0db767a7058798973f22cf6589601edab57996312f2ef7b56e5584d</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL GETUSER zhoujy</span><br><span class="line">1) &quot;flags&quot;</span><br><span class="line">2) 1) &quot;on&quot;</span><br><span class="line">3) &quot;passwords&quot;</span><br><span class="line">4) 1) &quot;ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad&quot;</span><br><span class="line">   2) &quot;6d970874d0db767a7058798973f22cf6589601edab57996312f2ef7b56e5584d&quot;</span><br><span class="line">5) &quot;commands&quot;</span><br><span class="line">6) &quot;-@all&quot;</span><br><span class="line">7) &quot;keys&quot;</span><br><span class="line">8) (empty array)</span><br><span class="line"></span><br><span class="line">## 认证密码</span><br><span class="line">&gt; AUTH zhoujy abc</span><br><span class="line">OK</span><br><span class="line">&gt; AUTH zhoujy cba</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- 移除密码</span><br><span class="line">## &lt;开头: &lt;password ，明文密码</span><br><span class="line">&gt; ACL SETUSER zhoujy &lt;abc</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 用!开头: !hash，SHA-256哈希值</span><br><span class="line">&gt; ACL SETUSER zhoujy on !6d970874d0db767a7058798973f22cf6589601edab57996312f2ef7b56e5584d</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL GETUSER zhoujy</span><br><span class="line">1) &quot;flags&quot;</span><br><span class="line">2) 1) &quot;on&quot;</span><br><span class="line">3) &quot;passwords&quot;</span><br><span class="line">4) (empty array)</span><br><span class="line">5) &quot;commands&quot;</span><br><span class="line">6) &quot;-@all&quot;</span><br><span class="line">7) &quot;keys&quot;</span><br><span class="line">8) (empty array)</span><br><span class="line"></span><br><span class="line">## 认证密码</span><br><span class="line">&gt; AUTH zhoujy abc</span><br><span class="line">(error) WRONGPASS invalid username-password pair</span><br></pre></td></tr></table></figure><p>2、清理 / 删除密码：通过 nopass 清理用户的密码，但是该用户连接还是需要 AUTH，只是密码可以是任意值</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">-- 清理/删除密码，可以用任意密码登陆</span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL GETUSER zhoujy</span><br><span class="line">1) &quot;flags&quot;</span><br><span class="line">2) 1) &quot;on&quot;</span><br><span class="line">   2) &quot;allkeys&quot;</span><br><span class="line">   3) &quot;allcommands&quot;</span><br><span class="line">3) &quot;passwords&quot;</span><br><span class="line">4) 1) &quot;ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad&quot;</span><br><span class="line">   2) &quot;6d970874d0db767a7058798973f22cf6589601edab57996312f2ef7b56e5584d&quot;</span><br><span class="line">5) &quot;commands&quot;</span><br><span class="line">6) &quot;+@all&quot;</span><br><span class="line">7) &quot;keys&quot;</span><br><span class="line">8) 1) &quot;*&quot;</span><br><span class="line"></span><br><span class="line">## 删除、清理用户密码</span><br><span class="line">&gt; ACL SETUSER zhoujy nopass</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL GETUSER zhoujy</span><br><span class="line">1) &quot;flags&quot;</span><br><span class="line">2) 1) &quot;on&quot;</span><br><span class="line">   2) &quot;allkeys&quot;</span><br><span class="line">   3) &quot;allcommands&quot;</span><br><span class="line">   4) &quot;nopass&quot;</span><br><span class="line">3) &quot;passwords&quot;</span><br><span class="line">4) (empty array)</span><br><span class="line">5) &quot;commands&quot;</span><br><span class="line">6) &quot;+@all&quot;</span><br><span class="line">7) &quot;keys&quot;</span><br><span class="line">8) 1) &quot;*&quot;</span><br><span class="line"></span><br><span class="line">## 验证</span><br><span class="line">&gt; AUTH zhoujy  --需要AUTH</span><br><span class="line">(error) WRONGPASS invalid username-password pair</span><br><span class="line"></span><br><span class="line">&gt; AUTH zhoujy &#x27;&#x27;  --可以输入任何密码</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- 清理/删除密码，不能登陆，需要设置密码后才能登陆</span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL GETUSER zhoujy</span><br><span class="line">1) &quot;flags&quot;</span><br><span class="line">2) 1) &quot;on&quot;</span><br><span class="line">   2) &quot;allkeys&quot;</span><br><span class="line">   3) &quot;allcommands&quot;</span><br><span class="line">3) &quot;passwords&quot;</span><br><span class="line">4) 1) &quot;ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad&quot;</span><br><span class="line">   2) &quot;6d970874d0db767a7058798973f22cf6589601edab57996312f2ef7b56e5584d&quot;</span><br><span class="line">5) &quot;commands&quot;</span><br><span class="line">6) &quot;+@all&quot;</span><br><span class="line">7) &quot;keys&quot;</span><br><span class="line">8) 1) &quot;*&quot;</span><br><span class="line"></span><br><span class="line">## 删除、清理用户密码</span><br><span class="line">&gt; ACL SETUSER zhoujy resetpass</span><br><span class="line">OK</span><br><span class="line">&gt; ACL GETUSER zhoujy</span><br><span class="line">1) &quot;flags&quot;</span><br><span class="line">2) 1) &quot;on&quot;</span><br><span class="line">   2) &quot;allkeys&quot;</span><br><span class="line">   3) &quot;allcommands&quot;</span><br><span class="line">3) &quot;passwords&quot;</span><br><span class="line">4) (empty array)</span><br><span class="line">5) &quot;commands&quot;</span><br><span class="line">6) &quot;+@all&quot;</span><br><span class="line">7) &quot;keys&quot;</span><br><span class="line">8) 1) &quot;*&quot;</span><br><span class="line"></span><br><span class="line">## 验证，被resetpass重置密码之后，不能登陆，只能设置密码或则设置nopass才能登陆</span><br><span class="line">&gt; AUTH zhoujy</span><br><span class="line">(error) WRONGPASS invalid username-password pair</span><br><span class="line"></span><br><span class="line">&gt; AUTH zhoujy &#x27;&#x27;</span><br><span class="line">(error) WRONGPASS invalid username-password pair</span><br></pre></td></tr></table></figure><p>3、重置用户和密码：实际上是执行 resetpass，resetkeys，off，-@all</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">## 查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line"></span><br><span class="line">## 重置用户</span><br><span class="line">&gt; ACL SETUSER zhoujy reset</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy off -@all&quot;</span><br></pre></td></tr></table></figure><p>4、获取随机密码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 生成随机密码</span><br><span class="line">&gt; ACL GENPASS</span><br><span class="line">&quot;7a3288b05577cb6fea9b1a9a8bcfe10d9589e64be74e8a0e16c131ba896c7bde&quot;</span><br></pre></td></tr></table></figure><h4 id="键模式"><a href="#键模式" class="headerlink" title="键模式"></a>键模式</h4><p><code>~&lt;pattern&gt;</code>，通配符模式。比如： <del>* 表示允许访问所有 key，也可以用 `<strong>allkeys</strong>来表示**</del>***。**resetkeys** 表示清空它之前所有的键模式，之后的键模式不影响。`</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">-- 可以操作foo开头和bar:开头的所有key</span><br><span class="line">&gt; ACL SETUSER zhoujy on &gt;abc ~foo* ~bar:*+@all</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~foo* ~bar:*+@all&quot;</span><br><span class="line"></span><br><span class="line">--  只能操作ob:开头的key，前面的key模式被resetkeys清空了</span><br><span class="line">&gt; ACL SETUSER zhoujy on &gt;abc ~foo* ~bar:* resetkeys ~ob:*+@all</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~ob:*+@all&quot;</span><br><span class="line"></span><br><span class="line">-- 操作所有key，allkeys 和 ~* 一样</span><br><span class="line">&gt; ACL SETUSER zhoujy allkeys +@all</span><br><span class="line">OK</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~*+@all&quot;</span><br></pre></td></tr></table></figure><h4 id="权限相关"><a href="#权限相关" class="headerlink" title="权限相关"></a>权限相关</h4><p>权限这块涉及到的比较多：权限的类别、类别里包含的命令，以及子权限。<br>注意：**-@all** 表示没有任何权限；**+@all** 表示有所有权限；</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">-- 返回权限的类别</span><br><span class="line">&gt; ACL CAT</span><br><span class="line"> 1) &quot;keyspace&quot;</span><br><span class="line"> 2) &quot;read&quot;</span><br><span class="line"> 3) &quot;write&quot;</span><br><span class="line"> 4) &quot;set&quot;</span><br><span class="line"> 5) &quot;sortedset&quot;</span><br><span class="line"> 6) &quot;list&quot;</span><br><span class="line"> 7) &quot;hash&quot;</span><br><span class="line"> 8) &quot;string&quot;</span><br><span class="line"> 9) &quot;bitmap&quot;</span><br><span class="line">10) &quot;hyperloglog&quot;</span><br><span class="line">11) &quot;geo&quot;</span><br><span class="line">12) &quot;stream&quot;</span><br><span class="line">13) &quot;pubsub&quot;</span><br><span class="line">14) &quot;admin&quot;</span><br><span class="line">15) &quot;fast&quot;</span><br><span class="line">16) &quot;slow&quot;</span><br><span class="line">17) &quot;blocking&quot;</span><br><span class="line">18) &quot;dangerous&quot;</span><br><span class="line">19) &quot;connection&quot;</span><br><span class="line">20) &quot;transaction&quot;</span><br><span class="line">21) &quot;scripting&quot;</span><br><span class="line"></span><br><span class="line">-- 返回指定类别中的命令，下面hash是上面返回的一个结果</span><br><span class="line">&gt; ACL CAT hash</span><br><span class="line"> 1) &quot;hsetnx&quot;</span><br><span class="line"> 2) &quot;hset&quot;</span><br><span class="line"> 3) &quot;hlen&quot;</span><br><span class="line"> 4) &quot;hmget&quot;</span><br><span class="line"> 5) &quot;hincrbyfloat&quot;</span><br><span class="line"> 6) &quot;hgetall&quot;</span><br><span class="line"> 7) &quot;hvals&quot;</span><br><span class="line"> 8) &quot;hscan&quot;</span><br><span class="line"> 9) &quot;hkeys&quot;</span><br><span class="line">10) &quot;hstrlen&quot;</span><br><span class="line">11) &quot;hget&quot;</span><br><span class="line">12) &quot;hdel&quot;</span><br><span class="line">13) &quot;hexists&quot;</span><br><span class="line">14) &quot;hincrby&quot;</span><br><span class="line">15) &quot;hmset&quot; </span><br></pre></td></tr></table></figure><p>从上面的权限列表里看到：权限对 key 的类型和命令的类型进行了分类，如有对类型进行分类：string、hash、list、set、sortedset，和对命令类型进行分类：connection、admin、dangerous。 以及对每个分类的方法进行说明，如上面查看 hash 类型 key 的一些方法。</p><p><strong>授权方法</strong>：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+&lt;command&gt;：将命令添加到用户可以调用的命令列表中，如+@hash</span><br><span class="line">-&lt;command&gt;: 将命令从用户可以调用的命令列表中移除</span><br><span class="line">+@&lt;category&gt;: 添加一类命令，如：@admin, @set, @hash ... 可以ACL CAT 查看具体的操作指令。特殊类别@all表示所有命令，包括当前在服务器中存在的命令，以及将来将通过模块加载的命令</span><br><span class="line">-@&lt;category&gt;: 类似+@&lt;category&gt;，从客户端可以调用的命令列表中删除命令</span><br><span class="line">+&lt;command&gt;|subcommand: 允许否则禁用特定子命令。注意，这种形式不允许像-DEBUG | SEGFAULT那样，而只能以“ +”开头</span><br><span class="line">allcommands：+@all的别名，允许所有命令操作执行。注意，这意味着可以执行将来通过模块系统加载的所有命令。</span><br><span class="line">nocommands：-@all的别名，不允许所有命令操作执行。</span><br></pre></td></tr></table></figure><p>1、添加指定类型的权限：+@hash</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 添加hash类型key的所有权限</span><br><span class="line">&gt; ACL SETUSER zhoujy +@hash</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* -@all +@hash&quot; </span><br></pre></td></tr></table></figure><p><strong>说明</strong>：用户 zhoujy 只有对 hash 类型的 key 有权限。</p><p>2、删除指定类型的权限：-@hash</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 删除hash类型key的所有权限</span><br><span class="line">&gt; ACL SETUSER zhoujy -@hash +@string</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad -@all +@string&quot;</span><br></pre></td></tr></table></figure><p><strong>说明</strong>：用户 zhoujy 移除对 hash 类型的 key 有权限。</p><p>3、指定特定 key 的权限：如 sortedset：~z*，z 开头的 key</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 访问指定key的正则</span><br><span class="line">&gt; ACL SETUSER zhoujy ~z* +@sortedset -@string</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~z* -@all +@sortedset&quot;</span><br></pre></td></tr></table></figure><p><strong>说明</strong>：用户 zhoujy 只有对 z 开头的 key 有权限。</p><p>4、授权只读 / 只写的权限：+@read、+@write</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-- 授权所有key的只读权限</span><br><span class="line">&gt; ACL SETUSER zhoujy ~* +@read</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">##查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* -@all +@read +@hash +@bitmap +@geo -georadiusbymember -hsetnx -setbit -hset -geoadd -bitop -hincrbyfloat -hdel -bitfield -hincrby -hmset -georadius&quot;</span><br><span class="line"></span><br><span class="line">-- 授权所有key的只写权限</span><br><span class="line">&gt; ACL SETUSER zhoujy +@write</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">##查看</span><br><span class="line">192.168.163.134:8379&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* -@all +@write +@list +@string +@stream +@fast +@blocking -dbsize -getrange -scard -xrevrange -zrank -llen -xread -ttl -get -ping -watch -publish -hlen -xrange -stralgo -zcount -getbit -lastsave -readonly -hmget -hello -zcard -discard -hstrlen -xinfo -hget -exists -bitfield_ro -select -role -zlexcount -zrevrank -lolwut -hexists -touch -lindex -unwatch -sismember -strlen -xlen -asking -type -mget -time -xpending -echo -multi -auth -readwrite -lrange -pttl -zscore -substr&quot;</span><br></pre></td></tr></table></figure><p><strong>说明</strong>：用户 zhoujy 对所有 key 有只读或则只写的权限，如果下个这对指定 key，则替换 <strong>~*</strong> 即可。</p><p>5、授权管理权限：@admin</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 授权管理权限</span><br><span class="line">&gt; ACL SETUSER zhoujy on &gt;abc ~* +@admin</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">## 查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* -@all +@admin +@dangerous -flushall -flushdb -swapdb -keys -role -sort -migrate -restore-asking -restore -info&quot;</span><br></pre></td></tr></table></figure><p><strong>说明</strong>：用户 zhoujy 有管理权限，包含了危险操作的类型，但排除了 <strong>-</strong> 开头命令的权限。</p><p>6、允许特定类型 key 的子命令权限：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 设置子命令。</span><br><span class="line">&gt; ACL SETUSER zhoujy on &gt;abc ~* -client +client|getname +client|setname</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">##查看</span><br><span class="line">&gt; ACL LIST</span><br><span class="line">1) &quot;user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all&quot;</span><br><span class="line">2) &quot;user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* -@all +client|getname +client|setname&quot;</span><br></pre></td></tr></table></figure><p><strong>说明</strong>：开始删除 CLIENT 命令，然后添加了两个允许的子命令。请注意，不能相反，即不能 + 在前面，只能添加而不是排除子命令，因为将来可能会添加新的子命令。<strong>注意</strong>子命令匹配可能会增加一些性能损失。</p><p>7、特定用途的账号权限：Sentinel 和 Replicas</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-- Sentinel：允许用户在主和副本实例中都有以下命令权限</span><br><span class="line">&gt; ACL SETUSER sentinel-user &gt;somepassword +client +subscribe +publish +ping +info +multi +slaveof +config +client +exec on</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">-- Replicas:副本需要在主实例上有以下命令权限</span><br><span class="line">&gt; ACL SETUSER replica-user &gt;somepassword +psync +replconf +ping on</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h4 id="保存、加载相关：save、load"><a href="#保存、加载相关：save、load" class="headerlink" title="保存、加载相关：save、load"></a>保存、加载相关：save、load</h4><p>通过 ACL 创建的用户是保存在内存里的，如果 Redis Server 重启则 ACL 创建的用户会丢失，所以在创建完用户后需要用 <strong>save</strong> 保存，在重启之后需要用 <strong>load</strong> 加载。有两种方式进行保存和加载：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1，使用ACL命令:ACL SAVE、ACL LOAD</span><br><span class="line">2，使用Redis配置，用户被定义，然后重启服务器并生效。 或者使用外部ACL文件，使用ACL LOAD 来导入ACL信息</span><br></pre></td></tr></table></figure><p><strong>注意：ACL 的配合文件需要事先手动 touch，否则实例启动会失败。</strong>在 redis.conf 里配置和 acl 文件里配置的方法互不兼容，Redis 会要求使用其中一种。 否则实例启动报错：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 报错信息</span><br><span class="line">#Configuring Redis with users defined in redis.conf and at the same setting an ACL file path is invalid. This setup is very likely to lead to configuration errors and security holes, please define either an ACL file or declare users directly in your redis.conf, but not both.</span><br></pre></td></tr></table></figure><p>在 redis.conf 中指定用户是一种非常简单的方法，适用于简单的用例。 当有多个用户要定义时，在复杂的环境中，强烈建议使用 ACL 文件。该 2 个文件里的配置内容是一致的，可以相互进行配置，如格式如下：在 redis.conf 和 users.acl 里的格式</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 配置文件</span><br><span class="line">user default on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all</span><br><span class="line">user zhoujy on #ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad ~* +@all</span><br></pre></td></tr></table></figure><p>1、保存 ACL 规则</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 保存ACL规则</span><br><span class="line">&gt; ACL SAVE</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>2、加载 ACL 规则</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 加载ACL规则</span><br><span class="line">&gt; ACL LOAD</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p><strong>说明</strong>：在使用 ACL 配置文件之后，如果设置了默认用户（default）规则的话，需要看配置文件中 aclfile 和 requirepass 参数的先后顺序，密码以最后出现的为准。</p><h4 id="日志相关"><a href="#日志相关" class="headerlink" title="日志相关"></a>日志相关</h4><p>显示最近的 ACL 安全事件列表<br>通过 ACL LOG [<count> | RESET] 返回 ACL 的日志信息，可以指定条目显示，也可以进行重置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">-- 显示日志信息</span><br><span class="line">&gt; ACL LOG 1</span><br><span class="line">1)  1) &quot;count&quot;</span><br><span class="line">    2) (integer) 1</span><br><span class="line">    3) &quot;reason&quot;</span><br><span class="line">    4) &quot;auth&quot;</span><br><span class="line">    5) &quot;context&quot;</span><br><span class="line">    6) &quot;toplevel&quot;</span><br><span class="line">    7) &quot;object&quot;</span><br><span class="line">    8) &quot;AUTH&quot;</span><br><span class="line">    9) &quot;username&quot;</span><br><span class="line">   10) &quot;zhoujy&quot;</span><br><span class="line">   11) &quot;age-seconds&quot;</span><br><span class="line">   12) &quot;282.90499999999997&quot;</span><br><span class="line">   13) &quot;client-info&quot;</span><br><span class="line">   14) &quot;id=5 addr=192.168.163.134:35246 fd=7 name= age=403 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=36 qbuf-free=32732 obl=0 oll=0 omem=0 events=r cmd=auth user=zhoujy&quot;</span><br><span class="line"></span><br><span class="line">-- 重置日志，类似slow</span><br><span class="line">&gt; acl log reset</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h2 id="场景说明"><a href="#场景说明" class="headerlink" title="场景说明"></a>场景说明</h2><p><strong>注意：</strong>以上操作完只有需要执行 ACL SAVE。不然重置之后用户信息全部都清空了。</p><ol><li><p>创建 DBA 管理账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ACL SETUSER dba on #6d0ac515af9df81653ed0aa3ffa692663c3f556079791e2f00a4578990da66f3 allkeys +@all</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li><li><p>创建读写账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ACL SETUSER readwrite on &gt;abc allkeys -@all +@read +@write</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li><li><p>创建只读账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ACL SETUSER readonly on &gt;abc allkeys -@all +@read</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li><li><p>创建只写账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ACL SETUSER write_user on &gt;abc allkeys -@all +@write</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li><li><p>创建复制账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ACL SETUSER replica-user &gt;abc -@all +psync +replconf +ping on</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li><li><p>创建哨兵账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ACL SETUSER sentinel-user &gt;abc -@all +client +subscribe +publish +ping +info +multi +slaveof +config +client +exec on</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li><li><p>创建监控账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ACL SETUSER monitor on &gt;abc +monitor</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li><li><p>创建指定 key、有指定类型权限的账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 指定对h开头的hash类型的key有权限</span><br><span class="line">&gt; ACL SETUSER ops_user on &gt;abc ~h* +@hash</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>其中 key 的模式是正则匹配，需要 <strong>~</strong> 开头，针对权限则是 hash 的类，其权限可以通过 ACL CAT hash 查看。</p></li></ol><h2 id="使用外部-ACL-文件"><a href="#使用外部-ACL-文件" class="headerlink" title="使用外部 ACL 文件"></a>使用外部 ACL 文件</h2><p>有两种方法可以将用户存储在 Redis 配置中，一种是 <code>redis.conf</code> 中配置，一种是使用一个独立的外部 acl 文件，这两种方式不兼容，只能选择一种方式。</p><p>在<code>redis.conf</code>内部指定用户是一种非常简单的方法，适用于简单的用例。当需要定义多个用户时，在复杂的环境中，我们强烈建议您使用 ACL 文件。</p><p>通常外部文件的方式更灵活，推荐使用。</p><p>配置内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user &lt;username&gt; ... acl rules ...</span><br></pre></td></tr></table></figure><p>来看一个示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99</span><br></pre></td></tr></table></figure><p>当您要使用外部 ACL 文件时，需要在 redis.conf 文件中设置 <code>aclfile</code>文件的路径，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aclfile /etc/redis/users.acl</span><br></pre></td></tr></table></figure><p>当仅在 redis.conf 文件内部直接指定几个用户时，可以使用 CONFIG REWRITE 以便通过重写将新的用户配置存储在文件中。</p><p>但是，外部 ACL 文件功能更强大。您可以执行以下操作：</p><ul><li>使用 <code>ACL LOAD</code> 重新加载外部 ACL 文件，通常在你手动修改了这个文件，希望 redis 重新加载的时候使用，需要注意的是要确保 acl 文件内容的正确性</li><li>使用 <code>ACL SAVE</code> 将当前 ACL 配置保存到一个外部文件</li></ul><div class="note success flat"><p><strong>参考文档</strong></p><p><a href="https://redis.io/topics/acl">https://redis.io/topics/acl</a></p><p><a href="https://redis.io/commands/acl-setuser">https://redis.io/commands/acl-setuser</a></p></div>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Redis高可用总结：Redis主从复制、哨兵集群、脑裂... </title>
      <link href="/2021/11/08/2021-02-10-redis-high-availability/"/>
      <url>/2021/11/08/2021-02-10-redis-high-availability/</url>
      
        <content type="html"><![CDATA[<h1 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h1><p>在实际的项目中，服务高可用非常重要，如，当Redis作为缓存服务使用时， 缓解数据库的压力，提高数据的访问速度，提高网站的性能 ，但如果使用Redis 是单机模式运行 ，只要一个服务器宕机就不可以提供服务，这样会可能造成服务效率低下，甚至出现其相对应的服务应用不可用。</p><p>因此为了实现高可用，Redis 提供了哪些高可用方案？</p><ul><li>Redis主从复制</li><li>Redis持久化</li><li>哨兵集群</li><li>…</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/1.png"></p><p>Redis基于一个Master主节点多Slave从节点的模式和Redis持久化机制，将一份数据保持在多个实例中实现增加副本冗余量，又使用哨兵机制实现主备切换， 在master故障时，自动检测，将某个slave切换为master，最终实现Redis高可用 。</p><hr><h3 id="Redis主从复制"><a href="#Redis主从复制" class="headerlink" title="Redis主从复制"></a><strong>Redis主从复制</strong></h3><p>Redis主从复制，主从库模式一个Master主节点多Slave从节点的模式，将一份数据保存在多Slave个实例中，增加副本冗余量，当某些出现宕机后，Redis服务还可以使用。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/2.png"></p><p>但是这会存在数据不一致问题，那redis的副本集是如何数据一致性？</p><p>Redis为了保证数据副本的一致，主从库之间采用读写分离的方式：</p><ul><li><strong>读操作：主库、从库都可以执行处理；</strong></li><li><strong>写操作：先在主库执行，再由主库将写操作同步给从库。</strong></li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/3.png"></p><p>使用读写分离方式的好处，可以避免当主从库都可以处理写操作时，主从库处理写操作加锁等一系列巨额的开销。</p><p>采用读写分离方式，写操作只会在主库中进行后同步到从库中，那主从库是如何同步数据的呢？</p><p>主从库是同步数据方式有两种：</p><ul><li><strong>全量同步：</strong>通常是主从服务器刚刚连接的时候，会先进行全量同步</li><li><strong>增量同步 ：</strong>一般在全同步结束后，进行增量同步，比如主从库间网络断，再进行数据同步。</li></ul><h4 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a><strong>全量同步</strong></h4><p>主从库间第一次全量同步，具体分成三个阶段：</p><ul><li>当一个从库启动时，从库给主库发送 psync 命令进行数据同步（psync 命令包含：主库的 runID 和复制进度 offset 两个参数），</li><li>当主库接收到psync 命令后将会保存RDB 文件并发送给从库，发送期间会使用缓存区（replication buffer）记录后续的所有写操作 ，从库收到数据后，会先清空当前数据库，然后加载从主库获取的RDB 文件，</li><li>当主库完成 RDB 文件发送后，也会把将保存发送RDB文件期间写操作的replication buffer发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/4.png"></p><p>另外，为了分担主库生成 RDB 文件和传输 RDB 文件压力，提高效率，可以使用 “主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/5.png"></p><h4 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a><strong>增量同步</strong></h4><p>增量同步，基于环形缓冲区repl_backlog_buffer缓存区实现。</p><p>在环形缓冲区，主库会记录自己写到的位置 master_repl_offset ，从库则会记录自己已经读到的位置slave_repl_offset, 主库并通过master_repl_offset 和 slave_repl_offset的差值的数据同步到从库。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/6.png"></p><p>主从库间网络断了， 主从库会采用增量复制的方式继续同步，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区，然后主库并通过master_repl_offset 和 slave_repl_offset的差值数据同步到从库。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/7.png"></p><p>因为repl_backlog_buffer 是一个环形缓冲区，当在缓冲区写满后，主库会继续写入，此时，会出现什么情况呢？</p><p>覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。因此需要关注 repl_backlog_size参数，调整合适的缓冲空间大小，避免数据覆盖，主从数据不一致。</p><p>主从复制，除了会出现数据不一致外，甚至可能出现主库宕机的情况，Redis会有主从自主切换机制，那如何实现的呢？</p><hr><h3 id="Redis哨兵机制"><a href="#Redis哨兵机制" class="headerlink" title="Redis哨兵机制"></a><strong>Redis哨兵机制</strong></h3><p>当主库挂了，redis写操作和数据同步无法进行，为了避免这样情况，可以在主库挂了后重新在从库中选举出一个新主库，并通知到客户端，redis提供了 哨兵机制，哨兵为运行在特殊模式下的 Redis 进程。</p><h4 id="Redis会有主从自主切换机制，那如何实现的呢？"><a href="#Redis会有主从自主切换机制，那如何实现的呢？" class="headerlink" title="Redis会有主从自主切换机制，那如何实现的呢？"></a><strong>Redis会有主从自主切换机制，那如何实现的呢？</strong></h4><p>哨兵机制是实现主从库自动切换的关键机制，其主要分为三个阶段:</p><ul><li><strong>监控：哨兵进程会周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。</strong></li><li><strong>选主（选择主库）：主库挂了以后，哨兵基于一定规则评分选选举出一个从库实例新的主库 。</strong></li><li><strong>通知 ：哨兵会将新主库的信息发送给其他从库，让它们和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的信息广播通知给客户端，让它们把请求操作发到新主库上。</strong></li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/8.png"></p><p><strong>其中，在监控中如何判断主库是否处于下线状态？</strong></p><p>哨兵对主库的下线判断分为：</p><ul><li>主观下线：<strong>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态</strong>， 如果单哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”</li><li>客观下线：在哨兵集群中，基于少数服从多数，多数实例都判定主库已“主观下线”，则认为主库“客观下线”。</li></ul><p><strong>为什么会有这两种”主观下线”和“客观下线”的下线状态呢？</strong></p><p>由于单机哨兵很容易产生误判，误判后主从切换会产生一系列的额外开销，为了减少误判，避免这些不必要的开销，采用哨兵集群，引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况，</p><p>基于少数服从多数原则， 当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线” （可以自定义设置阙值）。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/9.png"></p><p><strong>那么哨兵之间是如何互相通信的呢？</strong></p><p>哨兵集群中哨兵实例之间可以相互发现，<strong>基于 Redis 提供的发布 / 订阅机制（pub/sub 机制）</strong>,</p><p>哨兵可以在主库中发布/订阅消息，在主库上有一个名为“_<em>sentinel</em>_:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的，而且只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/10.png"></p><p>哨兵 1连接相关信息（IP端口）发布到“_<em>sentinel</em>_:hello”频道上，哨兵 2 和 3 订阅了该频道。</p><p>哨兵 2 和 3 就可以从这个频道直接获取哨兵 1连接信息，以这样的方式哨兵集群就形成了，实现各个哨兵互相通信。</p><p>哨兵集群中各个实现通信后，就可以判定主库是否已客观下线。</p><p><strong>在已判定主库已下线后，又如何选举出新的主库？</strong></p><p>新主库选举按照<strong>一定条件</strong>筛选出的符合条件的从库，并按照<strong>一定规则</strong>对其进行打分，最高分者为新主库。</p><p>通常<strong>一定条件</strong>包括：</p><ul><li>从库的当前在线状态，</li><li>判断它之前的网络连接状态，通过down-after-milliseconds * num(断开连接次数)，当断开连接次数超过阈值，不适合为新主库。</li></ul><p><strong>一定规则包括</strong></p><ul><li>从库优先级 ， 通过slave-priority 配置项，给不同的从库设置不同优先级，优先级最高的从库得分高</li><li>从库复制进度，和旧主库同步程度最接近的从库得分高，通过repl_backlog_buffer缓冲区记录主库 master_repl_offset 和从库slave_repl_offset 相差最小高分</li><li>从库 ID 号 ， ID 号小的从库得分高。</li></ul><p><strong>全都都基于在只有在一定规则中的某一轮评出最高分从库就选举结束，哨兵发起主从切换。</strong></p><h4 id="leader哨兵"><a href="#leader哨兵" class="headerlink" title="leader哨兵"></a><strong>leader哨兵</strong></h4><p><strong>选举完新的主库后，不能每个哨兵都发起主从切换，需要选举成leader哨兵，那如何选举leader哨兵执行主从切换？</strong></p><p>选举leader哨兵，也是基于少数服从多数原则”投票仲裁”选举出来，</p><ul><li>当任何一个从库判定主库“主观下线”后，发送命令 s-master-down-by-addr命令发送想要成为Leader的信号，</li><li>其他哨兵根据与主机连接情况作出相对的响应，赞成票Y，反对票N，而且如果有多个哨兵发起请求，每个哨兵的赞成票只能投给其中一个，其他只能为反对票。</li></ul><p>想要成为Leader 的哨兵，要满足两个条件：</p><ul><li>第一，获得半数以上的赞成票；</li><li>第二，获得的票数同时还需要大于等于哨兵配置文件中的quorum值。</li></ul><p><strong>选举完leader哨兵并新主库切换完毕之后，那么leader哨兵怎么通知客户端？</strong></p><p>还是基于哨兵自身的 pub/sub 功能，实现了客户端和哨兵之间的事件通知，客户端订阅哨兵自身消息频道 ，而且哨兵提供的消息订阅频道有很多，不同频道包含了：</p><table><thead><tr><th>事件</th><th>相关频道</th></tr></thead><tbody><tr><td>主库下线事件</td><td>+sdown（实例进入“主观下线”状态） -sdown（实例退出“主观下线”状态） +odown（实例进入“客观下线”状态） -odown（实例退出“客观下线”状态）</td></tr><tr><td>新主库切换</td><td>+ switch-master（主库地址发生变化）</td></tr></tbody></table><p>其中，当客户端从哨兵订阅消息主从库切换，当主库切换后，端户端就会接收到新主库的连接信息：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">switch-master &lt;master name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt;</span><br></pre></td></tr></table></figure><p>在这样的方式哨兵就可以通知客户端切换了新库。</p><p>基于上述的机制和原理Redis实现了高可用，但也会带了一些潜在的风险，比如数据缺失。</p><hr><h3 id="数据问题"><a href="#数据问题" class="headerlink" title="数据问题"></a><strong>数据问题</strong></h3><p>Redis实现高可用，但实现期间可能产出一些风险：</p><ul><li><strong>主备切换的过程， 异步复制导致的数据丢失</strong></li><li><strong>脑裂导致的数据丢失</strong></li><li><strong>主备切换的过程，异步复制导致数据不一致</strong></li></ul><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h4 id="数据丢失-主从异步复制"><a href="#数据丢失-主从异步复制" class="headerlink" title="数据丢失-主从异步复制"></a><strong>数据丢失-主从异步复制</strong></h4><p>因为master 将数据复制给slave是异步实现的，在复制过程中，这可能存在master有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了。</p><p><strong>总结：主库的数据还没有同步到从库，结果主库发生了故障，未同步的数据就丢失了。</strong></p><h4 id="数据丢失-脑裂"><a href="#数据丢失-脑裂" class="headerlink" title="数据丢失-脑裂"></a><strong>数据丢失-脑裂</strong></h4><p>何为脑裂？当一个集群中的 master 恰好网络故障，导致与 sentinal 通信不上了，sentinal会认为master下线，且sentinal选举出一个slave 作为新的 master，此时就存在两个 master了。</p><p>此时，可能存在client还没来得及切换到新的master，还继续写向旧master的数据，当master再次恢复的时候，会被作为一个slave挂到新的master 上去，自己的数据将会清空，重新从新的master 复制数据，这样就会导致数据缺失。</p><p><strong>总结：主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。</strong></p><h4 id="数据丢失解决方案"><a href="#数据丢失解决方案" class="headerlink" title="数据丢失解决方案"></a><strong>数据丢失解决方案</strong></h4><p>数据丢失可以通过合理地配置参数 min-slaves-to-write 和 min-slaves-max-lag 解决，比如</p><ul><li>min-slaves-to-write 1</li><li>min-slaves-max-lag 10</li></ul><p>如上两个配置：要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒，如果超过 1 个 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。</p><h4 id="数据不一致"><a href="#数据不一致" class="headerlink" title="数据不一致"></a><strong>数据不一致</strong></h4><p>在主从异步复制过程，当从库因为网络延迟或执行复杂度高命令阻塞导致滞后执行同步命令，这样就会导致数据不一致</p><p><strong>解决方案：可以开发一个外部程序来监控主从库间的复制进度（master_repl_offset 和 slave_repl_offset ），通过监控 master_repl_offset 与slave_repl_offset差值得知复制进度，当复制进度不符合预期设置的Client不再从该从库读取数据。</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/11.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>Redis使用主从复制、持久化、哨兵机制等实现高可用，需要理解其实现过程，也要明白其带了风险以及解决方案，才能在实际项目更好优化，提升系统的可靠性、稳定性。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 利用Github Action实现Github到Gitee的持续同步 </title>
      <link href="/2021/08/17/2021-08-17-github-to-gitee/"/>
      <url>/2021/08/17/2021-08-17-github-to-gitee/</url>
      
        <content type="html"><![CDATA[<div class="note success flat"><p>文章转载</p><p>作者：SSgeek</p><p>链接：<a href="https://mp.weixin.qq.com/s/9IvYUurEqw9JU1UR714Yow">https://mp.weixin.qq.com/s/9IvYUurEqw9JU1UR714Yow</a></p><p>来源：仙人技术</p></div><h3 id="1、什么是Github-Action"><a href="#1、什么是Github-Action" class="headerlink" title="1、什么是Github Action"></a>1、什么是Github Action</h3><p><code>github action</code>是<code>github</code>推出的自动化<code>CI/CD</code>的功能，随着<code>2019</code>年<code>11</code>月后<code>github</code>对该功能的全面开放，现在所有的<code>github</code>用户可以直接使用该功能</p><p><code>github action</code>的语法类似于<code>gitlab ci</code>，与之相比，还有更多优势，例如：</p><ul><li><code>action</code>对<code>github</code>各个事件的支持更为全面，如<code>release</code>、<code>pull-request</code>、<code>issue</code>事件等等</li><li><code>action</code>支持直接使用别人编写好的<code>action</code></li><li><code>action</code>的执行器类似于<code>gitlab runner</code>，可以使用<code>github</code>托管的执行器，也可以托管自己的执行器。甚至在<code>action</code>运行的时候，还可以通过某些特殊技巧进入到执行器里面，相当于一台临时的服务器供我们使用</li></ul><p>更多这里不再介绍，感兴趣的小伙伴可以自行搜索</p><h3 id="2、github-和-gitee-同步"><a href="#2、github-和-gitee-同步" class="headerlink" title="2、github 和 gitee 同步"></a>2、github 和 gitee 同步</h3><p><code>github</code>的服务器在国外，因为某些原因，在大多数的网络环境下都是无法顺畅访问的</p><p><code>gitee</code>的服务器在国内，由国内公司运营</p><p>纵使如此，大多数开发者还是习惯使用<code>github</code>（远在海外，也要想尽各种办法）</p><p>那么为什么需要把<code>github</code>和<code>gitee</code>的仓库进行同步呢？原因不言而喻</p><p>目前可用的进行同步的方法可能有：</p><ul><li><p>利用<code>gitee</code>官方的同步（导入<code>github</code>项目），这种方法只能一次性导入</p></li><li><p>本地同时关联<code>gitee</code>和<code>github</code>，提交时都<code>push</code>一份，这种方法纯属手动</p></li><li><p>利用<code>github action</code></p></li></ul><p>下面介绍利用<code>github action</code>如何实现<code>github</code>到<code>gitee</code>的持续同步</p><h2 id="3、选用或编写-action"><a href="#3、选用或编写-action" class="headerlink" title="3、选用或编写 action"></a>3、选用或编写 action</h2><p>实现<code>github</code>和<code>gitee</code>同步的思路主要是基于我们的账户调用<code>github</code>和<code>gitee</code>各自的<code>api</code>接口和密钥通信，在执行器内拉取并推送代码库到<code>gitee</code></p><p><code>action</code>的编写语法和<code>gitlab ci</code>很相似，同时<code>github</code>还推出了官方的<code>action</code>市场，地址为 <a href="https://github.com/marketplace">https://github.com/marketplace</a></p><p>这里我们使用的<code>action</code>是<a href="https://github.com/marketplace/actions/hub-mirror-action">Yikun/hub-mirror-action</a></p><h2 id="4、准备5-1-设置-dst-key"><a href="#4、准备5-1-设置-dst-key" class="headerlink" title="4、准备5.1 设置 dst_key"></a>4、准备5.1 设置 dst_key</h2><p>在<code>github</code>上打开一个自己的仓库，这里以我的个人公开仓库为例</p><p>首先在本地生成一个<code>ssh</code>密钥对工作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh-keygen -t rsa -f ~/Documents/ssh-key/id_rsa</span></span><br></pre></td></tr></table></figure><p>在<code>github</code>打开<code>settings</code>—&gt;<code>secrets</code>，新建一个<code>secret</code>，名为<code>GITEE_PRIVATE_KEY</code>，值为上面生成的密钥对的私钥</p><p>然后登录到<code>gitee</code>，在个人设置—&gt;安全设置—&gt;<code>SSH</code>公钥中添加上面生成的密钥对的公钥，命名随意</p><h3 id="5-2-设置-dst-token"><a href="#5-2-设置-dst-token" class="headerlink" title="5.2 设置 dst_token"></a>5.2 设置 dst_token</h3><p>在<code>gitee</code>打开个人设置—&gt;安全设置—&gt;私人令牌，新建一个私人令牌，命名随意，复制生成的令牌值</p><p>在<code>github</code>打开<code>settings</code>—&gt;<code>secrets</code>，新建一个<code>secret</code>，名为<code>GITEE_TOKEN</code>，值为上面复制的令牌值</p><h2 id="6、github-同步到-gitee"><a href="#6、github-同步到-gitee" class="headerlink" title="6、github 同步到 gitee"></a>6、github 同步到 gitee</h2><p>在刚才的<code>GitHub</code>仓库中，新建 <code>.github/workflows/SyncToGitee.yml</code> 文件，<strong>其中<code>.github/workflows/</code>是固定的目录名</strong></p><p>内容如下</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Sync</span> <span class="string">Github</span> <span class="string">Repos</span> <span class="string">To</span> <span class="string">Gitee</span></span><br><span class="line"></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="attr">branches:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">build:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-20.04</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line"></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Sync</span> <span class="string">Github</span> <span class="string">Repos</span> <span class="string">To</span> <span class="string">Gitee</span>  <span class="comment"># 名字随便起</span></span><br><span class="line">      <span class="attr">uses:</span> <span class="string">Yikun/hub-mirror-action@v1.1</span>  <span class="comment"># 使用Yikun/hub-mirror-action</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">src:</span> <span class="string">github/like-ycy</span>  <span class="comment"># 源端账户名(github)</span></span><br><span class="line">        <span class="attr">dst:</span> <span class="string">gitee/like-ycy</span>  <span class="comment"># 目的端账户名(gitee)</span></span><br><span class="line">        <span class="attr">dst_key:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.GITEE_PRIVATE_KEY</span> <span class="string">&#125;&#125;</span>  <span class="comment"># SSH密钥对中的私钥</span></span><br><span class="line">        <span class="attr">dst_token:</span>  <span class="string">$&#123;&#123;</span> <span class="string">secrets.GITEE_TOKEN</span> <span class="string">&#125;&#125;</span>  <span class="comment"># Gitee账户的私人令牌</span></span><br><span class="line">        <span class="attr">account_type:</span> <span class="string">user</span>  <span class="comment"># 账户类型</span></span><br><span class="line">        <span class="attr">clone_style:</span> <span class="string">&quot;https&quot;</span>  <span class="comment"># 使用https方式进行clone，也可以使用ssh</span></span><br><span class="line">        <span class="attr">debug:</span> <span class="literal">true</span>  <span class="comment"># 启用后会显示所有执行命令</span></span><br><span class="line">        <span class="attr">force_update:</span> <span class="literal">true</span>  <span class="comment"># 启用后，强制同步，即强制覆盖目的端仓库</span></span><br><span class="line">        <span class="attr">static_list:</span> <span class="string">&quot;Linux-Commands&quot;</span>  <span class="comment"># 静态同步列表，在此填写需要同步的仓库名称，可填写多个</span></span><br><span class="line">        <span class="attr">timeout:</span> <span class="string">&#x27;600s&#x27;</span>  <span class="comment"># git超时设置，超时后会自动重试git操作</span></span><br></pre></td></tr></table></figure><p>提交该<code>action</code>，观察<code>github</code>上的执行视图</p><p>执行完毕后</p><p>此时打开<code>gitee</code>，就会发现自动创建了同名称的仓库且自动提交了同样的代码</p>]]></content>
      
      
      
        <tags>
            
            <tag> Github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 一文搞清楚，QPS、TPS、并发用户数、吞吐量 </title>
      <link href="/2021/06/30/2021-06-30-pv-uv/"/>
      <url>/2021/06/30/2021-06-30-pv-uv/</url>
      
        <content type="html"><![CDATA[<div class="note success flat"><p>文章转载</p><p>作者：Fysddsw_lc<br>链接：<a href="https://juejin.cn/post/6844904084504313863">https://juejin.cn/post/6844904084504313863</a><br>来源：掘金</p></div><h3 id="QPS"><a href="#QPS" class="headerlink" title="QPS"></a>QPS</h3><p><strong>QPS</strong> <code>Queries Per Second</code> 是每秒查询率 ,是<strong>一台服务器</strong>每秒能够相应的查询次数，是对一个特定的查询服务器<strong>在规定时间内</strong>所处理流量多少的衡量标准, 即每秒的响应请求数，也即是最大吞吐能力。</p><h3 id="TPS"><a href="#TPS" class="headerlink" title="TPS"></a>TPS</h3><p><strong>TPS</strong> <code>Transactions Per Second</code> 也就是事务数/秒。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，</p><p><strong>QPS和TPS区别</strong></p><p>个人理解如下：</p><p>1、Tps即每秒处理事务数，包括了</p><p>1）用户请求服务器 2）服务器自己的内部处理 3）服务器返回给用户</p><p>这三个过程，每秒能够完成N个这三个过程，Tps也就是N；</p><p>2、Qps基本类似于Tps，但是不同的是，对于一个页面的一次访问，形成一个Tps；但一次页面请求，可能产生多次对服务器的请求，服务器对这些请求，就可计入“Qps”之中。</p><p><strong>例子</strong></p><p>例如：访问一个页面会请求服务器3次，一次放，产生一个“T”，产生3个“Q”</p><p>例如：一个大胃王一秒能吃10个包子，一个女孩子0.1秒能吃1个包子，那么他们是不是一样的呢？答案是否定的，因为这个女孩子不可能在一秒钟吃下10个包子，她可能要吃很久。这个时候这个大胃王就相当于TPS，而这个女孩子则是QPS。虽然很相似，但其实是不同的。</p><h3 id="并发数"><a href="#并发数" class="headerlink" title="并发数"></a>并发数</h3><p>并发数（并发度）：指系统同时能处理的请求数量，同样反应了系统的负载能力。这个数值可以分析机器1s内的访问日志数量来得到</p><h3 id="吐吞量"><a href="#吐吞量" class="headerlink" title="吐吞量"></a>吐吞量</h3><p><strong>吐吞量</strong>：吞吐量是指系统在单位时间内处理请求的数量，TPS、QPS都是吞吐量的常用量化指标</p><p><strong>系统吞吐量要素</strong></p><p>一个系统的吞吐量（承压能力）与request（请求）对cpu的消耗，外部接口，IO等等紧密关联。</p><p>单个request 对cpu消耗越高，外部系统接口，IO影响速度越慢，系统吞吐能力越低，反之越高。</p><p><strong>重要参数</strong></p><p>QPS(TPS),并发数，响应时间</p><ol><li>QPS(TPS):每秒钟request/事务 数量</li><li>并发数：系统同时处理的request/事务数</li><li>响应时间：一般取平均响应时间</li></ol><p><strong>关系</strong></p><p>QPS(TPS)=并发数/平均响应时间</p><p>一个系统吞吐量通常有QPS(TPS),并发数两个因素决定，每套系统这个两个值都有一个相对极限值，在应用场景访问压力下，只要某一项达到系统最高值，系统吞吐量就上不去了，如果压力继续增大，系统的吞吐量反而会下降，原因是系统超负荷工作，上下文切换，内存等等其他消耗导致系统性能下降。</p><h3 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h3><p><strong>PV</strong>（Page View）：页面访问量，即页面浏览量或点击量，用户每次刷新即被计算一次。可以统计服务一天的访问日志得到。</p><h3 id="UV"><a href="#UV" class="headerlink" title="UV"></a>UV</h3><p><strong>UV</strong>（Unique Visitor）：独立访客，统计1天内访问某站点的用户数。可以统计服务一天的访问日志并根据用户的唯一标识去重得到。 响应时间（RT）：响应时间是指系统对请求作出响应的时间，一般取平均响应时间。可以通过Nginx、Apache之类的Web Server得到。</p><h3 id="DAU"><a href="#DAU" class="headerlink" title="DAU"></a>DAU</h3><p><strong>DAU</strong>(Daily Active User)，日活跃用户数量。常用于反映网站、互联网应用或网络游戏的运营情况。DAU通常统计一日（统计日）之内，登录或使用了某个产品的用户数（去除重复登录的用户），与UV概念相似</p><h3 id="MAU"><a href="#MAU" class="headerlink" title="MAU"></a>MAU</h3><p><strong>MAU</strong>(Month Active User)：月活跃用户数量，指网站、app等去重后的月活跃用户数量</p><h2 id="系统吞吐量评估"><a href="#系统吞吐量评估" class="headerlink" title="系统吞吐量评估"></a>系统吞吐量评估</h2><p>我们在做系统设计的时候就需要考虑CPU运算，IO，外部系统响应因素造成的影响以及对系统性能的初步预估。</p><p>而通常情况下，我们面对需求，我们评估出来的出来QPS，并发数之外，还有另外一个维度：日pv。</p><p>通过观察系统的访问日志发现，在用户量很大的情况下，各个时间周期内的同一时间段的访问流量几乎一样。比如工作日的每天早上。只要能拿到日流量图和QPS我们就可以推算日流量。</p><p>通常的技术方法：</p><p>​        \1. 找出系统的最高TPS和日PV，这两个要素有相对比较稳定的关系（除了放假、季节性因素影响之外）</p><p>​        \2. 通过压力测试或者经验预估，得出最高TPS，然后跟进1的关系，计算出系统最高的日吞吐量。B2B中文和淘宝面对的客户群不一样，这两个客户群的网络行为不应用，他们之间的TPS和PV关系比例也不一样。</p><h2 id="软件性能测试的基本概念和计算公式"><a href="#软件性能测试的基本概念和计算公式" class="headerlink" title="软件性能测试的基本概念和计算公式"></a>软件性能测试的基本概念和计算公式</h2><h3 id="软件性能的关注点"><a href="#软件性能的关注点" class="headerlink" title="软件性能的关注点"></a>软件性能的关注点</h3><p>软件做性能测试时需要关注哪些性能呢</p><p>首先，开发软件的目的是为了让用户使用，我们先站在用户的角度分析一下，用户需要关注哪些性能。</p><p>对于用户来说，当点击一个按钮、链接或发出一条指令开始，到系统把结果已用户感知的形式展现出来为止，这个过程所消耗的时间是用户对这个软件性能的直观印 象。也就是我们所说的响应时间，当相应时间较小时，用户体验是很好的，当然用户体验的响应时间包括个人主观因素和客观响应时间，在设计软件时，我们就需要 考虑到如何更好地结合这两部分达到用户最佳的体验。如：用户在大数据量查询时，我们可以将先提取出来的数据展示给用户，在用户看的过程中继续进行数据检 索，这时用户并不知道我们后台在做什么。</p><p>用户关注的是用户操作的相应时间。</p><p><strong>其次，我们站在管理员的角度考虑需要关注的性能点。</strong></p><p>1、 响应时间<br>2、 服务器资源使用情况是否合理<br>3、 应用服务器和数据库资源使用是否合理<br>4、 系统能否实现扩展<br>5、 系统最多支持多少用户访问、系统最大业务处理量是多少<br>6、 系统性能可能存在的瓶颈在哪里<br>7、 更换那些设备可以提高性能<br>8、 系统能否支持7×24小时的业务访问</p><p><strong>再次，站在开发（设计）人员角度去考虑。</strong></p><p>1、 架构设计是否合理<br>2、 数据库设计是否合理<br>3、 代码是否存在性能方面的问题<br>4、 系统中是否有不合理的内存使用方式<br>5、 系统中是否存在不合理的线程同步方式<br>6、 系统中是否存在不合理的资源竞争</p>]]></content>
      
      
      
        <tags>
            
            <tag> 并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> DNS基础知识 </title>
      <link href="/2021/06/01/2021-06-01-dns-basic-knowledge/"/>
      <url>/2021/06/01/2021-06-01-dns-basic-knowledge/</url>
      
        <content type="html"><![CDATA[<div class="note success flat"><p>文章转载</p><p>作者：多米诺<br>链接：<a href="https://juejin.cn/post/6844903497494855687">https://juejin.cn/post/6844903497494855687</a></p></div><h2 id="DNS-基础知识"><a href="#DNS-基础知识" class="headerlink" title="DNS 基础知识"></a>DNS 基础知识</h2><p>DNS（Domain Name System）， 也叫网域名称系统，是互联网的一项服务。它实质上是一个 域名 和 IP 相互映射的分布式数据库，有了它，我们就可以通过域名更方便的访问互联网。</p><p>DNS 有以下特点：</p><ul><li>分布式的</li><li>协议支持 TCP 和 UDP，常用端口是 53</li><li>每一级域名的长度限制是 63</li><li>域名总长度限制是 253</li></ul><p><strong>那么，什么情况下使用 TCP，什么情况下使用 UDP 呢?</strong></p><p>最早的时候，DNS 的 UDP 报文上限大小是 512 字节， 所以当某个 response 大小超过512 (返回信息太多)，DNS 服务就会使用 TCP 协议来传输。后来 DNS 协议扩展了自己的UDP 协议，DNS client 发出查询请求时，可以指定自己能接收超过512字节的 UDP 包， 这种情况下，DNS 还是会使用 UDP 协议。</p><h3 id="分层的数据库结构"><a href="#分层的数据库结构" class="headerlink" title="分层的数据库结构"></a>分层的数据库结构</h3><p>DNS 的结构跟 Linux 文件系统很相似，像一棵倒立的树。下面用站长之家的域名举例：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/1.webp"></p><p>最上面的.是根域名，接着是顶级域名com，再下来是站长之家域名 chinaz 依次类推。使用域名时，从下而上。s.tool.chinaz.com. 就是一个完整的域名，<a href="http://www.chinaz.com/">www.chinaz.com</a>. 也是。</p><p>之所以设计这样复杂的树形结构， 是为了防止名称冲突。这样一棵树结构，当然可以存储在一台机器上，但现实世界中完整的域名非常多，并且每天都在新增、删除大量的域名，存在一台机器上，对单机器的存储性能就是不小的挑战。另外，集中管理还有一个缺点就是管理不够灵活。可以想象一下，每次新增、删除域名都需要向中央数据库申请是多么麻烦。所以现实中的 DNS 都是分布式存储的。</p><p>根域名服务器只管理顶级域，同时把每个顶级域的管理委派给各个顶级域，所以当你想要申请com下的二级域名时，找 com 域名注册中心就好了。例如你申请了上图的 chinaz.com 二级域名，chinaz.com 再向下的域名就归你管理了。当你管理 chinaz.com 的子域名时，你可以搭建自己的 nameserver，在 .com 注册中心把 chinaz.com 的管理权委派给自己搭建的nameserver。自建nameserver 和不自建的结构图如下:</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/2.webp"></p><p>一般情况下，能不自建就不要自建，因为维护一个高可用的 DNS 也并非容易。据我所知，有两种情况需要搭建自己的 nameserver：</p><ol><li>搭建对内的 DNS。公司内部机器众多，通过 IP 相互访问太过凌乱，这时可以搭建对内的 nameserver，允许内部服务器通过域名互通</li><li>公司对域名厂商提供的 nameserver 性能不满意。虽然顶级域名注册商都有自己的nameserver，但注册商提供的 nameserver 并不专业，在性能和稳定性上无法满足企业需求，这时就需要企业搭建自己的高性能 nameserver，比如增加智能解析功能，让不同地域的用户访问最近的 IP，以此来提高服务质量</li></ol><p>概括一下 DNS 的分布式管理， 当把一个域委派给一个nameserver后，这个域下的管理权都交由此nameserver处理。这种设计一方面解决了存储压力，另一方面提高了域名管理的灵活性 (这种结构像极了Linux File System, 可以把任何一个子目录挂载到另一个磁盘，还可以把它下面的子目录继续挂载出去)</p><h3 id="顶级域名"><a href="#顶级域名" class="headerlink" title="顶级域名"></a>顶级域名</h3><p>像 com 这样的顶级域名，由 ICANN 严格控制，是不允许随便创建的。顶级域名分两类:</p><ul><li>通用顶级域名</li><li>国家顶级域名</li></ul><p>通用顶级域名常见的如.com、.org、.edu等， 国家顶级域名如我国的.cn， 美国的.us。一般公司申请公网域名时，如果是跨国产品，应该选择通用顶级域名；如果没有跨国业务，看自己喜好（可以对比各家顶级域的服务、稳定性等再做选择）。这里说一下几个比较热门的顶级域，完整的顶级域参见维基百科。</p><p><strong>me</strong><br>me顶级域其实是国家域名， 是黑山共和国的国家域名，只不过它对个人开发申请，所以很多个人博主就用它作为自己的博客域名</p><p><strong>io</strong><br>很多开源项目常用io做顶级域名，它也是国家域名。因为io 与计算机中的 input/output 缩写相同，和计算机二机制10也很像，给人一种geek的感觉。相较于.com域名，.io下的资源很多，更多选择。</p><h2 id="DNS-解析流程"><a href="#DNS-解析流程" class="headerlink" title="DNS 解析流程"></a>DNS 解析流程</h2><p>聊完了 DNS 的基本概念，我们再来聊一聊 DNS 的解析流程。当我们通过浏览器或者应用程序访问互联网时，都会先执行一遍 DNS 解析流程。标准 glibc 提供了 libresolv.so.2 动态库，我们的应用程序就是用它进行域名解析（也叫 resolving）的， 它还提供了一个配置文件<code>/etc/nsswitch.conf</code> 来控制 resolving 行为，配置文件中最关键的是这行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hosts:      files dns myhostname</span><br></pre></td></tr></table></figure><p>它决定了 resolving 的顺序，默认是先查找 hosts 文件，如果没有匹配到，再进行 DNS 解析。默认的解析流程如下图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/3.webp"></p><p>上图主要描述了 client 端的解析流程，我们可以看到最主要的是第四步请求本地 DNS 服务器去执行 resolving，它会根据本地 DNS 服务器配置，发送解析请求到递归解析服务器（稍后介绍什么是递归解析服务器)， 本地 DNS 服务器在 /etc/resolv.conf 中配置。下面我们再来看看服务端的 resolving 流程：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/4.webp"></p><p>我们分析一下解析流程：</p><ol><li><p>客户端向本地DNS服务器(递归解析服务器) 发出解析tool.chinaz.com域名的请求</p></li><li><p>本地dns服务器查看缓存，是否有缓存过tool.chinaz.com域名，如果有直接返回给客户端；</p><p>如果没有执行下一步</p></li><li><p>本地dns服务器向根域名服务器发送请求，查询com顶级域的nameserver 地址</p></li><li><p>拿到com域名的IP后，再向com nameserver发送请求，获取chinaz域名的nameserver地址</p></li><li><p>继续请求 chinaz 的nameserver，获取 tool 域名的地址，最终得到了tool.chinaz.com 的 IP，本地 dns 服务器把这个结果缓存起来，以供下次查询快速返回</p></li><li><p>本地dns服务器把把结果返回给客户端</p></li></ol><p><strong>递归解析服务器 vs 权威域名服务器</strong></p><p>我们在解析流程中发现两类 DNS 服务器，客户端直接访问的是递归解析服务器， 它在整个解析过程中也最忙。它的查询步骤是递归的，从根域名服务器开始，一直询问到目标域名。</p><p>递归解析服务器通过请求一级一级的权威域名服务器，获得下一目标的地址，直到找到目标域名的权威域名服务器</p><p>简单来说：递归解析服务器是负责解析域名的，权威域名服务器是负责存储域名记录的</p><p>递归解析服务器一般由 ISP 提供，除此之外也有一些比较出名的公共递归解析服务器， 如谷歌的 8.8.8.8，联通的 114，BAT 也都有推出公共递归解析服务器，但性能最好的应该还是你的ISP提供的，只是可能会有 DNS劫持的问题</p><p><strong>缓存</strong></p><p>由于整个解析过程非常复杂，所以 DNS 通过缓存技术来实现服务的鲁棒性。当递归nameserver 解析过 tool.chianaz.com 域名后，再次收到 tool.chinaz.com 查询时，它不会再走一遍递归解析流程，而是把上一次解析结果的缓存直接返回。并且它是分级缓存的，也就是说，当下次收到的是 <a href="http://www.chinaz.com/">www.chinaz.com</a> 的查询时， 由于这台递归解析服务器已经知道 chinaz.com 的权威 nameserver，所以它只需要再向 chinaz.com nameserver 发送一个查询 www 的请求就可以了。</p><p>根域名服务器递归解析服务器是怎么知道根域名服务器的地址的呢？根域名服务器的地址是固定的，目前全球有13个根域名解析服务器，这13条记录持久化在递归解析服务器中：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/5.webp"></p><p>为什么只有 13 个根域名服务器呢，不是应该越多越好来做负载均衡吗？之前说过 DNS 协议使用了 UDP 查询， 由于 UDP 查询中能保证性能的最大长度是 512 字节，要让所有根域名服务器数据能包含在512字节的UDP包中， 根服务器只能限制在13个， 而且每个服务器要使用字母表中单字母名。</p><p><strong>智能解析</strong></p><p>智能解析，就是当一个域名对应多个 IP 时，当你查询这个域名的 IP，会返回离你最近的 IP。</p><p>由于国内不同运营商之间的带宽很低，所以电信用户访问联通的IP就是一个灾难，而智能 DNS 解析就能解决这个问题。</p><p>智能解析依赖 EDNS 协议，这是 google 起草的 DNS 扩展协议， 修改比较简单，就是在 DNS 包里面添加 origin client IP, 这样 nameserver 就能根据 client IP 返回距离 client 比较近的 server IP 了</p><p>国内最新支持 EDNS 的就是 DNSPod 了，DNSPod 是国内比较流行的域名解析厂商，很多公司会把域名利用DNSPod 加速， 它已经被鹅厂收购</p><h2 id="域名注册商"><a href="#域名注册商" class="headerlink" title="域名注册商"></a>域名注册商</h2><p>一般我们要注册域名，都要需要找域名注册商，比如说我想注册 hello.com，那么我需要找com域名注册商注册hello域名。com的域名注册商不止一家， 这些域名注册商也是从ICANN 拿到的注册权， [参见如何申请成为.com域名注册商](<a href="https://www.zhihu.com/question/19578540">GitHub (zhihu.com)</a>)</p><p>那么，域名注册商 和 权威域名解析服务器  有什么关系呢？</p><p>域名注册商都会自建权威域名解析服务器，比如你在狗爹上申请一个.com下的二级域名，你并不需要搭建nameserver， 直接在godaddy控制中心里管理你的域名指向就可以了， 原因就是你新域名的权威域名服务器默认由域名注册商提供。当然你也可以更换，比如从godaddy申请的境外域名，把权威域名服务器改成DNSPod，一方面加快国内解析速度，另一方面还能享受DNSPod 提供的智能解析功能</p><h2 id="用-bind-搭建域名解析服务器"><a href="#用-bind-搭建域名解析服务器" class="headerlink" title="用 bind 搭建域名解析服务器"></a>用 bind 搭建域名解析服务器</h2><p>由于网上介绍bind搭建的文章实在太多了，我就不再赘述了， 喜欢动手的朋友可以网上搜一搜搭建教程，一步步搭建一个本地的nameserver 玩一玩。这里主要介绍一下bind 的配置文件吧</p><p>bind 的配置文件分两部分: bind配置文件 和 zone配置文件</p><h3 id="bind-配置文件"><a href="#bind-配置文件" class="headerlink" title="bind 配置文件"></a>bind 配置文件</h3><p>bind 配置文件位于 <code>/etc/named.conf</code>，它主要负责 bind 功能配置，如 zone 路径、日志、安全、主从等配置</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/6.webp"></p><p>其中最主要的是添加zone的配置以及指定zone配置文件。recursion 开启递归解析功能， 这个如果是no， 那么此bind服务只能做权威解析服务，当你的bind服务对外时，打开它会有安全风险，如果防御不当，会让你的nameserver 被hacker 用来做肉鸡</p><h3 id="zone-配置文件"><a href="#zone-配置文件" class="headerlink" title="zone 配置文件"></a>zone 配置文件</h3><p>zone 的配置文件在 bind 配置文件中指定，下图是一份简单的 zone 配置：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/7.webp"></p><p>zone的配置是 nameserver 的核心配置， 它指定了 DNS 资源记录，如 SOA、A、CNAME、AAAA 等记录，各种记录的概念网上资料太多，我这里就不重复了。其中主要讲一下 SOA 和 CNAME 的作用。</p><p><strong>SOA记录</strong></p><p>SOA 记录表示此域名的权威解析服务器地址。上文讲了权威解析服务器和递归解析服务器的差别， 当所有递归解析服务器中有没你域名解析的缓存时，它们就会回源来请求此域名的SOA记录，也叫权威解析记录</p><p><strong>CNAME</strong></p><p>CNAME 的概念很像别名，它的处理逻辑也如此。一个server 执行resloving 时，发现 name 是一个 CNAME， 它会转而查询这个 CNAME 的A记录。一般来说，能使用CNAME的地方都可以用A记录代替， 那么为什么还要发明 CNAME 这样一个东西呢？它是让多个域名指向同一个 IP 的一种快捷手段， 这样当最低层的 CNAME 对应的IP换了之后，上层的 CNAME 不用做任何改动。就像我们代码中的硬编码，我们总会去掉这些硬编码，用一个变量来表示，这样当这个变量变化时，我们只需要修改一处</p><p>配置完之后可以用 <code>named-checkconf</code> 和 <code>named-checkzone</code> 两个命令来check我们的配置文件有没有问题， 之后就可以启动 bind 服务了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$&gt; service named start</span><br><span class="line">Redirecting to /bin/systemctl restart  named.service</span><br></pre></td></tr></table></figure><p>我们用 <code>netstat -ntlp</code> 来检查一下服务是否启动:</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/8.webp"></p><p>53 端口已启动，那么我们测试一下效果， 用 dig 解析一下 <a href="http://www.hello.com/">www.hello.com</a> 域名，使用127.0.0.1 作为递归解析服务器</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/9.webp"></p><p>我们看到 dig 的结果跟我们配置文件中配置的一样是 1.2.3.4，DNS 完成了它的使命，根据域名获取到 IP，但我们这里用来做示范的IP明显是个假IP。</p><h3 id="用-DNS-实现负载均衡"><a href="#用-DNS-实现负载均衡" class="headerlink" title="用 DNS 实现负载均衡"></a>用 DNS 实现负载均衡</h3><p>一个域名添加多条A记录，解析时使用轮询的方式返回随机一条，流量将会均匀分类到多个A记录。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">www     IN      A       1.2.3.4</span><br><span class="line">www     IN      A       1.2.3.5</span><br></pre></td></tr></table></figure><p>复制代码上面的配置中，我们给 www 域添加了两条A记录， 这种做法叫 multi-homed hosts， 它的效果是：当我们请求 nameserver 解析 <a href="http://www.hello.com/">www.hello.com</a> 域名时，返回的IP会在两个IP中轮转（默认行为，有些智能解析 DNS 会根据 IP 判断距离，返回一个离client近的IP）。</p><p>其实每次DNS解析请求时，nameserver都会返回全部IP，如上面配置，它会把1.2.3.4 和1.2.3.5 都返回给client端。那么它是怎么实现RR的呢？nameserver 只是每次返回的IP排序不同，客户端会把response里的第一个IP用来发请求。</p><p><strong>DNS负载均衡 vs LVS专业负载均衡</strong></p><p>和 LVS 这种专业负载均衡工具相比，在DNS层做负载均衡有以下特点:</p><ol><li>实现非常简单</li><li>默认只能通过RR方式调度</li><li>DNS 对后端服务不具备健康检查</li><li>DNS 故障恢复时间比较长（DNS 服务之间有缓存）</li><li>可负载的 rs 数量有限（受 DNS response 包大小限制)</li></ol><p>真实场景中，还需要根据需求选择相应的负载均衡策略</p><h3 id="子域授权"><a href="#子域授权" class="headerlink" title="子域授权"></a>子域授权</h3><p>我们从 .com 域下申请一个二级域名 hello.com 后， 发展到某一天我们的公司扩大了，需要拆分两个事业部A和B， 并且公司给他们都分配了三级域名  a.hello.com 和 b.hello.com， 域名结构如下图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/10.webp"></p><p>再发展一段时间，A部门和B部门内部业务太多，需要频繁的为新产品申请域名， 这个时候他们就想搭建自己的 namserver，并且需要上一级把相应的域名管理权交给自己，他们期望的结构如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/11.webp"></p><p>注意第一阶段和第二阶段的区别：第一阶段，A 部门想申请 a.hello.com 下的子域名，需要向上级申请，整个 a.hello.com 域的管理都在总公司；第二阶段，A 部门先自己搭建 nameserver，然后总公司把 a.hello.com 域管理权转交给自建的 nameserver， 这个转交管理权的行为，就叫子域授权</p><p>子域授权分两部操作:</p><ol><li>A部门自建 nameserver，并且在 zone 配置文件中指定 a.hello.com 的权威解析服务器为自己的 nameserver 地址</li><li>总公司在 nameserver 上增加一条 NS 记录， 把 a.hello.com 域授权给 A 部门的 nameserver</li></ol><p>第一步我们在用 bind 搭建域名解析服务器里讲过， 只要在 zone 配置文件里指定SOA记录就好:</p><p>-</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@       IN     SOA      ns.a.hello.com    admin.a.hello.com. (……)复制代码</span><br></pre></td></tr></table></figure><p>第二步，在 hello.com 域的 nameserver 上添加一条NS记录:</p><h2 id=""><a href="#" class="headerlink" title="-"></a>-</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a.hello.com      IN       NS       ns.a.hello.com</span><br><span class="line">ns.a.hello.com      IN      A        xx.xx.xx.xx (自建nameserver的IP)复制代码</span><br></pre></td></tr></table></figure><p>这样当解析 xx.a.hello.com 域名时，hello.com nameserver 发现配置中有 NS 记录，就会继续递归向下解析</p><h2 id="DNS-调试工具"><a href="#DNS-调试工具" class="headerlink" title="DNS 调试工具"></a>DNS 调试工具</h2><p>OPS 常用的 DNS 调试工具有：host，nslookup，dig</p><p>这三个命令都属于 bind-utils 包， 也就是 bind 工具集，它们的使用复杂度、功能 依次递增。关于它们的使用， man 手册和网上有太多教程，这里简单分析一下dig命令的输出吧：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/12.webp"></p><p>dig 的参数非常多， 功能也很多，详细使用方法大家自行man吧</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="DNS-放大攻击"><a href="#DNS-放大攻击" class="headerlink" title="DNS 放大攻击"></a>DNS 放大攻击</h3><p>DNS 放大攻击属于DoS攻击的一种，是通过大量流量占满目标机带宽， 使得目标机对正常用户的请求拒绝连接从而挂掉。</p><p><strong>思路</strong></p><p>正常的流量攻击，hack 机向目标机建立大量 request-response，但这样存在的问题是需要大量的 hack 机器。因为服务器一般的带宽远大于家用网络， 如果我们自己的家用机用来做 hack 机器，还没等目标机的带宽占满，我们的带宽早超载了。</p><p><strong>原理</strong></p><p>DNS 递归解析的流程比较特殊， 我们可以通过几个字节的 query 请求，换来几百甚至几千字节的 resolving 应答（流量放大）， 并且大部分服务器不会对DNS服务器做防御。那么 hacker 们只要可以伪装 DNS query 包的 source IP， 从而让 DNS 服务器发送大量的 response 到目标机，就可以实现 DoS 攻击。</p><p>但一般常用的 DNS 服务器都会对攻击请求做过滤，所以找 DNS 服务器漏洞也是一个问题。详细的放大攻击方法大家有兴趣自行 google 吧，这里只做一个简单介绍 :)</p>]]></content>
      
      
      
        <tags>
            
            <tag> DNS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 图解 Git 工作原理 </title>
      <link href="/2021/02/11/2021-02-11-visual-git-guide/"/>
      <url>/2021/02/11/2021-02-11-visual-git-guide/</url>
      
        <content type="html"><![CDATA[<h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/1.png"></p><p>上面的四条命令在工作目录、暂存目录(也叫做索引)和仓库之间复制文件。</p><ul><li><code>git add files</code>把当前文件放入暂存区域。</li><li><code>git commit</code>给暂存区域生成快照并提交。</li><li><code>git reset</code> — files用来撤销最后一次git add files，你也可以用git reset撤销所有暂存区域文件。</li><li><code>git checkout</code> — files把文件从暂存区域复制到工作目录，用来丢弃本地修改。</li></ul><p>你可以用<code>git reset -p</code>，<code>git checkout -p</code>， or <code>git add -p</code>进入交互模式。</p><p>也可以跳过暂存区域直接从仓库取出文件或者直接提交代码。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/2.png"></p><ul><li><code>git commit -a</code>相当于运行git add把所有当前目录下的文件加入暂存区域再运行。git commit.</li><li><code>git commit files</code>进行一次包含最后一次提交加上工作目录中文件快照的提交。并且文件被添加到暂存区域。</li><li><code>git checkout HEAD -- files</code>回滚到复制最后一次提交。</li></ul><h2 id="约定"><a href="#约定" class="headerlink" title="约定"></a>约定</h2><p>后文中以下面的形式使用图片。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/3.png"></p><p>绿色的5位字符表示提交的 ID，分别指向父节点。分支用橘色显示，分别指向特定的提交。当前分支由附在其上的 HEAD 标识。这张图片里显示最后 5 次提交，ed489 是最新提交。master 分支指向此次提交，另一个 maint 分支指向祖父提交节点。</p><h2 id="命令详解"><a href="#命令详解" class="headerlink" title="命令详解"></a>命令详解</h2><h3 id="Diff"><a href="#Diff" class="headerlink" title="Diff"></a>Diff</h3><p>有许多种方法查看两次提交之间的变动。下面是一些示例。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/4.png"></p><h3 id="Commit"><a href="#Commit" class="headerlink" title="Commit"></a>Commit</h3><p>提交时，git 用暂存区域的文件创建一个新的提交，并把此时的节点设为父节点。然后把当前分支指向新的提交节点。下图中，当前分支是 master。在运行命令之前，master 指向 ed489，提交后，master 指向新的节点 f0cec 并以 ed489 作为父节点。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/5.png"></p><p>即便当前分支是某次提交的祖父节点，git会同样操作。下图中，在master分支的祖父节点maint分支进行一次提交，生成了1800b。这样，maint分支就不再是master分支的祖父节点。此时，合并 (或者 衍合) 是必须的。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/6.png"></p><p>如果想更改一次提交，使用 git commit —amend。git 会使用与当前提交相同的父节点进行一次新提交，旧的提交会被取消。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/7.png"></p><p>另一个例子是分离 HEAD 提交，后文讲。</p><h3 id="Checkout"><a href="#Checkout" class="headerlink" title="Checkout"></a>Checkout</h3><p>checkout 命令通常用来从仓库中取出文件，或者在分支中切换。</p><p>checkout 命令让 git 把文件复制到工作目录和暂存区域。比如 git checkout HEAD~ foo.c把文件从foo.c提交节点HEAD~ (当前提交节点的父节点)复制到工作目录并且生成索引。注意当前分支没有变化。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/8.png"></p><p>如果没有指定文件名，而是一个本地分支，那么将切换到那个分支去。同时把索引和工作目录切换到那个分支对应的状态。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/9.png"></p><p>如果既没有指定文件名，也没有指定分支名，而是一个标签、远程分支、SHA-1值或者是像master~3类似的东西，就得到一个匿名分支，称作detached HEAD。这样可以很方便的在历史版本之间互相切换。但是，这样的提交是完全不同的，详细的在下面。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/10.png"></p><h3 id="用分离-HEAD-提交"><a href="#用分离-HEAD-提交" class="headerlink" title="用分离 HEAD 提交"></a>用分离 HEAD 提交</h3><p>HEAD是分离的时候, 提交可以正常进行, 但是没有更新已命名的分支. 。(可以看作是匿名分支。)</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/11.png"></p><p>如果此时切换到别的分支，那么所做的工作会全部丢失。注意这个命令之后就不存在2eecb了。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/12.png"></p><p>如果你想保存当前的状态，可以用这个命令创建一个新的分支：git checkout -b name。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/13.png"></p><h3 id="Reset"><a href="#Reset" class="headerlink" title="Reset"></a>Reset</h3><p>reset 命令把当前分支指向另一个位置，并且有选择的变动工作目录和索引。也用来在从历史仓库中复制文件到索引，而不动工作目录。</p><p>如果不给选项，那么当前分支指向到那个提交。如果用—hard选项，那么工作目录也更新，如果用—soft选项，那么都不变。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/14.png"></p><p>如果没有给出提交点的版本号，那么默认用 HEAD。这样，分支指向不变，但是索引会回滚到最后一次提交，如果用—hard选项，工作目录也同样。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/15.png"></p><p>如果给了文件名(或者-p选项), 那么工作效果和带文件名的checkout差不多，除了索引被更新。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/16.png"></p><h3 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h3><p>merge 命令把不同分支合并起来。合并前，索引必须和当前提交相同。如果另一个分支是当前提交的祖父节点，那么合并命令将什么也不做。另一种情况是如果当前提交是另一个分支的祖父节点，就导致fast-forward合并。指向只是简单的移动，并生成一个新的提交。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/17.png"></p><p>否则就是一次真正的合并。默认把当前提交(ed489 如下所示)和另一个提交(33104)以及他们的共同祖父节点(b325c)进行一次三方合并。结果是先保存当前目录和索引，然后和父节点33104一起做一次新提交。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/18.png"></p><h3 id="Cherry-Pick"><a href="#Cherry-Pick" class="headerlink" title="Cherry Pick"></a>Cherry Pick</h3><p>cherry-pick命令”复制”一个提交节点并在当前复制做一次完全一样的新提交。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/19.png"></p><h3 id="Rebase"><a href="#Rebase" class="headerlink" title="Rebase"></a>Rebase</h3><p>衍合是合并命令的另一种选择。合并把两个父分支合并进行一次提交，提交历史不是线性的。衍合在当前分支上重演另一个分支的历史，提交历史是线性的。本质上，这是线性化的自动的 cherry-pick</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/20.png"></p><p>上面的命令都在topic分支中进行，而不是master分支，在master分支上重演，并且把分支指向新的节点。注意旧提交没有被引用，将被回收。</p><p>要限制回滚范围，使用—onto选项。下面的命令在master分支上重演当前分支从169a6以来的最近几个提交，即2c33a。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/21.png"></p><p>同样有 git rebase —interactive 让你更方便的完成一些复杂操作，比如丢弃、重排、修改、合并提交。没有图片体现着下，细节看这里:git-rebase(1)</p><h2 id="技术说明"><a href="#技术说明" class="headerlink" title="技术说明"></a>技术说明</h2><p>文件内容并没有真正存储在索引(.git/index)或者提交对象中，而是以blob的形式分别存储在数据库中 (.git/objects)，并用 SHA-1 值来校验。索引文件用识别码列出相关的blob文件以及别的数据。对于提交来说，以树(tree)的形式存储，同样用对于的哈希值识别。树对应着工作目录中的文件夹，树中包含的 树或者 blob 对象对应着相应的子目录和文件。每次提交都存储下它的上一级树的识别码。</p><p>如果用detached HEAD提交，那么最后一次提交会被the reflog for HEAD引用。但是过一段时间就失效，最终被回收，与git commit —amend或者git rebase很像。</p><p>转载自：微信公众号crossincode</p><p>原文地址：<a href="http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg">http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Mysql面试题50道 </title>
      <link href="/2020/10/01/2020-10-01-mysql-interview-questions/"/>
      <url>/2020/10/01/2020-10-01-mysql-interview-questions/</url>
      
        <content type="html"><![CDATA[<p><strong>1、MySQL 中有哪几种锁？</strong></p><p>（1）表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最 高，并发度最低。</p><p>（2）行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最 低，并发度也最高。</p><p>（3）页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表 锁和行锁之间，并发度一般。</p><p><strong>2、MySQL 中有哪些不同的表格？</strong></p><p>共有 5 种类型的表格：</p><p>（1）MyISAM</p><p>（2）Heap</p><p>（3）Merge</p><p>（4）INNODB</p><p>（5）ISAM</p><p><strong>3、简述在 MySQL 数据库中 MyISAM 和 InnoDB 的区别</strong></p><p>MyISAM：</p><p>（1）不支持事务，但是每次查询都是原子的；</p><p>（2）支持表级锁，即每次操作是对整个表加锁；</p><p>（3）存储表的总行数；</p><p>（4）一个 MYISAM 表有三个文件：索引文件、表结构文件、数据文件；</p><p>（5）采用菲聚集索引，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性。</p><p>InnoDb：</p><p>（1）支持 ACID 的事务，支持事务的四种隔离级别；</p><p>（2）支持行级锁及外键约束：因此可以支持写并发；</p><p>（3）不存储总行数：</p><p>（4）一个 InnoDb 引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一个表可能分布在多个文件里），也有可能为多个（设置为独立表空，表大小受操作系统文件大小限制，一般为 2G），受操作系统文件大小的限制；</p><p>（5）主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；最好使用自增主键，防止插入数据时，为维持 B+树结构，文件的大调整。</p><p><strong>4、MySQL 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别</strong></p><p>SQL 标准定义的四个隔离级别为：</p><p>（1）read uncommited ：读到未提交数据</p><p>（2）read committed：脏读，不可重复读</p><p>（3）repeatable read：可重读</p><p>（4）serializable ：串行事物</p><p><strong>5、CHAR 和 VARCHAR 的区别？</strong></p><p>（1）CHAR 和 VARCHAR 类型在存储和检索方面有所不同</p><p>（2）CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255 当 CHAR值被存储时，它们被用空格填充到特定长度，检索 CHAR 值时需删除尾随空格。</p><p><strong>6、主键和候选键有什么区别？</strong></p><p>表格的每一行都由主键唯一标识,一个表只有一个主键。</p><p>主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。</p><p><strong>7、myisamchk 是用来做什么的？</strong></p><p>它用来压缩 MyISAM 表，这减少了磁盘或内存使用。</p><p>MyISAM Static 和 MyISAM Dynamic 有什么区别？</p><p>在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像 TEXT，BLOB 等字段，以适应不同长度的数据类型。</p><p>MyISAM Static 在受损情况下更容易恢复。</p><p><strong>8、如果一个表有一列定义为 TIMESTAMP，将发生什么？</strong></p><p>每当行被更改时，时间戳字段将获取当前时间戳。</p><p>列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？</p><p>它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。</p><p>怎样才能找出最后一次插入时分配了哪个自动增量？</p><p>LAST_INSERT_ID 将返回由 Auto_increment 分配的最后一个值，并且不需要指定表名称。</p><p><strong>9、你怎么看到为表格定义的所有索引？</strong></p><p>索引是通过以下方式为表格定义的：</p><p>SHOW INDEX FROM <tablename>;</p><p><strong>10、LIKE 声明中的％和_是什么意思？</strong></p><p>％对应于 0 个或更多字符，_只是 LIKE 语句中的一个字符。</p><p>如何在 Unix 和 MySQL 时间戳之间进行转换？</p><p>UNIX_TIMESTAMP 是从 MySQL 时间戳转换为 Unix 时间戳的命令</p><p>FROM_UNIXTIME 是从 Unix 时间戳转换为 MySQL 时间戳的命令</p><p><strong>11、列对比运算符是什么？</strong></p><p>在 SELECT 语句的列比较中使用=，&lt;&gt;，&lt;=，&lt;，&gt; =，&gt;，&lt;&lt;，&gt;&gt;，&lt;=&gt;，AND，OR 或 LIKE 运算符。</p><p><strong>12、BLOB 和 TEXT 有什么区别？</strong></p><p>BLOB 是一个二进制对象，可以容纳可变数量的数据。TEXT 是一个不区分大小写的 BLOB。</p><p>BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对 TEXT 值不区分大小写。</p><p><strong>13、MySQL_fetch_array 和 MySQL_fetch_object 的区别是什么？</strong></p><p>以下是 MySQL_fetch_array 和 MySQL_fetch_object 的区别：</p><p>MySQL_fetch_array（） – 将结果行作为关联数组或来自数据库的常规数组返回。</p><p>MySQL_fetch_object – 从数据库返回结果行作为对象。</p><p><strong>14、MyISAM 表格将在哪里存储，并且还提供其存储格式？</strong></p><p>每个 MyISAM 表格以三种格式存储在磁盘上：</p><p>（1）·“.frm”文件存储表定义</p><p>（2）·数据文件具有“.MYD”（MYData）扩展名</p><p>（3）索引文件具有“.MYI”（MYIndex）扩展名</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p><strong>15、MySQL 如何优化 DISTINCT？</strong></p><p>DISTINCT 在所有列上转换为 GROUP BY，并与 ORDER BY 子句结合使用。</p><p>SELECT DISTINCT t1.a FROM t1,t2 where t1.a=t2.a;</p><p><strong>16、如何显示前 50 行？</strong></p><p>在 MySQL 中，使用以下代码查询显示前 50 行：</p><p>SELECT*FROM</p><p>LIMIT 0,50;</p><h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><p><strong>17、可以使用多少列创建索引？</strong></p><p>任何标准表最多可以创建 16 个索引列。</p><h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><p><strong>18、NOW（）和 CURRENT_DATE（）有什么区别？</strong></p><p>NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。</p><p>CURRENT_DATE（）仅显示当前年份，月份和日期。</p><h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><p><strong>19、什么是非标准字符串类型？</strong></p><p>（1）TINYTEXT</p><p>（2）TEXT</p><p>（3）MEDIUMTEXT</p><p>（4）LONGTEXT</p><h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><p><strong>20、什么是通用 SQL 函数？</strong></p><p>（1）CONCAT(A, B) – 连接两个字符串值以创建单个字符串输出。通常用于将两个或多个字段合并为一个字段。</p><p>（2）FORMAT(X, D)- 格式化数字 X 到 D 有效数字。</p><p>（3）CURRDATE(), CURRTIME()- 返回当前日期或时间。</p><p>（4）NOW（） – 将当前日期和时间作为一个值返回。</p><p>（5）MONTH（），DAY（），YEAR（），WEEK（），WEEKDAY（） – 从日期值中提取给定数据。</p><p>（6）HOUR（），MINUTE（），SECOND（） – 从时间值中提取给定数据。</p><p>（7）DATEDIFF（A，B） – 确定两个日期之间的差异，通常用于计算年龄</p><p>（8）SUBTIMES（A，B） – 确定两次之间的差异。</p><p>（9）FROMDAYS（INT） – 将整数天数转换为日期值。</p><h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><p><strong>21、MySQL 支持事务吗？</strong></p><p>在缺省模式下，MySQL 是 autocommit 模式的，所有的数据库更新操作都会即时提交，所以在缺省情况下，MySQL 是不支持事务的。</p><p>但是如果你的 MySQL 表类型是使用 InnoDB Tables 或 BDB tables 的话，你的MySQL 就可以使用事务处理,使用 SETAUTOCOMMIT=0 就可以使 MySQL 允许在非 autocommit 模式，在非autocommit 模式下，你必须使用 COMMIT 来提交你的更改，或者用 ROLLBACK来回滚你的更改。</p><h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><p><strong>22、MySQL 里记录货币用什么字段类型好</strong></p><p>NUMERIC 和 DECIMAL 类型被MySQL 实现为同样的类型，这在 SQL92 标准允许。他们被用于保存值，该值的准确精度是极其重要的值，例如与金钱有关的数据。当声明一个类是这些类型之一时，精度和规模的能被(并且通常是)指定。</p><p>例如：</p><p>salary DECIMAL(9,2)</p><p>在这个例子中，9(precision)代表将被用于存储值的总的小数位数，而 2(scale)代 表将被用于存储小数点后的位数。</p><p>因此，在这种情况下，能被存储在 salary 列中的值的范围是从-9999999.99 到9999999.99。</p><h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><p><strong>23、MySQL 有关权限的表都有哪几个？</strong></p><p>MySQL 服务器通过权限表来控制用户对数据库的访问，权限表存放在 MySQL 数据库里，由 MySQL_install_db 脚本初始化。这些权限表分别 user，db，table_priv，columns_priv 和 host。</p><h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><p><strong>24、列的字符串类型可以是什么？</strong></p><p>字符串类型是：</p><p>（1）SET2</p><p>（2）BLOB</p><p>（3）ENUM</p><p>（4）CHAR</p><p>（5）TEXT</p><h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><p><strong>25、MySQL 数据库作发布系统的存储，一天五万条以上的增量，预计运维三年,怎么优化？</strong></p><p>（1）设计良好的数据库结构，允许部分数据冗余，尽量避免 join 查询，提高效率。</p><p>（2）选择合适的表字段数据类型和存储引擎，适当的添加索引。</p><p>（3）MySQL 库主从读写分离。</p><p>（4）找规律分表，减少单表中的数据量提高查询速度。</p><p>（5）添加缓存机制，比如 memcached，apc 等。</p><p>（6）不经常改动的页面，生成静态页面。</p><p>（7）书写高效率的 SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE.</p><h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><p><strong>26、锁的优化策略</strong></p><p>（1）读写分离</p><p>（2）分段加锁</p><p>（3）减少锁持有的时间</p><p>（4）多个线程尽量以相同的顺序去获取资源</p><p>不能将锁的粒度过于细化，不然可能会出现线程的加锁和释放次数过多，反而效率不如一次加一把大锁。</p><h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><p><strong>27、索引的底层实现原理和优化</strong></p><p>B+树，经过优化的 B+树</p><p>主要是在所有的叶子结点中增加了指向下一个叶子节点的指针，因此 InnoDB 建议为大部分表使用默认自增的主键作为主索引。</p><h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><p><strong>28、什么情况下设置了索引但无法使用</strong></p><p>（1）以“%”开头的 LIKE 语句，模糊匹配</p><p>（2）OR 语句前后没有同时使用索引</p><p>（3）数据类型出现隐式转化（如 varchar 不加单引号的话可能会自动转换为 int 型）</p><h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><p><strong>29、实践中如何优化 MySQL</strong></p><p>最好是按照以下顺序优化：</p><p>（1）SQL 语句及索引的优化</p><p>（2）数据库表结构的优化</p><p>（3）系统配置的优化</p><p>（4）硬件的优化</p><h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><p><strong>30、优化数据库的方法</strong></p><p>（1）选取最适用的字段属性，尽可能减少定义字段宽度，尽量把字段设置 NOTNULL，例如’省份’、’性别’最好适用 ENUM</p><p>（2）使用连接(JOIN)来代替子查询</p><p>（3）适用联合(UNION)来代替手动创建的临时表</p><p>（4）事务处理</p><p>（5）锁定表、优化事务处理</p><p>（6）适用外键，优化锁定表</p><p>（7）建立索引</p><p>（8）优化查询语句</p><h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><p><strong>31、简单描述 MySQL 中，索引，主键，唯一索引，联合索引的区别，对数据库的性能有什么影响（从读写两方面）</strong></p><p>索引是一种特殊的文件(InnoDB 数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。</p><p>普通索引(由关键字 KEY 或 INDEX 定义的索引)的唯一任务是加快对数据的访问速度。</p><p>普通索引允许被索引的数据列包含重复的值。如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字 UNIQUE 把它定义为一个唯一索引。也就是说，唯一索引可以保证数据记录的唯一性。</p><p>主键，是一种特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录，使用关键字 PRIMARY KEY 来创建。</p><p>索引可以覆盖多个数据列，如像 INDEX(columnA, columnB)索引，这就是联合索引。</p><p>索引可以极大的提高数据的查询速度，但是会降低插入、删除、更新表的速度，因为在执行这些写操作时，还要操作索引文件。</p><h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><p><strong>32、数据库中的事务是什么?</strong></p><p>事务（transaction）是作为一个单元的一组有序的数据库操作。如果组中的所有操作都成功，则认为事务成功，即使只有一个操作失败，事务也不成功。如果所有操作完成，事务则提交，其修改将作用于所有其他数据库进程。如果一个操作失败，则事务将回滚，该事务所有操作的影响都将取消。</p><p>事务特性：</p><p>（1）原子性：即不可分割性，事务要么全部被执行，要么就全部不被执行。</p><p>（2）一致性或可串性。事务的执行使得数据库从一种正确状态转换成另一种正确状态。</p><p>（3）隔离性。在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务。</p><p>（4）持久性。事务正确提交后，其结果将永久保存在数据库中，即使在事务提交后有了其他故障，事务的处理结果也会得到保存。</p><p>或者这样理解：</p><p>事务就是被绑定在一起作为一个逻辑工作单元的 SQL 语句分组，如果任何一个语句操作失败那么整个操作就被失败，以后操作就会回滚到操作前状态，或者是上有个节点。为了确保要么执行，要么不执行，就可以使用事务。要将有组语句作为事务考虑，就需要通过 ACID 测试，即原子性，一致性，隔离性和持久性。</p><h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><p><strong>33、SQL 注入漏洞产生的原因？如何防止？</strong></p><p>SQL 注入产生的原因：程序开发过程中不注意规范书写 sql 语句和对特殊字符进行过滤，导致客户端可以通过全局变量 POST 和 GET 提交一些 sql 语句正常执行。</p><p>防止 SQL 注入的方式：</p><p>开启配置文件中的 magic_quotes_gpc 和 magic_quotes_runtime 设置</p><p>执行 sql 语句时使用 addslashes 进行 sql 语句转换</p><p>Sql 语句书写尽量不要省略双引号和单引号。</p><p>过滤掉 sql 语句中的一些关键词：update、insert、delete、select、 * 。</p><p>提高数据库表和字段的命名技巧，对一些重要的字段根据程序的特点命名，取不易被猜到的。</p><h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><p><strong>34、为表中得字段选择合适得数据类型</strong></p><p>字段类型优先级: 整形&gt;date,time&gt;enum,char&gt;varchar&gt;blob,text</p><p>优先考虑数字类型，其次是日期或者二进制类型，最后是字符串类型，同级别得数据类型，应该优先选择占用空间小的数据类型</p><h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1><p><strong>35、存储时期</strong></p><p>Datatime:以 YYYY-MM-DD HH:MM:SS 格式存储时期时间，精确到秒，占用 8 个字节得存储空间，datatime 类型与时区无关Timestamp:以时间戳格式存储，占用 4 个字节，范围小 1970-1-1 到 2038-1-19，显示依赖于所指定得时区，默认在第一个列行的数据修改时可以自动得修改timestamp 列得值</p><p>Date:（生日）占用得字节数比使用字符串.datatime.int 储存要少，使用 date 只需要 3 个字节，存储日期月份，还可以利用日期时间函数进行日期间得计算</p><p>Time:存储时间部分得数据</p><p>注意:不要使用字符串类型来存储日期时间数据（通常比字符串占用得储存空间小，在进行查找过滤可以利用日期得函数）</p><p>使用 int 存储日期时间不如使用 timestamp 类型</p><h1 id="-20"><a href="#-20" class="headerlink" title=""></a></h1><p><strong>36、对于关系型数据库而言，索引是相当重要的概念，请回答有关索引的几个问题：</strong></p><p>（1）索引的目的是什么？</p><p>快速访问数据表中的特定信息，提高检索速度</p><p>创建唯一性索引，保证数据库表中每一行数据的唯一性。</p><p>加速表和表之间的连接</p><p>使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间</p><p>（2）索引对数据库系统的负面影响是什么？</p><p>负面影响：</p><p>创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加；索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间；当对表进行增、删、改、的时候索引也要动态维护，这样就降低了数据的维护速度。</p><p>（3）为数据表建立索引的原则有哪些？</p><p>在最频繁使用的、用以缩小查询范围的字段上建立索引。</p><p>在频繁使用的、需要排序的字段上建立索引</p><p>（4）什么情况下不宜建立索引？</p><p>对于查询中很少涉及的列或者重复值比较多的列，不宜建立索引。</p><p>对于一些特殊的数据类型，不宜建立索引，比如文本字段（text）等</p><h1 id="-21"><a href="#-21" class="headerlink" title=""></a></h1><p><strong>37、解释 MySQL 外连接、内连接与自连接的区别</strong></p><p>先说什么是交叉连接: 交叉连接又叫笛卡尔积，它是指不使用任何条件，直接将一个表的所有记录和另一个表中的所有记录一一匹配。</p><p>内连接 则是只有条件的交叉连接，根据某个条件筛选出符合条件的记录，不符合条件的记录不会出现在结果集中，即内连接只连接匹配的行。</p><p>外连接 其结果集中不仅包含符合连接条件的行，而且还会包括左表、右表或两个表中的所有数据行，这三种情况依次称之为左外连接，右外连接，和全外连接。</p><p>左外连接，也称左连接，左表为主表，左表中的所有记录都会出现在结果集中，对于那些在右表中并没有匹配的记录，仍然要显示，右边对应的那些字段值以NULL 来填充。右外连接，也称右连接，右表为主表，右表中的所有记录都会出现在结果集中。左连接和右连接可以互换，MySQL 目前还不支持全外连接。</p><h1 id="-22"><a href="#-22" class="headerlink" title=""></a></h1><p><strong>38、Myql 中的事务回滚机制概述</strong></p><p>事务是用户定义的一个数据库操作序列，这些操作要么全做要么全不做，是一个不可分割的工作单位，事务回滚是指将该事务已经完成的对数据库的更新操作撤销。</p><p>要同时修改数据库中两个不同表时，如果它们不是一个事务的话，当第一个表修改完，可能第二个表修改过程中出现了异常而没能修改，此时就只有第二个表依旧是未修改之前的状态，而第一个表已经被修改完毕。而当你把它们设定为一个事务的时候，当第一个表修改完，第二表修改出现异常而没能修改，第一个表和第二个表都要回到未修改的状态，这就是所谓的事务回滚</p><h1 id="-23"><a href="#-23" class="headerlink" title=""></a></h1><p><strong>39、SQL 语言包括哪几部分？每部分都有哪些操作关键字？</strong></p><p>SQL 语言包括数据定义(DDL)、数据操纵(DML),数据控制(DCL)和数据查询（DQL） 四个部分。</p><p>数据定义：Create Table,Alter Table,Drop Table, Craete/Drop Index 等</p><p>数据操纵：Select ,insert,update,delete,</p><p>数据控制：grant,revoke</p><p>数据查询：select</p><p><strong>40、完整性约束包括哪些？</strong></p><p>数据完整性(Data Integrity)是指数据的精确(Accuracy)和可靠性(Reliability)。</p><p>分为以下四类：</p><p>（1）实体完整性：规定表的每一行在表中是惟一的实体。</p><p>（2）域完整性：是指表中的列必须满足某种特定的数据类型约束，其中约束又包括取值范围、精度等规定。</p><p>（3）参照完整性：是指两个表的主关键字和外关键字的数据应一致，保证了表之间的数据的一致性，防止了数据丢失或无意义的数据在数据库中扩散。</p><p>（4）用户定义的完整性：不同的关系数据库系统根据其应用环境的不同，往往还需要一些特殊的约束条件。用户定义的完整性即是针对某个特定关系数据库的约束条件，它反映某一具体应用必须满足的语义要求。</p><p>与表有关的约束：包括列约束(NOT NULL（非空约束）)和表约束(PRIMARY KEY、foreign key、check、UNIQUE) 。</p><h1 id="-24"><a href="#-24" class="headerlink" title=""></a></h1><p><strong>41、什么是锁？</strong></p><p>数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。</p><p>加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。</p><p>基本锁类型：锁包括行级锁和表级锁</p><h1 id="-25"><a href="#-25" class="headerlink" title=""></a></h1><p><strong>42、什么叫视图？游标是什么？</strong></p><p>视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，视图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易，相比多表查询。</p><p>游标：是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。</p><h1 id="-26"><a href="#-26" class="headerlink" title=""></a></h1><p><strong>43、什么是存储过程？用什么来调用？</strong></p><p>存储过程是一个预编译的 SQL 语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次 SQL，使用存储过程比单纯 SQL 语句执行要快。可以用一个命令对象来调用存储过程。</p><h1 id="-27"><a href="#-27" class="headerlink" title=""></a></h1><p><strong>44、如何通俗地理解三个范式？</strong></p><p>第一范式：1NF 是对属性的原子性约束，要求属性具有原子性，不可再分解；</p><p>第二范式：2NF 是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性；</p><p>第三范式：3NF 是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。。</p><p>范式化设计优缺点:</p><p>优点:可以尽量得减少数据冗余，使得更新快，体积小</p><p>缺点:对于查询需要多个表进行关联，减少写得效率增加读得效率，更难进行索引优化</p><p>反范式化:</p><p>优点:可以减少表得关联，可以更好得进行索引优化</p><p>缺点:数据冗余以及数据异常，数据得修改需要更多的成本</p><h1 id="-28"><a href="#-28" class="headerlink" title=""></a></h1><p><strong>45、什么是基本表？什么是视图？</strong></p><p>基本表是本身独立存在的表，在 SQL 中一个关系就对应一个表。视图是从一个或几个基本表导出的表。视图本身不独立存储在数据库中，是一个虚表</p><h1 id="-29"><a href="#-29" class="headerlink" title=""></a></h1><p><strong>46、试述视图的优点？</strong></p><p>(1) 视图能够简化用户的操作</p><p>(2) 视图使用户能以多种角度看待同一数据；</p><p>(3) 视图为数据库提供了一定程度的逻辑独立性；</p><p>(4)视图能够对机密数据提供安全保护。</p><h1 id="-30"><a href="#-30" class="headerlink" title=""></a></h1><p><strong>47、 NULL 是什么意思</strong></p><p>NULL 这个值表示 UNKNOWN(未知):它不表示“”(空字符串)。对 NULL 这个值的任何比较都会生产一个 NULL 值。您不能把任何值与一个 NULL 值进行比较，并在逻辑上希望获得一个答案。</p><p>使用 IS NULL 来进行 NULL 判断</p><h1 id="-31"><a href="#-31" class="headerlink" title=""></a></h1><p><strong>48、主键、外键和索引的区别？</strong></p><p>主键、外键和索引的区别</p><p>定义：</p><p>主键——唯一标识一条记录，不能有重复的，不允许为空</p><p>外键——表的外键是另一表的主键, 外键可以有重复的, 可以是空值</p><p>索引——该字段没有重复值，但可以有一个空值</p><p>作用：</p><p>主键——用来保证数据完整性</p><p>外键——用来和其他表建立联系用的</p><p>索引——是提高查询排序的速度</p><p>个数：</p><p>主键—— 主键只能有一个</p><p>外键—— 一个表可以有多个外键</p><p>索引—— 一个表可以有多个唯一索引</p><h1 id="-32"><a href="#-32" class="headerlink" title=""></a></h1><p><strong>49、你可以用什么来确保表格里的字段只接受特定范围里的值?</strong></p><p>Check 限制，它在数据库表格里被定义，用来限制输入该列的值。</p><p>触发器也可以被用来限制数据库表格里的字段能够接受的值，但是这种办法要求触发器在表格里被定义，这可能会在某些情况下影响到性能。</p><h1 id="-33"><a href="#-33" class="headerlink" title=""></a></h1><p><strong>50、说说对 SQL 语句优化有哪些方法？（选择几条）</strong></p><p>（1）Where 子句中：where 表之间的连接必须写在其他 Where 条件之前，那些可以过滤掉最大数量记录的条件必须写在 Where 子句的末尾.HAVING 最后。</p><p>（2）用 EXISTS 替代 IN、用 NOT EXISTS 替代 NOT IN。</p><p>（3） 避免在索引列上使用计算</p><p>（4）避免在索引列上使用 IS NULL 和 IS NOT NULL</p><p>（5）对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。</p><p>（6）应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描</p><p>（7）应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描</p>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 六种酷炫Python运行进度条 </title>
      <link href="/2020/09/29/2020-09-29-python-progressbar/"/>
      <url>/2020/09/29/2020-09-29-python-progressbar/</url>
      
        <content type="html"><![CDATA[<h2 id="1-普通进度条"><a href="#1-普通进度条" class="headerlink" title="1.普通进度条"></a>1.普通进度条</h2><p>在代码迭代运行中可以自己进行统计计算，并使用格式化字符串输出代码运行进度</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import time</span><br><span class="line">def progress_bar():</span><br><span class="line">    for i in range(1, 101):</span><br><span class="line">        print(&quot;\r&quot;, end=&quot;&quot;)</span><br><span class="line">        print(&quot;Download progress: &#123;&#125;%: &quot;.format(i), &quot;▋&quot; * (i // 2), end=&quot;&quot;)</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">        time.sleep(0.05)</span><br><span class="line">progress_bar()</span><br></pre></td></tr></table></figure><h2 id="2-带时间进度条"><a href="#2-带时间进度条" class="headerlink" title="2.带时间进度条"></a>2.带时间进度条</h2><p>导入time模块来计算代码运行的时间，加上代码迭代进度使用格式化字符串来输出代码运行进度</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">scale = 50</span><br><span class="line">print(&quot;执行开始，祈祷不报错&quot;.center(scale // 2,&quot;-&quot;))</span><br><span class="line">start = time.perf_counter()</span><br><span class="line">for i in range(scale + 1):</span><br><span class="line">    a = &quot;*&quot; * i</span><br><span class="line">    b = &quot;.&quot; * (scale - i)</span><br><span class="line">    c = (i / scale) * 100</span><br><span class="line">    dur = time.perf_counter() - start</span><br><span class="line">    print(&quot;\r&#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.2f&#125;s&quot;.format(c,a,b,dur),end = &quot;&quot;)</span><br><span class="line">    time.sleep(0.1)</span><br><span class="line">print(&quot;\n&quot;+&quot;执行结束，万幸&quot;.center(scale // 2,&quot;-&quot;))</span><br></pre></td></tr></table></figure><h2 id="3-tpdm进度条"><a href="#3-tpdm进度条" class="headerlink" title="3.tpdm进度条"></a>3.tpdm进度条</h2><p>这是一个专门生成进度条的工具包，可以使用pip在终端进行下载，当然还能切换进度条风格</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from time import sleep</span><br><span class="line">from tqdm import tqdm</span><br><span class="line"># 这里同样的，tqdm就是这个进度条最常用的一个方法</span><br><span class="line"># 里面存一个可迭代对象</span><br><span class="line">for i in tqdm(range(1, 500)):</span><br><span class="line">   # 模拟你的任务</span><br><span class="line">   sleep(0.01)</span><br><span class="line">sleep(0.5)</span><br></pre></td></tr></table></figure><h2 id="4-progress进度条"><a href="#4-progress进度条" class="headerlink" title="4.progress进度条"></a>4.progress进度条</h2><p>你只需要定义迭代的次数、进度条类型并在每次迭代时告知进度条即可，具体代码案例如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">from progress.bar import IncrementalBar</span><br><span class="line">mylist = [1,2,3,4,5,6,7,8]</span><br><span class="line">bar = IncrementalBar(&#x27;Countdown&#x27;, max = len(mylist))</span><br><span class="line">for item in mylist:</span><br><span class="line">    bar.next()</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    bar.finish()</span><br></pre></td></tr></table></figure><h2 id="5-alive-progress进度条"><a href="#5-alive-progress进度条" class="headerlink" title="5.alive_progress进度条"></a>5.alive_progress进度条</h2><p>顾名思义，这个库可以使得进度条变得生动起来，它比原来我们见过的进度条多了一些动画效果，需要使用pip进行下载，代码案例如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from alive_progress import alive_bar</span><br><span class="line">items = range(100)                  # retrieve your set of items</span><br><span class="line">with alive_bar(len(items)) as bar:   # declare your expected total</span><br><span class="line">    for item in items:               # iterate as usual</span><br><span class="line">        # process each item</span><br><span class="line">        bar()</span><br><span class="line">        time.sleep(0.1)</span><br></pre></td></tr></table></figure><h2 id="6-可视化进度条"><a href="#6-可视化进度条" class="headerlink" title="6.可视化进度条"></a>6.可视化进度条</h2><p>用 PySimpleGUI 得到图形化进度条，我们可以加一行简单的代码，在命令行脚本中得到图形化进度条，也是使用pip进行下载，代码案例如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import PySimpleGUI as sg</span><br><span class="line">import time</span><br><span class="line">mylist = [1,2,3,4,5,6,7,8]</span><br><span class="line">for i, item in enumerate(mylist):</span><br><span class="line">    sg.one_line_progress_meter(&#x27;This is my progress meter!&#x27;, i+1, len(mylist), &#x27;-key-&#x27;)</span><br><span class="line">    time.sleep(1)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Dockerfile就这么简单 </title>
      <link href="/2020/07/20/2020-07-20-dockerfile/"/>
      <url>/2020/07/20/2020-07-20-dockerfile/</url>
      
        <content type="html"><![CDATA[<p>当我们在使用docker时，最重要的就是镜像，只要有了镜像，我们就可以随时随地的根据镜像来创建一个容器，从而做到让我们的服务可以在任何时间任何地点任何环境下运行起来。那么镜像是怎么制作的呢？总体来讲，制作镜像有两种方法：</p><ol><li>根据一个已有的镜像运行容器，然后根据这个容器来制作我们自己的镜像；</li><li>使用DockerFile来制作一个镜像模板文件，使用这个文件来创建镜像；</li></ol><p>对于第一种方法，我们在上一篇文章中最后有提及，就是利用docker commit命令，将我们的变更打包成一个新的镜像。但是这种方法需要我们每次都运行一个容器，然后在容器中做更改后再打包，很明显这种方式效率很低，而且更改不方便。所以这种方式一般不建议大家采用。我们更多的要使用DockerFile的方式来定制我们的镜像，接下来，我们就详细的介绍一下DockerFile的制作方法。</p><h1 id="一、利用Dockerfile制作镜像的准备工作"><a href="#一、利用Dockerfile制作镜像的准备工作" class="headerlink" title="一、利用Dockerfile制作镜像的准备工作"></a>一、利用Dockerfile制作镜像的准备工作</h1><p>在制作Dockerfile前，我们需要做一系列的准备工作。首先，我们要创建一个目录，用来存储我们的Dockerfile，我们需要打包进镜像中的所有文件也都要放在这个这个目录下，我们制作镜像的时候也要在这个目录下来完成。其次，我们要创建一个文件名为Dockerfile，这个文件必须是大写开头，文件名必须为Dockerfile。当我们编写好我们的Dockerfile文件后，我们需要用docker build命令来执行创建镜像。</p><h1 id="二、Dockerfile指令"><a href="#二、Dockerfile指令" class="headerlink" title="二、Dockerfile指令"></a>二、Dockerfile指令</h1><p>我们准备好相关的目录和文件后，我们就可以开始编写我们的Dockerfile了，Dockerfile其实就是由一些指令组合成的，在Dockerfile中一行就是一条指令，每行开头的第一个单词就是指令本身，指令可以用大写也可以用小写，但是一般我们使用大写来表示指令。</p><h2 id="1-FROM指令"><a href="#1-FROM指令" class="headerlink" title="1. FROM指令"></a>1. FROM指令</h2><p>每一个Dockerfile的第一个非注释行都必须使用FROM指令，这个指令指明了我们制作镜像使用的基础镜像，格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM &lt;镜像仓库名&gt;[:tag]</span><br><span class="line">FROM &lt;镜像仓库名&gt;@&lt;镜像哈希值&gt;</span><br></pre></td></tr></table></figure><p>默认情况下，docker build命令会优先从本地查找我们使用到的基础镜像，如果找不到则自动去我们的镜像仓库中查找。我们在指定基础镜像的过程中可以使用镜像名，但是此时会出现一个问题，如果有人恶意更改了镜像名，用一个错误的镜像替换了我们正常的镜像，那么此时我们就会拉取到错误的镜像。为了避免这个问题的出现，我们可以使用镜像的哈希值来指定基础镜像，就是我们上面提到的使用@符号，这样一来我们使用的镜像就不会被恶意替换掉了。</p><p>FROM指令在使用镜像名时，可以省略标签名，默认会使用latest标签。</p><p>我们上面说了，每一个Dockerfile的第一个非注释行都必须使用FROM开头，但是ARG指令是唯一一个可以在FROM指令前出现的指令，这是一个例外的情况。</p><h2 id="2-LABEL指令"><a href="#2-LABEL指令" class="headerlink" title="2. LABEL指令"></a>2. LABEL指令</h2><p>LABEL指令用来指定一些元数据的，比如指定这个镜像文件的作者，联系方式，描述信息等等，格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LABEL key1=value1 key2=value2 ... keyN=valueN</span><br></pre></td></tr></table></figure><p>在docker的早期版本中并没有LABEL指令，而是使用MAINTAINER指令，MAINTAINER指令后面只能跟一个字符串，用来指定作者的信息，在新版的docker中，这个指令已经被弃用，官方推荐使用LABEL指令来实现。</p><h2 id="3-RUN指令"><a href="#3-RUN指令" class="headerlink" title="3. RUN指令"></a>3. RUN指令</h2><p>RUN指令用来在创建镜像过程中执行一些命令，RUN指令有两种格式：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RUN &lt;command&gt;      直接跟命令</span><br><span class="line">RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]    命令和其参数作为一个列表传入</span><br></pre></td></tr></table></figure><p>这两种方式有不同的效果，RUN指令后直接跟一个命令，会将此命令运行在一个shell中，在linux中默认是/bin/sh，这也就意味着我们可以在命令字符串中引用一些shell变量。但是在第二种方式中，所有的命令和参数放在了一个列表中传入，此时就无法引用shell中的变量。</p><p>除此之外，还有一点需要注意，就是在列表中一定不要用单引号来包裹参数，每个元素都要用双引号，否则会出现docker镜像运行错误的问题。原因就是docker build时会把这些列表当做json来处理，所以要符合json字符串的规则。</p><p>RUN指令执行的命令的结果会被打包到镜像当中，而且Dockerfile中后续的指令也可以使用。使用SHELL指令可以改变默认使用的shell。</p><h2 id="4-CMD指令"><a href="#4-CMD指令" class="headerlink" title="4. CMD指令"></a>4. CMD指令</h2><p>CMD指令是用来指定基于我们的镜像创建容器时，容器中运行的命令的，和RUN不同的地方在于，RUN是在构建镜像时执行的命令，CDM是在创建容器时执行的命令。在一个Dockerfile中只可以有一个CDM指令，如果定义了多个CMD指令，那只有最后一个CMD指令会生效。CMD指令使用格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form exec格式，这是推荐的格式)</span><br><span class="line">CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT 为ENTRYPOINT参数提供参数)</span><br><span class="line">CMD command param1 param2 (shell form shell格式的命令)</span><br></pre></td></tr></table></figure><p>CMD指令可以直接指定一个可执行命令，就是上述的第一和第三种方式，当创建容器时会去执行这个命令，而且需要注意的是，第三种方式是默认在shell中执行的，可以引用shell变量，而第一种方式并不会启动shell，所以就无法引用shell变量。</p><p>在采用第二种方式时，此时并没有指定可执行的命令，而是只指定了参数，此时，这些参数将作为ENTRYPOINT指令的参数，关于ENTRYPOINT指令，我们稍后介绍。</p><h2 id="5-ENTRYPOINT指令"><a href="#5-ENTRYPOINT指令" class="headerlink" title="5. ENTRYPOINT指令"></a>5. ENTRYPOINT指令</h2><p>ENTRYPOINT指令也是用来指定基于我们的镜像创建容器时需要执行的命令的，其使用格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form, preferred 推荐格式，使用json)</span><br><span class="line">ENTRYPOINT command param1 param2 (shell form shell格式)</span><br></pre></td></tr></table></figure><p>既然我们已经有了CMD指令了，那为什么我们还要弄一个ENTRYPOINT指令出来呢？这两者的区别在于，当我们使用CMD指令创建好镜像后，在使用这个镜像启动容器时，我们可以改变容器默认的命令，而自己定义启动容器时的命令，比如我们的CMD指令是启动nginx，但是我们在启动容器的时候可以指定命令来启动一个bash，此时，我们在命令行中指定的指令就替换掉了我们的CMD命令。但是我们如果使用ENTRYPOINT指令来指定执行的命令，那么在命令行中启动镜像时，在镜像名之后我们自己指定的命令将不会执行，而是作为参数传递给了ENTRYPOINT命令。而且，在命令行中指定的命令，第一个参数并没有被传递给<code>ENTRYPOINT</code>，这是因为我们的docker默认认为第一个参数是要执行的命令，而其之后的才是真正的参数，参见如下所示，我们的“echo” 字符串并没有被输出出来：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost img1]# cat Dockerfile</span><br><span class="line">FROM centos:centos7</span><br><span class="line">ENTRYPOINT echo &quot;abc&quot; $@</span><br><span class="line">[root@localhost img1]# docker run --rm centos:testv3 echo aaaaa bbbbb ccccc</span><br><span class="line">abc aaaaa bbbbb ccccc</span><br><span class="line">[root@localhost img1]#</span><br></pre></td></tr></table></figure><p>这个特性可以使我们在运行容器时禁止自定义启动命令，保证了容器运行结果与我们的预期完全一致。但是，我们并不是完全不能更改这个命令，docker为我们提供了<code>--entrypoint</code>参数来修改这个命令。但是这个参数和命令要写在镜像名之前才会生效。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost img1]# cat Dockerfile</span><br><span class="line">FROM centos:centos7</span><br><span class="line">ENTRYPOINT echo &quot;abc&quot;</span><br><span class="line">[root@localhost img1]# docker run -ti --rm centos:testv1 --entrypoint /bin/bash</span><br><span class="line">abc</span><br><span class="line">[root@localhost img1]# docker run -ti --rm --entrypoint /bin/bash centos:testv1</span><br><span class="line">[root@a0c502e6ba2f /]# exit</span><br><span class="line">exit</span><br></pre></td></tr></table></figure><p>在上面CMD命令的部分，我们可以给<code>CMD</code>命令不指定执行的命令而只指定参数，此时这些参数就会被传递给ENTRYPOINT指令。</p><p>此外，还需要注意一点，我们使用列表的格式来编写命令时，要注意使用双引号来包裹各个参数，而不是单引号。</p><p>Shell形式可防止使用任何CMD或<code>run</code> 命令行参数覆盖掉我们的运行命令，但具有以下缺点：ENTRYPOINT将作为<code>/bin/sh -c</code>的子命令启动，该子命令不传递信号。这意味着可执行文件将不是容器的<code>PID 1</code>，并且不会接收Unix信号，因此您的可执行文件将不会从<code>docker stop &lt;container&gt;</code>接收到<code>SIGTERM</code>。</p><h2 id="6-EXPOSE指令"><a href="#6-EXPOSE指令" class="headerlink" title="6. EXPOSE指令"></a>6. EXPOSE指令</h2><p>EXPOSE指令是用来暴露容器的端口的，其使用格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...]</span><br></pre></td></tr></table></figure><p>这个指令可以一次性指定暴露多个端口，且可以指定端口的协议，默认情况下是使用TCP协议，我们还可以自己定义使用的协议：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EXPOSE 8080/udp  暴露UDP协议的8080端口</span><br></pre></td></tr></table></figure><p>但是需要注意的是，在使用了EXPOSE指令后指定的端口，在运行容器时并不会自动的建立容器和宿主机的映射关系，而是当我们运行容器时指定-P选项后其才会将这些端口映射到宿主机上，且我们在定义Dockerfile时不能指定容器端口映射到宿主机上的端口，只能是随机映射一个宿主机上的端口。</p><h2 id="7-ENV指令"><a href="#7-ENV指令" class="headerlink" title="7. ENV指令"></a>7. ENV指令</h2><p>ENV指令用于创建环境变量，这些环境变量可以在构建镜像阶段供Dockerfile之后的指令所引用，其格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENV &lt;key&gt; &lt;value&gt;</span><br><span class="line">ENV &lt;key&gt;=&lt;value&gt; ...</span><br></pre></td></tr></table></figure><p>第一种格式用来设置单个的环境变量，ENV指令后被空格分隔的第一个字符串会被当成是环境变量的KEY，后面的所有值都会被当成是该KEY的VALUE值，第二种格式可以一次设置多个环境变量，使用等号来声明KEY和VALUE，如果VALUE部分包含空格，我们可以用引号将VALUE部分引起来，也可以用反斜杠对空格做转义处理。例如：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 第一种格式，一行定义一对环境变量</span><br><span class="line">ENV myName John Doe</span><br><span class="line">ENV myDog Rex The Dog</span><br><span class="line">ENV myCat fluffy</span><br><span class="line"></span><br><span class="line"># 第二种方式，一行定义多对环境变量</span><br><span class="line">ENV myName=&quot;John Doe&quot; myDog=Rex\ The\ Dog \</span><br><span class="line">    myCat=fluffy</span><br></pre></td></tr></table></figure><p>通过ENV指令设置的环境变量将被保留在生成的镜像中，我们用此镜像创建容器后，可以用docker inspect 命令来查看，也可以在运行容器时，使用<code>docker run --env &lt;key&gt;=&lt;value&gt;</code>的方式来指定。</p><h2 id="8-ADD指令"><a href="#8-ADD指令" class="headerlink" title="8. ADD指令"></a>8. ADD指令</h2><p>ADD指令用来向镜像中添加文件，其有两种格式：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;</span><br><span class="line">ADD [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</span><br></pre></td></tr></table></figure><p><code>--chown</code>选项可以在添加文件时改变文件的属主和属组，但是需要注意，这个特性只支持Linux类型的容器，在windows容器上不起作用。</p><p>ADD指令可以从<code>&lt;src&gt;</code>指定的文件、目录或者URL拷贝文件到镜像文件系统中的<code>&lt;dest&gt;</code>路径下，并且可以指定多个<code>&lt;src&gt;</code>，在有多个<code>&lt;src&gt;</code>时，最后一个作为目的地址，其前面的字段都会作为<code>&lt;src&gt;</code>字段。同时，在原地址字段中，也支持正则匹配。并且，目的地址是一个绝对路径，或者当<code>WORKDIR</code>指令指定了工作目录后，也可以是这个目录下的相对路径。而原文件必须在Dockerfile所在的目录下或其子目录下。</p><p>添加包含特殊字符（例如[和]）的文件或目录时，您需要按照Golang规则转义那些路径，以防止将它们视为匹配模式。例如，要添加名为arr [0] .txt的文件，请使用以下命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ADD arr[[]0].txt /mydir/    # copy a file named &quot;arr[0].txt&quot; to /mydir/</span><br></pre></td></tr></table></figure><p>如果没有添加<code>--chown</code>标志，所有新添加的文件或目录属主属组默认是0。<code>--chown</code>标志允许提供属主名和属组名，如果提供了用户名或组名，则将使用容器的根文件系统<code>/etc/passwd</code>和<code>/etc/group</code>文件分别执行从名称到整数UID或GID的转换，也可以提供其对应的UID和GID，如果只提供了属主，则默认会使用和属主UID相同的GID来指定属组，如下都是正确的定义格式：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ADD --chown=55:mygroup files* /somedir/</span><br><span class="line">ADD --chown=bin files* /somedir/</span><br><span class="line">ADD --chown=1 files* /somedir/</span><br><span class="line">ADD --chown=10:11 files* /somedir/</span><br></pre></td></tr></table></figure><p>如果通过<code>--chown</code>标志使用用户名或者属主名来指定属主或属组，而在容器的文件系统中不存在 <code>/etc/passwd</code> 或者 <code>/etc/group</code> 文件，此时构建镜像时会在ADD操作时失败。但是使用数字来指定时，创建镜像的时候并不会去查找此UID或GID是否存在，也不会依赖容器的根文件系统。需要注意的是，如果源文件是一个URL，而这个URL需要登录认证的话，那么需要使用wget或者curl的方式来下载文件，ADD指令并不能完成登录认证。</p><p><strong>「ADD指令遵循如下的规则：」</strong></p><ol><li>如果是URL，并且不以斜杠结尾，则从URL下载文件并将其复制到;</li><li>如果是URL，并且以斜杠结尾，则从URL推断文件名，并将文件下载到/。例如，ADD <a href="http://example.com/foobar">http://example.com/foobar</a> /，将创建文件 /foobar。该URL必须具有具体的路径及文件名，以便在这种情况下可以找到适当的文件名（例如这样的URL：<a href="http://example.com将不起作用)/">http://example.com将不起作用）</a>;</li><li>如果是目录，则将复制目录的整个内容，包括文件系统元数据。注意，此时目录本身并不会被复制，而是递归复制这个目录下的所有文件;</li><li>当是本地的一个通过gzip, bzip2 or xz压缩的tar压缩包，ADD指令会自动将这个包解压。但是如果是一个URL时则不会解压。</li></ol><blockquote><p>❝</p><p><strong>「注意」</strong>：文件是否被识别为压缩格式仅根据文件的内容而不是文件的名称来确定。例如，如果一个空文件碰巧以.tar.gz结尾，则该文件将不会被识别为压缩文件，并且不会生成任何类型的解压缩错误消息，而是会将文件简单地复制到目标位置。</p><p>❞</p></blockquote><ol><li>如果是任何其他类型的文件，则将其与其元数据一起单独复制。在这种情况下，如果以尾斜杠/结束，则它将被视为目录，并且的内容将写入/base();</li><li>如果直接或由于使用通配符而指定了多个资源，则必须是目录，并且必须以斜杠/结尾;</li><li>如果不以斜杠结尾，它将被视为常规文件，并且的内容将写入;</li><li>如果不存在，它将与路径中所有缺少的目录一起创建。</li></ol><h2 id="9-COPY指令"><a href="#9-COPY指令" class="headerlink" title="9. COPY指令"></a>9. COPY指令</h2><p>COPY用于向镜像中复制文件，用法与ADD指令类似，但是也有一些区别，其格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;</span><br><span class="line">COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</span><br></pre></td></tr></table></figure><p>COPY指令也可以复制多个文件，也支持通配符匹配，用法基本类似ADD指令，但是COPY指令只能接受一个本地文件或目录，不能COPY远程的URL。而且COPY的文件也必须放在Dockerfile同级目录或其同级目录之下的目录中。</p><p><strong>「COPY指令遵循如下规则：」</strong></p><ol><li>如果是目录，则将复制目录的整个内容，包括文件系统元数据。且目录本身不被复制，仅其内容被复制；</li><li>如果是任何其他类型的文件，则将其与其元数据一起单独复制。在这种情况下，如果以尾斜杠/结束，则它将被视为目录，并且的内容将写入/base()；</li><li>如果直接或由于使用通配符而指定了多个资源，则必须是目录，并且必须以斜杠/结尾；</li><li>如果不以斜杠结尾，它将被视为常规文件，并且的内容将写入；</li><li>如果不存在，它将与路径中所有缺少的目录一起创建；</li></ol><h2 id="10-VOLUME指令"><a href="#10-VOLUME指令" class="headerlink" title="10. VOLUME指令"></a>10. VOLUME指令</h2><p>VOLUME指令用于挂载宿主机上的目录到容器中，其格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">VOLUME [&quot;/data&quot;]</span><br></pre></td></tr></table></figure><p>VOLUME指令创建具有指定名称的挂载点，并将其标记为保存来自本地主机或其他容器的外部安装的卷。该值可以是JSON数组，<code>VOLUME [&quot;/var/log/&quot;]</code> 或具有多个参数的纯字符串，例如<code>VOLUME /var/log</code> 或 <code>VOLUME /var/log/var/db</code>。在指定挂载点后，docker创建容器时，会把挂载点下已经存在的文件移动到卷中。</p><p>关于Dockerfile中的卷，请记住以下几点。</p><ol><li><p>基于Windows的容器上的卷：使用基于Windows的容器时，容器内的卷的目的地必须是以下之一：</p><p>a、不存在的或空目录</p><p>b、C盘以外的磁盘分区</p></li><li><p>从Dockerfile内更改卷：如果在声明了卷后有任何构建步骤更改了卷内的数据，则这些更改将被丢弃;</p></li><li><p>JSON格式：列表被解析为JSON数组。您必须用双引号（”）而不是单引号（’）括起单词;</p></li><li><p>主机目录在容器运行时声明：主机目录（挂载点）从本质上说是依赖于主机的。这是为了保留镜像的可移植性，因为不能保证给定的主机目录在所有主机上都可用。因此，您无法从Dockerfile中挂载主机目录。VOLUME指令不支持指定host-dir参数。创建或运行容器时，必须指定挂载点。</p></li></ol><h2 id="11-USER指令"><a href="#11-USER指令" class="headerlink" title="11. USER指令"></a>11. USER指令</h2><p>USER指令设置运行镜像时要使用的用户名（或UID）以及可选的用户组（或GID），以及Dockerfile中的所有RUN，CMD和ENTRYPOINT指令。其格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">USER &lt;user&gt;[:&lt;group&gt;] or</span><br><span class="line">USER &lt;UID&gt;[:&lt;GID&gt;]</span><br></pre></td></tr></table></figure><h2 id="12、WORKDIR指令"><a href="#12、WORKDIR指令" class="headerlink" title="12、WORKDIR指令"></a>12、WORKDIR指令</h2><p>WORKDIR指令为Dockerfile中跟在其后的所有RUN，CMD，ENTRYPOINT，COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使以后的Dockerfile指令中未使用，它也将被创建。其格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WORKDIR /path/to/workdir</span><br></pre></td></tr></table></figure><p>WORKDIR指令可在Dockerfile中多次使用。如果提供了相对路径，则它将相对于上一个WORKDIR指令的路径。例如：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WORKDIR /a</span><br><span class="line">WORKDIR b</span><br><span class="line">WORKDIR c</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure><p>该Dockerfile中最后一个pwd命令的输出为<code>/a/b/c</code>。</p><p>WORKDIR指令可以解析以前使用ENV设置的环境变量。你只能使用在Dockerfile中显式设置的环境变量。例如：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENV DIRPATH /path</span><br><span class="line">WORKDIR $DIRPATH/$DIRNAME</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure><p>pwd命令的运行结果就是<code>/path/$DIRNAME</code>。</p><h2 id="13-ARG指令"><a href="#13-ARG指令" class="headerlink" title="13. ARG指令"></a>13. ARG指令</h2><p>ARG指令定义了一个变量，用户可以在创建镜像时使用–build-arg=参数将其传递给构建器。如果用户指定了未在Dockerfile中定义的ARG变量，则构建会输出警告。其格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ARG &lt;name&gt;[=&lt;default value&gt;]</span><br></pre></td></tr></table></figure><p>在Dockerfile中可以包含一个或多个变量。</p><blockquote><p>❝</p><p><strong>「注意:」</strong> 不建议使用创建镜像时使用变量来传递诸如github密钥，用户凭据等机密。创建镜像时变量值对于使用docker history命令的镜像的任何用户都是可见的。</p><p>❞</p></blockquote><p>在定义ARG变量时，可以给变量赋初值，如果在创建镜像时没有传入变量值，那么就会使用这个初始值：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM busybox</span><br><span class="line">ARG user1=someuser</span><br><span class="line">ARG buildno=1</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>ARG变量也遵从先定义后使用的惯例，而且，Dockerfile中后定义的同名变量会覆盖之前的变量的值。</p><p>可以使用ARG或ENV指令来指定RUN指令可用的变量。使用ENV指令定义的环境变量始终会覆盖同名的ARG指令。我们来看一个例子：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ARG CONT_IMG_VER</span><br><span class="line">ENV CONT_IMG_VER v1.0.0</span><br><span class="line">RUN echo $CONT_IMG_VER</span><br></pre></td></tr></table></figure><p>我们创建镜像时使用如下命令，给<code>CONT_IMG_VER</code>传入不同的变量值：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker build --build-arg CONT_IMG_VER=v2.0.1 .</span><br></pre></td></tr></table></figure><p>在这种情况下，RUN指令使用v1.0.0而不是用户传递的ARG设置：v2.0.1，就是因为ENV指令定义的环境变量覆盖了同名的ARG变量。</p><p>Docker具有一组预定义的ARG变量，您可以在Dockerfile中使用它们而无需相应的ARG指令:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HTTP_PROXY</span><br><span class="line">http_proxy</span><br><span class="line">HTTPS_PROXY</span><br><span class="line">https_proxy</span><br><span class="line">FTP_PROXY</span><br><span class="line">ftp_proxy</span><br><span class="line">NO_PROXY</span><br><span class="line">no_proxy</span><br></pre></td></tr></table></figure><p>默认情况下，这些预定义变量从Docker历史记录的输出中删除。删除它们可以降低意外泄漏<code>HTTP_PROXY</code>变量中的敏感身份验证信息的风险。如果需要在docker历史记录中输出这些默认变量值，则需要我们在Dockerfile中显示的使用ARG指令指定这个变量。</p><h2 id="14-ONBUILD指令"><a href="#14-ONBUILD指令" class="headerlink" title="14. ONBUILD指令"></a>14. ONBUILD指令</h2><p>当我们的镜像被作为基础镜像执行构建时，此时ONBUILD指令就会生效。其格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ONBUILD [INSTRUCTION]</span><br></pre></td></tr></table></figure><p>运作方式如下：当它遇到<code>ONBUILD</code>指令时，构建器将触发器添加到正在构建的镜像的元数据中，该指令不会影响当前版本。构建结束时，所有触发器的列表都存储在镜像清单中的OnBuild键下。可以使用<code>docker inspect</code>命令查看它们。稍后，可以使用FROM指令将该镜像用作新构建的基础镜像，作为处理FROM指令的一部分，下游构建器将查找ONBUILD触发器，并以与注册时相同的顺序执行它们。如果任何触发器失败，那么FROM指令将中止，从而导致构建失败。如果所有触发器都成功，则FROM指令完成，并且构建照常继续。执行完触发器后，将从最终镜像中清除触发器。换句话说，它们不是<code>孙子代</code>版本所继承的。</p><blockquote><p>❝</p><p><strong>「注意」</strong>：在ONBUILD指令中再指定ONBUILD指令是不允许的，ONBUILD指令可能不会触发FROM或者MAINTAINER指令</p><p>❞</p></blockquote><h2 id="15-STOPSIGNAL指令"><a href="#15-STOPSIGNAL指令" class="headerlink" title="15. STOPSIGNAL指令"></a>15. STOPSIGNAL指令</h2><p><code>STOPSIGNAL</code>指令用来设置系统发送给容器的退出信号，该信号可以是内核syscall表中对应的无符号数字，例如9，也可以是SIGNAME格式的信号名称，例如SIGKILL。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">STOPSIGNAL signal</span><br></pre></td></tr></table></figure><h2 id="16-HEALTHCHECK指令"><a href="#16-HEALTHCHECK指令" class="headerlink" title="16. HEALTHCHECK指令"></a>16. HEALTHCHECK指令</h2><p>HEALTHCHECK指令是用来做容器健康检查的，这个指令是在Docker 1.12版本被加入的，在早期版本中并不支持，这个指令可以让我们自定义容器健康状态检查的脚本或者命令。其格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HEALTHCHECK [OPTIONS] CMD command (check container health by running a command inside the container)</span><br><span class="line">HEALTHCHECK NONE (disable any healthcheck inherited from the base image)</span><br></pre></td></tr></table></figure><p>我们为什么需要这样一个指令呢？是因为我们的容器是根据启动命令是否运行来判断容器是否健康的，这就导致一个问题，有时我们的应用程序确实在运行，进程并没有退出，但是此时由于bug或其他原因导致程序已经无法正常对外提供服务，那么此时我们就需要用一个命令或者脚本来检测我们的服务，这就是这个指令存在的意义。</p><p><strong>「HEALTHCHECK指令的OPTIONS字段可以有如下几个选项：」</strong></p><ol><li><code>--interval=DURATION (default: 30s)</code> 健康检测的命令将在容器启动后的DURATION秒后开始第一次运行，然后每隔DURATION秒运行一次，DURATION默认值是30秒;</li><li><code>--timeout=DURATION (default: 30s)</code> 健康检测的命令的超时时间，默认30秒;</li><li><code>--start-period=DURATION (default: 0s)</code> 此选项设置了当容器启动后的DURATION秒后的健康检测如果失败，不计入重试次数，这是为了给容器一个初始化的时间。但是如果这段时间中一旦健康检测为正常，则之后即使在初始化时间内，健康检测如果失败，此时会计入重试次数，默认是0秒;</li><li><code>--retries=N (default: 3)</code> 健康检测的重试次数，重试N次后容器被判断为异常，则退出进程。</li></ol><blockquote><p>❝</p><p><strong>「注意」</strong>：在一个Dockerfile中只能有一个HEALTHCHECK指令，如果指定了多个指令，则只有最后一个指令生效。</p><p>❞</p></blockquote><p>CMD关键字之后的命令可以是shell命令（例如<code>HEALTHCHECK CMD /bin/check-running</code>）或exec数组（与其他Dockerfile命令一样;有关详细信息，请参见ENTRYPOINT）。</p><p><strong>「命令的退出状态指示容器的健康状态。可能的值为：」</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0：success-容器健康且可以使用</span><br><span class="line">1：unhealthy-容器无法正常工作</span><br><span class="line">2：reserved-请勿使用此退出码</span><br></pre></td></tr></table></figure><p>为了调试方便，健康检测的输出会被记录到健康状态内，我们可以通过docker inspect命令去查询，但是当前最多只能存储输出的前4096个字节，所以，健康检测的命令要尽可能简洁。</p><h2 id="17-SHELL指令"><a href="#17-SHELL指令" class="headerlink" title="17. SHELL指令"></a>17. SHELL指令</h2><p>SHELL指令允许覆盖用于命令的shell形式的默认shell。在Linux上，默认shell程序是<code>[&quot;/bin/sh&quot;,&quot;-c&quot;]</code>，在Windows上，默认shell程序是<code>[&quot;cmd&quot;,&quot;/S&quot;,&quot;/C&quot;]</code>。SHELL指令必须使用JSON形式编写。格式如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SHELL [&quot;executable&quot;, &quot;parameters&quot;]</span><br></pre></td></tr></table></figure><p>SHELL指令可以有多个，每个SHELL指令都会覆盖之前的设置，并且影响其之后的指令。SHELL指令也是在Docker 1.12版本中加入的，所以在更早期的版本中是不支持的。</p><h2 id="18-注意"><a href="#18-注意" class="headerlink" title="18. 注意"></a>18. 注意</h2><p><strong>「很重要:」</strong></p><p>在我们编写Dockerfile时，每一行指令就会生成一个镜像的层，所以，我们应该尽量将相同的操作都写在同一行中，而且我们依然可以使用<code>\</code>来换行，这还是会被当成一层来处理。这样做的好处是可以减小我们的镜像文件的大小，加快容器创建的速度。</p><h1 id="三、构建镜像"><a href="#三、构建镜像" class="headerlink" title="三、构建镜像"></a>三、构建镜像</h1><p>当我们写好了Dockerfile之后，我们就可以使用docker build命令来构建镜像了。命令如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker build [OPTIONS] PATH | URL | -</span><br></pre></td></tr></table></figure><p>在构建镜像时，我们可以添加各种参数来定制镜像，还可以直接为镜像打好标签。docker build命令支持的参数详见docker build命令官方文档，在此不再赘述。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Linux内核调优 </title>
      <link href="/2020/07/20/2020-07-20-linux-kernel-optimize/"/>
      <url>/2020/07/20/2020-07-20-linux-kernel-optimize/</url>
      
        <content type="html"><![CDATA[<p>以nginx 10k并发连接为优化目标，附简单介绍，不一一解释。</p><h3 id="tcp容量规划"><a href="#tcp容量规划" class="headerlink" title="tcp容量规划"></a>tcp容量规划</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_mem  = 262144  524288 786432</span><br><span class="line">net.core.wmem_max = 16777216</span><br><span class="line">net.core.wmem_default = 131072</span><br><span class="line">net.core.rmem_max = 16777216</span><br><span class="line">net.core.rmem_default = 131072</span><br><span class="line">net.ipv4.tcp_wmem = 4096    131072  16777216</span><br><span class="line">net.ipv4.tcp_rmem = 4096    131072  16777216</span><br></pre></td></tr></table></figure><p>**net.ipv4.tcp_mem ** 单位是内存页，一般是4k，三个值分别代表tcp内存使用的水平，低、中、高， 低表示无内存压力，中级表示内存压力状态，高表示内存吃紧，最高峰时系统将会拒绝分配内存。262144 代表1G内存，即（262144x4/1024/1024），其他类推。</p><p>下面的参数单位都是字节 net.core.wmem_max 和net.core.wmem_default 会覆盖net.ipv4.tcp_wmem 的第二第三个值， 同理，net.core.rmem_max 和 net.core.rmem_default 会覆盖net.ipv4.tcp_rmem 的第二第三个值。稍微提高tcp读写缓冲区的容量，可以增加tcp传输效率，比如上文默认值131072=128k，现有一个1M的文件传输，只需8次传输即可，比较适合图片类传输。但也不是越大越好，比如一个文字页面只有15k，使用128k的内存显然有些浪费。上文tcp压力状态下的容量为2G，对应tcp读写缓冲区128k，可应对的连接数为16384 (2048x1024/128)，可满足10k要求。</p><h3 id="tcp连接行为管理"><a href="#tcp连接行为管理" class="headerlink" title="tcp连接行为管理"></a>tcp连接行为管理</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line">net.ipv4.tcp_timestamps = 1</span><br><span class="line">net.ipv4.tcp_fin_timeout = 30</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 8192</span><br><span class="line">net.ipv4.tcp_retries1 = 3</span><br><span class="line">net.ipv4.tcp_retries2 = 5</span><br><span class="line">net.ipv4.tcp_keepalive_time = 1800</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 5</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 30</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 8192</span><br><span class="line">net.ipv4.tcp_max_orphans = 262144</span><br></pre></td></tr></table></figure><p>上面主要是tcp连接行为的伴随的参数，主要是tcp重用，增加队列，减少等待重试频率等等来提升效率。</p><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vm.swappiness = 5</span><br><span class="line">vm.dirty_ratio = 40</span><br><span class="line">vm.min_free_kbytes = 524288</span><br><span class="line">vm.vfs_cache_pressure = 100</span><br></pre></td></tr></table></figure><ul><li>vm.swappiness = 5 表示物理内存剩余5%时，才考虑使用swap，默认60，这显然非常不合理</li><li>•vm.dirty_ratio = 40 表示拿出物理内存的40%用于写缓存，而不立即将数据写入硬盘。由于硬盘是众所周知的瓶颈，扩大它可提升写的效率，40%是个比较合适的比例。</li><li>vm.min_free_kbytes = 524288 这个用于控制剩余内存的大小，524288=512M，可根据需要调整。如果某些任务临时需要大量内存，可临时将它调大然后调小，回收页面缓存。它比vm.drop_caches 要温和得多，后者更粗暴。</li><li>vm.vfs_cache_pressure = 100 ，如果要尽快将脏数据刷进硬盘，提高它，比如150 。</li></ul><h3 id="内核其他行为"><a href="#内核其他行为" class="headerlink" title="内核其他行为"></a>内核其他行为</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">net.core.somaxconn = 8192</span><br><span class="line">net.core.netdev_max_backlog = 8192</span><br><span class="line">net.ipv4.ip_local_port_range = 15000 65000</span><br><span class="line">net.netfilter.nf_conntrack_max = 131072</span><br><span class="line">net.nf_conntrack_max = 131072</span><br><span class="line">net.ipv6.conf.all.disable_ipv6 =1</span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_established =3600</span><br><span class="line">net.core.rps_sock_flow_entries = 32768</span><br></pre></td></tr></table></figure><p>net.core.somaxconn 表示socket的最大连接数，默认128，对于php-fpm使用unix socket情况下，需要调大。</p><p>net.netfilter.nf_conntrack_tcp_timeout_established = 3600 默认2天时间，多数情况下，调小这个参数是有益的，如果是tcp长连接，这个参数可能不太合适。</p><p>net.core.rps_sock_flow_entries 这个参数启用RPS，自动将网卡中断均匀分配到多个CPU，改进网卡性能和系统负载。</p><p>RPS还需要脚本配合</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for fileRfc in $(ls /sys/class/net/eth*/queues/rx-*/rps_flow_cnt);do echo 2048 &gt; $fileRfc;done</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Nginx日志配置详解 </title>
      <link href="/2020/07/20/2020-07-20-nginx-logs/"/>
      <url>/2020/07/20/2020-07-20-nginx-logs/</url>
      
        <content type="html"><![CDATA[<p><strong>前言</strong></p><p>Nginx日志对于统计、系统服务排错很有用。</p><p><strong>Nginx日志主要分为两种：</strong>access_log(访问日志)和error_log(错误日志)。通过访问日志我们可以得到用户的IP地址、浏览器的信息，请求的处理时间等信息。错误日志记录了访问出错的信息，可以帮助我们定位错误的原因。</p><p><strong>本文将详细描述一下如何配置Nginx日志。</strong></p><h2 id="设置access-log"><a href="#设置access-log" class="headerlink" title="设置access_log"></a><strong>设置access_log</strong></h2><p>访问日志主要记录客户端的请求。客户端向Nginx服务器发起的每一次请求都记录在这里。客户端IP，浏览器信息，referer，请求处理时间，请求URL等都可以在访问日志中得到。当然具体要记录哪些信息，你可以通过log_format指令定义。</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; # 设置访问日志</span><br><span class="line">access_log off; # 关闭访问日志</span><br></pre></td></tr></table></figure><blockquote><ul><li>path 指定日志的存放位置。</li><li>format 指定日志的格式。默认使用预定义的combined。</li><li>buffer 用来指定日志写入时的缓存大小。默认是64k。</li><li>gzip 日志写入前先进行压缩。压缩率可以指定，从1到9数值越大压缩比越高，同时压缩的速度也越慢。默认是1。</li><li>flush 设置缓存的有效时间。如果超过flush指定的时间，缓存中的内容将被清空。</li><li>if 条件判断。如果指定的条件计算为0或空字符串，那么该请求不会写入日志。</li></ul></blockquote><p>另外，还有一个特殊的值off。如果指定了该值，当前作用域下的所有的请求日志都被关闭。</p><h3 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h3><p>可以应用access_log指令的作用域分别有http，server，location，limit_except。也就是说，在这几个作用域外使用该指令，Nginx会报错。</p><p>以上是access_log指令的基本语法和参数的含义。下面我们看一几个例子加深一下理解。</p><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">access_log /var/logs/nginx-access.log</span><br></pre></td></tr></table></figure><p>该例子指定日志的写入路径为/var/logs/nginx-access.log，日志格式使用默认的combined。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">access_log /var/logs/nginx-access.log buffer=32k gzip flush=1m</span><br></pre></td></tr></table></figure><p>该例子指定日志的写入路径为/var/logs/nginx-access.log，日志格式使用默认的combined，指定日志的缓存大小为32k，日志写入前启用gzip进行压缩，压缩比使用默认值1，缓存数据有效时间为1分钟。</p><h2 id="使用log-format自定义日志格式"><a href="#使用log-format自定义日志格式" class="headerlink" title="使用log_format自定义日志格式"></a><strong>使用log_format自定义日志格式</strong></h2><p>Nginx预定义了名为combined日志格式，如果没有明确指定日志格式默认使用该格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">log_format combined &#x27;$remote_addr - $remote_user [$time_local] &#x27;</span><br><span class="line">                    &#x27;&quot;$request&quot; $status $body_bytes_sent &#x27;</span><br><span class="line">                    &#x27;&quot;$http_referer&quot; &quot;$http_user_agent&quot;&#x27;;</span><br></pre></td></tr></table></figure><p>如果不想使用Nginx预定义的格式，可以通过log_format指令来自定义。</p><h3 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">log_format name [escape=default|json] string ...;</span><br></pre></td></tr></table></figure><blockquote><ul><li>name 格式名称。在access_log指令中引用。</li><li>escape 设置变量中的字符编码方式是json还是default，默认是default。</li><li>string 要定义的日志格式内容。该参数可以有多个。参数中可以使用Nginx变量。</li></ul></blockquote><p>下面是log_format指令中常用的一些变量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">$bytes_sent</span><br><span class="line">发送给客户端的总字节数</span><br><span class="line"></span><br><span class="line">$body_bytes_sent</span><br><span class="line">发送给客户端的字节数，不包括响应头的大小</span><br><span class="line"></span><br><span class="line">$connection</span><br><span class="line">连接序列号</span><br><span class="line"></span><br><span class="line">$connection_requests</span><br><span class="line">当前通过连接发出的请求数量</span><br><span class="line"></span><br><span class="line">$msec</span><br><span class="line">日志写入时间，单位为秒，精度是毫秒</span><br><span class="line"></span><br><span class="line">$pipe</span><br><span class="line">如果请求是通过http流水线发送，则其值为&quot;p&quot;，否则为“.&quot;</span><br><span class="line"></span><br><span class="line">$request_length</span><br><span class="line">请求长度（包括请求行，请求头和请求体）</span><br><span class="line"></span><br><span class="line">$request_time</span><br><span class="line">请求处理时长，单位为秒，精度为毫秒，从读入客户端的第一个字节开始，直到把最后一个字符发送张客户端进行日志写入为止</span><br><span class="line"></span><br><span class="line">$status</span><br><span class="line">响应状态码</span><br><span class="line"></span><br><span class="line">$time_iso8601</span><br><span class="line">标准格式的本地时间,形如“2017-05-24T18:31:27+08:00”</span><br><span class="line"></span><br><span class="line">$time_local</span><br><span class="line">通用日志格式下的本地时间，如&quot;24/May/2017:18:31:27 +0800&quot;</span><br><span class="line"></span><br><span class="line">$http_referer</span><br><span class="line">请求的referer地址。</span><br><span class="line"></span><br><span class="line">$http_user_agent</span><br><span class="line">客户端浏览器信息。</span><br><span class="line"></span><br><span class="line">$remote_addr</span><br><span class="line">客户端IP</span><br><span class="line"></span><br><span class="line">$http_x_forwarded_for</span><br><span class="line">当前端有代理服务器时，设置web节点记录客户端地址的配置，此参数生效的前提是代理服务器也要进行相关的x_forwarded_for设置。</span><br><span class="line"></span><br><span class="line">$request</span><br><span class="line">完整的原始请求行，如 &quot;GET / HTTP/1.1&quot;</span><br><span class="line"></span><br><span class="line">$remote_user</span><br><span class="line">客户端用户名称，针对启用了用户认证的请求</span><br><span class="line"></span><br><span class="line">$request_uri</span><br><span class="line">完整的请求地址，如 &quot;https://daojia.com/&quot;</span><br></pre></td></tr></table></figure><p>下面演示一下自定义日志格式的使用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">access_log /var/logs/nginx-access.log main</span><br><span class="line">log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span><br><span class="line">                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span><br><span class="line">                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;</span><br></pre></td></tr></table></figure><p>我们使用log_format指令定义了一个main的格式，并在access_log指令中引用了它。假如客户端有发起请求：<a href="https://suyunfe.com/%EF%BC%8C%E6%88%91%E4%BB%AC%E7%9C%8B%E4%B8%80%E4%B8%8B%E6%88%91%E6%88%AA%E5%8F%96%E7%9A%84%E4%B8%80%E4%B8%AA%E8%AF%B7%E6%B1%82%E7%9A%84%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95">https://suyunfe.com/，我们看一下我截取的一个请求的日志记录</a>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">112.195.209.90 - - [20/Feb/2018:12:12:14 +0800]</span><br><span class="line">&quot;GET / HTTP/1.1&quot; 200 190 &quot;-&quot; &quot;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N)</span><br><span class="line">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Mobile Safari/537.36&quot; &quot;-&quot;</span><br></pre></td></tr></table></figure><p>我们看到最终的日志记录中<code>$remote_user</code>、<code>$http_referer</code>、<code>$http_x_forwarded_for</code>都对应了一个<code>-</code>，这是因为这几个变量为空。</p><h2 id="设置error-log"><a href="#设置error-log" class="headerlink" title="设置error_log"></a><strong>设置error_log</strong></h2><p>错误日志在Nginx中是通过error_log指令实现的。该指令记录服务器和请求处理过程中的错误信息。</p><h3 id="语法-2"><a href="#语法-2" class="headerlink" title="语法"></a>语法</h3><p>配置错误日志文件的路径和日志级别。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">error_log file [level];</span><br><span class="line">Default:</span><br><span class="line">error_log logs/error.log error;</span><br></pre></td></tr></table></figure><p>第一个参数指定日志的写入位置。</p><p>第二个参数指定日志的级别。level可以是debug, info, notice, warn, error, crit, alert,emerg中的任意值。可以看到其取值范围是按紧急程度从低到高排列的。只有日志的错误级别等于或高于level指定的值才会写入错误日志中。默认值是error。</p><h3 id="基本用法-1"><a href="#基本用法-1" class="headerlink" title="基本用法"></a>基本用法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error_log /var/logs/nginx/nginx-error.log</span><br></pre></td></tr></table></figure><p>它可以配置在：main， http, mail, stream, server, location作用域。</p><p>例子中指定了错误日志的路径为：<code>/var/logs/nginx/nginx-error.log</code>，日志级别使用默认的error。</p><h2 id="open-log-file-cache"><a href="#open-log-file-cache" class="headerlink" title="open_log_file_cache"></a><strong>open_log_file_cache</strong></h2><p>每一条日志记录的写入都是先打开文件再写入记录，然后关闭日志文件。如果你的日志文件路径中使用了变量，如<code>access_log /var/logs/$host/nginx-access.log</code>，为提高性能，可以使用open_log_file_cache指令设置日志文件描述符的缓存。</p><h3 id="语法-3"><a href="#语法-3" class="headerlink" title="语法"></a>语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];</span><br></pre></td></tr></table></figure><blockquote><ul><li>max 设置缓存中最多容纳的文件描述符数量，如果被占满，采用LRU算法将描述符关闭。</li><li>inactive 设置缓存存活时间，默认是10s。</li><li>min_uses 在inactive时间段内，日志文件最少使用几次，该日志文件描述符记入缓存，默认是1次。</li><li>valid：设置多久对日志文件名进行检查，看是否发生变化，默认是60s。</li><li>off：不使用缓存。默认为off。</li></ul></blockquote><h3 id="基本用法-2"><a href="#基本用法-2" class="headerlink" title="基本用法"></a>基本用法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open_log_file_cache max=1000 inactive=20s valid=1m min_uses=2;</span><br></pre></td></tr></table></figure><p>它可以配置在http、server、location作用域中。</p><p>例子中，设置缓存最多缓存1000个日志文件描述符，20s内如果缓存中的日志文件描述符至少被被访问2次，才不会被缓存关闭。每隔1分钟检查缓存中的文件描述符的文件名是否还存在。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>Nginx中通过access_log和error_log指令配置访问日志和错误日志，通过log_format我们可以自定义日志格式。如果日志文件路径中使用了变量，我们可以通过open_log_file_cache指令来设置缓存，提升性能。</p><p>另外，在access_log和log_format中使用了很多变量，这些变量没有一一列举出来，详细的变量信息可以参考Nginx官方文档：<a href="http://nginx.org/en/docs/varindex.html">http://nginx.org/en/docs/varindex.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 用户访问网站慢，排查思路 </title>
      <link href="/2020/07/01/2020-07-01-user-slow-server/"/>
      <url>/2020/07/01/2020-07-01-user-slow-server/</url>
      
        <content type="html"><![CDATA[<p>当出现网站慢的时候我们脑子中要映出几点原因：</p><p>1.程序代码执行方面</p><p>2.大量数据库操作</p><p>3.域名DNS解析问题</p><p>4.服务器环境</p><p>5.网络的带宽</p><p>6.用许多javascript特效</p><p>7.访问的东西大</p><p>8.系统资源不足</p><p>9.防火墙的过多使用</p><p>10.网络中某个端口形成了瓶颈导致网速变慢</p><p>\1.打开访问慢的网站观察下情况，通过火狐的fixfox 插件 或者 IE的元素查看工具，你网站里面加载的信息会一览无遗的展现出来，并且那些元素加载耗时多少秒等等情况，如何解决能，把远程耗时久的js下载到本地，或者直接删除。</p><p>\2. 我看了下页面中有多处连接数据库操作的地方，并且有远程的数据库操作，并且还有多余的数据库连接代码，话不多说，改之.</p><p>   解决完了发现的确是快点了，但是还是不理想，于是我把页面执行数据库代码放到了数据库中执行没有耗慢的情况。</p><p>\3. 关于域名DNS的情况只是其中一种情况，不要急着找域名商的问题，你可以写个没有数据操作的页面放在同台服务器域名下，看看是不是访问同样慢，如果是才有可能，你还要让你周围的人也看看，最好别是你同公司的人。</p><p>\4. 我来看看服务器的情况吧，是不是CPU使用率过高造成的呢。</p><p>   a. top  发现cpu使用也不高啊，30% 左右，但是发现一个问题，sleeping 的进程数比较多。擦，最好别是僵尸进程，现在这样的东西不多了。</p><p>   b. 查看了下timewait的量: 发现有mysqld 和 httpd 的，大部分来自于 httpd  ； 命令 netstat -ae|grep TIME_WAIT</p><pre><code>  如何来解决timewait的量问题呢？</code></pre><p>TIME_WAIT解决办法：</p><p>vi /etc/sysctl.conf</p><p>编辑文件，加入以下内容：<br>net.ipv4.tcp_syncookies = 1<br>net.ipv4.tcp_tw_reuse = 1<br>net.ipv4.tcp_tw_recycle = 1<br>net.ipv4.tcp_fin_timeout = 30<br>net.ipv4.tcp_keepalive_time = 30  保持连接的时间<br>net.ipv4.tcp_max_tw_buckets = 100 这个是设置服务器同时保持的time_wait的数目</p><p>然后执行 /sbin/sysctl -p 让参数生效。</p><p>如果还不够满意可以 再设置下Ulimit参数<br>cat &gt;&gt;/etc/security/limits.conf&lt;&lt;EOF<br>* soft nofile 655350<br>* hard nofile 655350<br>EOF<br>然后ulimit -SHn 了 让生效。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Linux top命令参数详解 </title>
      <link href="/2020/06/29/2020-06-29-linux-top/"/>
      <url>/2020/06/29/2020-06-29-linux-top/</url>
      
        <content type="html"><![CDATA[<h3 id="一、top前5行统计信息"><a href="#一、top前5行统计信息" class="headerlink" title="一、top前5行统计信息"></a>一、top前5行统计信息</h3><p><strong>第1行：top - 05:43:27 up 4:52, 2 users, load average: 0.58, 0.41, 0.30</strong><br>第1行是任务队列信息，其参数如下：</p><table><thead><tr><th align="left">内容</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">05:43:27</td><td align="left">表示当前时间</td></tr><tr><td align="left">up 4:52</td><td align="left">系统运行时间 格式为时：分</td></tr><tr><td align="left">2 users</td><td align="left">当前登录用户数</td></tr><tr><td align="left">load average: 0.58, 0.41, 0.30</td><td align="left">系统负载，即任务队列的平均长度。 三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。</td></tr></tbody></table><p>load average: 如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。</p><p><strong>第2行：Tasks: 159 total, 1 running, 158 sleeping, 0 stopped, 0 zombie</strong><br><strong>第3行：%Cpu(s): 37.0 us, 3.7 sy, 0.0 ni, 59.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st</strong><br>第2、3行为进程和CPU的信息<br>当有多个CPU时，这些内容可能会超过两行，其参数如下：</p><table><thead><tr><th align="left">内容</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">159 total</td><td align="left">进程总数</td></tr><tr><td align="left">1 running</td><td align="left">正在运行的进程数</td></tr><tr><td align="left">158 sleeping</td><td align="left">睡眠的进程数</td></tr><tr><td align="left">0 stopped</td><td align="left">停止的进程数</td></tr><tr><td align="left">0 zombie</td><td align="left">僵尸进程数</td></tr><tr><td align="left">37.0 us</td><td align="left">用户空间占用CPU百分比</td></tr><tr><td align="left">3.7 sy</td><td align="left">内核空间占用CPU百分比</td></tr><tr><td align="left"><strong>0.0 ni</strong></td><td align="left">用户进程空间内改变过优先级的进程占用CPU百分比</td></tr><tr><td align="left">59.3 id</td><td align="left">空闲CPU百分比</td></tr><tr><td align="left">0.0 wa</td><td align="left">等待输入输出的CPU时间百分比</td></tr><tr><td align="left"><strong>0.0 hi</strong></td><td align="left">硬中断（Hardware IRQ）占用CPU的百分比</td></tr><tr><td align="left"><strong>0.0 si</strong></td><td align="left">软中断（Software Interrupts）占用CPU的百分比</td></tr><tr><td align="left"><strong>0.0 st</strong></td><td align="left"></td></tr></tbody></table><p>第4行：KiB Mem: 1530752 total, 1481968 used, 48784 free, 70988 buffers<br>第5行：KiB Swap: 3905532 total, 267544 used, 3637988 free. 617312 cached Mem<br>第4、5行为内存信息<br>其参数如下：</p><table><thead><tr><th align="left">内容</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">KiB Mem: 1530752 total</td><td align="left">物理内存总量</td></tr><tr><td align="left">1481968 used</td><td align="left">使用的物理内存总量</td></tr><tr><td align="left">48784 free</td><td align="left">空闲内存总量</td></tr><tr><td align="left">70988 buffers（buff/cache）</td><td align="left">用作内核缓存的内存量</td></tr><tr><td align="left">KiB Swap: 3905532 total</td><td align="left">交换区总量</td></tr><tr><td align="left">267544 used</td><td align="left">使用的交换区总量</td></tr><tr><td align="left">3637988 free</td><td align="left">空闲交换区总量</td></tr><tr><td align="left">617312 cached Mem</td><td align="left">缓冲的交换区总量。</td></tr><tr><td align="left">3156100 avail Mem</td><td align="left">代表可用于进程下一次分配的物理内存数量</td></tr></tbody></table><p>上述最后提到的缓冲的交换区总量，这里解释一下，所谓缓冲的交换区总量，即内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，该数值即为这些内容已存在于内存中的交换区的大小。相应的内存再次被换出时可不必再对交换区写入。</p><p>计算可用内存数有一个近似的公式：<br>第四行的free + 第四行的buffers + 第五行的cached</p><h3 id="二、进程信息"><a href="#二、进程信息" class="headerlink" title="二、进程信息"></a>二、进程信息</h3><table><thead><tr><th align="left">列名</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">PID</td><td align="left">进程id</td></tr><tr><td align="left">PPID</td><td align="left">父进程id</td></tr><tr><td align="left">RUSER</td><td align="left">Real user name</td></tr><tr><td align="left">UID</td><td align="left">进程所有者的用户id</td></tr><tr><td align="left">USER</td><td align="left">进程所有者的用户名</td></tr><tr><td align="left">GROUP</td><td align="left">进程所有者的组名</td></tr><tr><td align="left">TTY</td><td align="left">启动进程的终端名。不是从终端启动的进程则显示为 ?</td></tr><tr><td align="left">PR</td><td align="left">优先级</td></tr><tr><td align="left">NI</td><td align="left">nice值。负值表示高优先级，正值表示低优先级</td></tr><tr><td align="left">P</td><td align="left">最后使用的CPU，仅在多CPU环境下有意义</td></tr><tr><td align="left">%CPU</td><td align="left">上次更新到现在的CPU时间占用百分比</td></tr><tr><td align="left">TIME</td><td align="left">进程使用的CPU时间总计，单位秒</td></tr><tr><td align="left">TIME+</td><td align="left">进程使用的CPU时间总计，单位1/100秒</td></tr><tr><td align="left">%MEM</td><td align="left">进程使用的物理内存百分比</td></tr><tr><td align="left">VIRT</td><td align="left">进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES</td></tr><tr><td align="left">SWAP</td><td align="left">进程使用的虚拟内存中，被换出的大小，单位kb</td></tr><tr><td align="left">RES</td><td align="left">进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</td></tr><tr><td align="left">CODE</td><td align="left">可执行代码占用的物理内存大小，单位kb</td></tr><tr><td align="left">DATA</td><td align="left">可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb</td></tr><tr><td align="left">SHR</td><td align="left">共享内存大小，单位kb</td></tr><tr><td align="left">nFLT</td><td align="left">页面错误次数</td></tr><tr><td align="left">nDRT</td><td align="left">最后一次写入到现在，被修改过的页面数。</td></tr><tr><td align="left">S</td><td align="left">进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程</td></tr><tr><td align="left">COMMAND</td><td align="left">命令名/命令行</td></tr><tr><td align="left">WCHAN</td><td align="left">若该进程在睡眠，则显示睡眠中的系统函数名</td></tr><tr><td align="left">Flags</td><td align="left">任务标志</td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> kafka和各MQ的优劣对比 </title>
      <link href="/2020/06/29/2020-06-29-kafka-vs-mq/"/>
      <url>/2020/06/29/2020-06-29-kafka-vs-mq/</url>
      
        <content type="html"><![CDATA[<h1 id="目前在业界有哪些比较知名的消息引擎"><a href="#目前在业界有哪些比较知名的消息引擎" class="headerlink" title="目前在业界有哪些比较知名的消息引擎"></a>目前在业界有哪些比较知名的消息引擎</h1><ul><li>ZeroMQ</li><li>推特的Distributedlog</li><li>ActiveMQ：Apache旗下的老牌消息引擎</li><li>RabbitMQ、Kafka</li><li>RocketMQ</li><li>Artemis：Apache的ActiveMQ下的子项目</li><li>Apollo：同样为Apache的ActiveMQ的子项目的号称下一代消息引擎</li><li>商业化的消息引擎IronMQ</li><li>以及实现了JMS(Java Message Service)标准的OpenMQ。</li></ul><h1 id="MQ消息队列的技术应用场景"><a href="#MQ消息队列的技术应用场景" class="headerlink" title="MQ消息队列的技术应用场景"></a>MQ消息队列的技术应用场景</h1><p><strong>1. 解耦</strong><br>   解耦是消息队列要解决的最本质问题。</p><p><strong>2. 最终一致性</strong><br>   最终一致性指的是<strong>两个系统的状态保持一致，要么都成功，要么都失败</strong>。最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。</p><p><strong>2. 广播</strong><br>   <strong>消息队列的基本功能之一是进行广播。</strong>有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。</p><p><strong>3. 错峰与流控</strong><br>   典型的使用场景就是秒杀业务用于流量削峰场景。</p><h1 id="Kafka、RocketMQ、RabbitMQ简单比较"><a href="#Kafka、RocketMQ、RabbitMQ简单比较" class="headerlink" title="Kafka、RocketMQ、RabbitMQ简单比较"></a>Kafka、RocketMQ、RabbitMQ简单比较</h1><h2 id="1-ActiveMQ"><a href="#1-ActiveMQ" class="headerlink" title="1. ActiveMQ"></a>1. ActiveMQ</h2><ul><li>优点<br>单机吞吐量：万级<br>topic数量都吞吐量的影响：<br>时效性：ms级<br>可用性：高，基于主从架构实现高可用性<br>消息可靠性：有较低的概率丢失数据<br>功能支持：MQ领域的功能极其完备</li><li>缺点<br>官方社区现在对ActiveMQ 5.x维护越来越少，较少在大规模吞吐的场景中使用。</li></ul><h2 id="2-Kafka"><a href="#2-Kafka" class="headerlink" title="2. Kafka"></a>2. Kafka</h2><p>   号称大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开Kafka，这款为大数据而生的消息中间件，以其百万级TPS的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。<br>Apache Kafka它最初由LinkedIn公司基于独特的设计实现为一个分布式的提交日志系统( a distributed commit log)，之后成为Apache项目的一部分。<br>目前已经被LinkedIn，Uber, Twitter, Netflix等大公司所采纳。</p><ul><li>优点<br>性能卓越，单机写入TPS约在百万条/秒，最大的优点，就是吞吐量高。<br>时效性：ms级<br>可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用<br>消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;<br>有优秀的第三方Kafka Web管理界面Kafka-Manager；<br>在日志领域比较成熟，被多家公司和多个开源项目使用；<br>功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用</li><li>缺点<br>Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长<br>使用短轮询方式，实时性取决于轮询间隔时间；<br>消费失败不支持重试；<br>支持消息顺序，但是一台代理宕机后，就会产生消息乱序；<br>社区更新较慢；</li></ul><h2 id="3-RabbitMQ"><a href="#3-RabbitMQ" class="headerlink" title="3. RabbitMQ"></a>3. RabbitMQ</h2><p>   RabbitMQ 2007年发布，是一个在AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。</p><ul><li>优点<br>由于erlang语言的特性，mq 性能较好，高并发；<br>吞吐量到万级，MQ功能比较完备<br>健壮、稳定、易用、跨平台、支持多种语言、文档齐全；<br>开源提供的管理界面非常棒，用起来很好用<br>社区活跃度高；</li><li>缺点<br>erlang开发，很难去看懂源码，基本职能依赖于开源社区的快速维护和修复bug，不利于做二次开发和维护。<br>RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。<br>需要学习比较复杂的接口和协议，学习和维护成本较高。</li></ul><h2 id="4-RocketMQ"><a href="#4-RocketMQ" class="headerlink" title="4. RocketMQ"></a>4. RocketMQ</h2><p>   RocketMQ出自 阿里公司的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。<br>   RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。</p><ul><li>优点<br>单机吞吐量：十万级<br>可用性：非常高，分布式架构<br>消息可靠性：经过参数优化配置，消息可以做到0丢失<br>功能支持：MQ功能较为完善，还是分布式的，扩展性好<br>支持10亿级别的消息堆积，不会因为堆积导致性能下降<br>源码是java，我们可以自己阅读源码，定制自己公司的MQ，可以掌控</li><li>缺点<br>支持的客户端语言不多，目前是java及c++，其中c++不成熟；<br>社区活跃度一般<br>没有在 mq 核心中去实现JMS等接口，有些系统要迁移需要修改大量代码</li></ul><h1 id="消息队列选择建议"><a href="#消息队列选择建议" class="headerlink" title="消息队列选择建议"></a>消息队列选择建议</h1><h2 id="1-Kafka"><a href="#1-Kafka" class="headerlink" title="1. Kafka"></a>1. Kafka</h2><p>   Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。<br>大型公司建议可以选用，如果有日志采集功能，肯定是首选kafka了。</p><h2 id="2-RocketMQ"><a href="#2-RocketMQ" class="headerlink" title="2. RocketMQ"></a>2. RocketMQ</h2><p>   天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。<br>RoketMQ在稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择RocketMQ。</p><h2 id="3-RabbitMQ-1"><a href="#3-RabbitMQ-1" class="headerlink" title="3. RabbitMQ"></a>3. RabbitMQ</h2><p>   RabbitMQ :结合erlang语言本身的并发优势，性能较好，社区活跃度也比较高，但是不利于做二次开发和维护。不过，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug。</p><p>   如果你的数据量没有那么大，小公司优先选择功能比较完备的RabbitMQ。</p><p>本文转载，原文地址： <a href="https://links.jianshu.com/go?to=http://youzhixueyuan.com/comparison-of-kafka-rocketmq-rabbitmq.html">高并发架构系列：Kafka、RocketMQ、RabbitMQ的优劣势比较</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> linux运维面试问题总结 </title>
      <link href="/2020/06/29/2020-06-29-linux-devops/"/>
      <url>/2020/06/29/2020-06-29-linux-devops/</url>
      
        <content type="html"><![CDATA[<h3 id="K8S集群组件及作用"><a href="#K8S集群组件及作用" class="headerlink" title="K8S集群组件及作用"></a>K8S集群组件及作用</h3><ul><li><p><strong>API Server</strong>：集群资源操作的唯一入口，结果存储在etcd中</p></li><li><p><strong>etcd</strong>：保存集群的配置信息和各种资源的状态信息</p></li><li><p><strong>Controller Manager</strong>：责管理集群各种资源，保证资源处于预期的状态，Controller Manager由多种controller组成，包括replication controller、endpoints controller、namespace controller、serviceaccounts controller等</p></li><li><p><strong>Schedule</strong>：资源调度，负责决定将Pod放到哪个Node上运行</p></li><li><p><strong>Kubelet</strong>：创建和运行schedule调度过来的Pod，并向master报告运行状态</p></li><li><p><strong>Kube-proxy</strong>：负责将访问的service的数据流转发到后端的容器</p></li><li><p>网络组件：flannel，calico</p></li></ul><h3 id="K8S-CNI组件及其原理"><a href="#K8S-CNI组件及其原理" class="headerlink" title="K8S CNI组件及其原理"></a>K8S CNI组件及其原理</h3><ul><li><strong>flannel</strong></li></ul><p>Flannel 是一个overlay网络，工作在二层网络，flanneld进程会使用VXLAN协议把原始IP包加上目的MAC地址封装成二层数据帧，由linux内核把数据帧封装成UDP报文经过物理网络发送到另一台机器，然后另外一台机flanneld进行解包操作。</p><p>host-gw模式：直接把节点作为一个网关，比如节点node-02上的pod子网是10.64.1.0/24，那么集群中所有节点上都会增加一条路由指向node-02，要求宿主机在同一个二层网络</p><ul><li><strong>calico</strong></li></ul><p>Calico是一个基于BGP的纯三层的网络方案，Calico在每个计算节点都利用Linux Kernel实现了一个高效的vRouter来负责数据转发。每个vRouter都通过BGP1协议把在本节点上运行的容器的路由信息向整个Calico网络广播，并自动设置到达其他节点的路由转发规则，没有额外的封包解包，能够节约CPU运算，提高网络效率。</p><h3 id="K8S-pod之间无法通信，排查思路"><a href="#K8S-pod之间无法通信，排查思路" class="headerlink" title="K8S pod之间无法通信，排查思路"></a>K8S pod之间无法通信，排查思路</h3><p>跨主机pod之间无法通信：</p><ul><li><p>iptables问题，执行命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">iptables -P FORWARD ACCEPT</span><br><span class="line">iptables -P INPUT ACCEPT</span><br></pre></td></tr></table></figure></li><li><p>docker配置问题，没连上flannel</p></li></ul><h3 id="kube-proxy的三种代理模式及原理"><a href="#kube-proxy的三种代理模式及原理" class="headerlink" title="kube-proxy的三种代理模式及原理"></a>kube-proxy的三种代理模式及原理</h3><ul><li><p><strong>userspace：</strong></p><p>1、为每个service在node上打开一个随机端口（代理端口）</p><p>2、建立iptables规则，将clusterip的请求重定向到代理端口</p><p>3、到达代理端口（用户空间）的请求再由kubeproxy转发到后端pod。</p><p>这里为什么需要建iptables规则，因为kube-proxy 监听的端口在用户空间，所以需要一层 iptables 把访问服务的连接重定向给 kube-proxy 服务，这里就存在内核态到用户态的切换，代价很大，因此就有了iptables。</p></li><li><p><strong>iptables：</strong></p><p>iptables由kube-proxy动态的管理，kube-proxy不再负责转发，数据包的走向完全由iptables规则决定，这样的过程不存在内核态到用户态的切换，效率明显会高很多。但是随着service的增加，iptables规则会不断增加，导致内核十分繁忙</p></li><li><p><strong>ipvs：</strong></p><p>用ipset存储iptables规则，这样规则的数量就能够得到有效控制，而在查找时就类似hash表的查找</p></li></ul><h3 id="kube-proxy挂掉的影响"><a href="#kube-proxy挂掉的影响" class="headerlink" title="kube-proxy挂掉的影响"></a>kube-proxy挂掉的影响</h3><p>service的访问请求将不会转发到Pod上，用户无法访问</p><h3 id="k8s-service涉及到的组件"><a href="#k8s-service涉及到的组件" class="headerlink" title="k8s service涉及到的组件"></a>k8s service涉及到的组件</h3><p>kube-proxy、pod、Replication Controller</p><h3 id="ingress和service的区别"><a href="#ingress和service的区别" class="headerlink" title="ingress和service的区别"></a>ingress和service的区别</h3><p>Service可以看作是一组提供相同服务的Pod对外的访问接口。借助Service，应用可以方便地实现服务发现和负载均衡。Ingress 是全局的，为了代理不同后端 Service 而设置的负载均衡服务。</p><p>Service 有三种对外暴露的方法，但是由于每个 Service 都要有一个负载均衡的服务，所以采用 Service 的话，会造成既浪费成本又高的现象。而ingress是一个全局的负载均衡器,然后我只需要通过访问 URL 就可以把请求转发给不同的后端 Service ，从而可以访问到界面，而不是每个 Service 都需要负载均衡。</p><h3 id="k8s设置node节点污点"><a href="#k8s设置node节点污点" class="headerlink" title="k8s设置node节点污点"></a>k8s设置node节点污点</h3><p>kubectl taint node [node] key=value[effect]<br>     其中[effect] 可取值: [ NoSchedule | PreferNoSchedule | NoExecute ]<br>      NoSchedule: 一定不能被调度<br>      PreferNoSchedule: 尽量不要调度<br>      NoExecute: 不仅不会调度, 还会驱逐Node上已有的Pod</p><h3 id="k8s的pause容器有什么用"><a href="#k8s的pause容器有什么用" class="headerlink" title="k8s的pause容器有什么用"></a>k8s的pause容器有什么用</h3><p>pod内的其他容器会共用pause容器的网络栈和存储卷，保证pod内的其他容器的端口不能冲突，彼此都是通过localhost就可以访问，扮演PID1的角色,并在子进程称为”孤儿进程”的时候,通过调用wait()收割这个子进程,这样就不用担心我们的Pod的PID namespace里会堆满僵尸进程了。</p><h3 id="kubernetes中的pause容器主要为每个业务容器提供以下功能："><a href="#kubernetes中的pause容器主要为每个业务容器提供以下功能：" class="headerlink" title="kubernetes中的pause容器主要为每个业务容器提供以下功能："></a>kubernetes中的pause容器主要为每个业务容器提供以下功能：</h3><p>PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID。</p><p>网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围。</p><p>IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信。</p><p>UTS命名空间：Pod中的多个容器共享一个主机名；Volumes（共享存储卷）：</p><p>Pod中的各个容器可以访问在Pod级别定义的Volumes。</p><h3 id="K8S-PLEG错误处理"><a href="#K8S-PLEG错误处理" class="headerlink" title="K8S PLEG错误处理"></a>K8S PLEG错误处理</h3><p><strong>问题</strong>：k8s node节点显示 no ready</p><p><strong>过程1</strong>：pleg是pod生命周期事件生成器，pleg在每次迭代检查中会 调用docker ps来检测容器状态的变化，并调用docker Inspect来获取这些容器的详细信息。在完成每次迭代之后，它更新一个时间戳。如果时间戳有一段时间没有更新(即3分钟)，则运行状况检查失败。</p><p><strong>过程2</strong>：执行docker ps果然很慢</p><p><strong>解决</strong>：因为是测试环境，跑了太多的pod，机器资源已被占用满，重启了机器，执行systemctl daemon-reexec，</p><p>临时解决了，systemctl的一个小bug。</p><h3 id="Mysql-主从不同步检查思路"><a href="#Mysql-主从不同步检查思路" class="headerlink" title="Mysql 主从不同步检查思路"></a>Mysql 主从不同步检查思路</h3><p>1、master，slave节点个执行show master status查看，如果有NO，重新做主从</p><p>2、也可能是在slave上进行了写操作，或者slave机器重启，或者事务回滚</p><p>3、解决方法：停掉主从同步，忽略一次错误，再开启同步：</p><h3 id="Mysql备份方案"><a href="#Mysql备份方案" class="headerlink" title="Mysql备份方案"></a>Mysql备份方案</h3><p>每三天做全量备份，中间每天做增量，增量根据position值或者时间点进行备份</p><h3 id="nginx状态码"><a href="#nginx状态码" class="headerlink" title="nginx状态码"></a>nginx状态码</h3><p>301 永久重定向</p><p>302 临时重定向</p><p>403 服务器拒绝请求</p><p>404 访问的资源不存咋</p><p>500 服务器内部错误</p><p>502 错误网关</p><p>503 服务不可达</p><h3 id="nginx获取用户真实ip"><a href="#nginx获取用户真实ip" class="headerlink" title="nginx获取用户真实ip"></a>nginx获取用户真实ip</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">proxy_set_header   Host             $host;</span><br><span class="line">proxy_set_header   X-Real-IP        $remote_addr;</span><br><span class="line">proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;</span><br><span class="line">set_real_ip_from 0.0.0.0/0;         # 额外增加的配置</span><br><span class="line">real_ip_header  X-Forwarded-For;    # 额外增加的配置</span><br><span class="line">real_ip_recursive   on;             # 额外增加的配置</span><br></pre></td></tr></table></figure><h3 id="端口time-wait解决"><a href="#端口time-wait解决" class="headerlink" title="端口time_wait解决"></a>端口time_wait解决</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。</span><br><span class="line">net.ipv4.tcp_fin_timeout 修改系默认的 TIMEOUT 时间</span><br></pre></td></tr></table></figure><h3 id="linux系统执行命令很卡"><a href="#linux系统执行命令很卡" class="headerlink" title="linux系统执行命令很卡"></a>linux系统执行命令很卡</h3><ul><li>top命令查看系统资源使用情况，cpu、内存、负载</li><li>iostat命令查看磁盘IO使用情况</li></ul><h3 id="shell脚本的变量"><a href="#shell脚本的变量" class="headerlink" title="shell脚本的变量"></a>shell脚本的变量</h3><p>$0  文件名及路径</p><p>$1,$2  参数1，参数2</p><p>$#  传递给脚本或函数的参数个数</p><p>$$  当前Shell进程ID</p><p>$?  判断上个命令的执行成功与否，0为成功。</p><p>$@  传递脚本或函数的所有参数</p><p>$*  传递脚本或函数的所有参数</p><h3 id="linux-cpu-负载概念"><a href="#linux-cpu-负载概念" class="headerlink" title="linux cpu 负载概念"></a>linux cpu 负载概念</h3><p>这些数据来自于文件/proc/loadavg，内核会负责统计出这些数据。<br>top和uptime命令显示的内容就来自于这个文件，根据proc的帮助文件可知，这里的值就是单位时间内处于运行状态以及等待磁盘 I/O状态的平均job数量。这里的运行状态和job都是内核的概念，这里进行说明：<br>1、 对于内核而言，进程和线程都是job<br>2、 job处于运行状态指job处于内核的运行队列中，正在或等待被CPU调度（用户空间的进程正在运行不代表需要被CPU调度，有可能在等待I/O，也有可能在sleep等等）</p><h3 id="linux硬链接和软链接原理"><a href="#linux硬链接和软链接原理" class="headerlink" title="linux硬链接和软链接原理"></a>linux硬链接和软链接原理</h3><ul><li>硬链接：在Linux系统中，多个文件名指向同一索引节点(Inode)是正常且允许的。一般这种链接就称为硬链接。硬链接的作用之一是允许一个文件拥有多个有效路径名，这样用户就可以建立硬链接到重要的文件，以防止“误删”源数据。</li><li>软链接： 软链接就是一个普通文件，只是数据块内容有点特殊，文件用户数据块中存放的内容是另一文件的路径名的指向，通过这个方式可以快速定位到软连接所指向的源文件实体。软链接可对文件或目录创建。</li></ul><p>软连接和硬链接的特点：</p><p>软链接：</p><ul><li>1.软链接是存放另一个文件的路径的形式存在。</li><li>2.软链接可以 跨文件系统 ，硬链接不可以。</li><li>3.软链接可以对一个不存在的文件名进行链接，硬链接必须要有源文件。</li><li>4.软链接可以对目录进行链接。</li></ul><p>硬链接：</p><ul><li><ol><li>硬链接，以文件副本的形式存在。但不占用实际空间。</li></ol></li><li><ol start="2"><li>不允许给目录创建硬链接。</li></ol></li><li><ol start="3"><li>硬链接只有在同一个文件系统中才能创建。</li></ol></li><li><ol start="4"><li>删除其中一个硬链接文件并不影响其他有相同 inode 号的文件。</li></ol></li></ul><h3 id="linux进程退出指令"><a href="#linux进程退出指令" class="headerlink" title="linux进程退出指令"></a>linux进程退出指令</h3><p> INT（快速关闭）—-是当用户键入<Control-C>时由终端驱动程序发送的信号。这是一个终止当前操作的请求，如果捕获了这个信号，一些简单的程序应该退出，或者允许自给被终止，这也是程序没有捕获到这个信号时的默认处理方法。拥有命令行或者输入模式的那些程序应该停止它们在做的事情，清除状态，并等待用户的再次输入。</p><p>  TERM（快速关闭）—-是请求彻底终止某项执行操作，它期望接收进程清除自给的状态并退出。</p><p>  HUP—- 平滑启动。如果想要更改配置而不需停止并重新启动服务，请使用该命令。在对配置文件作必要的更改后，发出该命令以动态更新服务配置。</p><p>  QUIT：从容关闭。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Nginx location匹配规则 </title>
      <link href="/2020/06/11/2020-06-11-nginx-config-location/"/>
      <url>/2020/06/11/2020-06-11-nginx-config-location/</url>
      
        <content type="html"><![CDATA[<p>#一、location语法</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location [=|~|~*|^~] uri &#123; … &#125;</span><br></pre></td></tr></table></figure><p>其中，方括号中的四种标识符是可选项，用来改变请求字符串和uri的匹配方式。uri是待匹配的请求字符串，可以是不包含正则的字符串，这种模式被称为“标准的uri”；也可以包含正则，这种模式被称为”正则uri”。例如：</p><p>location ~ .*.(php|php5)?$ {<br>　　root /var/www/html;<br>　　……<br>}</p><h1 id="二、四种可选标识符"><a href="#二、四种可选标识符" class="headerlink" title="二、四种可选标识符"></a>二、四种可选标识符</h1><table><thead><tr><th>标识符</th><th>描述</th></tr></thead><tbody><tr><td>=</td><td><strong>精确匹配：</strong>用于标准uri前，要求请求字符串和uri严格匹配。如果匹配成功就停止匹配，立即执行该location里面的请求。</td></tr><tr><td>~</td><td><strong>正则匹配：</strong>用于正则uri前，表示uri里面包含正则，并且区分大小写。</td></tr><tr><td>~*</td><td><strong>正则匹配：</strong>用于正则uri前，表示uri里面包含正则，不区分大小写。</td></tr><tr><td>^~</td><td><strong>非正则匹配；</strong>用于标准uri前，nginx服务器匹配到前缀最多的uri后就结束，该模式匹配成功后，不会使用正则匹配。</td></tr><tr><td>无</td><td><strong>普通匹配（最长字符匹配）；</strong>与location顺序无关，是按照匹配的长短来取匹配结果。若完全匹配，就停止匹配。</td></tr></tbody></table><h1 id="三、匹配标识符案例"><a href="#三、匹配标识符案例" class="headerlink" title="三、匹配标识符案例"></a>三、匹配标识符案例</h1><h2 id="1-“-”精准匹配"><a href="#1-“-”精准匹配" class="headerlink" title="1. “=”精准匹配"></a>1. “=”精准匹配</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location = /news/ &#123;</span><br><span class="line">            echo &quot;test1&quot;;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@test]# curl 192.168.233.22/news/</span><br><span class="line">test1</span><br></pre></td></tr></table></figure><h2 id="2-“-”区分大小写正则匹配"><a href="#2-“-”区分大小写正则匹配" class="headerlink" title="2. “~”区分大小写正则匹配"></a>2. “~”区分大小写正则匹配</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location ~ \.(html) &#123;</span><br><span class="line">    echo &#x27;test2&#x27;;</span><br><span class="line">&#125;</span><br><span class="line">location ~ \.(htmL) &#123;</span><br><span class="line">    echo &#x27;test3&#x27;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@test]# curl 192.168.233.22/index.html</span><br><span class="line">test2</span><br><span class="line">[root@test]# curl 192.168.233.22/index.htmL</span><br><span class="line">test3</span><br></pre></td></tr></table></figure><h2 id="3-“-”不区分大小写的正则匹配"><a href="#3-“-”不区分大小写的正则匹配" class="headerlink" title="3. “~*”不区分大小写的正则匹配"></a>3. “~*”不区分大小写的正则匹配</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location ~* \.(html)&#123;</span><br><span class="line">            echo &#x27;test4&#x27;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@test]# curl 192.168.233.22/index.htmL</span><br><span class="line">test4</span><br><span class="line">[root@test]# curl 192.168.233.22/index.html</span><br><span class="line">test4</span><br></pre></td></tr></table></figure><h2 id="4-“-”不进行正则匹配的标准匹配，只匹配前缀"><a href="#4-“-”不进行正则匹配的标准匹配，只匹配前缀" class="headerlink" title="4. “^~”不进行正则匹配的标准匹配，只匹配前缀"></a>4. “^~”不进行正则匹配的标准匹配，只匹配前缀</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location ^~ /index/ &#123;</span><br><span class="line">            echo &#x27;test5&#x27;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@test]# curl 192.168.233.22/index/</span><br><span class="line">test5</span><br><span class="line">[root@test]# curl 192.168.233.22/index/heihei</span><br><span class="line">test5</span><br><span class="line">[root@test]# curl 192.168.233.22/index/asdnmkalsjd</span><br><span class="line">test5</span><br></pre></td></tr></table></figure><h2 id="5-普通匹配"><a href="#5-普通匹配" class="headerlink" title="5. 普通匹配"></a>5. 普通匹配</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location / &#123;</span><br><span class="line">            echo &#x27;test6&#x27;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@test]# curl 192.168.233.22</span><br><span class="line">test6</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Nginx配置location中proxy_pass的&#39;/&#39;号的作用 </title>
      <link href="/2020/05/26/2020-05-26-nginx-config-location-proxypass/"/>
      <url>/2020/05/26/2020-05-26-nginx-config-location-proxypass/</url>
      
        <content type="html"><![CDATA[<p><strong>真实案例，就因为在配置时，少写了一个字符“/”，就造成访问不通报错，因而接到投诉。那么是怎么引起的呢？原因就是：Nginx在配置proxy_pass代理转接时，少些“/”字符造成的。有同学就有疑问，加不加“/”,区别真的那么大吗？我们带着这个疑问，来探究下这个问题。</strong></p><h1 id="location目录匹配详解"><a href="#location目录匹配详解" class="headerlink" title="location目录匹配详解"></a>location目录匹配详解</h1><p>nginx每个location都是一个匹配目录，nginx的策略是：访问请求来时，会对访问地址进行解析，从上到下逐个匹配，匹配上就执行对应location大括号中的策略，并根据策略对请求作出相应。</p><p>依访问地址：<a href="http://www.example.com/book/index.html">http://www.example.com/book/index.html</a> 为例，nginx配置如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location /book/  &#123;</span><br><span class="line">proxy_connect_timeout 18000; ##修改成半个小时</span><br><span class="line">proxy_send_timeout 18000;</span><br><span class="line">proxy_read_timeout 18000;</span><br><span class="line">proxy_pass http://127.0.0.1:8080;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那访问时就会匹配这个location,从而把请求代理转发到本机的8080Tomcat服务中，Tomcat相应后，信息原路返回。总结：<strong>location如果没有“/”时，请求就可以模糊匹配以字符串开头的所有字符串，而有“/”时，只能精确匹配字符本身。</strong></p><p>下面举个例子说明：</p><p> 配置location /book可以匹配/bookdada请求，也可以匹配/book*/dada等等，只要以book开头的目录都可以匹配到。而location /book/必须精确匹配/book/这个目录的请求,不能匹配/bookdada/或/book*/dada等请求。</p><h1 id="proxy-pass有无“-”的四种区别探究"><a href="#proxy-pass有无“-”的四种区别探究" class="headerlink" title="proxy_pass有无“/”的四种区别探究"></a>proxy_pass有无“/”的四种区别探究</h1><p>访问地址都是以：<a href="http://www.book.com/bddd/index.html">http://www.book.com/bddd/index.html</a> 为例。请求都匹配目录/bddd/</p><h2 id="第一种：加”-“"><a href="#第一种：加”-“" class="headerlink" title="第一种：加”/“"></a>第一种：加”/“</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location  /bddd/ &#123;</span><br><span class="line">proxy_pass  http://127.0.0.1:8080/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试结果，请求被代理跳转到：<a href="http://127.0.0.1:8080/index.html">http://127.0.0.1:8080/index.html</a></p><h2 id="第二种-不加”-“"><a href="#第二种-不加”-“" class="headerlink" title="第二种: 不加”/“"></a>第二种: 不加”/“</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location  /bddd/ &#123;</span><br><span class="line">proxy_pass http://127.0.0.1:8080;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试结果，请求被代理跳转到：<a href="http://127.0.0.1:8080/bddd/index.html">http://127.0.0.1:8080/bddd/index.html</a></p><p>3# 第三种: 增加目录加”/“</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location  /bddd/ &#123;</span><br><span class="line">proxy_pass http://127.0.0.1:8080/sun/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试结果，请求被代理跳转到：<a href="http://127.0.0.1:8080/sun/index.html">http://127.0.0.1:8080/sun/index.html</a></p><h2 id="第四种：增加目录不加”-“"><a href="#第四种：增加目录不加”-“" class="headerlink" title="第四种：增加目录不加”/“"></a>第四种：增加目录不加”/“</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location  /bddd/ &#123;</span><br><span class="line">proxy_pass http://127.0.0.1:8080/sun;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试结果，请求被代理跳转到：<a href="http://127.0.0.1:8080/sunindex.html">http://127.0.0.1:8080/sunindex.html</a></p><p><strong>总结</strong></p><p>location目录后加”/“,只能匹配目录，不加“/”不仅可以匹配目录还对目录进行模糊匹配。而proxy_pass无论加不加“/”,代理跳转地址都直接拼接。</p><p>为了加深大家印象可以用下面的配置实验测试下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">  listen       80;</span><br><span class="line">  server_name  localhost;   # http://localhost/bddd01/xxx -&gt; http://localhost:8080/bddd01/xxx</span><br><span class="line"></span><br><span class="line">  location /bddd01/ &#123;</span><br><span class="line">    proxy_pass http://localhost:8080;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  # http://localhost/bddd02/xxx -&gt; http://localhost:8080/xxx</span><br><span class="line">  location /bddd02/ &#123;</span><br><span class="line">    proxy_pass http://localhost:8080/;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  # http://localhost/bddd03/xxx -&gt; http://localhost:8080/bddd03*/xxx</span><br><span class="line">  location /bddd03 &#123;</span><br><span class="line">    proxy_pass http://localhost:8080;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  # http://localhost/bddd04/xxx -&gt; http://localhost:8080//xxx，请注意这里的双斜线，好好分析一下。</span><br><span class="line">  location /bddd04 &#123;</span><br><span class="line">    proxy_pass http://localhost:8080/;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  # http://localhost/bddd05/xxx -&gt; http://localhost:8080/hahaxxx，请注意这里的haha和xxx之间没有斜杠，分析一下原因。</span><br><span class="line">  location /bddd05/ &#123;</span><br><span class="line">    proxy_pass http://localhost:8080/haha;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  # http://localhost/bddd06/xxx -&gt; http://localhost:8080/haha/xxx</span><br><span class="line">  location /bddd06/ &#123;</span><br><span class="line">    proxy_pass http://localhost:8080/haha/;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  # http://localhost/bddd07/xxx -&gt; http://localhost:8080/haha/xxx</span><br><span class="line">  location /bddd07 &#123;</span><br><span class="line">    proxy_pass http://localhost:8080/haha;</span><br><span class="line">  &#125;</span><br><span class="line">  # http://localhost/bddd08/xxx -&gt; http://localhost:8080/haha//xxx，请注意这里的双斜杠。</span><br><span class="line">  location /bddd08 &#123;</span><br><span class="line">    proxy_pass http://localhost:8080/haha/;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> MySQL常见面试题（后续的面试题会更新） </title>
      <link href="/2020/05/25/2020-05-25-mysql-examination-questions/"/>
      <url>/2020/05/25/2020-05-25-mysql-examination-questions/</url>
      
        <content type="html"><![CDATA[<p><strong>题目一</strong></p><p>MyISAM和InnoDB的区别，什么时候选择MyISAM</p><p><strong>参考回答</strong></p><p>InnoDB是目前MySQL主流版本(5.6、5.7、8.0)默认的存储引擎，支持事务、外键、行级锁，对于并发条件下要求数据的一致性，适用于对数据准确性要求高的场景。</p><p>MyISAM只支持表级锁、数据排列是按照插入顺序，没有做规则排序。适合应用以查询和插入为主，只有很少量的更新和删除操作，对事务的完整性和并发性要求不是很高的场景。</p><p><strong>实际运用</strong></p><p>看到很多人在选择存储引擎的时候会无脑的选择InnoDB，这个选择合理的一点是如果对数据准确性要求没有那么高，直接用NoSQL就好了。用MySQL就是为了可靠啊。</p><p>但是实际工作中，我设计的数据库中通常都会有几张MyISAM的数据表，通常用来存储历史记录，与使用InnoDB存储实时记录信息的配合使用。</p><p>举个例子：比如一条物流信息，在实时的表里存着目前物流的状态：比如配送中。这条物流在历史上经过了：正在通知快递公司取件、XXX已收揽等，这张记录表基本只有插入和查询，并且丢失一个中间状态不影响当前结果，这就很合适用MyISAM。</p><p><strong>题目二</strong></p><p>简述MySQL的MVCC多版本并发控制</p><p><strong>参考回答</strong></p><p>MVCC是对于事务隔离级别的读已提交RC和可重复读RR，基于乐观锁的实现。在LBCC(基于锁的并发控制)RC、RR和串行化分别是通过加行锁、间隙锁和表锁来基于悲观锁实现。而乐观锁的原理就是在特定的时间点(RC是每次读时，RR是事务开始时)生成一个当前快照，读数据读取快照，只在提交时判断是否有冲突，类似于git的branch和commit。</p><p>MVCC会在新开启一个事务时，给事务里包含的每行记录添加一个当前事务ID和回滚指针。并包含一个Read View，Read View里保存了当前活跃的事务列表，小于这些列表的最近的事务ID才是可见的。这样保证了读到的都是已提交的事务。</p><p><strong>实际运用</strong></p><p>MVCC不仅可以用于数据库，也是很常见的一种并发控制手段。比如使用有限状态自动机来控制的订单状态，在更新订单状态的时候先查询当前状态，比如当前状态是订单未提交，则更新时update XXX set status=’订单已提交’ where status=’订单未提交’，如果执行这条语句时，status已经发生了改变，这条语句就执行失败了。这样不通过数据库自身事务的MVCC，在业务逻辑里也实现了MVCC思想的乐观锁设计。</p><p><strong>题目三</strong></p><p>分布式锁的实现方式</p><p><strong>参考回答</strong></p><p>主流有三种</p><p>1&gt;基于数据库</p><p>1.1&gt;基于数据库主键：插入一条数据，指定主键。如果有两条插入会主键冲突，并发执行失败</p><p>1.2&gt;基于数据库排他锁：提交一个update事务，如果这个事务不提交，其他也对锁定范围内执行update就会阻塞，解决并发问题</p><p>2&gt;基于缓存比如redis的setNX</p><p>3&gt;基于zookeeper</p><p><strong>实际运用</strong></p><p>相信很多人选择分布式锁都是选择第二种，第三种虽然并发性差一下，如果本来就引入了zk，而没有缓存，而分布式锁应用量又不那么大，为了减少引入新组件带来的风险和维护成本，也有可能选择zk。很多人大概认为自己没有用过基于数据库的分布式锁，实际上在不使用MVCC的时代并不是这样。</p><p>在使用spring进行业务开发的时候，常见的一种场景就是使用spring配置事务。默认级别是Repeatable Read可重复读。在这里面如果使用的是LBCC，一进入事务就加入一个排他锁，比如insert、update、delete或者select XXX for update。然后做其他的，比如进行一个RPC调用。这时候一旦出现并发，只有一个能顺利执行，其他都会被阻塞。实际上就相当于使用了分布式锁。</p><p><strong>题目四</strong></p><p>为什么采用B+树作为索引结构?</p><p><em><strong>*参考回答*</strong></em></p><p>如果采用Hash表，范围查找需要全表扫描；如果采用二叉查找树，由于无法保证平衡，可能退化为链表；如果采用平衡二叉树，通过旋转解决了平衡的问题，但是旋转操作效率太低；如果采用红黑树，树太高，IO次数多；如果采用普通B树，节点要存数索引和数据，一个内存页可存储的数据还是少，另外范围查找也需要多次IO；</p><p>而B+Tree有三个特性：</p><p>1&gt;非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引</p><p>2&gt;叶子节点包含所有索引字段</p><p>3&gt;叶子节点用指针链接，提高范围查询的性能</p><p><strong>实际运用</strong></p><p>在分布式场景下，我们的业务ID都是全局唯一的字符串。如果单纯从业务上来考虑，用业务ID作为数据库的主键就足够了。可以DBA往往要求使用整型的自增主键作为数据库主键，而这个主键对业务来说就是个浪费，没有任何业务含义。</p><p>如果了解了索引的底层结构就不难理解</p><p>1&gt;整型比字符串占用更少的空间</p><p>2&gt;同时大小比较也很快</p><p>3&gt;之所以要自增是每次插入新的记录，对于叶子节点来说：记录会顺序的添加到当前索引节点的后续位置，当一页写满，会自动开辟一个新的页。而如果使用非自增主键，就需要插入的时候移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要读回来。分页操作造成大量的碎片，必须通过优化操作重建表并优化填充页面。</p><p><strong>题目五</strong></p><p>什么叫做覆盖索引？</p><p><em><strong>*参考回答*</strong></em></p><p>只需要在一棵辅助索引树上就可以获取SQL所需要的所有列数据，不需要回表。</p><p><strong>实际运用</strong></p><p>一些持久层框架比如mybatis的generator插件可以自动生成sql配置文件，这些配置文件往往效率很低。但是刚毕业的同学很多都不会去改这个文件，比如只需要个别列的时候会用java的lambda表达式等方式从逻辑上做处理。结果造成一些性能的问题。</p><p>我在根据一些条件进行范围查找的时候，如果只需要返回ID或者个别列，会自己去改mybatis的generator自动生成的文件，原因是尽量使用覆盖索引，较回表速度快。</p><p>想验证是否使用了覆盖索引，可以用explain执行计划，查看extra字段，如果只显示Using index说明正确使用了覆盖索引。如果extra为空或者除了using index还有filesort说明触发了回表。</p><p><strong>题目六</strong></p><p>查询在什么时候不走索引</p><p><em><strong>*参考回答*</strong></em></p><p>主要三种情况</p><p>1&gt;不满足走索引的条件，常见的情况有</p><p>1.1&gt;不满足最左匹配原则</p><p>1.2&gt;查询条件使用了函数</p><p>1.3&gt;or操作有一个字段没有索引</p><p>1.4&gt;使用like条件以%开头</p><p>2&gt;走索引效率低于全表扫描，常见的情况有</p><p>2.1&gt;查询条件对null做判断，而null的值很多</p><p>2.2&gt;一个字段区分度很小，比如性别、状态</p><p>3&gt;需要回表的查询结果集过大，超过了配置的范围</p><p><strong>实际运用</strong></p><p>使用索引是为了对查询做优化，要衡量优化效果需要数据说话。所以需要一些工具来衡量，常用的有：</p><p>1&gt;慢查询日志</p><p>开启慢查询日志，可以针对慢SQL进行分析看看哪些可以用索引进行优化</p><p>2&gt;show processlist</p><p>show processlist 语句可以查看当前正在执行的SQL，如果一些SQL执行慢，block了其他的SQL，这是个很好的工具</p><p>3&gt;show profile分析SQL</p><p>支持的话，可以用select @@profiling 查看是否开启，如果结果为0说明未开启。需要先set @@profiling=1;</p><p>这时候就可以用show profiles查看每一条SQL语句耗费的时间</p><p>show profile for query XXID 可以查看具体耗费在哪个阶段</p><p>4&gt;Trace分析优化器的执行计划</p><p>使用set optimizer_trace=’enabled=on’,end_markers_in_json=on;可以打开trace分析，想查看具体的优化器执行计划，只要执行</p><p>select * from <code>information_schema</code>.optimizer_trace即可</p>]]></content>
      
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> HTTP 面试问题 </title>
      <link href="/2020/05/19/2020-05-19-http-interviews/"/>
      <url>/2020/05/19/2020-05-19-http-interviews/</url>
      
        <content type="html"><![CDATA[<h1 id="HTTP-和-HTTPS-的区别"><a href="#HTTP-和-HTTPS-的区别" class="headerlink" title="HTTP 和 HTTPS 的区别"></a>HTTP 和 HTTPS 的区别</h1><p>HTTP 是一种 <code>超文本传输协议(Hypertext Transfer Protocol)</code>，<strong>HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http-content.png" alt="http-content"></p><p>HTTP 主要内容分为三部分，<strong>超文本（Hypertext）、传输（Transfer）、协议（Protocol）</strong>。</p><ul><li>超文本就是不单单只是本文，它还可以传输图片、音频、视频，甚至点击文字或图片能够进行<code>超链接</code>的跳转。</li><li>上面这些概念可以统称为数据，传输就是数据需要经过一系列的物理介质从一个端系统传送到另外一个端系统的过程。通常我们把传输数据包的一方称为<code>请求方</code>，把接到二进制数据包的一方称为<code>应答方</code>。</li><li>而协议指的就是是网络中(包括互联网)传递、管理信息的一些规范。如同人与人之间相互交流是需要遵循一定的规矩一样，计算机之间的相互通信需要共同遵守一定的规则，这些规则就称为协议，只不过是网络协议。</li></ul><p>说到 HTTP，不得不提的就是 TCP/IP 网络模型，一般是五层模型。如下图所示</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-five.png" alt="tcp-five"></p><p>但是也可以分为四层，就是<strong>把链路层和物理层都表示为网络接口层</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-four.png" alt="tcp-four"></p><p>还有一种就是 OSI 七层网络模型，它就是在五层协议之上加了<strong>表示层和会话层</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/osi-seven.png" alt="osi-seven"></p><p>而 HTTPS 的全称是 <code>Hypertext Transfer Protocol Secure</code>，从名称我们可以看出 HTTPS 要比 HTTPS 多了 secure 安全性这个概念，实际上， HTTPS 并不是一个新的应用层协议，它其实就是 HTTP + TLS/SSL 协议组合而成，而安全性的保证正是 TLS/SSL 所做的工作。</p><p>也就是说，<strong>HTTPS 就是身披了一层 SSL 的 HTTP</strong>。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http-https-content.png" alt="http-https-content"></p><p>那么，HTTP 和 HTTPS 的主要区别是什么呢？</p><ul><li>最简单的，HTTP 在地址栏上的协议是以 <code>http://</code> 开头，而 HTTPS 在地址栏上的协议是以 <code>https://</code> 开头</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://www.baidu.com/</span><br><span class="line">https://www.baidu.com/</span><br></pre></td></tr></table></figure><ul><li>HTTP 是未经安全加密的协议，它的传输过程容易被攻击者监听、数据容易被窃取、发送方和接收方容易被伪造；而 HTTPS 是安全的协议，它通过 <strong>密钥交换算法 - 签名算法 - 对称加密算法 - 摘要算法</strong> 能够解决上面这些问题。</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/chrome-ssl.png" alt="chrome-ssl"></p><ul><li>HTTP 的默认端口是 80，而 HTTPS 的默认端口是 443。</li></ul><h1 id="HTTP-Get-和-Post-区别"><a href="#HTTP-Get-和-Post-区别" class="headerlink" title="HTTP Get 和 Post 区别"></a>HTTP Get 和 Post 区别</h1><p>HTTP 中包括许多方法，<strong>Get 和 Post 是 HTTP 中最常用的两个方法</strong>，基本上使用 HTTP 方法中有 99% 都是在使用 Get 方法和 Post 方法，所以有必要我们对这两个方法有更加深刻的认识。</p><ul><li><p>get 方法一般用于请求，比如你在浏览器地址栏输入 <code>www.cxuanblog.com</code> 其实就是发送了一个 get 请求，它的主要特征是请求服务器返回资源，而 post 方法一般用于``</p><p><code>表单</code>的提交，相当于是把信息提交给服务器，等待服务器作出响应，get 相当于一个是 pull/拉的操作，而 post 相当于是一个 push/推的操作。</p></li><li><p>get 方法是不安全的，因为你在发送请求的过程中，你的请求参数会拼在 URL 后面，从而导致容易被攻击者窃取，对你的信息造成破坏和伪造；</p></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/test/demo_form.asp?name1=value1&amp;name2=value2</span><br></pre></td></tr></table></figure><p>而 post 方法是把参数放在请求体 body 中的，这对用户来说不可见。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST /test/demo_form.asp HTTP/1.1</span><br><span class="line">Host: w3schools.com</span><br><span class="line">name1=value1&amp;name2=value2</span><br></pre></td></tr></table></figure><ul><li>get 请求的 URL 有长度限制，而 post 请求会把参数和值放在消息体中，对数据长度没有要求。</li><li>get 请求会被浏览器主动 cache，而 post 不会，除非手动设置。</li><li>get 请求在浏览器反复的 <code>回退/前进</code> 操作是无害的，而 post 操作会再次提交表单请求。</li><li>get 请求在发送过程中会产生一个 TCP 数据包；post 在发送过程中会产生两个 TCP 数据包。对于 get 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；而对于 post，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。</li></ul><h1 id="什么是无状态协议，HTTP-是无状态协议吗，怎么解决"><a href="#什么是无状态协议，HTTP-是无状态协议吗，怎么解决" class="headerlink" title="什么是无状态协议，HTTP 是无状态协议吗，怎么解决"></a>什么是无状态协议，HTTP 是无状态协议吗，怎么解决</h1><p><code>无状态协议(Stateless Protocol)</code> 就是指<strong>浏览器对于事务的处理没有记忆能力</strong>。举个例子来说就是比如客户请求获得网页之后关闭浏览器，然后再次启动浏览器，登录该网站，但是服务器并不知道客户关闭了一次浏览器。</p><p>HTTP 就是一种无状态的协议，他对用户的操作没有记忆能力。可能大多数用户不相信，他可能觉得每次输入用户名和密码登陆一个网站后，下次登陆就不再重新输入用户名和密码了。这其实不是 HTTP 做的事情，起作用的是一个叫做 <code>小甜饼(Cookie)</code> 的机制。它能够让浏览器具有<code>记忆</code>能力。</p><p>如果你的浏览器允许 cookie 的话，查看方式 <strong>chrome://settings/content/cookies</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/chrome-cookies-set.png" alt="chrome-cookies-set"></p><p>也就说明你的记忆芯片通电了…… 当你向服务端发送请求时，服务端会给你发送一个认证信息，服务器第一次接收到请求时，开辟了一块 Session 空间（创建了Session对象），同时生成一个 sessionId ，并通过响应头的 Set-Cookie：JSESSIONID=XXXXXXX 命令，向客户端发送要求设置 Cookie 的响应；客户端收到响应后，在本机客户端设置了一个 JSESSIONID=XXXXXXX 的 Cookie 信息，该 Cookie 的过期时间为浏览器会话结束；</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/cookies-procedure.png" alt="cookies-procedure"></p><p>接下来客户端每次向同一个网站发送请求时，请求头都会带上该 Cookie信息（包含 sessionId ）， 然后，服务器通过读取请求头中的 Cookie 信息，获取名称为 JSESSIONID 的值，得到此次请求的 sessionId。这样，你的浏览器才具有了记忆能力。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/cookies-session.png" alt="cookies-session"></p><p>还有一种方式是使用 JWT 机制，它也是能够让你的浏览器具有记忆能力的一种机制。与 Cookie 不同，JWT 是保存在客户端的信息，它广泛的应用于单点登录的情况。JWT 具有两个特点</p><ul><li>JWT 的 Cookie 信息存储在<code>客户端</code>，而不是服务端内存中。也就是说，JWT 直接本地进行验证就可以，验证完毕后，这个 Token 就会在 Session 中随请求一起发送到服务器，通过这种方式，可以节省服务器资源，并且 token 可以进行多次验证。</li><li>JWT 支持跨域认证，Cookies 只能用在<code>单个节点的域</code>或者它的<code>子域</code>中有效。如果它们尝试通过第三个节点访问，就会被禁止。使用 JWT 可以解决这个问题，使用 JWT 能够通过<code>多个节点</code>进行用户认证，也就是我们常说的<code>跨域认证</code>。</li></ul><h1 id="UDP-和-TCP-的区别"><a href="#UDP-和-TCP-的区别" class="headerlink" title="UDP 和 TCP 的区别"></a>UDP 和 TCP 的区别</h1><p>TCP 和 UDP 都位于计算机网络模型中的运输层，它们负责传输应用层产生的数据。下面我们就来聊一聊 TCP 和 UDP 分别的特征和他们的区别</p><h2 id="UDP-是什么"><a href="#UDP-是什么" class="headerlink" title="UDP 是什么"></a>UDP 是什么</h2><p>UDP 的全称是 <code>User Datagram Protocol</code>，用户数据报协议。它不需要所谓的<code>握手</code>操作，从而加快了通信速度，允许网络上的其他主机在接收方同意通信之前进行数据传输。</p><blockquote><p>数据报是与分组交换网络关联的传输单元。</p></blockquote><p>UDP 的特点主要有</p><ul><li>UDP 能够支持容忍数据包丢失的带宽密集型应用程序</li><li>UDP 具有低延迟的特点</li><li>UDP 能够发送大量的数据包</li><li>UDP 能够允许 DNS 查找，DNS 是建立在 UDP 之上的应用层协议。</li></ul><h2 id="TCP-是什么"><a href="#TCP-是什么" class="headerlink" title="TCP 是什么"></a>TCP 是什么</h2><p>TCP 的全称是<code>Transmission Control Protocol</code> ，传输控制协议。它能够帮助你确定计算机连接到 Internet 以及它们之间的数据传输。通过三次握手来建立 TCP 连接，三次握手就是用来启动和确认 TCP 连接的过程。一旦连接建立后，就可以发送数据了，当数据传输完成后，会通过关闭虚拟电路来断开连接。</p><p>TCP 的主要特点有</p><ul><li>TCP 能够确保连接的建立和数据包的发送</li><li>TCP 支持错误重传机制</li><li>TCP 支持拥塞控制，能够在网络拥堵的情况下延迟发送</li><li>TCP 能够提供错误校验和，甄别有害的数据包。</li></ul><h2 id="TCP-和-UDP-的不同"><a href="#TCP-和-UDP-的不同" class="headerlink" title="TCP 和 UDP 的不同"></a>TCP 和 UDP 的不同</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-vs-udp.png" alt="tcp-vs-udp"></p><p>下面为你罗列了一些 TCP 和 UDP 的不同点，方便理解，方便记忆。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-vs-udp2.png" alt="tcp-vs-udp2"></p><h2 id="TCP-三次握手和四次挥手"><a href="#TCP-三次握手和四次挥手" class="headerlink" title="TCP 三次握手和四次挥手"></a>TCP 三次握手和四次挥手</h2><p>TCP 三次握手和四次挥手也是面试题的热门考点，它们分别对应 TCP 的连接和释放过程。下面就来简单认识一下这两个过程</p><h3 id="TCP-三次握手"><a href="#TCP-三次握手" class="headerlink" title="TCP 三次握手"></a>TCP 三次握手</h3><p>在了解具体的流程前，我们需要先认识几个概念</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-signals.png" alt="tcp-signals"></p><ul><li>SYN：它的全称是 <code>Synchronize Sequence Numbers</code>，同步序列编号。是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立 TCP 连接时，首先会发送的一个信号。客户端在接受到 SYN 消息时，就会在自己的段内生成一个随机值 X。</li><li>SYN-ACK：服务器收到 SYN 后，打开客户端连接，发送一个 SYN-ACK 作为答复。确认号设置为比接收到的序列号多一个，即 X + 1，服务器为数据包选择的序列号是另一个随机数 Y。</li><li>ACK：<code>Acknowledge character</code>, 确认字符，表示发来的数据已确认接收无误。最后，客户端将 ACK 发送给服务器。序列号被设置为所接收的确认值即 Y + 1。</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-three-hand.png" alt="tcp-three-hand"></p><p>如果用现实生活来举例的话就是</p><p>小明 - 客户端 小红 - 服务端</p><ul><li>小明给小红打电话，接通了后，小明说<strong>喂，能听到吗</strong>，这就相当于是连接建立。</li><li>小红给小明回应，<strong>能听到，你能听到我说的话吗</strong>，这就相当于是请求响应。</li><li>小明听到小红的回应后，<strong>好的</strong>，这相当于是连接确认。在这之后小明和小红就可以通话/交换信息了。</li></ul><h3 id="TCP-四次挥手"><a href="#TCP-四次挥手" class="headerlink" title="TCP 四次挥手"></a>TCP 四次挥手</h3><p>在连接终止阶段使用四次挥手，连接的每一端都会独立的终止。下面我们来描述一下这个过程。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-four-hand.png" alt="tcp-four-hand"></p><ul><li>首先，客户端应用程序决定要终止连接(这里服务端也可以选择断开连接)。这会使客户端将 FIN 发送到服务器，并进入 <code>FIN_WAIT_1</code> 状态。当客户端处于 FIN_WAIT_1 状态时，它会等待来自服务器的 ACK 响应。</li><li>然后第二步，当服务器收到 FIN 消息时，服务器会立刻向客户端发送 ACK 确认消息。</li><li>当客户端收到服务器发送的 ACK 响应后，客户端就进入 <code>FIN_WAIT_2</code> 状态，然后等待来自服务器的 <code>FIN</code> 消息</li><li>服务器发送 ACK 确认消息后，一段时间（可以进行关闭后）会发送 FIN 消息给客户端，告知客户端可以进行关闭。</li><li>当客户端收到从服务端发送的 FIN 消息时，客户端就会由 FIN_WAIT_2 状态变为 <code>TIME_WAIT</code> 状态。处于 TIME_WAIT 状态的客户端允许重新发送 ACK 到服务器为了防止信息丢失。客户端在 TIME_WAIT 状态下花费的时间取决于它的实现，在等待一段时间后，连接关闭，客户端上所有的资源（包括端口号和缓冲区数据）都被释放。</li></ul><p>还是可以用上面那个通话的例子来进行描述</p><ul><li>小明对小红说，我所有的东西都说完了，我要挂电话了。</li><li>小红说，收到，我这边还有一些东西没说。</li><li>经过若干秒后，小红也说完了，小红说，我说完了，现在可以挂断了</li><li>小明收到消息后，又等了若干时间后，挂断了电话。</li></ul><h1 id="简述-HTTP1-0-1-1-2-0-的区别"><a href="#简述-HTTP1-0-1-1-2-0-的区别" class="headerlink" title="简述 HTTP1.0/1.1/2.0 的区别"></a>简述 HTTP1.0/1.1/2.0 的区别</h1><h2 id="HTTP-1-0"><a href="#HTTP-1-0" class="headerlink" title="HTTP 1.0"></a>HTTP 1.0</h2><p>HTTP 1.0 是在 1996 年引入的，从那时开始，它的普及率就达到了惊人的效果。</p><ul><li>HTTP 1.0 仅仅提供了最基本的认证，这时候用户名和密码还未经加密，因此很容易收到窥探。</li><li>HTTP 1.0 被设计用来使用短链接，即每次发送数据都会经过 TCP 的三次握手和四次挥手，效率比较低。</li><li>HTTP 1.0 只使用 header 中的 If-Modified-Since 和 Expires 作为缓存失效的标准。</li><li>HTTP 1.0 不支持断点续传，也就是说，每次都会传送全部的页面和数据。</li><li>HTTP 1.0 认为每台计算机只能绑定一个 IP，所以请求消息中的 URL 并没有传递主机名（hostname）。</li></ul><h2 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP 1.1"></a>HTTP 1.1</h2><p>HTTP 1.1 是 HTTP 1.0 开发三年后出现的，也就是 1999 年，它做出了以下方面的变化</p><ul><li>HTTP 1.1 使用了摘要算法来进行身份验证</li><li>HTTP 1.1 默认使用长连接，长连接就是只需一次建立就可以传输多次数据，传输完成后，只需要一次切断连接即可。长连接的连接时长可以通过请求头中的 <code>keep-alive</code> 来设置</li><li>HTTP 1.1 中新增加了 E-tag，If-Unmodified-Since, If-Match, If-None-Match 等缓存控制标头来控制缓存失效。</li><li>HTTP 1.1 支持断点续传，通过使用请求头中的 <code>Range</code> 来实现。</li><li>HTTP 1.1 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。</li></ul><h2 id="HTTP-2-0"><a href="#HTTP-2-0" class="headerlink" title="HTTP 2.0"></a>HTTP 2.0</h2><p>HTTP 2.0 是 2015 年开发出来的标准，它主要做的改变如下</p><ul><li><code>头部压缩</code>，由于 HTTP 1.1 经常会出现 <strong>User-Agent、Cookie、Accept、Server、Range</strong> 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用 <code>HPACK</code> 算法进行压缩。</li><li><code>二进制格式</code>，HTTP 2.0 使用了更加靠近 TCP/IP 的二进制格式，而抛弃了 ASCII 码，提升了解析效率</li><li><code>强化安全</code>，由于安全已经成为重中之重，所以 HTTP2.0 一般都跑在 HTTPS 上。</li><li><code>多路复用</code>，即每一个请求都是是用作连接共享。一个请求对应一个id，这样一个连接上可以有多个请求。</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http1-vs-http2.png" alt="http1.1-vs-http2"></p><h1 id="请你说一下-HTTP-常见的请求头"><a href="#请你说一下-HTTP-常见的请求头" class="headerlink" title="请你说一下 HTTP 常见的请求头"></a>请你说一下 HTTP 常见的请求头</h1><p>这个问题比较开放，因为 HTTP 请求头有很多，这里只简单举出几个例子。</p><p>HTTP 标头会分为四种，分别是 <code>通用标头</code>、<code>实体标头</code>、<code>请求标头</code>、<code>响应标头</code>。分别介绍一下</p><h2 id="通用标头"><a href="#通用标头" class="headerlink" title="通用标头"></a>通用标头</h2><p>通用标头主要有三个，分别是 <code>Date</code>、<code>Cache-Control</code> 和 <code>Connection</code></p><p><strong>Date</strong></p><p>Date 是一个通用标头，它可以出现在请求标头和响应标头中，它的基本表示如下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Date: Wed, 21 Oct 2015 07:28:00 GMT</span><br></pre></td></tr></table></figure><p>表示的是格林威治标准时间，这个时间要比北京时间慢八个小时</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/timezone-transform.png" alt="timezone-transform"></p><p><strong>Cache-Control</strong></p><p>Cache-Control 是一个通用标头，他可以出现在<code>请求标头</code>和<code>响应标头</code>中，Cache-Control 的种类比较多，虽然说这是一个通用标头，但是有一些特性是请求标头具有的，有一些是响应标头才有的。主要大类有 <code>可缓存性</code>、<code>阈值性</code>、 <code>重新验证并重新加载</code> 和<code>其他特性</code></p><p><strong>Connection</strong></p><p>Connection 决定当前事务（一次三次握手和四次挥手）完成后，是否会关闭网络连接。Connection 有两种，一种是<code>持久性连接</code>，即一次事务完成后不关闭网络连接</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Connection: keep-alive</span><br></pre></td></tr></table></figure><p>另一种是<code>非持久性连接</code>，即一次事务完成后关闭网络连接</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Connection: close</span><br></pre></td></tr></table></figure><p>HTTP1.1 其他通用标头如下</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http1-1-head-content.png" alt="http1-1-head-content"></p><h2 id="实体标头"><a href="#实体标头" class="headerlink" title="实体标头"></a>实体标头</h2><p>实体标头是描述消息正文内容的 HTTP 标头。实体标头用于 HTTP 请求和响应中。头部<code>Content-Length</code>、 <code>Content-Language</code>、 <code>Content-Encoding</code> 是实体头。</p><ul><li><p>Content-Length 实体报头指示实体主体的大小，以字节为单位，发送到接收方。</p></li><li><p>Content-Language 实体报头描述了客户端或者服务端能够接受的语言。</p></li><li><p>Content-Encoding 这又是一个比较麻烦的属性，这个实体报头用来压缩媒体类型。Content-Encoding 指示对实体应用了何种编码。</p><p>常见的内容编码有这几种： <strong>gzip、compress、deflate、identity</strong> ，这个属性可以应用在请求报文和响应报文中</p></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Accept-Encoding: gzip, deflate //请求头</span><br><span class="line">Content-Encoding: gzip  //响应头</span><br></pre></td></tr></table></figure><p>下面是一些实体标头字段</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/entity-header-column.png" alt="entity-header-column"></p><h2 id="请求标头"><a href="#请求标头" class="headerlink" title="请求标头"></a>请求标头</h2><p><strong>Host</strong></p><p>Host 请求头指明了服务器的域名（对于虚拟主机来说），以及（可选的）服务器监听的 TCP 端口号。如果没有给定端口号，会自动使用被请求服务的默认端口（比如请求一个 HTTP 的 URL 会自动使用 80 作为端口）。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Host: developer.mozilla.org</span><br></pre></td></tr></table></figure><p>上面的 <code>Accpet</code>、 <code>Accept-Language</code>、<code>Accept-Encoding</code> 都是属于内容协商的请求标头。</p><p><strong>Referer</strong></p><p>HTTP Referer 属性是请求标头的一部分，当浏览器向 web 服务器发送请求的时候，一般会带上 Referer，告诉服务器该网页是从哪个页面链接过来的，服务器因此可以获得一些信息用于处理。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Referer: https://developer.mozilla.org/testpage.html</span><br></pre></td></tr></table></figure><p><strong>If-Modified-Since</strong></p><p>If-Modified-Since 通常会与 If-None-Match 搭配使用，If-Modified-Since 用于确认代理或客户端拥有的本地资源的有效性。获取资源的更新日期时间，可通过确认首部字段 <code>Last-Modified</code> 来确定。</p><p>大白话说就是如果在 <code>Last-Modified</code> 之后更新了服务器资源，那么服务器会响应 200，如果在 <code>Last-Modified</code> 之后没有更新过资源，则返回 304。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">If-Modified-Since: Mon, 18 Jul 2016 02:36:04 GMT</span><br></pre></td></tr></table></figure><p><strong>If-None-Match</strong></p><p>If-None-Match HTTP 请求标头使请求成为条件请求。对于 GET 和 HEAD 方法，仅当服务器没有与给定资源匹配的 <code>ETag</code> 时，服务器才会以 200 状态发送回请求的资源。对于其他方法，仅当最终现有资源的<code>ETag</code>与列出的任何值都不匹配时，才会处理请求。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">If-None-Match: &quot;c561c68d0ba92bbeb8b0fff2a9199f722e3a621a&quot;</span><br></pre></td></tr></table></figure><p><strong>Accept</strong></p><p>接受请求 HTTP 标头会通告客户端其能够理解的 MIME 类型</p><p><strong>Accept-Charset</strong></p><p>accept-charset 属性规定服务器处理表单数据所接受的字符集。</p><p>常用的字符集有：UTF-8 - Unicode 字符编码 ；ISO-8859-1 - 拉丁字母表的字符编码</p><p><strong>Accept-Language</strong></p><p>首部字段 Accept-Language 用来告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级。可一次指定多种自然语言集。</p><p>请求标头我们大概就介绍这几种，后面会有一篇文章详细深挖所有的响应头的，下面是一个响应头的汇总，基于 HTTP 1.1</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http1-1-request-header.png" alt="http1-1-request-header"></p><h2 id="响应标头"><a href="#响应标头" class="headerlink" title="响应标头"></a>响应标头</h2><p><strong>Access-Control-Allow-Origin</strong></p><p>一个返回的 HTTP 标头可能会具有 Access-Control-Allow-Origin ，<code>Access-Control-Allow-Origin</code> 指定一个来源，它告诉浏览器允许该来源进行资源访问。</p><p><strong>Keep-Alive</strong></p><p>Keep-Alive 表示的是 Connection 非持续连接的存活时间，可以进行指定。</p><p><strong>Server</strong></p><p>服务器标头包含有关原始服务器用来处理请求的软件的信息。</p><p>应该避免使用过于冗长和详细的 Server 值，因为它们可能会泄露内部实施细节，这可能会使攻击者容易地发现并利用已知的安全漏洞。例如下面这种写法</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Server: Apache/2.4.1 (Unix)</span><br></pre></td></tr></table></figure><p><strong>Set-Cookie</strong></p><p>Set-Cookie 用于服务器向客户端发送 sessionID。</p><p><strong>Transfer-Encoding</strong></p><p>首部字段 Transfer-Encoding 规定了传输报文主体时采用的编码方式。</p><p>HTTP /1.1 的传输编码方式仅对分块传输编码有效。</p><p><strong>X-Frame-Options</strong></p><p>HTTP 首部字段是可以自行扩展的。所以在 Web 服务器和浏览器的应用上，会出现各种非标准的首部字段。</p><p>首部字段 <code>X-Frame-Options</code> 属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（clickjacking）攻击。</p><p>下面是一个响应头的汇总，基于 HTTP 1.1</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http1-1-response-header.png" alt="http1-1-response-header"></p><h1 id="地址栏输入-URL-发生了什么"><a href="#地址栏输入-URL-发生了什么" class="headerlink" title="地址栏输入 URL 发生了什么"></a>地址栏输入 URL 发生了什么</h1><p>这道题也是一道经常会考的面试题。那么下面我们就来探讨一下从你输入 URL 后到响应，都经历了哪些过程。</p><ul><li>首先，你需要在浏览器中的 URL 地址上，输入你想访问的地址，如下</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/chrome-search.png" alt="chrome-search"></p><p>你应该访问不到的，对不对~</p><ul><li>然后，浏览器会根据你输入的 URL 地址，去查找域名是否被本地 DNS 缓存，不同浏览器对 DNS 的设置不同，如果浏览器缓存了你想访问的 URL 地址，那就直接返回 ip。如果没有缓存你的 URL 地址，浏览器就会发起系统调用来查询本机 <code>hosts</code> 文件是否有配置 ip 地址，如果找到，直接返回。如果找不到，就向网络中发起一个 DNS 查询。</li></ul><blockquote><p>首先来看一下 DNS 是啥，互联网中识别主机的方式有两种，通过<code>主机名</code>和 <code>IP 地址</code>。我们人喜欢用名字的方式进行记忆，但是通信链路中的路由却喜欢定长、有层次结构的 IP 地址。所以就需要一种能够把主机名到 IP 地址的转换服务，这种服务就是由 DNS 提供的。DNS 的全称是 <code>Domain Name System</code> 域名系统。DNS 是一种由分层的 DNS 服务器实现的分布式数据库。DNS 运行在 UDP 上，使用 53 端口。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/dns1.png"></p></blockquote><p>DNS 是一种分层数据库，它的主要层次结构如下</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/dns2.png" alt="dns2"></p><p>一般域名服务器的层次结构主要是以上三种，除此之外，还有另一类重要的 DNS 服务器，它是 <code>本地 DNS 服务器(local DNS server)</code>。严格来说，本地 DNS 服务器并不属于上述层次结构，但是本地 DNS 服务器又是至关重要的。每个 <code>ISP(Internet Service Provider)</code> 比如居民区的 ISP 或者一个机构的 ISP 都有一台本地 DNS 服务器。当主机和 ISP 进行连接时，该 ISP 会提供一台主机的 IP 地址，该主机会具有一台或多台其本地 DNS 服务器的 IP地址。通过访问网络连接，用户能够容易的确定 DNS 服务器的 IP地址。当主机发出 DNS 请求后，该请求被发往本地 DNS 服务器，它起着代理的作用，并将该请求转发到 DNS 服务器层次系统中。</p><p>首先，查询请求会先找到本地 DNS 服务器来查询是否包含 IP 地址，如果本地 DNS 无法查询到目标 IP 地址，就会向根域名服务器发起一个 DNS 查询。</p><blockquote><p>注意：DNS 涉及两种查询方式：一种是<code>递归查询(Recursive query)</code> ，一种是<code>迭代查询(Iteration query)</code>。《计算机网络：自顶向下方法》竟然没有给出递归查询和迭代查询的区别，找了一下网上的资料大概明白了下。<br>如果根域名服务器无法告知本地 DNS 服务器下一步需要访问哪个顶级域名服务器，就会使用递归查询；<br>如果根域名服务器能够告知 DNS 服务器下一步需要访问的顶级域名服务器，就会使用迭代查询。</p></blockquote><p>在由根域名服务器 -&gt; 顶级域名服务器 -&gt; 权威 DNS 服务器后，由权威服务器告诉本地服务器目标 IP 地址，再有本地 DNS 服务器告诉用户需要访问的 IP 地址。</p><ul><li>第三步，浏览器需要和目标服务器建立 TCP 连接，需要经过三次握手的过程，具体的握手过程请参考上面的回答。</li><li>在建立连接后，浏览器会向目标服务器发起 <code>HTTP-GET</code> 请求，包括其中的 URL，HTTP 1.1 后默认使用长连接，只需要一次握手即可多次传输数据。</li><li>如果目标服务器只是一个简单的页面，就会直接返回。但是对于某些大型网站的站点，往往不会直接返回主机名所在的页面，而会直接重定向。返回的状态码就不是 200 ，而是 301,302 以 3 开头的重定向码，浏览器在获取了重定向响应后，在响应报文中 Location 项找到重定向地址，浏览器重新第一步访问即可。</li><li>然后浏览器重新发送请求，携带新的 URL，返回状态码 200 OK，表示服务器可以响应请求，返回报文。</li></ul><h1 id="HTTPS-的工作原理"><a href="#HTTPS-的工作原理" class="headerlink" title="HTTPS 的工作原理"></a>HTTPS 的工作原理</h1><p>我们上面描述了一下 HTTP 的工作原理，下面来讲述一下 HTTPS 的工作原理。因为我们知道 HTTPS 不是一种新出现的协议，而是</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/https-compose.png" alt="https-compose"></p><p>所以，我们探讨 HTTPS 的握手过程，其实就是 SSL/TLS 的握手过程。</p><p>TLS 旨在为 Internet 提供通信安全的加密协议。TLS 握手是启动和使用 TLS 加密的通信会话的过程。在 TLS 握手期间，Internet 中的通信双方会彼此交换信息，验证密码套件，交换会话密钥。</p><p>每当用户通过 HTTPS 导航到具体的网站并发送请求时，就会进行 TLS 握手。除此之外，每当其他任何通信使用HTTPS（包括 API 调用和在 HTTPS 上查询 DNS）时，也会发生 TLS 握手。</p><p>TLS 具体的握手过程会根据所使用的<code>密钥交换算法的类型</code>和双方支持的<code>密码套件</code>而不同。我们以<code>RSA 非对称加密</code>来讨论这个过程。整个 TLS 通信流程图如下</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tls-procedure.png" alt="tls-procedure"></p><ul><li>在进行通信前，首先会进行 HTTP 的三次握手，握手完成后，再进行 TLS 的握手过程</li><li>ClientHello：客户端通过向服务器发送 <code>hello</code> 消息来发起握手过程。这个消息中会夹带着客户端支持的 <code>TLS 版本号(TLS1.0 、TLS1.2、TLS1.3)</code> 、客户端支持的密码套件、以及一串 <code>客户端随机数</code>。</li><li>ServerHello：在客户端发送 hello 消息后，服务器会发送一条消息，这条消息包含了服务器的 SSL 证书、服务器选择的密码套件和服务器生成的随机数。</li><li>认证(Authentication)：客户端的证书颁发机构会认证 SSL 证书，然后发送 <code>Certificate</code> 报文，报文中包含公开密钥证书。最后服务器发送 <code>ServerHelloDone</code> 作为 <code>hello</code> 请求的响应。第一部分握手阶段结束。</li><li><code>加密阶段</code>：在第一个阶段握手完成后，客户端会发送 <code>ClientKeyExchange</code> 作为响应，这个响应中包含了一种称为 <code>The premaster secret</code> 的密钥字符串，这个字符串就是使用上面公开密钥证书进行加密的字符串。随后客户端会发送 <code>ChangeCipherSpec</code>，告诉服务端使用私钥解密这个 <code>premaster secret</code> 的字符串，然后客户端发送 <code>Finished</code> 告诉服务端自己发送完成了。</li></ul><blockquote><p>Session key 其实就是用公钥证书加密的公钥。</p></blockquote><ul><li><code>实现了安全的非对称加密</code>：然后，服务器再发送 <code>ChangeCipherSpec</code> 和 <code>Finished</code> 告诉客户端解密完成，至此实现了 RSA 的非对称加密。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 详解 TCP 连接的“三次握手”与“四次挥手” </title>
      <link href="/2020/01/19/2020-01-19-tcp-second-talk/"/>
      <url>/2020/01/19/2020-01-19-tcp-second-talk/</url>
      
        <content type="html"><![CDATA[<h1 id="TCP-connection"><a href="#TCP-connection" class="headerlink" title="TCP connection"></a>TCP connection</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/1.png" alt="1.png"></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/2.png" alt="2.png"></p><p>客户端与服务器之间数据的发送和返回的过程当中需要创建一个叫TCP connection的东西；</p><p>由于TCP不存在连接的概念，只存在请求和响应，请求和响应都是数据包，它们之间都是经过由TCP创建的一个从客户端发起，服务器接收的类似连接的通道，这个连接可以一直保持，http请求是在这个连接的基础上发送的；</p><p>在一个TCP连接上是可以发送多个http请求的，不同的版本这个模式不一样。</p><p>在HTTP/1.0中这个TCP连接是在http请求创建的时候同步创建的，http请求发送到服务器端，服务器端响应了之后，这个TCP连接就关闭了；</p><p>HTTP/1.1中可以以某种方式声明这个连接一直保持，一个请求传输完之后，另一个请求可以接着传输。这样的好处是：在创建一个TCP连接的过程中需要“三次握手”的消耗，“三次握手”代表有三次网络传输。</p><p>如果TCP连接保持，第二个请求发送就没有这“三次握手”的消耗。HTTP/2中同一个TCP连接里还可以并发地传输http请求。</p><h1 id="TCP报文格式简介"><a href="#TCP报文格式简介" class="headerlink" title="TCP报文格式简介"></a>TCP报文格式简介</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/3.png"></p><p>其中比较重要的字段有：</p><p>（1）序号（sequence number）：Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。</p><p>（2）确认号（acknowledgement number）：Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。</p><p>（3）标志位（Flags）：共6个，即URG、ACK、PSH、RST、SYN、FIN等。具体含义如下：</p><blockquote><ul><li>URG：紧急指针（urgent pointer）有效。</li><li>ACK：确认序号有效。</li><li>PSH：接收方应该尽快将这个报文交给应用层。</li><li>RST：重置连接。</li><li>SYN：发起一个新连接。</li><li>FIN：释放一个连接。</li></ul></blockquote><p>需要注意的是：</p><blockquote><p>不要将确认序号Ack与标志位中的ACK搞混了。<br>确认方Ack=发起方Seq+1，两端配对。</p></blockquote><h1 id="TCP的三次握手（Three-Way-Handshake）"><a href="#TCP的三次握手（Three-Way-Handshake）" class="headerlink" title="TCP的三次握手（Three-Way Handshake）"></a>TCP的三次握手（Three-Way Handshake）</h1><h2 id="1-“三次握手”的详解"><a href="#1-“三次握手”的详解" class="headerlink" title="1.“三次握手”的详解"></a>1.“三次握手”的详解</h2><p>所谓的三次握手即TCP连接的建立。这个连接必须是一方主动打开，另一方被动打开的。<br>以下为客户端主动发起连接的图解：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/4.png"></p><p>握手之前主动打开连接的客户端结束CLOSED阶段，被动打开的服务器端也结束CLOSED阶段，并进入LISTEN阶段。随后开始“三次握手”：</p><p>（1）首先客户端向服务器端发送一段TCP报文，其中：</p><ul><li>标记位为SYN，表示“请求建立新连接”;</li><li>序号为Seq=X（X一般为1）；</li><li>随后客户端进入SYN-SENT阶段。</li></ul><p>（2）服务器端接收到来自客户端的TCP报文之后，结束LISTEN阶段。并返回一段TCP报文，其中：</p><ul><li>标志位为SYN和ACK，表示“确认客户端的报文Seq序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接”（即告诉客户端，服务器收到了你的数据）；</li><li>序号为Seq=y；</li><li>确认号为Ack=x+1，表示收到客户端的序号Seq并将其值加1作为自己确认号Ack的值；随后服务器端进入SYN-RCVD阶段。</li></ul><p>（3）客户端接收到来自服务器端的确认收到数据的TCP报文之后，明确了从客户端到服务器的数据传输是正常的，结束SYN-SENT阶段。并返回最后一段TCP报文。其中：</p><ul><li>标志位为ACK，表示“确认收到服务器端同意连接的信号”（即告诉服务器，我知道你收到我发的数据了）；</li><li>序号为Seq=x+1，表示收到服务器端的确认号Ack，并将其值作为自己的序号值；</li><li>确认号为Ack=y+1，表示收到服务器端序号Seq，并将其值加1作为自己的确认号Ack的值；</li><li>随后客户端进入ESTABLISHED阶段。</li></ul><p>服务器收到来自客户端的“确认收到服务器数据”的TCP报文之后，明确了从服务器到客户端的数据传输是正常的。结束SYN-SENT阶段，进入ESTABLISHED阶段。</p><p>在客户端与服务器端传输的TCP报文中，双方的确认号Ack和序号Seq的值，都是在彼此Ack和Seq值的基础上进行计算的，这样做保证了TCP报文传输的连贯性。一旦出现某一方发出的TCP报文丢失，便无法继续”握手”，以此确保了”三次握手”的顺利完成。</p><p>此后客户端和服务器端进行正常的数据传输。这就是“三次握手”的过程。</p><h2 id="2-“三次握手”的动态过程"><a href="#2-“三次握手”的动态过程" class="headerlink" title="2.“三次握手”的动态过程"></a>2.“三次握手”的动态过程</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/5.gif"></p><h2 id="3-“三次握手”的通俗理解"><a href="#3-“三次握手”的通俗理解" class="headerlink" title="3.“三次握手”的通俗理解"></a>3.“三次握手”的通俗理解</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/6.png"></p><p>举个栗子：把客户端比作男孩，服务器比作女孩。用他们的交往来说明“三次握手”过程：</p><p>（1）男孩喜欢女孩，于是写了一封信告诉女孩：我爱你，请和我交往吧！;写完信之后，男孩焦急地等待，因为不知道信能否顺利传达给女孩。</p><p>（2）女孩收到男孩的情书后，心花怒放，原来我们是两情相悦呀！于是给男孩写了一封回信：我收到你的情书了，也明白了你的心意，其实，我也喜欢你！我愿意和你交往！;</p><p>写完信之后，女孩也焦急地等待，因为不知道回信能否能顺利传达给男孩。</p><p>（3）男孩收到回信之后很开心，因为发出的情书女孩收到了，并且从回信中知道了女孩喜欢自己，并且愿意和自己交往。然后男孩又写了一封信告诉女孩：你的心意和信我都收到了，谢谢你，还有我爱你！</p><p>女孩收到男孩的回信之后，也很开心，因为发出的情书男孩收到了。由此男孩女孩双方都知道了彼此的心意，之后就快乐地交流起来了~~</p><p>这就是通俗版的“三次握手”，期间一共往来了三封信也就是“三次握手”，以此确认两个方向上的数据传输通道是否正常。</p><h2 id="4-为什么要进行第三次握手？"><a href="#4-为什么要进行第三次握手？" class="headerlink" title="4.为什么要进行第三次握手？"></a>4.为什么要进行第三次握手？</h2><p>为了防止服务器端开启一些无用的连接增加服务器开销以及防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。</p><p>由于网络传输是有延时的(要通过网络光纤和各种中间代理服务器)，在传输的过程中，比如客户端发起了SYN=1创建连接的请求(第一次握手)。</p><p>如果服务器端就直接创建了这个连接并返回包含SYN、ACK和Seq等内容的数据包给客户端，这个数据包因为网络传输的原因丢失了，丢失之后客户端就一直没有接收到服务器返回的数据包。</p><p>客户端可能设置了一个超时时间，时间到了就关闭了连接创建的请求。再重新发出创建连接的请求，而服务器端是不知道的，如果没有第三次握手告诉服务器端客户端收的到服务器端传输的数据的话，</p><p>服务器端是不知道客户端有没有接收到服务器端返回的信息的。</p><p>这个过程可理解为：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/7.png"></p><p>这样没有给服务器端一个创建还是关闭连接端口的请求，服务器端的端口就一直开着，等到客户端因超时重新发出请求时，服务器就会重新开启一个端口连接。那么服务器端上没有接收到请求数据的上一个端口就一直开着，长此以往，这样的端口多了，就会造成服务器端开销的严重浪费。</p><p>还有一种情况是已经失效的客户端发出的请求信息，由于某种原因传输到了服务器端，服务器端以为是客户端发出的有效请求，接收后产生错误。</p><p>所以我们需要“第三次握手”来确认这个过程，让客户端和服务器端能够及时地察觉到因为网络等一些问题导致的连接创建失败，这样服务器端的端口就可以关闭了不用一直等待。</p><p>也可以这样理解：“第三次握手”是客户端向服务器端发送数据，这个数据就是要告诉服务器，客户端有没有收到服务器“第二次握手”时传过去的数据。若发送的这个数据是“收到了”的信息，接收后服务器就正常建立TCP连接，否则建立TCP连接失败，服务器关闭连接端口。由此减少服务器开销和接收到失效请求发生的错误。</p><h2 id="5-抓包验证"><a href="#5-抓包验证" class="headerlink" title="5.抓包验证"></a>5.抓包验证</h2><p>下面是用抓包工具抓到的一些数据包，可用来分析TCP的三次握手：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/8.png"></p><p>图中显示的就是完整的TCP连接的”三次握手”过程。在52528 -&gt; 80中，52528是本地(客户端)端口，80是服务器的端口。80端口和52528端口之间的三次来回就是”三次握手”过程。</p><p>注意到”第一次握手”客户端发送的TCP报文中以[SYN]作为标志位，并且客户端序号Seq=0；</p><p>接下来”第二次握手”服务器返回的TCP报文中以[SYN，ACK]作为标志位；并且服务器端序号Seq=0；确认号Ack=1(“第一次握手”中客户端序号Seq的值+1);</p><p>最后”第三次握手”客户端再向服务器端发送的TCP报文中以[ACK]作为标志位；</p><p>其中客户端序号Seq=1（“第二次握手”中服务器端确认号Ack的值）；确认号Ack=1(“第二次握手”中服务器端序号Seq的值+1)。</p><p>这就完成了”三次握手”的过程，符合前面分析的结果。</p><h1 id="TCP的四次挥手（Four-Way-Wavehand）"><a href="#TCP的四次挥手（Four-Way-Wavehand）" class="headerlink" title="TCP的四次挥手（Four-Way Wavehand）"></a>TCP的四次挥手（Four-Way Wavehand）</h1><h2 id="1、前言"><a href="#1、前言" class="headerlink" title="1、前言"></a>1、前言</h2><p>对于”三次握手”我们耳熟能详，因为其相对的简单。但是，我们却不常听见“四次挥手”，就算听过也未必能详细地说明白它的具体过程。下面就为大家详尽，直观，完整地介绍“四次挥手”的过程。</p><h2 id="2、“四次挥手”的详解"><a href="#2、“四次挥手”的详解" class="headerlink" title="2、“四次挥手”的详解"></a>2、“四次挥手”的详解</h2><p>所谓的四次挥手即TCP连接的释放(解除)。连接的释放必须是一方主动释放，另一方被动释放。以下为客户端主动发起释放连接的图解：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/9.png"></p><blockquote><p>挥手之前主动释放连接的客户端结束ESTABLISHED阶段。随后开始“四次挥手”：</p></blockquote><p>（1）首先客户端想要释放连接，向服务器端发送一段TCP报文，其中：</p><ul><li>标记位为FIN，表示“请求释放连接“；</li><li>序号为Seq=U；</li><li>随后客户端进入FIN-WAIT-1阶段，即半关闭阶段。并且停止在客户端到服务器端方向上发送数据，但是客户端仍然能接收从服务器端传输过来的数据。</li></ul><p>注意：这里不发送的是正常连接时传输的数据(非确认报文)，而不是一切数据，所以客户端仍然能发送ACK确认报文。</p><p>（2）服务器端接收到从客户端发出的TCP报文之后，确认了客户端想要释放连接，随后服务器端结束ESTABLISHED阶段，进入CLOSE-WAIT阶段（半关闭状态）并返回一段TCP报文，其中：</p><ul><li>标记位为ACK，表示“接收到客户端发送的释放连接的请求”；</li><li>序号为Seq=V；</li><li>确认号为Ack=U+1，表示是在收到客户端报文的基础上，将其序号Seq值加1作为本段报文确认号Ack的值；</li><li>随后服务器端开始准备释放服务器端到客户端方向上的连接。</li></ul><p>客户端收到从服务器端发出的TCP报文之后，确认了服务器收到了客户端发出的释放连接请求，随后客户端结束FIN-WAIT-1阶段，进入FIN-WAIT-2阶段</p><blockquote><p>前”两次挥手”既让服务器端知道了客户端想要释放连接，也让客户端知道了服务器端了解了自己想要释放连接的请求。于是，可以确认关闭客户端到服务器端方向上的连接了</p></blockquote><p>（3）服务器端自从发出ACK确认报文之后，经过CLOSED-WAIT阶段，做好了释放服务器端到客户端方向上的连接准备，再次向客户端发出一段TCP报文，其中：</p><ul><li>标记位为FIN，ACK，表示“已经准备好释放连接了”。注意：这里的ACK并不是确认收到服务器端报文的确认报文。</li><li>序号为Seq=W；</li><li>确认号为Ack=U+1；表示是在收到客户端报文的基础上，将其序号Seq值加1作为本段报文确认号Ack的值。</li></ul><p>随后服务器端结束CLOSE-WAIT阶段，进入LAST-ACK阶段。并且停止在服务器端到客户端的方向上发送数据，但是服务器端仍然能够接收从客户端传输过来的数据。</p><p>（4）客户端收到从服务器端发出的TCP报文，确认了服务器端已做好释放连接的准备，结束FIN-WAIT-2阶段，进入TIME-WAIT阶段，并向服务器端发送一段报文，其中：</p><ul><li>标记位为ACK，表示“接收到服务器准备好释放连接的信号”。</li><li>序号为Seq=U+1；表示是在收到了服务器端报文的基础上，将其确认号Ack值作为本段报文序号的值。</li><li>确认号为Ack=W+1；表示是在收到了服务器端报文的基础上，将其序号Seq值作为本段报文确认号的值。</li></ul><p>随后客户端开始在TIME-WAIT阶段等待2MSL</p><blockquote><p>为什么要客户端要等待2MSL呢？见后文。</p></blockquote><p>服务器端收到从客户端发出的TCP报文之后结束LAST-ACK阶段，进入CLOSED阶段。由此正式确认关闭服务器端到客户端方向上的连接。</p><p>客户端等待完2MSL之后，结束TIME-WAIT阶段，进入CLOSED阶段，由此完成“四次挥手”。</p><blockquote><p>后“两次挥手”既让客户端知道了服务器端准备好释放连接了，也让服务器端知道了客户端了解了自己准备好释放连接了。于是，可以确认关闭服务器端到客户端方向上的连接了，由此完成“四次挥手”。</p></blockquote><p>与“三次挥手”一样，在客户端与服务器端传输的TCP报文中，双方的确认号Ack和序号Seq的值，都是在彼此Ack和Seq值的基础上进行计算的，这样做保证了TCP报文传输的连贯性，一旦出现某一方发出的TCP报文丢失，便无法继续”挥手”，以此确保了”四次挥手”的顺利完成。</p><h2 id="3、“四次挥手”的通俗理解"><a href="#3、“四次挥手”的通俗理解" class="headerlink" title="3、“四次挥手”的通俗理解"></a>3、“四次挥手”的通俗理解</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/10.png"></p><blockquote><p>举个栗子：把客户端比作男孩，服务器比作女孩。通过他们的分手来说明“四次挥手”过程。</p></blockquote><ul><li>“第一次挥手”：日久见人心，男孩发现女孩变成了自己讨厌的样子，忍无可忍，于是决定分手，随即写了一封信告诉女孩。</li><li>“第二次挥手”：女孩收到信之后，知道了男孩要和自己分手，怒火中烧，心中暗骂：你算什么东西，当初你可不是这个样子的！于是立马给男孩写了一封回信：分手就分手，给我点时间，我要把你的东西整理好，全部还给你！<br>男孩收到女孩的第一封信之后，明白了女孩知道自己要和她分手。随后等待女孩把自己的东西收拾好。</li><li>“第三次挥手”：过了几天，女孩把男孩送的东西都整理好了，于是再次写信给男孩：你的东西我整理好了，快把它们拿走，从此你我恩断义绝！</li><li>“第四次挥手”：男孩收到女孩第二封信之后，知道了女孩收拾好东西了，可以正式分手了，于是再次写信告诉女孩：我知道了，这就去拿回来！</li></ul><blockquote><p>这里双方都有各自的坚持。</p><ul><li>女孩自发出第二封信开始，限定一天内收不到男孩回信，就会再发一封信催促男孩来取东西！</li><li>男孩自发出第二封信开始，限定两天内没有再次收到女孩的信就认为，女孩收到了自己的第二封信；若两天内再次收到女孩的来信，就认为自己的第二封信女孩没收到，需要再写一封信，再等两天…..</li></ul></blockquote><p>倘若双方信都能正常收到，最少只用四封信就能彻底分手！这就是“四次挥手”。</p><h2 id="4-为什么“握手”是三次，“挥手”却要四次？"><a href="#4-为什么“握手”是三次，“挥手”却要四次？" class="headerlink" title="4.为什么“握手”是三次，“挥手”却要四次？"></a>4.为什么“握手”是三次，“挥手”却要四次？</h2><p>TCP建立连接时之所以只需要”三次握手”，是因为在第二次”握手”过程中，服务器端发送给客户端的TCP报文是以SYN与ACK作为标志位的。SYN是请求连接标志，表示服务器端同意建立连接；ACK是确认报文，表示告诉客户端，服务器端收到了它的请求报文。</p><p>即SYN建立连接报文与ACK确认接收报文是在同一次”握手”当中传输的，所以”三次握手”不多也不少，正好让双方明确彼此信息互通。</p><p>TCP释放连接时之所以需要“四次挥手”,是因为FIN释放连接报文与ACK确认接收报文是分别由第二次和第三次”握手”传输的。为何建立连接时一起传输，释放连接时却要分开传输？</p><blockquote><ul><li>建立连接时，被动方服务器端结束CLOSED阶段进入“握手”阶段并不需要任何准备，可以直接返回SYN和ACK报文，开始建立连接。</li><li>释放连接时，被动方服务器，突然收到主动方客户端释放连接的请求时并不能立即释放连接，因为还有必要的数据需要处理，所以服务器先返回ACK确认收到报文，经过CLOSE-WAIT阶段准备好释放连接之后，才能返回FIN释放连接报文。</li></ul></blockquote><p>所以是“三次握手”，“四次挥手”。</p><h2 id="5-为什么客户端在TIME-WAIT阶段要等2MSL"><a href="#5-为什么客户端在TIME-WAIT阶段要等2MSL" class="headerlink" title="5.为什么客户端在TIME-WAIT阶段要等2MSL?"></a>5.为什么客户端在TIME-WAIT阶段要等2MSL?</h2><p>为的是确认服务器端是否收到客户端发出的ACK确认报文</p><p>当客户端发出最后的ACK确认报文时，并不能确定服务器端能够收到该段报文。所以客户端在发送完ACK确认报文之后，会设置一个时长为2MSL的计时器。MSL指的是Maximum Segment Lifetime：一段TCP报文在传输过程中的最大生命周期。2MSL即是服务器端发出为FIN报文和客户端发出的ACK确认报文所能保持有效的最大时长。</p><p>服务器端在1MSL内没有收到客户端发出的ACK确认报文，就会再次向客户端发出FIN报文；</p><blockquote><ul><li>如果客户端在2MSL内，再次收到了来自服务器端的FIN报文，说明服务器端由于各种原因没有接收到客户端发出的ACK确认报文。客户端再次向服务器端发出ACK确认报文，计时器重置，重新开始2MSL的计时；</li><li>否则客户端在2MSL内没有再次收到来自服务器端的FIN报文，说明服务器端正常接收了ACK确认报文，客户端可以进入CLOSED阶段，完成“四次挥手”。</li></ul></blockquote><p>所以，客户端要经历时长为2SML的TIME-WAIT阶段；这也是为什么客户端比服务器端晚进入CLOSED阶段的原因</p><h2 id="6-抓包验证"><a href="#6-抓包验证" class="headerlink" title="6.抓包验证"></a>6.抓包验证</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/11.png"></p><p>图中显示的就是完整的TCP连接释放的”四次挥手”过程。在 80 -&gt; 55389 中，假设80是本地(客户端)端口，55389是服务器端口。80端口与55389之间的四次来回就是”四次挥手”过程。</p><ul><li>”第一次挥手”客户端发送的FIN请求释放连接报文以[FIN，ACK]作为标志位，其中报文序号Seq=2445；确认号Ack=558；<br>注意：这里与“第三次握手”的ACK并不是表示确认的ACK报文。</li><li>”第二次挥手”服务器端返回的ACK确认报文以[ACK]作为标志位；其中报文序号Seq=558；确认号Ack=2246；</li><li>”第三次挥手”服务器端继续返回的FIN同意释放连接报文以[FIN，ACK]作为标志位；其中报文序号Seq=558；确认号Ack=2246；</li><li>”第四次挥手”客户端发出的ACK确认接收报文以[ACK]作为标志位；其中报文序号Seq=2446；确认号Ack=559。</li></ul><blockquote><p>后一次“挥手”传输报文中的序号Seq值等于前一次”握手”传输报文中的确认号Ack值；<br>后一次“挥手”传输报文中的确认号Ack值等于前一次”握手”传输报文中的序号Seq值；</p></blockquote><p>故这是连续的“四次挥手”过程，与前面的分析相符。</p>]]></content>
      
      
      
        <tags>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 为什么 TCP 建立连接需要三次握手 </title>
      <link href="/2020/01/17/2020-01-17-why-tcp-third-hand/"/>
      <url>/2020/01/17/2020-01-17-why-tcp-third-hand/</url>
      
        <content type="html"><![CDATA[<blockquote><p>为什么这么设计（Why’s THE Design）是一系列关于计算机领域中程序设计决策的文章，我们在这个系列的每一篇文章中都会提出一个具体的问题并从不同的角度讨论这种设计的优缺点、对具体实现造成的影响。如果你有想要了解的问题，可以在文章下面留言。</p></blockquote><p>TCP 协议是我们几乎每天都会接触到的网络协议，绝大多数网络连接的建立都是基于 TCP 协议的，学过计算机网络或者对 TCP 协议稍有了解的人都知道 —— 使用 TCP 协议建立连接需要经过三次握手（three-way handshake）。</p><p>如果让我们简单说说 TCP 建立连接的过程，相信很多准备过面试的人都会非常了解，但是一旦想要深究『为什么 TCP 建立连接需要三次握手？』，作者相信大多数人都没有办法回答这个问题或者会给出错误的答案，这边文章就会讨论究竟为什么我们需要三次握手才能建立 TCP 连接？</p><blockquote><p>需要注意的是我们会将重点放到为什么需要 TCP 建立连接需要<strong>『三次握手』</strong>，而<em>不仅仅</em>是为什么需要<strong>『三次』</strong>握手。</p></blockquote><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>在具体分析今天的问题之前，我们首先可以了解一下最常见的错误类比，这个对 TCP 连接过程的错误比喻误导了很多人，作者在比较长的一段时间内也认为它能够很好地描述 TCP 建立连接为什么需要三次握手：</p><ol><li>你听得到吗？</li><li>我能听到，你听得到？</li><li>我也能听到；</li></ol><p>这种用类比来解释问题往往就会面临『十个类比九个错』的尴尬局面，如果别人用类比回答你的为什么，你需要仔细想一想它的类比里究竟哪里有漏洞；类比带来的解释往往只能有片面的相似性，我们永远也无法找到绝对正确的类比，它只在我们想要通俗易懂地展示事物的特性时才能发挥较大的作用，我们在文章的后面会介绍为什么这里的类比有问题，各位读者也可以带着疑问来阅读剩下的内容。</p><p>很多人尝试回答或者思考这个问题的时候其实关注点都放在了三次握手中的<strong>三次</strong>上面，这确实很重要，但是如果重新审视这个问题，我们对于『什么是连接』真的清楚？只有知道<strong>连接的定义</strong>，我们才能去尝试回答为什么 TCP 建立连接需要三次握手。</p><blockquote><p>The reliability and flow control mechanisms described above require that TCPs initialize and maintain certain status information for each data stream. The combination of this information, including sockets, sequence numbers, and window sizes, is called a connection.</p></blockquote><p>RFC 793 - Transmission Control Protocol 文档中非常清楚地定义了 TCP 中的连接是什么，我们简单总结一下：用于保证可靠性和流控制机制的信息，包括 Socket、序列号以及窗口大小叫做连接。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-17/01.png"></p><p>所以，建立 TCP 连接就是通信的双方需要对上述的三种信息达成共识，连接中的一对 Socket 是由互联网地址标志符和端口组成的，窗口大小主要用来做流控制，最后的序列号是用来追踪通信发起方发送的数据包序号，接收方可以通过序列号向发送方确认某个数据包的成功接收。</p><p>到这里，我们将原有的问题转换成了『为什么需要通过三次握手才可以初始化 Sockets、窗口大小和初始序列号？』，那么接下来我们就开始对这个细化的问题进行分析并寻找解释。</p><h1 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h1><p>这篇文章主要会从以下几个方面介绍为什么我们需要通过三次握手才可以初始化 Sockets、窗口大小、初始序列号并建立 TCP 连接：</p><ul><li>通过三次握手才能阻止重复历史连接的初始化；</li><li>通过三次握手才能对通信双方的初始序列号进行初始化；</li><li>讨论其他次数握手建立连接的可能性；</li></ul><p>这几个论点中的第一个是 TCP 选择使用三次握手的最主要原因，其他的几个原因相比之下都是次要的原因，我们在这里对它们的讨论只是为了让整个视角更加丰富，通过多方面理解这一有趣的设计决策。</p><h2 id="历史连接"><a href="#历史连接" class="headerlink" title="历史连接"></a>历史连接</h2><p>RFC 793 - Transmission Control Protocol 其实就指出了 TCP 连接使用三次握手的首要原因 —— 为了阻止历史的重复连接初始化造成的混乱问题，防止使用 TCP 协议通信的双方建立了错误的连接。</p><blockquote><p>The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.</p></blockquote><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-17/02.png"></p><p>想象一下这个场景，如果通信双方的通信次数只有两次，那么发送方一旦发出建立连接的请求之后它就没有办法撤回这一次请求，如果在网络状况复杂或者较差的网络中，发送方连续发送多次建立连接的请求，如果 TCP 建立连接只能通信两次，那么接收方只能选择接受或者拒绝发送方发起的请求，它并不清楚这一次请求是不是由于网络拥堵而早早过期的连接。</p><p>所以，TCP 选择使用三次握手来建立连接并在连接引入了 <code>RST</code> 这一控制消息，接收方当收到请求时会将发送方发来的 <code>SEQ+1</code> 发送回接收方，这时由发送方来判断当前连接是否是历史连接：</p><ul><li>如果当前连接是历史连接，即 <code>SEQ</code> 过期或者超时，那么发送方就会直接发送 <code>RST</code> 控制消息中止这一次连接；</li><li>如果当前连接不是历史连接，那么发送方就会发送 <code>ACK</code> 控制消息，通信双方就会成功建立连接；</li></ul><p>使用三次握手和 <code>RST</code> 控制消息将是否建立连接的最终控制权交给了发送方，因为只有发送方有足够的上下文来判断当前连接是否是错误的或者过期的，这也是 TCP 使用三次握手建立连接的最主要原因。</p><h2 id="初始序列号"><a href="#初始序列号" class="headerlink" title="初始序列号"></a>初始序列号</h2><p>另一个使用三次握手的重要的原因就是通信双方都需要获得一个用于发送信息的初始化序列号，作为一个可靠的传输层协议，TCP 需要在不稳定的网络环境中构建一个可靠的传输层，网络的不确定性可能会导致数据包的缺失和顺序颠倒等问题，常见的问题可能包括：</p><ul><li>数据包被发送方多次发送造成数据的重复；</li><li>数据包在传输的过程中被路由或者其他节点丢失；</li><li>数据包到达接收方可能无法按照发送顺序；</li></ul><p>为了解决上述这些可能存在的问题，TCP 协议要求发送方在数据包中加入『序列号』字段，有了数据包对应的序列号，我们就可以：</p><ul><li>接收方可以通过序列号对重复的数据包进行去重；</li><li>发送方会在对应数据包未被 ACK 时进行重复发送；</li><li>接收方可以根据数据包的序列号对它们进行重新排序；</li></ul><p>序列号在 TCP 连接中有着非常重要的作用，初始序列号作为 TCP 连接的一部分也需要在三次握手期间进行初始化，由于 TCP 连接通信的双方都需要获得初始序列号，所以它们其实需要向对方发送 <code>SYN</code> 控制消息并携带自己期望的初始化序列号 <code>SEQ</code>，对方在收到 <code>SYN</code> 消息之后会通过 <code>ACK</code> 控制消息以及 <code>SEQ+1</code> 来进行确认。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-17/03.png"></p><p>如上图所示，通信双方的两个 <code>TCP A/B</code> 分别向对方发送 <code>SYN</code> 和 <code>ACK</code> 控制消息，等待通信双方都获取到了自己期望的初始化序列号之后就可以开始通信了，由于 TCP 消息头的设计，我们可以将中间的两次通信合成一个，<code>TCP B</code> 可以向 <code>TCP A</code> 同时发送 <code>ACK</code> 和 <code>SYN</code> 控制消息，这也就帮助我们将四次通信减少至三次。</p><blockquote><p>A three way handshake is necessary because sequence numbers are not tied to a global clock in the network, and TCPs may have different mechanisms for picking the ISN’s. The receiver of the first SYN has no way of knowing whether the segment was an old delayed one or not, unless it remembers the last sequence number used on the connection (which is not always possible), and so it must ask the sender to verify this SYN. The three way handshake and the advantages of a clock-driven scheme are discussed in [3].</p></blockquote><p>除此之外，网络作为一个分布式的系统，其中并不存在一个用于计数的全局时钟，而 TCP 可以通过不同的机制来初始化序列号，作为 TCP 连接的接收方我们无法判断对方传来的初始化序列号是否过期，所以我们需要交由对方来判断，TCP 连接的发起方可以通过保存发出的序列号判断连接是否过期，如果让接收方来保存并判断序列号却是不现实的，这也再一次强化了我们在上一节中提出的观点 —— 避免历史错连接的初始化。</p><h2 id="通信次数"><a href="#通信次数" class="headerlink" title="通信次数"></a>通信次数</h2><p>当我们讨论 TCP 建立连接需要的通信次数时，我们经常会执着于为什么通信三次才可以建立连接，而不是两次或者四次；讨论使用更多的通信次数来建立连接往往是没有意义的，因为我们总可以<strong>使用更多的通信次数交换相同的信息</strong>，所以使用四次、五次或者更多次数建立连接在技术上都是完全可以实现的。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-17/04.png"></p><p>这种增加 TCP 连接通信次数的问题往往没有讨论的必要性，我们追求的其实是用更少的通信次数（理论上的边界）完成信息的交换，也就是为什么我们在上两节中也一再强调使用『两次握手』没有办法建立 TCP 连接，使用三次握手是建立连接所需要的最小次数。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我们在这篇文章中讨论了为什么 TCP 建立连接需要经过三次握手，在具体分析这个问题之前，我们首先重新思考了 TCP 连接究竟是什么，RFC 793 - Transmission Control Protocol - IETF Tools 对 TCP 连接有着非常清楚的定义 —— 用于保证可靠性和流控制机制的数据，包括 Socket、序列号以及窗口大小。</p><p>TCP 建立连接时通过三次握手可以有效地避免历史错误连接的建立，减少通信双方不必要的资源消耗，三次握手能够帮助通信双方获取初始化序列号，它们能够保证数据包传输的不重不丢，还能保证它们的传输顺序，不会因为网络传输的问题发生混乱，到这里不使用『两次握手』和『四次握手』的原因已经非常清楚了：</p><ul><li>『两次握手』：无法避免历史错误连接的初始化，浪费接收方的资源；</li><li>『四次握手』：TCP 协议的设计可以让我们同时传递 <code>ACK</code> 和 <code>SYN</code> 两个控制信息，减少了通信次数，所以不需要使用更多的通信次数传输相同的信息；</li></ul><p>我们重新回到在文章开头提的问题，为什么使用类比解释 TCP 使用三次握手是错误的？这主要还是因为，这个类比没有解释清楚核心问题 —— 避免历史上的重复连接。到最后，我们还是来看一些比较开放的相关问题，有兴趣的读者可以仔细想一下下面的问题：</p><ul><li>除了使用序列号是否还有其他方式保证消息的不重不丢？</li><li>UDP 协议有连接的概念么，它能保证数据传输的可靠么？</li></ul><p><strong>来源：</strong>微信公众号<strong>『真没什么逻辑』</strong>，作者 Draveness</p>]]></content>
      
      
      
        <tags>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 听上去超酷的 Service Mesh 到底是什么？ </title>
      <link href="/2020/01/16/2020-01-16-what-is-servicemesh/"/>
      <url>/2020/01/16/2020-01-16-what-is-servicemesh/</url>
      
        <content type="html"><![CDATA[<p>Service Mesh 作为下一代微服务技术的代名词，初出茅庐却深得人心一鸣惊人，大有一统微服务时代的趋势。那么到底什么是Service Mesh？</p><p>一言以蔽之：<strong>Service Mesh是微服务时代的TCP协议。</strong></p><p>有了这样一个感性的初步认知，我们再来看到底什么是Service Mesh。提到Service Mesh，就不得不提微服务。根据维基百科的定义：</p><blockquote><p>微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通信。</p></blockquote><p>目前业界跟微服务相关的开发平台和框架更是不胜枚举：Spring Cloud， Service Fabric，Linkerd，Envoy，Istio … 这些纷繁的产品和Sevice Mesh有什么样的关联？哪些属于Service Mesh的范畴？</p><p>为了理清这些繁复的产品和概念，我们先来了解下微服务和Service Mesh技术的历史发展脉络。了解清楚了技术的主要脉络，就能清晰的知道上述的各个平台、框架属于技术脉络中的哪个结点，其间的关系也就一目了然。</p><p>Phil Calçado的文章《Pattern: Service Mesh》详细的介绍了从开发者视角来看，服务开发模式和Service Mesh技术的演化过程，个人认为是非常经典的学习Service Mesh的资料。</p><p>这里借用文章的脉络，结合自己的理解并予以简化，试图说清楚ServiceMesh的概念和这项技术诞生的历史必然性。</p><p>时代0：开发人员想象中，不同服务间通信的方式，抽象表示如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/developer.png"></p><p><strong>时代1：原始通信时代</strong><br>然而现实远比想象的复杂，在实际情况中，通信需要底层能够传输字节码和电子信号的物理层来完成，在TCP协议出现之前，服务需要自己处理网络通信所面临的丢包、乱序、重试等一系列流控问题，因此服务实现中，除了业务逻辑外，还夹杂着对网络传输问题的处理逻辑。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time1.png"></p><p><strong>时代2：TCP时代</strong><br>为了避免每个服务都需要自己实现一套相似的网络传输处理逻辑，TCP协议出现了，它解决了网络传输中通用的流量控制问题，将技术栈下移，从服务的实现中抽离出来，成为操作系统网络层的一部分。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time2.png"></p><p><strong>时代3：第一代微服务</strong><br>在TCP出现之后，机器之间的网络通信不再是一个难题，以GFS/BigTable/MapReduce为代表的分布式系统得以蓬勃发展。这时，分布式系统特有的通信语义又出现了，如熔断策略、负载均衡、服务发现、认证和授权、quota限制、trace和监控等等，于是服务根据业务需求来实现一部分所需的通信语义。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time3.png"></p><p><strong>时代4：第二代微服务</strong><br>为了避免每个服务都需要自己实现一套分布式系统通信的语义功能，随着技术的发展，一些面向微服务架构的开发框架出现了，如Twitter的Finagle、Facebook的Proxygen以及Spring Cloud等等，这些框架实现了分布式系统通信需要的各种通用语义功能：如负载均衡和服务发现等，因此一定程度上屏蔽了这些通信细节，使得开发人员使用较少的框架代码就能开发出健壮的分布式系统。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time4.png"></p><p><strong>时代5：第一代Service Mesh</strong><br>第二代微服务模式看似完美，但开发人员很快又发现，它也存在一些本质问题：</p><ul><li>其一，虽然框架本身屏蔽了分布式系统通信的一些通用功能实现细节，但开发者却要花更多精力去掌握和管理复杂的框架本身，在实际应用中，去追踪和解决框架出现的问题也绝非易事；</li><li>其二，开发框架通常只支持一种或几种特定的语言，回过头来看文章最开始对微服务的定义，一个重要的特性就是语言无关，但那些没有框架支持的语言编写的服务，很难融入面向微服务的架构体系，想因地制宜的用多种语言实现架构体系中的不同模块也很难做到；</li><li>其三，框架以lib库的形式和服务联编，复杂项目依赖时的库版本兼容问题非常棘手，同时，框架库的升级也无法对服务透明，服务会因为和业务无关的lib库升级而被迫升级；</li></ul><p>因此以Linkerd，Envoy，Ngixmesh为代表的代理模式（边车模式）应运而生，这就是第一代Service Mesh，它将分布式服务的通信抽象为单独一层，在这一层中实现负载均衡、服务发现、认证授权、监控追踪、流量控制等等分布式系统所需要的功能，作为一个和服务对等的代理服务，和服务部署在一起，接管服务的流量，通过代理之间的通信间接完成服务之间的通信请求，这样上边所说的三个问题也迎刃而解。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time5-1.png"></p><p>如果我们从一个全局视角来看，就会得到如下部署图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time5-2.png"></p><p>如果我们暂时略去服务，只看Service Mesh的单机组件组成的网络：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time5-3.png"></p><p>相信现在，大家已经理解何所谓Service Mesh，也就是服务网格了。<strong>它看起来确实就像是一个由若干服务代理所组成的错综复杂的网格。</strong></p><p><strong>时代6：第二代Service Mesh</strong><br>第一代Service Mesh由一系列独立运行的单机代理服务构成，为了提供统一的上层运维入口，演化出了集中式的控制面板，所有的单机代理组件通过和控制面板交互进行网络拓扑策略的更新和单机数据的汇报。这就是以Istio为代表的第二代Service Mesh。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time6-1.png"></p><p>只看单机代理组件(数据面板)和控制面板的Service Mesh全局部署视图如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time6-2.png"></p><p>至此，见证了6个时代的变迁，大家一定清楚了Service Mesh技术到底是什么，以及是如何一步步演化到今天这样一个形态。</p><p>现在，我们再回过头来看Buoyant的CEO William Morgan，也就是Service Mesh这个词的发明人，对Service Mesh的定义：</p><blockquote><p>服务网格是一个基础设施层，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证请求在这些拓扑中可靠地穿梭。在实际应用当中，服务网格通常是由一系列轻量级的网络代理组成的，它们与应用程序部署在一起，但对应用程序透明。</p></blockquote><p>这个定义中，有四个关键词：</p><p><strong>基础设施层+请求在这些拓扑中可靠穿梭</strong>：这两个词加起来描述了Service Mesh的定位和功能，是不是似曾相识？没错，你一定想到了TCP；</p><p><strong>网络代理</strong>：这描述了Service Mesh的实现形态；</p><p><strong>对应用透明</strong>：这描述了Service Mesh的关键特点，正是由于这个特点，Service Mesh能够解决以Spring Cloud为代表的第二代微服务框架所面临的三个本质问题；</p><p>总结一下，Service Mesh具有如下优点：</p><ul><li>屏蔽分布式系统通信的复杂性(负载均衡、服务发现、认证授权、监控追踪、流量控制等等)，服务只用关注业务逻辑；</li><li>真正的语言无关，服务可以用任何语言编写，只需和Service Mesh通信即可；</li><li>对应用透明，Service Mesh组件可以单独升级；</li></ul><p>当然，Service Mesh目前也面临一些挑战：</p><ul><li>Service Mesh组件以代理模式计算并转发请求，一定程度上会降低通信系统性能，并增加系统资源开销；</li><li>Service Mesh组件接管了网络流量，因此服务的整体稳定性依赖于Service Mesh，同时额外引入的大量Service Mesh服务实例的运维和管理也是一个挑战；</li></ul><p>历史总是惊人的相似。为了解决端到端的字节码通信问题，TCP协议诞生，让多机通信变得简单可靠；微服务时代，Service Mesh 应运而生，屏蔽了分布式系统的诸多复杂性，让开发者可以回归业务，聚焦真正的价值。</p><p>原文链接：<a href="https://smwyzi.github.io/post/what-is-service-mesh/">https://smwyzi.github.io/post/what-is-service-mesh/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ServerMesh </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 为什么执行自己的程序要在前面加./ </title>
      <link href="/2020/01/15/2020-01-15-why-exec-program/"/>
      <url>/2020/01/15/2020-01-15-why-exec-program/</url>
      
        <content type="html"><![CDATA[<p>在Linux中，我们执行内置命令时，直接输入命令名称即可，如：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mv a b <span class="comment">#将a重命名为b</span></span><br></pre></td></tr></table></figure><p>而在执行自己写好的程序时，却要带上./，例如：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hello</span><br><span class="line">hello: <span class="built_in">command</span> not found</span><br><span class="line">$ ./hello</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p>这是为什么呢？它们有什么区别呢？</p><h1 id="shell是如何运行程序的"><a href="#shell是如何运行程序的" class="headerlink" title="shell是如何运行程序的"></a>shell是如何运行程序的</h1><p>在说明清楚问题之前，我们必须了解shell是如何运行程序的。首先我们必须要清楚的是，执行一条Linux命令，本质是在运行一个程序，如执行ls命令，它执行的是ls程序。那么在shell中输入一条命令，到底发生了什么？如果没有给出当前路径或绝对路径，它会经历哪几个查找过程？</p><h2 id="alias中查找"><a href="#alias中查找" class="headerlink" title="alias中查找"></a>alias中查找</h2><p>alias命令可用来设置命令别名，而单独输入alias可以查看到已设置的别名：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">alias</span></span><br><span class="line"><span class="built_in">alias</span> egrep=<span class="string">&#x27;egrep --color=auto&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> fgrep=<span class="string">&#x27;fgrep --color=auto&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> grep=<span class="string">&#x27;grep --color=auto&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> l=<span class="string">&#x27;ls -CF&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> la=<span class="string">&#x27;ls -A&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> ll=<span class="string">&#x27;ls -alF&#x27;</span></span><br><span class="line"><span class="built_in">alias</span> ls=<span class="string">&#x27;ls --color=auto&#x27;</span></span><br></pre></td></tr></table></figure><p>如果这里没有找到你执行的命令，那么就会接下去查找。如果找到了，那么就会执行下去。</p><h2 id="内置命令中查找"><a href="#内置命令中查找" class="headerlink" title="内置命令中查找"></a>内置命令中查找</h2><p>不同的shell包含一些不同的内置命令，通常不需要shell到磁盘中去搜索。通过help命令可以看到有哪些内置命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">help</span></span><br></pre></td></tr></table></figure><p>通过type 命令可以查看命令类型：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">type</span> <span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> is a shell <span class="built_in">builtin</span></span><br></pre></td></tr></table></figure><p>如果是内置命令，则会直接执行，否则继续查找。</p><h2 id="PATH中查找"><a href="#PATH中查找" class="headerlink" title="PATH中查找"></a>PATH中查找</h2><p>以ls为例，在shell输入ls时，首先它会从PATH环境变量中查找，PATH内容是什么呢，我们看看：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="variable">$PATH</span></span><br><span class="line">/usr/<span class="built_in">local</span>/sbin:/usr/<span class="built_in">local</span>/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/<span class="built_in">local</span>/games</span><br></pre></td></tr></table></figure><p>所以它会在这些路径下去寻找ls程序，按照路径找到的第一个ls程序就会被执行。使用whereis也能确定ls的位置：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ whereis ls</span><br><span class="line">ls: /bin/ls /usr/share/man/man1/ls.1.g</span><br></pre></td></tr></table></figure><p>既然它是在bin目录下，那么我把ls从bin目录下移走是不是就找不到了呢？是的。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mv /bin/ls /temp/ls_bak  <span class="comment">#测试完后记得改回来奥</span></span><br></pre></td></tr></table></figure><p>现在再来执行ls命令看看：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ls</span><br><span class="line">The program <span class="string">&#x27;ls&#x27;</span> is currently not installed. You can install it by typing:</span><br><span class="line">apt install coreutils</span><br></pre></td></tr></table></figure><p>没错，它会提示你没有安装这个程序或者命令没有找到。</p><p>所以你现在明白为什么你第一次安装jdk或者python的时候要设置环境变量了吧？不设置的话行不行？</p><p>行。这个时候你就需要指定路径了。怎么指定路径？无非就是那么几种，相对路径，绝对路径等等。<br>比如：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /temp</span><br><span class="line">$ ./ls_bak</span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ /temp/ls_bak</span><br></pre></td></tr></table></figure><p>是不是发现和运行自己的普通程序方式没什么差别呢？</p><p>到这里，如果还没有找到你要执行的命令，那么就会报错。</p><h2 id="确定解释程序"><a href="#确定解释程序" class="headerlink" title="确定解释程序"></a>确定解释程序</h2><p>在找到程序之后呢，需要确定解释程序。什么意思呢？<br>shell通常可以执行两种程序，一种是二进制程序，一种是脚本程序。</p><p>而一旦发现要执行的程序文件是文本文件，且文本未指定解释程序，那么就会默认当成shell脚本来执行。例如，假设有test.txt内容如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;hello world&quot;</span></span><br></pre></td></tr></table></figure><p>赋予执行权限并执行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ chmod +x test.txt</span><br><span class="line">$ ./test.txt</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p>当然了，我们通常会在shell脚本程序的来头带上下面这句：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br></pre></td></tr></table></figure><p>这是告诉shell，你要用bash程序来解释执行test.txt。作为一位调皮的开发者，如果开头改成下面这样呢？</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/python</span></span><br></pre></td></tr></table></figure><p>再次执行之后结果如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ./test.txt</span><br><span class="line">  File <span class="string">&quot;./test.txt&quot;</span>, line 2</span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;hello world&quot;</span></span><br><span class="line">                        ^</span><br><span class="line">SyntaxError: invalid syntax</span><br></pre></td></tr></table></figure><p>是的，它被当成python脚本来执行了，自然就会报错了。</p><p>那么如果是二进制程序呢？就会使用execl族函数去创建一个新的进程来运行新的程序了。</p><p>小结一下前面的内容，就是说，如果是文本程序，且开头没有指定解释程序，则按照shell脚本处理，如果指定了解释程序，则使用解释程序来解释运行；对于二进制程序，则直接创建新的进程即可。</p><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><p>前面我们也已经看到了运行方式，设置环境变量或者使用相对路径，绝对路径即可。不过对于shell脚本，你还可以像下面这样执行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sh test.txt</span><br><span class="line">$ . test.txt</span><br></pre></td></tr></table></figure><p>即便test.txt没有执行权限，也能够正常执行。</p><p>什么？你说为什么txt也能执行？注意，Linux下的文件后缀不过是为了方便识别文件类型罢了，以.txt结尾，并不代表一定是文本。当然在这里它确实是，而且还是ASCII text executable：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ file test.txt</span><br><span class="line">test.txt: Bourne-Again shell script, ASCII text executable</span><br><span class="line">$ file hello</span><br><span class="line">hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/l, <span class="keyword">for</span> GNU/Linux 2.6.32, BuildID[sha1]=8ae48f0f84912dec98511581c876aa042824efdb, not stripped</span><br></pre></td></tr></table></figure><h1 id="扩展一下"><a href="#扩展一下" class="headerlink" title="扩展一下"></a>扩展一下</h1><p>那么如果让我们自己的程序也能够像Linux内置命令一样输入即可被识别呢？</p><h2 id="将程序放到PATH路径下"><a href="#将程序放到PATH路径下" class="headerlink" title="将程序放到PATH路径下"></a>将程序放到PATH路径下</h2><p>第一种方法就是将我们自己的程序放到PATH中的路径中去，这样在shell输入hello时，也能找到，例如我们将其放在/bin目录下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hello</span><br><span class="line">hello world</span><br><span class="line">$ whereis hello</span><br><span class="line">hello: /bin/hello</span><br></pre></td></tr></table></figure><p>也就是说，如果你的程序安装在了PATH指定的路径，就需要配置PATH环境变量，在命令行输入就可以直接找到了。</p><h2 id="设置PATH环境变量"><a href="#设置PATH环境变量" class="headerlink" title="设置PATH环境变量"></a>设置PATH环境变量</h2><p>那么如果想在指定的目录能够直接运行呢？很简单，那就是添加环境变量，例如将当前路径加入到PATH中：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ PATH=<span class="variable">$PATH</span>:./   <span class="comment">#这种方式只在当前shell有效，所有shell生效可修改/etc/profile文件</span></span><br><span class="line">$ hello</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><h2 id="设置别名"><a href="#设置别名" class="headerlink" title="设置别名"></a>设置别名</h2><p>例如：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">alias</span> hello=<span class="string">&quot;/temp/hello&quot;</span></span><br><span class="line">$ hello</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><p>以上三种方法都可以达到目的。</p><h1 id="执行顺序"><a href="#执行顺序" class="headerlink" title="执行顺序"></a>执行顺序</h1><p>那么假设我写了一个自己的printf程序，当执行printf的时候，到底执行的是哪一个呢？</p><p>实际上它的查找顺序可以可以通过type -a来查看：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">type</span> -a <span class="built_in">printf</span></span><br><span class="line"><span class="built_in">printf</span> is aliased to `<span class="built_in">printf</span> <span class="string">&quot;hello</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">printf is a shell builtin</span></span><br><span class="line"><span class="string">printf is /usr/bin/printf</span></span><br><span class="line"><span class="string">printf is ./printf</span></span><br></pre></td></tr></table></figure><p>这里就可以很清楚地看到查找顺序了。也就是说，如果你输入printf，它执行的是：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">printf</span></span><br><span class="line">hello</span><br></pre></td></tr></table></figure><p>而如果删除别名：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">unalias</span> <span class="built_in">printf</span></span><br></pre></td></tr></table></figure><p>它执行的将会是内置命令printf。<br>以此类推。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>说到这里，想必标题的问题以及下面的问题你都清楚了：</p><ul><li>安装Python或者Jdk程序为什么要设置PATH环境变量？如果不设置，该如何运行？</li><li>除了./方式运行自己的程序还有什么方式？</li><li>如果让自己的程序能够像内置命令一样被识别？</li><li>如何查看文件类型？</li><li>执行一条命令，如何确定是哪里的命令被执行</li></ul><p>本文涉及命令：</p><ul><li>mv 移动/重命名</li><li>file 查看文件信息</li><li>whereis 查看命令或者手册位置</li><li>type 查看命令类别</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 分布式和集群的区别 </title>
      <link href="/2020/01/14/2020-01-14-distributed-and-cluster-difference/"/>
      <url>/2020/01/14/2020-01-14-distributed-and-cluster-difference/</url>
      
        <content type="html"><![CDATA[<p>分布式开发的时代实际上早已悄悄地成为了时代的主流，吵得很热的云计算实际上只是包装在分布式之外的商业概念，很多开发者（包括我）都想加入研究云计算这个潮流，在 Google 上通过 “云计算” 这个关键词来查询资料，查到的都是些概念性或商业性的宣传资料，其实真正需要深入的还是那个早以被人熟知的概念——分布式。</p><p>分布式可繁也可以简，最简单的分布式就是大家最常用的，在负载均衡服务器后加一堆 Web 服务器，然后在上面搞一个缓存服务器来保存临时状态，后面共享一个数据库，其实很多号称分布式专家的人也就停留于此，大致结构如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-14/1.png"></p><p>这种环境下真正进行分布式的只是 Web Server 而已，并且 Web Server 之间没有任何联系，所以结构和实现都非常简单。</p><p>有些情况下，对分布式的需求就没这么简单，在每个环节上都有分布式的需求，比如 Load Balance、DB、Cache 和文件等等，并且当分布式节点之间有关联时，还得考虑之间的通讯，另外，节点非常多的时候，得有监控和管理来支撑。这样看起来，分布式是一个非常庞大的体系，只不过你可以根据具体需求进行适当地裁剪。按照最完备的分布式体系来看，可以由以下模块组成：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-14/2.png"></p><ul><li>分布式任务处理服务：负责具体的业务逻辑处理</li><li>分布式节点注册和查询：负责管理所有分布式节点的命名和物理信息的注册与查询，是节点之间联系的桥梁</li><li>分布式 DB：分布式结构化数据存取</li><li>分布式 Cache：分布式缓存数据（非持久化）存取</li><li>分布式文件：分布式文件存取</li><li>网络通信：节点之间的网络数据通信</li><li>监控管理：搜集、监控和诊断所有节点运行状态</li><li>分布式编程语言：用于分布式环境下的专有编程语言，比如 Elang、Scala</li><li>分布式算法：为解决分布式环境下一些特有问题的算法，比如解决一致性问题的 Paxos 算法</li></ul><p>因此，若要深入研究云计算和分布式，就得深入研究以上领域，而这些领域每一块的水都很深，都需要很底层的知识和技术来支撑，所以说，对于想提升技术的开发者来说，以分布式来作为切入点是非常好的，可以以此为线索，探索计算机世界的各个角落。</p><p>集群是个物理形态，分布式是个工作方式。</p><p>只要是一堆机器，就可以叫集群，他们是不是一起协作着干活，这个谁也不知道；一个程序或系统，只要运行在不同的机器上，就可以叫分布式，嗯，C/S 架构也可以叫分布式。</p><p>集群一般是物理集中、统一管理的，而分布式系统则不强调这一点。</p><p>所以，集群可能运行着一个或多个分布式系统，也可能根本没有运行分布式系统；分布式系统可能运行在一个集群上，也可能运行在不属于一个集群的多台（2 台也算多台）机器上。</p><p>布式是相对中心化而来，强调的是任务在多个物理隔离的节点上进行。中心化带来的主要问题是可靠性，若中心节点宕机则整个系统不可用，分布式除了解决部分中心化问题，也倾向于分散负载，但分布式会带来很多的其他问题，最主要的就是一致性。</p><p>集群就是逻辑上处理同一任务的机器集合，可以属于同一机房，也可分属不同的机房。分布式这个概念可以运行在某个集群里面，某个集群也可作为分布式概念的一个节点。</p><p>一句话，就是：“分头做事” 与 “一堆人” 的区别。</p><p>分布式是指将不同的业务分布在不同的地方。而集群指的是将几台服务器集中在一起，实现同一业务。</p><p>分布式中的每一个节点，都可以做集群。而集群并不一定就是分布式的。</p><p>举例：就比如新浪网，访问的人多了，他可以做一个群集，前面放一个响应服务器，后面几台服务器完成同一业务，如果有业务访问的时候，响应服务器看哪台服务器的负载不是很重，就将给哪一台去完成。</p><p>而分布式，从窄意上理解，也跟集群差不多， 但是它的组织比较松散，不像集群，有一个组织性，一台服务器垮了，其它的服务器可以顶上来。</p><p>分布式的每一个节点，都完成不同的业务，一个节点垮了，哪这个业务就不可访问了。</p><p>简单说，分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。</p><p>例如：如果一个任务由 10 个子任务组成，每个子任务单独执行需 1 小时，则在一台服务器上执行该任务需 10 小时。</p><p>采用分布式方案，提供 10 台服务器，每台服务器只负责处理一个子任务，不考虑子任务间的依赖关系，执行完这个任务只需一个小时。(这种工作模式的一个典型代表就是 Hadoop 的 Map/Reduce 分布式计算模型）</p><p>而采用集群方案，同样提供 10 台服务器，每台服务器都能独立处理这个任务。假设有 10 个任务同时到达，10 个服务器将同时工作，1 小时后，10 个任务同时完成，这样，整身来看，还是 1 小时内完成一个任务！</p><p>集群一般被分为三种类型，高可用集群如 RHCS、LifeKeeper 等，负载均衡集群如 LVS 等、高性能运算集群;分布式应该是高性能运算集群范畴内。</p><ul><li>分布式：不同的业务模块部署在不同的服务器上或者同一个业务模块分拆多个子业务，部署在不同的服务器上，解决高并发的问题</li><li>集群：同一个业务部署在多台机器上，提高系统可用性</li></ul><p>大白话讲：</p><p>小饭店原来只有一个厨师，切菜洗菜备料炒菜全干。后来客人多了，厨房一个厨师忙不过来，又请了个厨师，两个厨师都能炒一样的菜，这两个厨师的关系是集群。为了让厨师专心炒菜，把菜做到极致，又请了个配菜师负责切菜，备菜，备料，厨师和配菜师的关系是分布式，一个配菜师也忙不过来了，又请了个配菜师，两个配菜师关系是集群。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么需要微服务网关</title>
      <link href="/2020/01/13/2020-01-13-why-microservice-gateway/"/>
      <url>/2020/01/13/2020-01-13-why-microservice-gateway/</url>
      
        <content type="html"><![CDATA[<h1 id="一、什么是服务网关"><a href="#一、什么是服务网关" class="headerlink" title="一、什么是服务网关"></a>一、什么是服务网关</h1><p>服务网关 = 路由转发 + 过滤器</p><p>1、路由转发：接收一切外界请求，转发到后端的微服务上去；</p><p>2、过滤器：在服务网关中可以完成一系列的横切功能，例如权限校验、限流以及监控等，这些都可以通过过滤器完成（其实路由转发也是通过过滤器实现的）。</p><h1 id="二、为什么需要服务网关"><a href="#二、为什么需要服务网关" class="headerlink" title="二、为什么需要服务网关"></a>二、为什么需要服务网关</h1><p>上述所说的横切功能（以权限校验为例）可以写在三个位置：</p><ul><li>每个服务自己实现一遍</li><li>写到一个公共的服务中，然后其他所有服务都依赖这个服务</li><li>写到服务网关的前置过滤器中，所有请求过来进行权限校验</li></ul><p>第一种，缺点太明显，基本不用；第二种，相较于第一点好很多，代码开发不会冗余，但是有两个缺点：</p><ul><li>由于每个服务引入了这个公共服务，那么相当于在每个服务中都引入了相同的权限校验的代码，使得每个服务的jar包大小无故增加了一些，尤其是对于使用docker镜像进行部署的场景，jar越小越好；</li><li>由于每个服务都引入了这个公共服务，那么我们后续升级这个服务可能就比较困难，而且公共服务的功能越多，升级就越难，而且假设我们改变了公共服务中的权限校验的方式，想让所有的服务都去使用新的权限校验方式，我们就需要将之前所有的服务都重新引包，编译部署。</li></ul><p>而服务网关恰好可以解决这样的问题：</p><ul><li>将权限校验的逻辑写在网关的过滤器中，后端服务不需要关注权限校验的代码，所以服务的jar包中也不会引入权限校验的逻辑，不会增加jar包大小；</li><li>如果想修改权限校验的逻辑，只需要修改网关中的权限校验过滤器即可，而不需要升级所有已存在的微服务。</li></ul><p>所以，需要服务网关！！！</p><h1 id="三、服务网关技术选型"><a href="#三、服务网关技术选型" class="headerlink" title="三、服务网关技术选型"></a>三、服务网关技术选型</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-13/1.png"></p><p>引入服务网关后的微服务架构如上，总体包含三部分：服务网关、open-service和service。</p><h2 id="1、总体流程"><a href="#1、总体流程" class="headerlink" title="1、总体流程"></a>1、总体流程</h2><ul><li>服务网关、open-service和service启动时注册到注册中心上去；</li><li>用户请求时直接请求网关，网关做智能路由转发（包括服务发现，负载均衡）到open-service，这其中包含权限校验、监控、限流等操作</li><li>open-service聚合内部service响应，返回给网关，网关再返回给用户</li></ul><h2 id="2、引入网关的注意点"><a href="#2、引入网关的注意点" class="headerlink" title="2、引入网关的注意点"></a>2、引入网关的注意点</h2><ul><li>增加了网关，多了一层转发（原本用户请求直接访问open-service即可），性能会下降一些（但是下降不大，通常，网关机器性能会很好，而且网关与open-service的访问通常是内网访问，速度很快）；</li><li>网关的单点问题：在整个网络调用过程中，一定会有一个单点，可能是网关、nginx、dns服务器等。防止网关单点，可以在网关层前边再挂一台nginx，nginx的性能极高，基本不会挂，这样之后，网关服务就可以不断的添加机器。但是这样一个请求就转发了两次，所以最好的方式是网关单点服务部署在一台牛逼的机器上（通过压测来估算机器的配置），而且nginx与zuul的性能比较，根据国外的一个哥们儿做的实验来看，其实相差不大，zuul是netflix开源的一个用来做网关的开源框架；</li><li>网关要尽量轻。</li></ul><h2 id="3、服务网关基本功能"><a href="#3、服务网关基本功能" class="headerlink" title="3、服务网关基本功能"></a>3、服务网关基本功能</h2><ul><li><p>智能路由：接收</p><p>外部一切请求，并转发到后端的对外服务open-service上去；</p></li><li><p>注意：我们只转发外部请求，服务之间的请求不走网关，这就表示全链路追踪、内部服务API监控、内部服务之间调用的容错、智能路由不能在网关完成；当然，也可以将所有的服务调用都走网关，那么几乎所有的功能都可以集成到网关中，但是这样的话，网关的压力会很大，不堪重负。</p></li><li><p>权限校验：只校验用户向open-service服务的请求，不校验服务内部的请求。服务内部的请求有必要校验吗？</p></li><li><p>API监控：只监控经过网关的请求，以及网关本身的一些性能指标（例如，gc等）；</p></li><li><p>限流：与监控配合，进行限流操作；</p></li><li><p>API日志统一收集：类似于一个aspect切面，记录接口的进入和出去时的相关日志</p></li><li><p>。。。后续补充</p></li></ul><p>上述功能是网关的基本功能，网关还可以实现以下功能：</p><ul><li>A|B测试：A|B测试时一块比较大的东西，包含后台实验配置、数据埋点（看转化率）以及分流引擎，在服务网关中，可以实现分流引擎，但是实际上分流引擎会调用内部服务，所以如果是按照上图的架构，分流引擎最好做在open-service中，不要做在服务网关中。</li><li>。。。后续补充</li></ul><h2 id="4、技术选型"><a href="#4、技术选型" class="headerlink" title="4、技术选型"></a>4、技术选型</h2><p>笔者准备自建一个轻量级的服务网关，技术选型如下：</p><ul><li>开发语言：java + groovy，groovy的好处是网关服务不需要重启就可以动态的添加filter来实现一些功能；</li><li>微服务基础框架：springboot；</li><li>网关基础组件：netflix zuul；</li><li>服务注册中心：consul；</li><li>权限校验：jwt；</li><li>API监控：prometheus + grafana；</li><li>API统一日志收集：logback + ELK；</li><li>压力测试：Jmeter；</li><li>。。。后续补充</li></ul><p>在后续的介绍中，会逐渐介绍各个知识点，并完成一个轻量级的服务网关！！！</p>]]></content>
      
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 迄今为止把同步/异步/阻塞/非阻塞/BIO/NIO/AIO讲的这么清楚的好文章 </title>
      <link href="/2020/01/10/2020-01-10-sync-async/"/>
      <url>/2020/01/10/2020-01-10-sync-async/</url>
      
        <content type="html"><![CDATA[<p><strong>常规的误区</strong></p><p>假设有一个展示用户详情的需求，分两步，先调用一个HTTP接口拿到详情数据，然后使用适合的视图展示详情数据。</p><p>如果网速很慢，代码发起一个HTTP请求后，就卡住不动了，直到十几秒后才拿到HTTP响应，然后继续往下执行。</p><p>这个时候你问别人，刚刚代码发起的这个请求是不是一个同步请求，对方一定回答是。这是对的，它确实是。</p><p>但你要问它为什么是呢？对方一定是这样回答的，“因为发起请求后，代码就卡住不动了，直到拿到响应后才可以继续往下执行”。</p><p>我相信很多人也都是这样认为的，其实这是不对的，是把因果关系搞反了：</p><p>不是因为代码卡住不动了才叫同步请求，而是因为它是同步请求所以代码才卡住不动了。</p><p>至于为什么能卡住不动，这是由操作系统和CPU决定的：</p><p>因为内核空间里的对应函数会卡住不动，造成用户空间发起的系统调用卡住不动，继而使程序里的用户代码卡住不动了。</p><p>因此卡住不动了只是同步请求的一个副作用，并不能用它来定义同步请求，那该如何定义呢？</p><p><strong>同步和异步</strong></p><p>所谓同步，指的是协同步调。既然叫协同，所以至少要有2个以上的事物存在。协同的结果就是：</p><p>多个事物不能同时进行，必须一个一个的来，上一个事物结束后，下一个事物才开始。</p><p>那当一个事物正在进行时，其它事物都在干嘛呢？</p><p>严格来讲这个并没有要求，但一般都是处于一种“等待”的状态，因为通常后面事物的正常进行都需要依赖前面事物的结果或前面事物正在使用的资源。</p><p>因此，可以认为，同步更希望关注的是从宏观整体来看，多个事物是一种逐个逐个的串行化关系，绝对不会出现交叉的情况。</p><p>所以，自然也不太会去关注某个瞬间某个具体事物是处于一个什么状态。</p><p>把这个理论应用的出神入化的非“排队”莫属。凡是在资源少需求多的场景下都会用到排队。</p><p>比如排队买火车票这件事：</p><p>其实售票大厅更在意的是旅客一个一个的到窗口去买票，因为一次只能卖一张票。</p><p>即使大家一窝蜂的都围上去，还是一次只能卖一张票，何必呢？挤在一起又不安全。</p><p>只是有些人素质太差，非要往上挤，售票大厅迫不得已，采用排队这种形式来达到自己的目的，即一个一个的买票。</p><p>至于每个旅客排队时的状态，是看手机呀还是说话呀，根本不用去在意。</p><p>除了这种由于资源导致的同步外，还存在一种由于逻辑上的先后顺序导致的同步。</p><p>比如，先更新代码，然后再编译，接着再打包。这些操作由于后一步要使用上一步的结果，所以只能按照这种顺序一个一个的执行。</p><p>关于同步还需知道两个小的点：</p><p>一是范围，并不需要在全局范围内都去同步，只需要在某些关键的点执行同步即可。</p><p>比如食堂只有一个卖饭窗口，肯定是同步的，一个人买完，下一个人再买。但吃饭的时候也是一个人吃完，下一个人才开始吃吗？当然不是啦。</p><p>二是粒度，并不是只有大粒度的事物才有同步，小粒度的事物也有同步。</p><p>只不过小粒度的事物同步通常是天然支持的，而大粒度的事物同步往往需要手工处理。</p><p>比如两个线程的同步就需要手工处理，但一个线程里的两个语句天然就是同步的。</p><p>所谓异步，就是步调各异。既然是各异，那就是都不相同。所以结果就是：</p><p>多个事物可以你进行你的、我进行我的，谁都不用管谁，所有的事物都在同时进行中。</p><p>一言以蔽之，同步就是多个事物不能同时开工，异步就是多个事物可以同时开工。</p><p>注：一定要去体会“多个事物”，多个线程是多个事物，多个方法是多个事物，多个语句是多个事物，多个CPU指令是多个事物。等等等等。</p><p><strong>阻塞和非阻塞</strong></p><p>所谓阻塞，指的是阻碍堵塞。它的本意可以理解为由于遇到了障碍而造成的动弹不得。</p><p>所谓非阻塞，自然是和阻塞相对，可以理解为由于没有遇到障碍而继续畅通无阻。</p><p>对这两个词最好的诠释就是，当今中国一大交通难题，堵车：</p><p>汽车可以正常通行时，就是非阻塞。一旦堵上了，全部趴窝，一动不动，就是阻塞。</p><p>因此阻塞关注的是不能动，非阻塞关注的是可以动。</p><p>不能动的结果就是只能等待，可以动的结果就是继续前行。</p><p>因此和阻塞搭配的词一定是等待，和非阻塞搭配的词一定是进行。</p><p>回到程序里，阻塞同样意味着停下来等待，非阻塞表明可以继续向下执行。</p><p><strong>阻塞和等待</strong></p><p>等待只是阻塞的一个副作用而已，表明随着时间的流逝，没有任何有意义的事物发生或进行。</p><p>阻塞的真正含义是你关心的事物由于某些原因无法继续进行，因此让你等待。但没必要干等，你可以做一些其它无关的事物，因为这并不影响你对相关事物的等待。</p><p>在堵车时，你可以干等。也可以玩手机、和别人聊天，或者打牌、甚至先去吃饭都行。因为这些事物并不影响你对堵车的等待。不过你的车必须呆在原地。</p><p>在计算机里，是没有人这么灵活的，一般在阻塞时，选在干等，因为这最容易实现，只需要挂起线程，让出CPU即可。在条件满足时，会重新调度该线程。</p><p><strong>两两组合</strong></p><p>所谓同步/异步，关注的是能不能同时开工。</p><p>所谓阻塞/非阻塞，关注的是能不能动。</p><p>通过推理进行组合：</p><p>同步阻塞，不能同时开工，也不能动。只有一条小道，一次只能过一辆车，可悲的是还TMD的堵上了。</p><p>同步非阻塞，不能同时开工，但可以动。只有一条小道，一次只能过一辆车，幸运的是可以正常通行。</p><p>异步阻塞，可以同时开工，但不可以动。有多条路，每条路都可以跑车，可气的是全都TMD的堵上了。</p><p>异步非阻塞，可以工时开工，也可以动。有多条路，每条路都可以跑车，很爽的是全都可以正常通行。</p><p>是不是很容易理解啊。其实它们的关注点是不同的，只要搞明白了这点，组合起来也不是事儿。</p><p>回到程序里，把它们和线程关联起来：</p><p>同步阻塞，相当于一个线程在等待。</p><p>同步非阻塞，相当于一个线程在正常运行。</p><p>异步阻塞，相当于多个线程都在等待。</p><p>异步非阻塞，相当于多个线程都在正常运行。</p><p><strong>I/O</strong></p><p>IO指的就是读入/写出数据的过程，和<strong>等待</strong>读入/写出数据的过程。一旦拿到数据后就变成了数据操作了，就不是IO了。</p><p>拿网络IO来说，等待的过程就是数据从网络到网卡再到内核空间。读写的过程就是内核空间和用户空间的相互拷贝。</p><p>所以IO就包括两个过程，一个是等待数据的过程，一个是读写（拷贝）数据的过程。而且还要明白，一定<strong>不</strong>能包括操作数据的过程。</p><p><strong>阻塞IO和非阻塞IO</strong></p><p>应用程序都是运行在用户空间的，所以它们能操作的数据也都在用户空间。按照这样子来理解，只要数据没有到达用户空间，用户线程就操作不了。</p><p>如果此时用户线程已经参与，那它一定会被阻塞在IO上。这就是常说的阻塞IO。用户线程被阻塞在等待数据上或拷贝数据上。</p><p>非阻塞IO就是用户线程不参与以上两个过程，即数据已经拷贝到用户空间后，才去通知用户线程，一上来就可以直接操作数据了。</p><p>用户线程没有因为IO的事情出现阻塞，这就是常说的非阻塞IO。</p><p><strong>同步IO和同步阻塞IO</strong></p><p>按照上文中对同步的理解，同步IO是指发起IO请求后，必须拿到IO的数据才可以继续执行。</p><p>按照程序的表现形式又分为两种：</p><p>在等待数据的过程中，和拷贝数据的过程中，线程都在阻塞，这就是同步阻塞IO。</p><p>在等待数据的过程中，线程采用死循环式轮询，在拷贝数据的过程中，线程在阻塞，这其实还是同步阻塞IO。</p><p>网上很多文章把第二种归为同步非阻塞IO，这肯定是<strong>错误</strong>的，它一定是阻塞IO，因为拷贝数据的过程，线程是阻塞的。</p><p>严格来讲，在IO的概念上，同步和非阻塞是不可能搭配的，因为它们是一对相悖的概念。</p><p>同步IO意味着必须拿到IO的数据，才可以继续执行。因为后续操作依赖IO数据，所以它必须是阻塞的。</p><p>非阻塞IO意味着发起IO请求后，可以继续往下执行。说明后续执行不依赖于IO数据，所以它肯定不是同步的。</p><p>因此，在IO上，同步和非阻塞是互斥的，所以不存在同步非阻塞IO。但同步非阻塞是存在的，那不叫IO，叫操作数据了。</p><p>所以，同步IO一定是阻塞IO，同步IO也就是同步阻塞IO。</p><p><strong>异步IO和异步阻塞/非阻塞IO</strong></p><p>按照上文中对异步的理解，异步IO是指发起IO请求后，不用拿到IO的数据就可以继续执行。</p><p>用户线程的继续执行，和操作系统准备IO数据的过程是同时进行的，因此才叫做异步IO。</p><p>按照IO数据的两个过程，又可以分为两种：</p><p>在等待数据的过程中，用户线程继续执行，在拷贝数据的过程中，线程在阻塞，这就是异步阻塞IO。</p><p>在等待数据的过程中，和拷贝数据的过程中，用户线程都在继续执行，这就是异步非阻塞IO。</p><p>第一种情况是，用户线程没有参与数据等待的过程，所以它是异步的。但用户线程参与了数据拷贝的过程，所以它又是阻塞的。合起来就是异步阻塞IO。</p><p>第二种情况是，用户线程既没有参与等待过程也没有参与拷贝过程，所以它是异步的。当它接到通知时，数据已经准备好了，它没有因为IO数据而阻塞过，所以它又是非阻塞的。合起来就是异步非阻塞IO。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> sonarqube 搭配gitlab-ci </title>
      <link href="/2020/01/07/2020-01-07-sonarqube-and-gitlab/"/>
      <url>/2020/01/07/2020-01-07-sonarqube-and-gitlab/</url>
      
        <content type="html"><![CDATA[<p>1、项目文件中创建sonar-project.properties 文件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#项目的key</span></span><br><span class="line">sonar.projectKey=admin</span><br><span class="line"><span class="comment">#sonarqube的主机地址</span></span><br><span class="line">sonar.host.url=https://192.168.1.6:9000</span><br><span class="line"><span class="comment">#项目的名字（这个名字在sonar界面显示的,此处根据项目名称修改）</span></span><br><span class="line">sonar.projectName=sonar-test</span><br><span class="line"><span class="comment">#项目的版本（这个名字在sonar界面显示的,根据项目版本修改）</span></span><br><span class="line">sonar.projectVersion=1.0</span><br><span class="line"><span class="comment">#需要分析源码的目录，多个目录用英文逗号隔开（根据需要修改）</span></span><br><span class="line">sonar.sources=./</span><br><span class="line"><span class="comment">#编码格式</span></span><br><span class="line"><span class="comment">#sonar.sourceEncoding=UTF-8</span></span><br><span class="line"><span class="comment">#项目所用语言</span></span><br><span class="line">sonar.language=java</span><br><span class="line"><span class="comment">#登录账号</span></span><br><span class="line">sonar.login=admin</span><br><span class="line"><span class="comment">#登录密码</span></span><br><span class="line">sonar.password=admin</span><br><span class="line"><span class="comment">#包含与源文件对应的已编译字节码文件 (如果没编译可以不写,默认创建target/sonar目录)</span></span><br><span class="line">sonar.java.binaries=target/sonar</span><br></pre></td></tr></table></figure><p>例如：如下图</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-07/1.png"></p><p>2、修改项目.gitlab-ci.yml文件，在首部添加如下：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">sonar_preview:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/usr/local/sonar-scanner/bin/sonar-scanner</span></span><br><span class="line">  <span class="attr">except:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sonar</span></span><br></pre></td></tr></table></figure><p>例如：如下图</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-07/2.png"></p><p>3、修改完成后，分支用户每次commit都会触发进行代码检测（没有触发请手动）</p>]]></content>
      
      
      
        <tags>
            
            <tag> Gitlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Docker安装sonarqube </title>
      <link href="/2020/01/06/2020-01-06-sonarqube-install/"/>
      <url>/2020/01/06/2020-01-06-sonarqube-install/</url>
      
        <content type="html"><![CDATA[<p><strong>Sonarqube</strong>，是一种自动代码审查工具，可检测代码中的错误，漏洞和代码异常。它可以与您现有的工作流程集成，以实现跨项目分支和请求请求的连续代码检查。</p><p>1、拉取镜像</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull soanrqube</span><br><span class="line">docker pull postgres</span><br></pre></td></tr></table></figure><p>2、启动postgres</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name postgresql --restart=always \</span><br><span class="line">-p 5432:5432 \</span><br><span class="line">-e POSTGRES_USER=sonarqube \</span><br><span class="line">-e POSTGRES_PASSWORD=sonarqube \</span><br><span class="line">-e POSTGRES_DB=sonarqube \</span><br><span class="line">postgres</span><br></pre></td></tr></table></figure><p>POSTGRES_DB：如果未指定此参数，那么第一次启动容器时创建的默认数据库将使用POSTGRES_USER的值</p><p>3、启动soanrqube</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name sonarqube --restart=always \</span><br><span class="line">-p 9000:9000 \</span><br><span class="line">-v /opt/sonarqube/conf:/opt/sonarqube/conf \</span><br><span class="line">-v /opt/sonarqube/data:/opt/sonarqube/data \</span><br><span class="line">-v /opt/sonarqube/logs:/opt/sonarqube/logs \</span><br><span class="line">-v /opt/sonarqube/extensions:/opt/sonarqube/extensions \</span><br><span class="line">-e sonar.jdbc.username=sonarqube \</span><br><span class="line">-e sonar.jdbc.password=sonarqube \</span><br><span class="line">-e sonar.jdbc.url=jdbc:postgresql://192.168.1.6:5432/sonarqube \</span><br><span class="line">sonarqube</span><br></pre></td></tr></table></figure><p>4、浏览器打开192.168.1.6:9000 账号:admin 密码:admin</p><p>5、安装中文插件，configuration–market–搜索Chinese Pack</p><p>6、安装soanr-scanner（安装在gitlab-runner服务器上，可以搭配gitlab-ci）</p><p><a href="https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/">官网下载</a></p><p>解压放入/usr/local/目录下</p><p>7、项目文件根目录中创建sonar-project.properties 文件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#项目的key</span></span><br><span class="line">sonar.projectKey=admin</span><br><span class="line"><span class="comment">#sonarqube的主机地址</span></span><br><span class="line">sonar.host.url=https://192.168.1.6:9000</span><br><span class="line"><span class="comment">#项目的名字（这个名字在sonar界面显示的,此处根据项目名称修改）</span></span><br><span class="line">sonar.projectName=sonar-test</span><br><span class="line"><span class="comment">#项目的版本（这个名字在sonar界面显示的,根据项目版本修改）</span></span><br><span class="line">sonar.projectVersion=1.0</span><br><span class="line"><span class="comment">#需要分析源码的目录，多个目录用英文逗号隔开（根据需要修改）</span></span><br><span class="line">sonar.sources=./</span><br><span class="line"><span class="comment">#编码格式</span></span><br><span class="line"><span class="comment">#sonar.sourceEncoding=UTF-8</span></span><br><span class="line"><span class="comment">#项目所用语言</span></span><br><span class="line">sonar.language=java</span><br><span class="line"><span class="comment">#登录账号</span></span><br><span class="line">sonar.login=admin</span><br><span class="line"><span class="comment">#登录密码</span></span><br><span class="line">sonar.password=admin</span><br><span class="line"><span class="comment">#包含与源文件对应的已编译字节码文件 (如果没编译可以不写,默认创建target/sonar目录)</span></span><br><span class="line">sonar.java.binaries=target/sonar</span><br></pre></td></tr></table></figure><p>8、cd 到项目文件中，执行/usr/local/sonar-scanner/bin/sonar-scanner</p><p>9、再次进入web界面，可以看到分析结果</p>]]></content>
      
      
      
        <tags>
            
            <tag> Gitlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Gitlab-CI 流程 </title>
      <link href="/2020/01/03/2020-01-03-gitlab-ci/"/>
      <url>/2020/01/03/2020-01-03-gitlab-ci/</url>
      
        <content type="html"><![CDATA[<p><strong>持续集成(Continuous Integration)</strong></p><p>持续集成指的是频繁的将代码集成到主干，每次集成都通过自动化的构建（包括编译、发布、自动化测试）来验证，它的好处主要有两个：</p><ul><li>快速发现错误。每完成一点更新，就集成到主干，可以快速发现错误，定位错误也比较容易；</li><li>防止分支大幅偏离主干。如果不经常集成，很容易导致集成难度变大，以至于难以集成。</li></ul><h2 id="一、GitLab-CI-CD"><a href="#一、GitLab-CI-CD" class="headerlink" title="一、GitLab CI/CD"></a><strong>一、GitLab CI/CD</strong></h2><p>从<code>8.0</code>版开始，<code>GitLab</code>持续集成(CI)完全集成到<code>GitLab</code>本身，它还具有持续部署和持续交付功能，可用于构建、测试和部署你的应用程序。下面是<code>GitLab CI/CD</code>流程图。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-03/1.png"></p><p>那么怎样让<code>GitLab CI</code>工作起来呢？总结起来就两条：</p><ol><li>将<code>.gitlab-ci.yml</code>文件添加到远程仓库的根目录；</li><li>将<code>GitLab</code>项目配置为使用<code>Runner</code></li></ol><p>设置好这些后，你每次<code>push</code>代码到<code>Git</code>仓库，<code>Runner</code>都会自动触发<code>CI pipeline</code>，你可以在项目的<code>Pipelines</code>页面下。如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-03/2.png"></p><p>如果一切运行正常，你可以看到绿色复选标记，这样你就可以在查看代码之前轻松查看任何提交是否导致测试失败。</p><h2 id="二、什么是-gitlab-ci-yml"><a href="#二、什么是-gitlab-ci-yml" class="headerlink" title="二、什么是 .gitlab-ci.yml"></a><strong>二、什么是 .gitlab-ci.yml</strong></h2><p>1、.gitlab-ci.yml文件配置CI对项目执行的操作，它告诉GitLab runner该做什么。</p><p>2、它位于存储库的根目录中，你代码的每次提交，GitLab都会查找.gitlab-ci.yml这个文件，并根据这个文件的内容，在Runner上启动你提交的工作。</p><p>3、默认情况下，它运行一个包含三个stage的管道：build，test，deploy。你不需要使用所有三个stage，没有工作的stage将会被忽略。</p><p>注意： .gitlab-ci.yml是一个YAML文件，因此您必须特别注意缩进。始终使用空格键，而不是Tab键。</p><p>你需要在你仓库的根目录下创建一个名为<code>.gitlab-ci.yml</code>的文件，下面是一个工程示例。它是最简单的配置。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">`before_script:``</span> <span class="string">``-</span> <span class="string">hostname``</span> <span class="string">``-</span> <span class="string">ip</span> <span class="string">addr`</span> <span class="string">`stages:``</span> <span class="string">``-</span> <span class="string">test``</span> <span class="string">``-</span> <span class="string">deploy-app``</span> <span class="string">`</span> <span class="string">`sonar_analyze:``</span> <span class="string">``stage:</span> <span class="string">test``</span> <span class="string">``script:``</span>   <span class="string">``-</span> <span class="string">/usr/local/sonar-scanner/bin/sonar-scanner``</span> <span class="string">``except:``</span>  <span class="string">``-</span> <span class="string">master``</span> <span class="string">``tags:``</span>  <span class="string">``-</span> <span class="string">sonar`</span> <span class="string">`deploy-app-to-test:``</span> <span class="string">``stage:</span> <span class="string">deploy-app``</span> <span class="string">``only:``</span>  <span class="string">``-</span> <span class="string">master``</span> <span class="string">``script:``</span>  <span class="string">``-</span> <span class="string">hostname``</span>  <span class="string">``-</span> <span class="string">ls``</span> <span class="string">``tags:``</span>  <span class="string">``-</span> <span class="string">sonar`</span></span><br></pre></td></tr></table></figure><p>上面的配置主要做了两件事：</p><ol><li>执行了两个job（名称是任意的）；</li><li>在每个<code>job</code>之前，执行<code>before_script</code>定义的命令。</li></ol><p>关于<code>.gitlab-ci.yml</code>的语法讲解，可以查看<a href="https://docs.gitlab.com/ee/ci/yaml/">官网的介绍</a>，然后根据项目的具体需求，使用这些语法，创建自己的脚本。</p><h2 id="三、配置Runner"><a href="#三、配置Runner" class="headerlink" title="三、配置Runner"></a><strong>三、配置Runner</strong></h2><p><strong>runner简单介绍</strong></p><p>GitLab Runner是一个开源项目，用于运行您的作业并将结果发送回GitLab。它与GitLab CI一起使用，GitLab CI是GitLab随附的开源持续集成服务，用于协调作业。</p><p>要求</p><ul><li>GitLab Runner是用Go编写的，可以作为单个二进制文件运行，不需要语言特定的要求。</li><li>它运行在GNU / Linux，macOS和Windows操作系统上。只要您可以在其上编译Go二进制文件，它就可以正常工作。</li><li>如果要使用Docker，请安装最新版本。GitLab Runner至少需要的Docker v1.13.0。</li><li>建议使用和gitlab相同版本</li></ul><p><strong>1、Runner安装</strong></p><p>请参考官方文档，这里不再详细说明   <a href="https://docs.gitlab.com/runner/">https://docs.gitlab.com/runner/</a></p><p><strong>2、Runner注册</strong></p><p>要求<br>在注册Runner之前，您需要先：</p><ul><li>将其安装在与安装GitLab的位置不同的服务器上</li><li>通过GitLab的界面获取共享或特定Runner的令牌</li></ul><p>如下图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-03/3.png"></p><p><strong>GNU / Linux</strong></p><p>1、运行以下命令：<br>gitlab-runner register</p><p>2、输入您的GitLab实例URL：<br>Please enter the gitlab-ci coordinator URL (e.g. <a href="https://gitlab.com/">https://gitlab.com</a> ):</p><p><a href="https://gitlab.xxx.xxx/">https://gitlab.xxx.xxx</a></p><p>3、输入您获得的令牌以注册Runner：<br>Please enter the gitlab-ci token for this runner:</p><p>xxx</p><p>4、输入Runner的描述，您可以稍后在GitLab的UI中更改：（根据需求更改）<br>Please enter the gitlab-ci description for this runner:</p><p>my-runner</p><p>5、输入与Runner关联的标签，您可以稍后在GitLab的UI中更改：（根据需求更改）<br>Please enter the gitlab-ci tags for this runner (comma separated):</p><p>my-tag</p><p>6、输入Runner执行程序：(每个执行程序的作用，详情请点击<a href="https://docs.gitlab.com/runner/executors/README.html">runner执行程序</a>，请根据需要选择执行器)<br>Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:</p><p>docker</p><p>7、如果您选择Docker作为执行程序，您将被要求为没有在.gitlab-ci.yml中定义映像的项目使用默认映像（根据需要设置默认镜像）</p><p>Please enter the Docker image (eg. ruby:2.1):</p><p>maven:latest</p><p><strong>3、查看注册是否成功</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-03/4.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Gitlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> mesos 以容器方式启动,拉取镜像失败问题 </title>
      <link href="/2020/01/01/2020-01-01-mesos-pull-images-error/"/>
      <url>/2020/01/01/2020-01-01-mesos-pull-images-error/</url>
      
        <content type="html"><![CDATA[<p>为了方便快速部署,将 mesos、marathon进行了容器化部署, 但是容器化完后发现在<code>marathon</code> 上创建应用一直创建不成功</p><p><strong>分析过程</strong></p><p>因为是容器化部署的mesos-slave和marathon,是不是因为没有找到证书和登录信息导致的,随后在mesos-salve容器手动的进行<code>docker login</code> 操作并将证书进行挂载到对应目录,手工执行命令docker -H unix:///var/run/docker.sock pull registry.cn-beijing.aliyuncs.com/xxxx/xxxxx-service:12984 能正常下载仓库镜像,但通过marathon创建应用问题依旧,此时我们查看了一下日志发现一些踪迹</p><p><strong>mesos-slave 错误信息</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Failed to launch container: Failed to run <span class="string">&#x27;docker -H unix:///var/run/docker.sock pull registry.cn-beijing.aliyuncs.com/xxxx/xxxxx-service:12984&#x27;</span>: exited with status 1; stderr=<span class="string">&#x27;Error response from daemon: pull access denied for registry.cn-beijing.aliyuncs.com/xxxxx/xxxxx-service, repository does not exist or may require &#x27;</span>docker login<span class="string">&#x27;: denied: requested access to the resource is denied &#x27;</span></span><br></pre></td></tr></table></figure><p>镜像仓库报错很明显,认证不通过,通过查找<code>marathon</code> 官方文档,我们发现官方说明在使用<code>Private Docker Registry</code> 时候需要额外做一些配置,参考<a href="https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html">marathon使用私有仓库配置</a> ,配置简单的步骤如下,所有<code>slave</code>节点和<code>marathon</code>节点都需要配置</p><ul><li>宿主机手工进行docker login</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker login</span><br></pre></td></tr></table></figure><ul><li>登录信息会保存在/root/.docker 目录下,将其进行打包</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root</span><br><span class="line">tar -cvf docker.tar.gz .docker/</span><br></pre></td></tr></table></figure><ul><li>将打包的文件复制到所有节点目录,<strong>注意:</strong> 放置在一个公共目录,因为marathon和mesos-slave都需要调用到</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp  docker.tar.gz  所有节点:/一个公共目录</span><br></pre></td></tr></table></figure><ul><li>容器启动marathon 和mesos-slave时候进行挂载对应公共目录</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#mesos-slave</span></span><br><span class="line">docker run -v /tmp/docker.tar.gz:/tmp/docker.tar.gz  .....  mesos-salve</span><br><span class="line"><span class="comment">#marathon</span></span><br><span class="line">docker run -v /tmp/docker.tar.gz:/tmp/docker.tar.gz  .....  marathon</span><br></pre></td></tr></table></figure><ul><li>创建应用时候,配置urls参数</li></ul><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;fetch&quot;</span>: [</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">&quot;uri&quot;</span>: <span class="string">&quot;file:///etc/docker.tar.gz&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>应用启动后,我们登录到mesos-slave 容器上查看资源stderr日志可以发现,资源节点如何下载和使用docker.tar.gz 包，这里就不贴出日志信息啦。</p><p>因为我使用的图形化界面配置，mesos版本为1.5.0，配置图如下</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-01/1.png"></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-01/2.png"></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-01/3.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Mesos </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> TCP 超时与重传 </title>
      <link href="/2019/12/31/2019-12-31-tcp-timeout-and-retransmission/"/>
      <url>/2019/12/31/2019-12-31-tcp-timeout-and-retransmission/</url>
      
        <content type="html"><![CDATA[<p>我们都知道 TCP 协议具有重传机制，也就是说，如果发送方认为发生了丢包现象，就重发这些数据包。很显然，我们需要一个方法来「<strong>猜测</strong>」是否发生了丢包。最简单的想法就是，接收方每收到一个包，就向发送方返回一个 <strong>ACK</strong>，表示自己已经收到了这段数据，反过来，如果发送方一段时间内没有收到 ACK，就知道<strong>很可能</strong>是数据包丢失了，紧接着就重发该数据包，直到收到 ACK 为止。</p><p>你可能注意到我用的是「猜测」，因为即使是超时了，这个数据包也可能并没有丢，它只是绕了一条远路，来的很晚而已。毕竟 TCP 协议是位于<strong>传输层</strong>的协议，不可能明确知道数据链路层和物理层发生了什么。但这并不妨碍我们的超时重传机制，因为接收方会自动忽略重复的包。</p><p>超时和重传的概念其实就是这么简单，但内部的细节却是很多，我们最先想到的一个问题就是，<strong>到底多长时间才能算超时呢</strong>？</p><h2 id="超时是怎么确定的？"><a href="#超时是怎么确定的？" class="headerlink" title="超时是怎么确定的？"></a>超时是怎么确定的？</h2><p>一刀切的办法就是，我<strong>直接把超时时间设成一个固定值</strong>，比如说 200ms，但这样肯定是有问题的，我们的电脑和很多服务器都有交互，这些服务器位于天南海北，国内国外，延迟差异巨大，打个比方：</p><ul><li>我的个人博客搭在国内，延迟大概 30ms，也就是说正常情况下的数据包，60ms 左右就已经能收到 ACK 了，但是按照我们的方法，200ms 才能确定丢包（正常可能是 90 到 120 ms），这<strong>效率实在是有点低</strong>。</li><li>假设你访问某国外网站，延迟有 130 ms，这就麻烦了，<strong>正常的数据包都可能被认为是超时，导致大量数据包被重发，可以想象，重发的数据包也很容易被误判为超时。。。雪崩效应的感觉</strong></li></ul><p>所以设置固定值是很不可靠的，<strong>我们要根据网络延迟，动态调整超时时间</strong>，延迟越大，超时时间越长。</p><p>在这里先引入两个概念：</p><ul><li>RTT（Round Trip Time）：往返时延，也就是<strong>数据包从发出去到收到对应 ACK 的时间。</strong>RTT 是针对连接的，每一个连接都有各自独立的 RTT。</li><li>RTO（Retransmission Time Out）：重传超时，也就是前面说的超时时间。</li></ul><p>比较标准的 RTT 定义：</p><blockquote><p>Measure the elapsed time between sending a data octet with a particular sequence number and <strong>receiving an acknowledgment that covers that sequence number</strong> (segments sent do not have to match segments received). This measured elapsed time is the Round Trip Time (RTT).</p></blockquote><h3 id="经典方法"><a href="#经典方法" class="headerlink" title="经典方法"></a>经典方法</h3><p>最初的规范「RFC0793」采用了下面的公式来得到平滑的 RTT 估计值（称作 SRTT）：</p><p><strong>SRTT  &lt;-  α·SRTT +（1 - α）·RTT</strong></p><p>RTT 是指最新的样本值，这种估算方法叫做「指数加权移动平均」，名字听起来比较高大上，但整个公式比较好理解，就是利用现存的 SRTT 值和最新测量到的 RTT 值取一个加权平均。</p><p>有了 SRTT，就该设置对应的 RTO 的值了，「RFC0793」是这么算的：</p><p><strong>RTO = min(ubound, max(lbound, (SRTT)·β))</strong></p><p>这里面的 <strong>ubound</strong> 是 RTO 的<strong>上边界</strong>，<strong>lbound</strong> 为 RTO 的<strong>下边界</strong>，β 称为<strong>时延离散因子</strong>，推荐值为 1.3 ~ 2.0。这个计算公式就是将  (SRTT)·β 的值作为 RTO，只不过另外<strong>限制了 RTO 的上下限</strong>。</p><p>这个计算方法，初看是没有什么问题（至少我是这么感觉的），但是实际应用起来，有两个缺陷：</p><blockquote><p>There were two known problems with the RTO calculations specified in RFC-793. First, the accurate measurement of RTTs is difficult <strong>when there are retransmissions</strong>. Second, the algorithm to compute the smoothed round-trip time is inadequate [TCP:7], <strong>because it incorrectly assumed that the variance in RTT values would be small and constant</strong>. These problems were solved by <strong>Karn’s and Jacobson’s algorithm</strong>, respectively.</p></blockquote><p>这段话摘自「RFC1122」，我来解释一下：</p><ul><li>当<strong>出现数据包重传的情况</strong>下，RTT 的计算就会很“麻烦”，我画了张图来说明这些情况：</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-31/rtt.png"></p><ul><li><p>图上列了两种情况，这两种情况下计算 RTT 的方法是不一样的（这就是所谓的重传二义性）：</p><p>但是对于客户端来说，它不知道发生了哪种情况，选错情况的结果就是 RTT 偏大/偏小，影响到 RTO 的计算。（最简单粗暴的解决方法就是<strong>忽略有重传的数据包，只计算那些没重传过的</strong>，但这样会导致其他问题。。详见 Karn’s algorithm）</p></li><li><ul><li>情况一：RTT = t2 - t0</li><li>情况二：RTT = t2 - t1</li></ul></li><li><p>另一个问题是，<strong>这个算法假设 RTT 波动比较小</strong>，因为这个加权平均的算法又叫<strong>低通滤波器</strong>，对突然的网络波动不敏感。如果网络时延突然增大导致实际 RTT 值远大于估计值，会导致不必要的重传，增大网络负担。（ RTT 增大已经表明网络出现了过载，这些不必要的重传会进一步加重网络负担）。</p></li></ul><h3 id="标准方法"><a href="#标准方法" class="headerlink" title="标准方法"></a>标准方法</h3><p>说实话这个标准方法比较，，，麻烦，我就直接贴公式了：</p><p><strong>SRTT  &lt;-  (1 - α)·SRTT  + α·RTT</strong>  //跟基本方法一样，<strong>求 SRTT 的加权平均</strong></p><p><strong>rttvar  &lt;- (1 - h)·rttvar + h·(|RTT - SRTT |)</strong>  //计算 <strong>SRTT 与真实值的差距</strong>（称之为绝对误差|Err|），同样用到<strong>加权平均</strong></p><p><strong>RTO = SRTT  + 4·rttvar</strong> //估算出来的新的 RTO，rttvar 的系数 4 是调参调出来的</p><p>这个算法的整体思想就是结合<strong>平均值</strong>（就是基本方法）和<strong>平均偏差</strong>来进行估算，一波玄学调参得到不错的效果。如果想更深入了解这个算法，参考「RFC6298」。</p><h2 id="重传——TCP的重要事件"><a href="#重传——TCP的重要事件" class="headerlink" title="重传——TCP的重要事件"></a>重传——TCP的重要事件</h2><h3 id="基于计时器的重传"><a href="#基于计时器的重传" class="headerlink" title="基于计时器的重传"></a>基于计时器的重传</h3><p>这种机制下，<strong>每个数据包都有相应的计时器</strong>，一旦超过 RTO 而没有收到 ACK，就重发该数据包。没收到 ACK 的数据包都会存在重传缓冲区里，等到 ACK 后，就从缓冲区里删除。</p><p>首先明确一点，对 TCP 来说，超时重传是<strong>相当重要</strong>的事件（RTO 往往大于两倍的 RTT，超时往往意味着拥塞），一旦发生这种情况，<strong>TCP 不仅会重传对应数据段，还会降低当前的数据发送速率</strong>，因为TCP 会认为当前网络发生了拥塞。</p><p>简单的超时重传机制往往比较低效，如下面这种情况：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-31/transfer.png"></p><p>假设数据包5丢失，数据包 6,7,8,9 都已经到达接收方，这个时候客户端就只能等服务器发送 ACK，注意对于包 6,7,8,9，服务器都不能发送 ACK，这是滑动窗口机制决定的，因此对于客户端来说，他完全不知道丢了几个包，可能就悲观的认为，5 后面的数据包也都丢了，就重传这 5 个数据包，这就比较浪费了。</p><h3 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h3><p>快速重传机制「RFC5681」基于接收端的反馈信息来引发重传，而非重传计时器超时。</p><p>刚刚提到过，基于计时器的重传往往要等待很长时间，而快速重传使用了很巧妙的方法来解决这个问题：<strong>服务器如果收到乱序的包，也给客户端回复 ACK</strong>，只不过是重复的 ACK。就拿刚刚的例子来说，收到乱序的包 6,7,8,9 时，服务器全都发 ACK = 5。这样，客户端就知道 5 发生了空缺。一般来说，如果客户端连续三次收到重复的 ACK，就会重传对应包，而不需要等到计时器超时。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-31/fast-transfer.png"></p><p>但快速重传仍然没有解决第二个问题：到底该重传多少个包？</p><h3 id="带选择确认的重传"><a href="#带选择确认的重传" class="headerlink" title="带选择确认的重传"></a>带选择确认的重传</h3><p>改进的方法就是 SACK（Selective Acknowledgment），简单来讲就是在快速重传的基础上，<strong>返回最近收到的报文段的序列号范围</strong>，这样客户端就知道，哪些数据包已经到达服务器了。</p><p>来几个简单的示例：</p><ul><li><p>case 1：第一个包丢失，剩下的 7 个包都被收到了。</p><p>当收到 7 个包的<strong>任何一个</strong>的时候，接收方会返回一个带 SACK 选项的 ACK，告知发送方自己收到了哪些乱序包。注：<strong>Left Edge，Right Edge 就是这些乱序包的左右边界</strong>。</p></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Triggering    ACK      Left Edge   Right Edge</span><br><span class="line">Segment</span><br><span class="line"></span><br><span class="line">5000         (lost)</span><br><span class="line">5500         5000     5500       6000</span><br><span class="line">6000         5000     5500       6500</span><br><span class="line">6500         5000     5500       7000</span><br><span class="line">7000         5000     5500       7500</span><br><span class="line">7500         5000     5500       8000</span><br><span class="line">8000         5000     5500       8500</span><br><span class="line">8500         5000     5500       9000</span><br></pre></td></tr></table></figure><ul><li><p>case 2：第 2, 4, 6, 8 个数据包丢失。</p></li><li><ul><li>收到第一个包时，没有乱序的情况，正常回复 ACK。</li><li>收到第 3, 5, 7 个包时，由于出现了乱序包，回复带 SACK 的 ACK。</li><li>因为这种情况下有很多碎片段，所以相应的 Block 段也有很多组，当然，因为选项字段大小限制， Block 也有上限。</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Triggering  ACK    First Block   2nd Block     3rd Block</span><br><span class="line">Segment            Left   Right  Left   Right  Left   Right</span><br><span class="line">                   Edge   Edge   Edge   Edge   Edge   Edge</span><br><span class="line"></span><br><span class="line">5000       5500</span><br><span class="line">5500       (lost)</span><br><span class="line">6000       5500    6000   6500</span><br><span class="line">6500       (lost)</span><br><span class="line">7000       5500    7000   7500   6000   6500</span><br><span class="line">7500       (lost)</span><br><span class="line">8000       5500    8000   8500   7000   7500   6000   6500</span><br><span class="line">8500       (lost)</span><br></pre></td></tr></table></figure><p>不过 SACK 的规范「RFC2018」有点坑爹，接收方可能会在提供一个 SACK 告诉发送方这些信息后，又「食言」，也就是说，接收方可能把这些（乱序的）数据包删除掉，然后再通知发送方。以下摘自「RFC2018」：</p><blockquote><p>Note that the data receiver is permitted to discard data in its queue that has not been acknowledged to the data sender, even if the data has already been reported in a SACK option. <strong>Such discarding of SACKed packets is discouraged, but may be used if the receiver runs out of buffer space.</strong></p></blockquote><p>最后一句是说，<strong>当接收方缓冲区快被耗尽时</strong>，可以采取这种措施，当然并不建议这种行为。。。</p><p>由于这个操作，发送方在收到 SACK 以后，也不能直接清空重传缓冲区里的数据，一直到接收方发送普通的，ACK 号大于其最大序列号的值的时候才能清除。另外，重传计时器也收到影响，重传计时器应该忽略 SACK 的影响，毕竟接收方把数据删了跟丢包没啥区别。</p><h3 id="DSACK-扩展"><a href="#DSACK-扩展" class="headerlink" title="DSACK 扩展"></a>DSACK 扩展</h3><p>DSACK，即重复 SACK，这个机制是在 SACK 的基础上，额外携带信息，<strong>告知发送方有哪些数据包自己重复接收了</strong>。DSACK 的目的是帮助发送方判断，是否发生了包失序、ACK 丢失、包重复或伪重传。让 TCP 可以更好的做网络流控。</p><p>关于 DSACK，「RFC2883」里举了很多例子，有兴趣的读者可以去阅读一下，我这里就不讲那么细了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> TCP 协议，握手挥手不是你想的那么简单 </title>
      <link href="/2019/12/30/2019-12-30-tcp-handshake/"/>
      <url>/2019/12/30/2019-12-30-tcp-handshake/</url>
      
        <content type="html"><![CDATA[<h2 id="TCP-报文段结构"><a href="#TCP-报文段结构" class="headerlink" title="TCP 报文段结构"></a>TCP 报文段结构</h2><p>一谈到 TCP 协议，大家最先想到的词就是「<strong>面向连接</strong>」和「<strong>可靠</strong>」。没错，TCP 协议的设计就是为了能够在客户端和服务器之间建立起一个可靠连接。</p><p>在讲连接过程之前，我们先来看看 TCP 的报文段结构，通过这个结构，我们可以知道 TCP 能够提供什么信息：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/tcp-message.png" alt="TCP报文结构"></p><p>这里有几点是需要注意的：</p><ul><li>TCP 协议需要一个<strong>四元组</strong>（源IP，源端口，目的IP，目的端口）来确定连接，这要和 UDP 协议区分开。多说一句，IP 地址位于 IP 报文段，TCP 报文段是不含 IP 地址信息的。</li><li><strong>基本 TCP 头部</strong>的长度是 20 字节，但是由于「<strong>选项</strong>」的长度是不确定的，所以需要「<strong>首部长度</strong>」字段明确给出头部长度。这里要注意的是，首部长度字段的单位是 32bit，也就是 4 字节，所以该字段的最小值是 5。</li><li>标橙色的字段（<strong>确认序号，接收窗口大小，ECE，ACK</strong>）用于「回复」对方，举个例子，服务器收到对方的数据包后，不单独发一个数据包来回应，而是稍微等一下，把确认信息附在<strong>下一个</strong>发往<strong>客户端</strong>的数据帧上，也就是<strong>捎带</strong>技术。</li><li>窗口大小是一个 16 位无符号数，也就是说窗口被限制在了 65535 字节，也就限制了 TCP 的吞吐量性能，这对一些高速以及高延迟的网络不太友好（可以想想为什么）。所幸 TCP 额外提供了<strong>窗口缩放</strong>（Window Scale）选项，允许对这个值进行缩放。</li></ul><p>下面是 8 个标志位的含义，有的协议比较旧，可能没有前两个标志位：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/8flag.png" alt="8个标志位的含义"></p><p>标志位虽然很多，但是如果放到具体场景里来看的话，就很容易理解他们的作用了。</p><h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p>三次握手就是为了在客户端和服务器间建立连接，这个过程并不复杂，但里面有很多细节需要注意。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/three-handshake.png" alt="三次握手"></p><p>这张图就是握手的过程，可以看到客户端与服务器之间一共传递了三次消息，这三次握手其实就是两台机器之间互相确认状态，我们来一点一点看。</p><p><strong>第一次握手</strong></p><p>首先是<strong>客户端发起连接</strong>，第一个数据包将 SYN 置位（也就是 SYN = 1），表明这个数据包是 SYN 报文段（也被称为<strong>段 1</strong>）。这一次发送的目的是告诉服务器，自己的<strong>初始序列号</strong>是 <code>client_isn</code> ，还有一个隐含的信息在图里没有表现出来，那就是告知服务端自己想连接的<strong>端口号</strong>。除了这些，客户端还会发送一些<strong>选项</strong>，不过这跟三次握手没多大关系，暂且按下不表。</p><p>段 1 里最需要注意的就是这个<code>client_isn</code> ，也就是初始序列号。「RFC0793^1」指出:</p><blockquote><p>When new connections are created, an initial sequence number (ISN) generator is employed which selects a new 32 bit ISN. The generator is bound to a (possibly fictitious) 32 bit clock whose low order bit is incremented roughly every 4 microseconds.  Thus, the ISN cycles approximately every 4.55 hours.</p></blockquote><p>翻译过来就是，初始序列号是一个 32 位的（虚拟）计数器，而且这个计数器每 4 微秒加 1，也就是说，ISN 的值<strong>每 4.55 小时循环一次</strong>。这个举措是为了<strong>防止序列号重叠</strong>。</p><p>但即使这样还是会有安全隐患——因为初始 ISN 仍然是可预测的，恶意程序可能会分析 ISN ，然后根据先前使用的 ISN <strong>预测</strong>后续 TCP 连接的 ISN，然后进行攻击，一个著名的例子就是「The Mitnick attack^2」 。这里摘一段原文：</p><blockquote><p>Mitnick sent SYN request to X-Terminal and received SYN/ACK response.  Then he sent RESET response to keep the X-Terminal from being filled up. He repeated this for twenty times. He found there is a pattern between  two successive TCP sequence numbers. It turned out that the numbers were not random at all. The latter number was greater than the previous one  by 128000.</p></blockquote><p>所以为了让初始序列号<strong>更难预测</strong>，现代系统常常使用<strong>半随机</strong>的方法选择初始序列号，详细的方法就不在这里展开了。</p><p><strong>第二次握手</strong></p><p>当服务器接收到客户端的连接请求后，就会向客户端发送 <strong>ACK</strong> 表示自己收到了连接请求，而且，服务器还得<strong>把自己的初始序列号告诉客户端</strong>，这其实是两个步骤，但是发送<strong>一个数据包</strong>就可以完成，用的就是前面说的<strong>捎带</strong>技术。图里的 <code>ACK = client_isn + 1</code> 是指<strong>确认号字段</strong>的值，要注意和 <strong>ACK 标志位</strong>区分开。</p><p>ACK 字段其实也有不少需要注意的点，不过这个跟滑动窗口一块讲比较直观，这里就先不提了。</p><p>这里重点强调一下，当一个 SYN 报文段到达的时候，<strong>服务器会检查处于 SYN_RCVD 状态的连接数目是否超过了 <code>tcp_max_syn_backlog</code> 这个参数，如果超过了，服务器就会拒绝连接</strong>。当然，这个也会被黑客所利用，「SYN Flood」就是个很好的例子。因为服务器在回复 SYN-ACK 后，会等待客户端的 ACK ，如果一定时间内没有收到，认为是丢包了，就重发 SYN-ACK，重复几次后才会断开这个连接，linux 可能要一分钟才会断开，所以攻击者如果制造一大批 SYN 请求而不回复，服务器的 SYN 队列很快就被耗尽，这一段时间里，正常的连接也会得不到响应。</p><p>服务器的这种状态称为<strong>静默</strong>（muted）。为了抵御 SYN Flood 攻击，服务器可以采用「SYN cookies」，这种思想是，当 SYN 到达时，<strong>并不直接为其分配内存</strong>，而是把这条连接的信息编码并保存在 SYN-ACK 报文段的<strong>序列号</strong>字段，如果客户端回复了，服务器再<strong>从 ACK 字段里解算出 SYN 报文的重要信息</strong>（有点黑魔法的感觉了），验证成功后才为该连接分配内存。这样，服务器不会响应攻击者的请求，正常连接则不会受到影响。</p><p>但 SYN cookies 本身有一些限制，并不适合作为默认选项，有兴趣可以自行 Google。</p><p><strong>第三次握手</strong></p><p>这是建立 TCP 连接的最后一步，经过前两次握手，客户端（服务器）已经知道对方的<strong>滑动窗口大小</strong>，<strong>初始序列号</strong>等信息了，这不就完了吗？为什么还要第三次握手？</p><p>这是因为服务器虽然把数据包发出去了，但他<strong>还不知道客户端是否收到了这个包</strong>，所以服务器需要等待客户端返回一个 ACK，表明客户端收到了数据，至此，连接完成。</p><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p>有了三次握手的基础，四次挥手就比较容易理解了：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/four-breakup.png" alt="四次挥手"></p><p>四次挥手的过程其实很简单，就是服务器和客户端互相发送 FIN 和 ACK 报文段，告知对方要断开连接。</p><p>四次挥手里值得关注的一点就是 <strong>TIME_WAIT</strong> 状态，也就是说主动关闭连接的一方，即使收到了对方的 FIN 报文，也还要等待 2<strong>MSL</strong> 的时间才会彻底关闭这条连接。（这里面的 MSL 指的是<strong>最大段生成期</strong>，指的是报文段<strong>在网络中</strong>被允许存在的最长时间。）可<strong>为什么不直接关闭连接呢</strong>？</p><p>一个原因是，<strong>第四次挥手的 ACK 报文段不一定到达了服务器</strong>，为了不让服务器一直处于 LAST_ACK 状态（服务器会重发 FIN，<strong>直到收到 ACK</strong>），客户端还得等一会儿，看看是否需要重发。假如真的丢包了，服务器发送 FIN ，这个 FIN 报文到达客户端时不会超过 2MSL（一来一回最多 2MSL），这时候客户端这边的 TCP 还没关掉，还能重发 ACK。</p><p>另一个原因是，<strong>经过 2MSL 之后，网络中与该连接相关的包都已经消失</strong>了，不会干扰新连接。我们来看一个例子：假如客户端向服务器建立了<strong>新的连接</strong>，<strong>旧连接中某些延迟的数据坚持到了新连接建立完毕，而且序列号刚好还在滑动窗口内，服务器就误把它当成新连接的数据包接收</strong>，如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/example.png" alt="四次挥手"></p><p>2MSL 机制就避免了这种情况。</p>]]></content>
      
      
      
        <tags>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 浅谈 TCP 的三次握手和四次挥手 </title>
      <link href="/2019/12/27/2019-12-27-talk-tcp/"/>
      <url>/2019/12/27/2019-12-27-talk-tcp/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是OSI-七层模型"><a href="#什么是OSI-七层模型" class="headerlink" title="什么是OSI 七层模型?"></a>什么是OSI 七层模型?</h2><blockquote><p>开放式系统互联通信参考模型（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为 OSI 模型（OSI model），一种概念模型，由国际标准化组织（ISO）提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于 ISO/IEC 7498-1。</p></blockquote><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-27/osi7.png" alt="OSI七层模型"></p><ul><li>第 7 层应用层 ( Application Layer )</li></ul><p><strong>主要功能：</strong> 为应用软件提供接口，使应用程序能够使用网络服务<br><strong>典型设备：</strong> 网关<br><strong>典型协议、标准和应用：</strong> http(80)、ftp(20/21)、smtp(25)、pop3(110)、telnet(23)、dns(53)</p><ul><li>第 6 层表示层 ( Presentation Layer )</li></ul><p><strong>主要功能：</strong> 数据的解码和编码，数据的加密和解密，数据的压缩和解压缩<br><strong>典型设备：</strong> 网关<br><strong>典型协议、标准和应用：</strong> ASCLL、PICT、TIFF、JPEG、 MIDI、MPEG</p><ul><li>第 5 层会话层 ( Session Layer )</li></ul><p><strong>主要功能：</strong> 建立、维护、管理应用程序之间的会话<br><strong>典型设备：</strong> 网关<br><strong>典型协议、标准和应用：</strong> RPC、SQL、NFS 、X WINDOWS、ASP</p><ul><li>第 4 层传输层 (Transport Layer)</li></ul><p><strong>主要功能：</strong> 负责建立端到端的链接，保证保温在端到端之间的传输<br><strong>典型设备：</strong> 网关<br><strong>典型协议、标准和应用：</strong> TCP、UDP、SPX</p><ul><li>第 3 层网络层 (Network Layer)</li></ul><p><strong>主要功能：</strong> 负责将分组数据从源端传输到目的端，网络层的主要作用就是路由和寻址<br><strong>典型设备：</strong> 路由器<br><strong>典型协议、标准和应用：</strong> IP、IPX、APPLETALK、ICMP</p><ul><li>第 2 层数据链接层 (Data Link Layer)</li></ul><p><strong>主要功能：</strong> 在不可靠的物理链路上，提供可靠的数据传输服务<br><strong>典型设备：</strong> 交换机、网桥、网卡<br><strong>典型协议、标准和应用：</strong> 802.2、802.3ATM、HDLC、FRAME RELAY</p><ul><li>第 1 层物理层 (Physical Layer)</li></ul><p><strong>主要功能：</strong> 利用传输介质为数据链路层提供物理连接，实现比特流的透明传输<br><strong>典型设备：</strong> 集线器、中继器<br><strong>典型协议、标准和应用：</strong> V.35、EIA/TIA-232</p><ul><li> TCP/IP 协议族常用协议</li></ul><p><strong>应用层：</strong> TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 等等<br><strong>传输层：</strong> TCP，UDP<br><strong>网络层：</strong> IP，ICMP，OSPF，EIGRP，IGMP<br><strong>数据链路层：</strong> SLIP，CSLIP，PPP，MTU</p><h2 id="什么是-TCP-IP"><a href="#什么是-TCP-IP" class="headerlink" title="什么是  TCP/IP ?"></a>什么是  TCP/IP ?</h2><blockquote><p>互联网协议族（英语：Internet Protocol Suite，缩写为 IPS），是一个网络通信模型，以及一整个网络传输协议家族，为互联网的基础通信架构。它常被通称为 TCP/IP 协议族（英语：TCP/IP Protocol Suite，或 TCP/IP Protocols），简称 TCP/IP 。</p><p>因为这个协议家族的两个核心协议，包括TCP（传输控制协议）和 IP（网际协议），为这个家族中最早通过的标准。由于在网络通讯协议普遍采用分层的结构，当多个层次的协议共同工作时，类似计算机科学中的堆栈，因此又被称为 TCP/IP 协议栈（英语：TCP/IP Protocol Stack） 。</p><p>这些协议最早发源于美国国防部（缩写为 DoD）的ARPA 网项目，因此也被称作 DoD 模型（DoD Model）。这个协议套组由互联网工程任务组负责维护。</p><p>TCP/IP 提供点对点的链接机制，将数据应该如何封装、定址、传输、路由以及在目的地如何接收，都加以标准化。它将软件通信过程抽象化为四个抽象层，采取协议堆栈的方式，分别实现出不同通信协议。协议套组下的各种协议，依其功能不同，被分别归属到这四个层次结构之中，常被视为是简化的七层 OSI 模型。</p></blockquote><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-27/7-4-model.png" alt="七层/四层模型"></p><p>在建立 TCP 连接之前需要进行三次握手，以便于链接到服务器，如果要断开服务器需要进行四次挥手，具体流程如下。</p><h2 id="TCP-IP-三次握手"><a href="#TCP-IP-三次握手" class="headerlink" title="TCP/IP 三次握手"></a>TCP/IP 三次握手</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-27/handshake.png" alt="三次握手"></p><ol><li><p><strong>第一次握手：</strong> Client 将标志位 SYN 设置为 1，随机产生一个 Number 值 SEQ=100，并将数据发送给 Server，Client 进入 SYN_SENT 状态，等待 Server 确认；</p></li><li><p><strong>第二次握手：</strong> Server 收到数据包后 Client 设置的标志位 SYN=1 知道 Client 要求建立连接，Server 将标志位 SYN 和 ACK 都置为 1，并且发送一个确认序号 ACK=100+1，然后随机产生一个值 SEQ=130，并将该数据包发送给 Client 以确认连接请求，Server 进入 SYN_RCVD 状态。</p></li><li><p><strong>第三次握手：</strong> Client 收到确认后，检查 ACK 状态是否为 100+1，ACK 是否为 1，如果正确则将标志位 ACK 置为 1，ACK=130+1，并将该数据包发送给 Server，Server 检查 ACK 是否为 130+1，ACK 是否为1，如果正确则连接建立成功，Client 和 Server 进入 ESTABLISHED 状态，完成三次握手，随后 Client 与 Server 之间可以开始传输数据了。</p></li></ol><p>一个完整的三次握手也就是<strong>请求—应答—再次确认</strong></p><h2 id="TCP-IP-四次挥手"><a href="#TCP-IP-四次挥手" class="headerlink" title="TCP/IP 四次挥手"></a>TCP/IP 四次挥手</h2><p>为什么要挥手，简单点来说就是既然建立了链接，那么肯定还要断开连接吖，连接总不能一直占用吧，这样多浪费系统该资源，下面让我们来看看四次挥手的流程。</p><ol><li><p><strong>第一次挥手：</strong> Client 发送一个 FIN，用来关闭 Client 到 Server 的数据传送，Client 进入 FIN_WAIT_1 状态。</p></li><li><p><strong>第二次挥手：</strong> Server 收到 FIN 后，发送一个 ACK 给 Client，确认序号为 ACK=100+1（与 SYN 相同，一个 FIN 占用一个序号），Server 进入 CLOSE_WAIT 状态。</p></li><li><p><strong>第三次挥手：</strong> Server 发送一个 FIN，用来关闭 Server 到 Client 的数据传送，Server 进入 LAST_ACK 状态。</p></li><li><p><strong>第四次挥手：</strong> Client 收到 FIN 后，Client 进入 TIME_WAIT 状态，接着发送一个 ACK 给 Server，确认序号为 131+1，Server 进入 CLOSED 状态，完成四次挥手。</p></li></ol><h2 id="Q-A"><a href="#Q-A" class="headerlink" title="Q/A"></a>Q/A</h2><ul><li>为什么建立连接是三次握手，而关闭连接却是四次挥手呢？</li></ul><p>这是因为服务端在 LISTEN 状态下，收到建立连接请求的 SYN 报文后，把 ACK 和 SYN 放在一个报文里发送给客户端。而关闭连接时，当收到对方的 FIN 报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即 Close，也可以发送一些数据给对方后，再发送 FIN 报文给对方来表示同意现在关闭连接，因此，己方 ACK 和 FIN一般都会分开发送。</p><ul><li>为什么建立连接要三次握手？</li></ul><p><strong>目的：</strong> 防止已经失效的连接请求到达服务端，创建无效的连接，浪费资源。</p><p><strong>说明：</strong> 当客户端发出的第一个连接请求在网络上的某个节点被滞留了（网络会存在许多不可靠的因素），过一段时间后突然又到达了服务端，服务端误以为这是一个新的建立连接的请求，于是就会向客户端发出确认包并建立连接。</p><p>实际上客户端当前并没有发出创建连接的请求，就会丢弃服务端的确认包。而服务端却创建了连接并等待客户端发送数据，浪费了相关的资源。</p><ul><li>SYN 攻击</li></ul><p>在三次握手过程中，服务器<code>发送 SYN-ACK 之后，收到客户端的 ACK 之前</code>的 TCP 连接称为半连接 (half-open connect)。此时服务器处于 SYN_RECV 状态，当收到 ACK 后，服务器转入 ESTABLISHED 状态.</p><p>SYN 攻击就是：攻击客户端在短时间内伪造大量不存在的 IP 地址，向服务器不断地发送 SYN 包，服务器回复 ACK 确认包，并等待客户的确认从而建立连接。由于源地址是不存在的，不会再发送 ACK 确认包，所以服务器需要不断的重发直至超时，这些伪造的 SYN 包将长时间占用未连接队列，正常的 SYN 请求被丢弃，目标系统运行缓慢，严重者引起网络堵塞甚至系统瘫痪。</p><p>SYN 攻击是一个典型的 DDOS 攻击。检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击</p><ul><li>为什么 TIME_WAIT 状态需要经过 2MSL (最大报文段生存时间)才能返回到 CLOSE 状态？</li></ul><p>虽然按道理，四个报文都发送完毕，我们可以直接进入 CLOSE 状态了，但是我们必须假象网络是不可靠的，有可以最后一个 ACK 丢失。所以 TIME_WAIT 状态就是用来重发可能丢失的 ACK 报文。</p>]]></content>
      
      
      
        <tags>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Nginx 中 reload 流程 </title>
      <link href="/2019/12/26/2019-12-26-nginx-reload/"/>
      <url>/2019/12/26/2019-12-26-nginx-reload/</url>
      
        <content type="html"><![CDATA[<p>今天这篇文章主要来介绍下 Nginx 的 reload 流程。实际上在之前文章中，在更改了 nginx 配置文件时，我们都会执行 nginx -s reload 命令，我们执行这条命令的原因是希望 nginx 不停止服务始终在处理新的请求的同时把 nginx 的配置文件平滑的把旧的 nginx.conf 配置更新为新的 nginx.conf 配置。</p><p>这样一个功能对于 nginx 非常有必要，但是有时候我们会发现在执行 <code>nginx -s reload</code> 命令后，worker 子进程的数量会变多了，这是因为老的配置运行的 worker 进程长时间没有退出，当使用 stream 做四层反向代理的时候，可能这种场景会更多。</p><p>那么下面我们通过分析 nginx 的 reload 流程，来探究下 nginx 到底做了些什么？所谓优雅的退出和立即退出有什么区别？</p><h2 id="reload-流程"><a href="#reload-流程" class="headerlink" title="reload 流程"></a>reload 流程</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-26/reload1.png"></p><p>第一步在修改好 nginx 的配置文件 nginx.conf 后，向 master 进程发送 HUP 信号，这实际上和我们在命令行执行 <code>nginx -s reload</code> 命令效果是一样的。</p><p>那么 master 进程在收到 HUP 信号以后，会在第二步检查我们的配置文件语法是否正确，也就是说我们并不一定非要在 nginx -s reload 前执行 nginx -t 检验下语法是否正确，因为在第二步 nginx 的 master 进程一定会执行这个步骤。</p><p>在 nginx 的配置语法全部正确以后，master 进程会打开新的监听端口，为什么要在 master 进程中打开新的监听端口？因为我们可能在 nginx.conf 中会引入新的例如 443 或者之前我们没有打开的的监听端口，而所有 worker 进程是 master 进程 的子进程，子进程会继承父进程所有已经打开的端口，这是 linux 操作系统定义的，所以第三步，我们 master 进程打开了可能引入的新的监听端口。</p><p>接下来 mster 进程会用新的 nginx.conf 配置文件来启动新的 worker 子进程，那么老的 worker 子进程会怎么样呢？</p><p>我们会在第五步在启动新的 worker 子进程以后，由 master 进程再向老 worker 子进程发送 QUIT 信号，QUIT 信号和 TERM，INT 信号是不一样的，QUIT 信号是请优雅地关闭子进程，这时候需要关注顺序，因为 nginx 需要保证平滑，所以要先启动新的 worker 子进程，再向老的 worker 子进程发送 QUIT 信号。</p><p>那么老的 master 子进程收到 QUIT 信号后，首先关闭监听句柄，也就是说这个时候新的连接只会到新的 worker 子进程，所以虽然他们之间有时间差，但是时间是非常快速的，那么关闭监听句柄后，处理完当前连接后就结束进程。</p><p>下面看 reload 不停机载入新配置的图示。</p><h2 id="reload-不停机载入新配置"><a href="#reload-不停机载入新配置" class="headerlink" title="reload 不停机载入新配置"></a>reload 不停机载入新配置</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-26/reload2.png"></p><p>master 进程上原先有四个绿色的 worker 子进程，它们使用了老的配置，当我们更改了 nginx.conf 配置文件后，向 master 发送 SIGHUP 信号或者执行 reload 命令， 然后 master 会用新的配置文件启动四个新的黄色 worker 子进程，此时是四个老的绿色 worker 子进程和四个新的黄色的 worker 子进程是并存的。那么老的 worker 子进程在正常的情况下会在处理已经建立好的连接上的请求之后关闭这个连接，哪怕这个连接是 keeplive 请求也会正常关闭。</p><p>但是异常情况，如果有一些请求出现问题，客户端长时间无法处理，那么就会导致这个请求长时间停留在这个 worker 子进程当中，那么这个 worker 子进程会长时间存在，因为新的连接已经跑在黄色的 worker 子进程中，所以影响并不会很大，唯一会影响的就是绿色的 worker 子进程会长时间存在，但也只影响已存在的连接，不会影响新的连接。</p><p>我们有什么办法处理呢？在新版本中提供了一个新的配置 worker_shutdown_timeout，也就是说最长等待多长时间，这样 master 进程启动新的黄色 worker 进程之后，如果老的 worker 进程一直没有退出，时间到了之后会强制把老的 worker 进程退出掉。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> linux中inode包含什么内容？ </title>
      <link href="/2019/12/25/2019-12-25-linux-inode/"/>
      <url>/2019/12/25/2019-12-25-linux-inode/</url>
      
        <content type="html"><![CDATA[<h2 id="1、inode是什么"><a href="#1、inode是什么" class="headerlink" title="1、inode是什么"></a>1、inode是什么</h2><p>理解inode，要从文件储存说起。</p><p>文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。</p><p>操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。</p><p>文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。</p><h2 id="2、inode内容"><a href="#2、inode内容" class="headerlink" title="2、inode内容"></a>2、inode内容</h2><p>inode包含文件的元信息，具体来说有以下内容：</p><p>* 文件的字节数</p><p>* 文件拥有者的User ID</p><p>* 文件的Group ID</p><p>* 文件的读、写、执行权限</p><p>* 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。</p><p>* 链接数，即有多少文件名指向这个inode</p><p>* 文件数据block的位置</p><p>可以用stat命令，查看某个文件的inode信息：</p><p>stat example.txt</p><p>总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。</p><h2 id="3、inode的大小"><a href="#3、inode的大小" class="headerlink" title="3、inode的大小"></a>3、inode的大小</h2><p>inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。</p><p>每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。</p><p>查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">df -i</span><br></pre></td></tr></table></figure><p>查看每个inode节点的大小，可以用如下命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo dumpe2fs -h /dev/hda | grep <span class="string">&quot;Inode size&quot;</span></span><br></pre></td></tr></table></figure><p>由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。</p><h2 id="4、inode号码"><a href="#4、inode号码" class="headerlink" title="4、inode号码"></a>4、inode号码</h2><p>每个inode都有一个号码，操作系统用inode号码来识别不同的文件。</p><p>这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。</p><p>使用ls -i命令，可以看到文件名对应的inode号码：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls -i example.txt</span><br></pre></td></tr></table></figure><h2 id="5、目录文件"><a href="#5、目录文件" class="headerlink" title="5、目录文件"></a>5、目录文件</h2><p>Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。</p><p>目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。</p><p>ls命令只列出目录文件中的所有文件名：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls /etc</span><br></pre></td></tr></table></figure><p>ls -i命令列出整个目录文件，即文件名和inode号码：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls -i /etc</span><br></pre></td></tr></table></figure><p>如果要查看文件的详细信息，就必须根据inode号码，访问inode节点，读取信息。ls -l命令列出文件的详细信息。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls -l /etc</span><br></pre></td></tr></table></figure><h2 id="6、硬链接"><a href="#6、硬链接" class="headerlink" title="6、硬链接"></a>6、硬链接</h2><p>一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。</p><p>ln命令可以创建硬链接：</p><p>ln 源文件 目标文件</p><p>运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。</p><p>这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）,这里的2是父目录对其的“硬链接”和当前目录下的”.硬链接“。</p><h2 id="7、软连接"><a href="#7、软连接" class="headerlink" title="7、软连接"></a>7、软连接</h2><p>除了硬链接以外，还有一种特殊情况。文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。</p><p>这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。</p><p>ln -s命令可以创建软链接。</p><p>ln -s 源文文件或目录 目标文件或目录</p><h2 id="8、inode的特殊作用"><a href="#8、inode的特殊作用" class="headerlink" title="8、inode的特殊作用"></a>8、inode的特殊作用</h2><p>由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。</p><p>\1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。</p><p>\2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。</p><p>\3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。</p><p>第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。</p><h2 id="9、实际问题"><a href="#9、实际问题" class="headerlink" title="9、实际问题"></a>9、实际问题</h2><p>在一台配置较低的Linux服务器（内存、硬盘比较小）的/data分区内创建文件时，系统提示磁盘空间不足，用df -h命令查看了一下磁盘使用情况，发现/data分区只使用了66%，还有12G的剩余空间，按理说不会出现这种问题。 后来用df -i查看了一下/data分区的索引节点(inode)，发现已经用满(IUsed=100%)，导致系统无法创建新目录和文件。</p><p><strong>查找原因：</strong></p><p>/data/cache目录中存在数量非常多的小字节缓存文件，占用的Block不多，但是占用了大量的inode。</p><p><strong>解决方案：</strong></p><p>1、删除/data/cache目录中的部分文件，释放出/data分区的一部分inode。<br>2、用软连接将空闲分区/opt中的newcache目录连接到/data/cache，使用/opt分区的inode来缓解/data分区inode不足的问题：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /opt/newcache /data/cache</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> HTTPS 原理分析 </title>
      <link href="/2019/12/24/2019-12-24-https-principle/"/>
      <url>/2019/12/24/2019-12-24-https-principle/</url>
      
        <content type="html"><![CDATA[<p>随着 HTTPS 建站的成本下降，现在大部分的网站都已经开始用上 HTTPS 协议。大家都知道 HTTPS 比 HTTP 安全，也听说过与 HTTPS 协议相关的概念有 SSL 、非对称加密、 CA证书等，但对于以下灵魂三拷问可能就答不上了：</p><ol><li>为什么用了 HTTPS 就是安全的？</li><li>HTTPS 的底层原理如何实现？</li><li>用了 HTTPS 就一定安全吗？</li></ol><p>本文将层层深入，从原理上把 HTTPS 的安全性讲透。</p><h2 id="HTTPS-的实现原理"><a href="#HTTPS-的实现原理" class="headerlink" title="HTTPS 的实现原理"></a>HTTPS 的实现原理</h2><p>大家可能都听说过 HTTPS 协议之所以是安全的是因为 HTTPS 协议会对传输的数据进行加密，而加密过程是使用了非对称加密实现。但其实，HTTPS 在内容传输的加密上使用的是对称加密，非对称加密只作用在证书验证阶段。</p><p>HTTPS的整体过程分为证书验证和数据传输阶段，具体的交互过程如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/1.png"></p><p>1、证书验证阶段</p><ul><li>浏览器发起 HTTPS 请求</li><li>服务端返回 HTTPS 证书</li><li>客户端验证证书是否合法，如果不合法则提示告警</li></ul><p>2、数据传输阶段</p><ul><li>当证书验证合法后，在本地生成随机数</li><li>通过公钥加密随机数，并把加密后的随机数传输到服务端</li><li>服务端通过私钥对随机数进行解密</li><li>服务端通过客户端传入的随机数构造对称加密算法，对返回结果内容进行加密后传输</li></ul><h2 id="为什么数据传输是用对称加密？"><a href="#为什么数据传输是用对称加密？" class="headerlink" title="为什么数据传输是用对称加密？"></a>为什么数据传输是用对称加密？</h2><p>首先，非对称加密的加解密效率是非常低的，而 http 的应用场景中通常端与端之间存在大量的交互，非对称加密的效率是无法接受的；</p><p>另外，在 HTTPS 的场景中只有服务端保存了私钥，一对公私钥只能实现单向的加解密，所以 HTTPS 中内容传输加密采取的是对称加密，而不是非对称加密。</p><h2 id="为什么需要-CA-认证机构颁发证书？"><a href="#为什么需要-CA-认证机构颁发证书？" class="headerlink" title="为什么需要 CA 认证机构颁发证书？"></a>为什么需要 CA 认证机构颁发证书？</h2><p>HTTP 协议被认为不安全是因为传输过程容易被监听者勾线监听、伪造服务器，而 HTTPS 协议主要解决的便是网络传输的安全性问题。</p><p>首先我们假设不存在认证机构，任何人都可以制作证书，这带来的安全风险便是经典的“中间人攻击”问题。“中间人攻击”的具体过程如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/2.png"></p><p>过程原理：</p><ol><li>本地请求被劫持（如DNS劫持等），所有请求均发送到中间人的服务器</li><li>中间人服务器返回中间人自己的证书</li><li>客户端创建随机数，通过中间人证书的公钥对随机数加密后传送给中间人，然后凭随机数构造对称加密对传输内容进行加密传输</li><li>中间人因为拥有客户端的随机数，可以通过对称加密算法进行内容解密</li><li>中间人以客户端的请求内容再向正规网站发起请求</li><li>因为中间人与服务器的通信过程是合法的，正规网站通过建立的安全通道返回加密后的数据</li><li>中间人凭借与正规网站建立的对称加密算法对内容进行解密</li><li>中间人通过与客户端建立的对称加密算法对正规内容返回的数据进行加密传输</li><li>客户端通过与中间人建立的对称加密算法对返回结果数据进行解密</li></ol><p>由于缺少对证书的验证，所以客户端虽然发起的是 HTTPS 请求，但客户端完全不知道自己的网络已被拦截，传输内容被中间人全部窃取。</p><h2 id="浏览器是如何确保-CA-证书的合法性？"><a href="#浏览器是如何确保-CA-证书的合法性？" class="headerlink" title="浏览器是如何确保 CA 证书的合法性？"></a>浏览器是如何确保 CA 证书的合法性？</h2><p>1、证书包含什么信息？<br>颁发机构信息 公钥 公司信息 域名 有效期 指纹 ……</p><p>2、证书的合法性依据是什么？<br>首先，权威机构是要有认证的，不是随便一个机构都有资格颁发证书，不然也不叫做权威机构。另外，证书的可信性基于信任制，权威机构需要对其颁发的证书进行信用背书，只要是权威机构生成的证书，我们就认为是合法的。所以权威机构会对申请者的信息进行审核，不同等级的权威机构对审核的要求也不一样，于是证书也分为免费的、便宜的和贵的。</p><p>3、浏览器如何验证证书的合法性？<br>浏览器发起 HTTPS 请求时，服务器会返回网站的 SSL 证书，浏览器需要对证书做以下验证：</p><ul><li>验证域名、有效期等信息是否正确。证书上都有包含这些信息，比较容易完成验证；</li><li>判断证书来源是否合法。每份签发证书都可以根据验证链查找到对应的根证书，操作系统、浏览器会在本地存储权威机构的根证书，利用本地根证书可以对对应机构签发证书完成来源验证；</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/3.png"></p><ul><li>判断证书是否被篡改。需要与 CA 服务器进行校验；</li><li>判断证书是否已吊销。通过CRL（Certificate Revocation List 证书注销列表）和 OCSP（Online Certificate Status Protocol 在线证书状态协议）实现，其中 OCSP 可用于第3步中以减少与 CA 服务器的交互，提高验证效率</li></ul><p>以上任意一步都满足的情况下浏览器才认为证书是合法的。</p><blockquote><p>这里插一个我想了很久的但其实答案很简单的问题：</p><p>既然证书是公开的，如果要发起中间人攻击，我在官网上下载一份证书作为我的服务器证书，那客户端肯定会认同这个证书是合法的，如何避免这种证书冒用的情况？</p><p>其实这就是非加密对称中公私钥的用处，虽然中间人可以得到证书，但私钥是无法获取的，一份公钥是不可能推算出其对应的私钥，中间人即使拿到证书也无法伪装成合法服务端，因为无法对客户端传入的加密数据进行解密。</p></blockquote><p>4、只有认证机构可以生成证书吗？</p><p>如果需要浏览器不提示安全风险，那只能使用认证机构签发的证书。但浏览器通常只是提示安全风险，并不限制网站不能访问，所以从技术上谁都可以生成证书，只要有证书就可以完成网站的 HTTPS 传输。例如早期的 12306 采用的便是手动安装私有证书的形式实现 HTTPS 访问。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/4.png"></p><h2 id="本地随机数被窃取怎么办？"><a href="#本地随机数被窃取怎么办？" class="headerlink" title="本地随机数被窃取怎么办？"></a>本地随机数被窃取怎么办？</h2><p>证书验证是采用非对称加密实现，但是传输过程是采用对称加密，而其中对称加密算法中重要的随机数是由本地生成并且存储于本地的，HTTPS 如何保证随机数不会被窃取？</p><p>其实 HTTPS 并不包含对随机数的安全保证，HTTPS 保证的只是传输过程安全，而随机数存储于本地，本地的安全属于另一安全范畴，应对的措施有安装杀毒软件、反木马、浏览器升级修复漏洞等。</p><h2 id="用了-HTTPS-会被抓包吗？"><a href="#用了-HTTPS-会被抓包吗？" class="headerlink" title="用了 HTTPS 会被抓包吗？"></a>用了 HTTPS 会被抓包吗？</h2><p>HTTPS 的数据是加密的，常规下抓包工具代理请求后抓到的包内容是加密状态，无法直接查看。</p><p>但是，正如前文所说，浏览器只会提示安全风险，如果用户授权仍然可以继续访问网站，完成请求。因此，只要客户端是我们自己的终端，我们授权的情况下，便可以组建中间人网络，而抓包工具便是作为中间人的代理。通常 HTTPS 抓包工具的使用方法是会生成一个证书，用户需要手动把证书安装到客户端中，然后终端发起的所有请求通过该证书完成与抓包工具的交互，然后抓包工具再转发请求到服务器，最后把服务器返回的结果在控制台输出后再返回给终端，从而完成整个请求的闭环。</p><p>既然 HTTPS 不能防抓包，那 HTTPS 有什么意义？</p><p>HTTPS 可以防止用户在不知情的情况下通信链路被监听，对于主动授信的抓包操作是不提供防护的，因为这个场景用户是已经对风险知情。要防止被抓包，需要采用应用级的安全防护，例如采用私有的对称加密，同时做好移动端的防反编译加固，防止本地算法被破解。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以下用简短的 Q&amp;A 形式进行全文总结：</p><ul><li>Q: HTTPS 为什么安全？</li></ul><p>​    A: 因为 HTTPS 保证了传输安全，防止传输过程被监听、防止数据被窃取，可以确认网站的真实性。</p><ul><li>Q: HTTPS 的传输过程是怎样的？</li></ul><p>​    A: 客户端发起 HTTPS 请求，服务端返回证书，客户端对证书进行验证，验证通过后本地生成用于改造对称加密算法的随机数，通过证书中的公钥对随机数进行加密传输到服务端，服务端接收后通过私钥解密得到随机数，之后的数据交互通过对称加密算法进行加解密。</p><ul><li>Q: 为什么需要证书？</li></ul><p>​    A: 防止”中间人“攻击，同时可以为网站提供身份证明。</p><ul><li>Q: 使用 HTTPS 会被抓包吗？</li></ul><p>​    A: 会被抓包，HTTPS 只防止用户在不知情的情况下通信被监听，如果用户主动授信，是可以构建“中间人”网络，代理软件可以对传输内容进行解密。</p><p>最后顺手分享一张学习 HTTPS  的过程图。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/5.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 云原生云景高清大图 </title>
      <link href="/2019/12/23/2019-12-23-cloudnativemap/"/>
      <url>/2019/12/23/2019-12-23-cloudnativemap/</url>
      
        <content type="html"><![CDATA[<p><strong>云原生地图</strong></p><p>查看官方最新版: <a href="https://landscape.cncf.io/">https://landscape.cncf.io/</a></p><p>Cloud Native Trail Map ，是由CNCF发布的云原生云景大图，为企业拥抱云原生指明方向，地图涵盖：容器Registry，存储，容器运行时，网络，编排系统，服务发现，服务代理，API网关，服务网格，数据库，CI/CD等。（地图最后更新时间：2019.12.29）</p><p>图片较大，加载速度较为缓慢，请耐心等待。。。</p><p>图片下载地址：链接: <a href="https://pan.baidu.com/s/1m8Gqt3Rw974P42Hcy3_jnw">https://pan.baidu.com/s/1m8Gqt3Rw974P42Hcy3_jnw</a> 提取码: 7bc3</p><p>(含PDF和PNG格式)</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-23/landscape.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> CloudNative </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Nginx 原理和架构 </title>
      <link href="/2019/12/22/2019-12-22-nginx-principle/"/>
      <url>/2019/12/22/2019-12-22-nginx-principle/</url>
      
        <content type="html"><![CDATA[<h1 id="1、Nginx-的整体架构"><a href="#1、Nginx-的整体架构" class="headerlink" title="1、Nginx 的整体架构"></a>1、Nginx 的整体架构</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-22/191222principle1.png"></p><p>Nginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。</p><p><strong>1.1. 主进程</strong></p><p>master进程主要用来管理worker进程，具体包括如下4个主要功能：</p><ol><li>接收来自外界的信号。</li><li>向各worker进程发送信号。</li><li>监控woker进程的运行状态。</li><li>当woker进程退出后（异常情况下），会自动重新启动新的woker进程。</li></ol><p><strong>1.2. 工作进程</strong></p><p>woker进程主要用来处理基本的网络事件：</p><ol><li>多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。</li><li>一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</li><li>worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。</li></ol><p><strong>1.3. 模块化设计</strong></p><p>Nginx的worker进程，包括核心和功能性模块，核心模块负责维持一个运行循环 （ run-loop ），执行网络请求处理的 不同阶段 的模块功能。</p><p>比如： 网络读写 、 存储读写、 内容传输 、 外出过滤 ，以及将请求发往上游服务器等。</p><p>而其代码的模块化设计 ，也使得我们可以根据需要对 功能模块 进行适当的 选择 和 修改 ，编译成具有 特定功能的服务器。</p><p><strong>1.4. 事件驱动模型</strong></p><p>基于 异步及非阻塞的事件驱动模型 ，可以说是 Nginx 得以获得高并发、高性能的关键因素，同时也得益于对 Linux 、 Solaris 及类 BSD 等操作系统内核中 事件通知 及 I/O 性能增强功能 的采用，如 kqueue 、 epoll 及 event ports 。</p><p><strong>1.5. 代理（proxy）设计</strong></p><p>代理设计，可以说是 Nginx 深入骨髓的设计，无论是对于 HTTP ，还是对于 FastCGI 、 Memcache 、 Redis 等的网络请求或响应，本质上都采用了 代理机制 。所以， Nginx 天生就是高性能的 代理服务器 。</p><h1 id="2、Nginx的模块化设计"><a href="#2、Nginx的模块化设计" class="headerlink" title="2、Nginx的模块化设计"></a>2、Nginx的模块化设计</h1><p>高度模块化的设计是 Nginx 的架构基础。Nginx 服务器被分解为多个模块 ，每个模块就是一个功能模块 ，只负责自身的功能，模块之间严格遵循 “高内聚，低耦合” 的原则。</p><p>如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-22/191222principle2.png"></p><p><strong>2.1. 核心模块</strong></p><p>核心模块是 Nginx 服务器正常运行 必不可少的模块，提供错误日志记录 、 配置文件解析 、 事件驱动机制 、 进程管理 等核心功能。</p><p><strong>2.2. 标准HTTP模块</strong></p><p>标准 HTTP 模块提供 HTTP 协议解析相关的功能，比如： 端口配置 、 网页编码设置 、 HTTP响应头设置 等等。</p><p><strong>2.3. 可选HTTP模块</strong></p><p>可选 HTTP 模块主要用于 扩展 标准的 HTTP 功能，让 Nginx 能处理一些特殊的服务，比如：Flash 多媒体传输 、解析 GeoIP 请求、 网络传输压缩 、 安全协议 SSL 支持等。</p><p><strong>2.4. 邮件服务模块</strong></p><p>邮件服务模块主要用于支持 Nginx 的 邮件服务 ，包括对 POP3 协议、 IMAP 协议和 SMTP协议的支持。</p><p><strong>2.5. 第三方模块</strong></p><p>第三方模块是为了扩展 Nginx 服务器应用，完成开发者自定义功能，比如：Json 支持、 Lua 支持等。</p><h1 id="3、Nginx的请求方式处理"><a href="#3、Nginx的请求方式处理" class="headerlink" title="3、Nginx的请求方式处理"></a>3、Nginx的请求方式处理</h1><p>Nginx 是一个 高性能 的 Web 服务器，能够同时处理大量的并发请求 。它结合多进程机制和 异步机制 ，异步机制使用的是 异步非阻塞方式 ，接下来就给大家介绍一下 Nginx 的 多线程机制 和 异步非阻塞机制 。</p><p><strong>3.1. 多进程机制</strong></p><p>服务器每当收到一个客户端时，就有 服务器主进程 （ master process ）生成一个 子进程（ worker process ）出来和客户端建立连接进行交互，直到连接断开，该子进程就结束了。</p><p>使用 进程 的好处是 各个进程之间相互独立 ， 不需要加锁 ，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发成本。</p><p>其次，采用独立的进程，可以让 进程互相之间不会影响 ，如果一个进程发生异常退出时，其它进程正常工作， master 进程则很快启动新的 worker 进程，确保服务不会中断，从而将风险降到最低。</p><p>缺点是操作系统生成一个 子进程 需要进行 内存复制 等操作，在 资源 和 时间 上会产生一定的开销。当有 大量请求 时，会导致 系统性能下降 。</p><p><strong>3.2. 异步非阻塞机制</strong></p><p>每个 工作进程 使用 异步非阻塞方式 ，可以处理多个客户端请求 。</p><p>当某个 工作进程 接收到客户端的请求以后，调用 IO 进行处理，如果不能立即得到结果，就去处理其他请求 （即为非阻塞 ），而客户端在此期间也无需等待响应 ，可以去处理其他事情（即为异步 ）</p><p>当 IO 返回时，就会通知此工作进程，该进程得到通知，暂时挂起当前处理的事务去 响应客户端请求 。</p><h1 id="4、Nginx事件驱动模型"><a href="#4、Nginx事件驱动模型" class="headerlink" title="4、Nginx事件驱动模型"></a>4、Nginx事件驱动模型</h1><p>在 Nginx 的 异步非阻塞机制 中， 工作进程在调用 IO 后，就去处理其他的请求，当 IO 调用返回后，会通知该工作进程 。</p><p>对于这样的系统调用，主要使用 Nginx 服务器的<strong>事件驱动模型</strong>来实现，如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-22/191222principle3.png"></p><p>如上图所示， Nginx 的 事件驱动模型 由 事件收集器 、 事件发送器 和 事件处理器 三部分基本单元组成。</p><ul><li><strong>事件收集器</strong>：负责收集 worker 进程的各种 IO 请求；</li><li><strong>事件发送器</strong>：负责将 IO 事件发送到 事件处理器 ；</li><li><strong>事件处理器</strong>：负责各种事件的 响应工作 。</li></ul><p>事件发送器将每个请求放入一个 待处理事件列表 ，使用非阻塞 I/O 方式调用 事件处理器来处理该请求。</p><p>其处理方式称为 “多路 IO 复用方法” ，常见的包括以下三种：select 模型、 poll模型、 epoll 模型。</p><h1 id="5、Nginx进程处理模型"><a href="#5、Nginx进程处理模型" class="headerlink" title="5、Nginx进程处理模型"></a>5、Nginx进程处理模型</h1><p>Nginx 服务器使用 <strong>master/worker</strong> 多进程模式，多线程启动和执行的流程如下：</p><ol><li>主程序Master process启动后，通过一个 for 循环来接收和处理外部信号</li></ol><ol start="2"><li>主进程通过 fork() 函数产生 worker 子进程 ，每个 子进程 执行一个 for 循环来实现 Nginx 服务器 对事件的接收 和 处理</li></ol><p>一般推荐 worker 进程数 与 CPU 内核数 一致，这样一来不存在 大量的子进程 生成和管理任务，避免了进程之间 竞争 CPU 资源 和 进程切换 的开销。</p><p>而且 Nginx 为了更好的利用 多核特性 ，提供了 CPU 亲缘性 的绑定选项，我们可以将某 一个进程绑定在某一个核上，这样就不会因为 进程的切换 带来 Cache 的失效。</p><p>对于每个请求，有且只有一个 工作进程 对其处理。首先，每个 worker 进程都是从 master进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket（listenfd） 之后，然后再 fork 出多个 worker 进程。</p><p>所有 worker 进程的 listenfd 会在 新连接 到来时变得 可读 ，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢占 accept_mutex</p><p>抢到 互斥锁 的那个进程注册 listenfd 读事件 ，在读事件里调用 accept 接受该连接。</p><p>当一个 worker 进程在 accept 这个连接之后，就开始读取请求 ， 解析请求 ， 处理请求，产生数据后，再返回给客户端 ，最后才断开连接 ，一个完整的请求就是这样。</p><p>我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。</p><p>如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-22/191222principle4.png"></p><p>在 Nginx 服务器的运行过程中， 主进程 和 工作进程 需要进程交互。交互依赖于 Socket 实现的管道来实现。</p><p><strong>5.1. 主进程与工作进程交互</strong></p><p>这条管道与普通的管道不同，它是由 主进程 指向 工作进程 的单向管道 ，包含主进程向工作进程发出的指令工，作进程 ID 等。同时主进程与外界通过信号通信 ；每个子进程具备接收信号 ，并处理相应的事件的能力。</p><p><strong>5.2. 工作进程与工作进程交互</strong></p><p>这种交互和 主进程-工作进程 交互基本一致，但是会通过主进程间接完成，工作进程之间是相互隔离的。</p><p>所以当工作进程 W1 需要向工作进程 W2 发指令时，首先找到 W2 的 进程ID ，然后将正确的指令写入指向 W2 的 通道，W2 收到信号采取相应的措施。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Linux find命令教程：15个find命令用法 </title>
      <link href="/2019/12/20/2019-12-20-linux-find/"/>
      <url>/2019/12/20/2019-12-20-linux-find/</url>
      
        <content type="html"><![CDATA[<h1 id="查找目录"><a href="#查找目录" class="headerlink" title="查找目录"></a>查找目录</h1><p>您可以使用-type d选项告诉find命令专门查找目录。这将使find命令仅搜索匹配的目录名，而不搜索文件名。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> d -name <span class="string">&quot;name-of-dir&quot;</span></span><br></pre></td></tr></table></figure><p>#查找隐藏文件</p><p>由于Linux中的隐藏文件和目录以句点开头，因此我们可以在搜索字符串中指定此搜索模式，以便递归列出隐藏的文件和目录。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -name <span class="string">&quot;.*&quot;</span></span><br></pre></td></tr></table></figure><p>#查找特定大小或大于X的文件</p><p>find的-size选项允许我们搜索特定大小的文件。它可用于查找确切大小的文件，大于或小于特定大小的文件或适合指定大小范围的文件。以下有些例子：<br>搜索大于10MB的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -size +10M</span><br></pre></td></tr></table></figure><p>搜索小于10MB的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -size -10M</span><br></pre></td></tr></table></figure><p>搜索大小恰好为10MB的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -size 10M</span><br></pre></td></tr></table></figure><p>搜索大小在100MB到1GB之间的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -size +100M -size -1G</span><br></pre></td></tr></table></figure><h1 id="从文件列表中查找"><a href="#从文件列表中查找" class="headerlink" title="从文件列表中查找"></a>从文件列表中查找</h1><p>如果您有需要搜索的文件列表（例如，在.txt文件中），则可以使用find和grep命令的组合来搜索文件列表。为了使此命令起作用，只需确保要搜索的每个模式之间都用换行符隔开。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search | grep -f filelist.txt</span><br></pre></td></tr></table></figure><p>grep的-f选项表示“file”，并允许我们指定要匹配的字符串文件。这导致find命令返回与列表中的文件或目录名称匹配的任何文件或目录名称。</p><h1 id="不在列表中查找"><a href="#不在列表中查找" class="headerlink" title="不在列表中查找"></a>不在列表中查找</h1><p>使用上一个示例中提到的相同文件列表，您还可以使用find来搜索与文本文件内的模式不符的任何文件。再一次，我们将结合使用find和grep命令；我们只需要用grep指定一个附加选项：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search | grep -f filelist.txt</span><br></pre></td></tr></table></figure><p>grep的-v选项表示“逆向匹配”，并且将返回与文件列表中指定的任何模式都不匹配的文件列表。</p><h1 id="设置maxdepth"><a href="#设置maxdepth" class="headerlink" title="设置maxdepth"></a>设置maxdepth</h1><p>find命令默认将进行递归搜索。这意味着它将在指定的目录中搜索您指定的模式，以及您告诉它要搜索的目录中的所有子目录。<br>例如，如果告诉find搜索Linux（/）的根目录，则无论存在多少个子目录，它都会搜索整个硬盘。您可以使用-maxdepth选项来规避此行为。<br>在-maxdepth之后指定一个数字，以指示查找应递归搜索的子目录数。<br>仅搜索当前目录中的文件，而不递归搜索：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find . -maxdepth 0 -name <span class="string">&quot;myfile.txt&quot;</span></span><br></pre></td></tr></table></figure><p>仅在当前目录和更深的一个子目录中搜索文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find . -maxdepth 1 -name <span class="string">&quot;myfile.txt&quot;</span></span><br></pre></td></tr></table></figure><h1 id="查找空文件（零长度）"><a href="#查找空文件（零长度）" class="headerlink" title="查找空文件（零长度）"></a>查找空文件（零长度）</h1><p>要使用find搜索空文件，可以使用-empty标志。搜索所有空文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -empty</span><br></pre></td></tr></table></figure><p>搜索所有空目录：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> d -empty</span><br></pre></td></tr></table></figure><p>如果希望自动删除find返回的空文件或目录，那么将此命令与-delete选项结合使用也非常方便。<br>删除目录（和子目录）中的所有空文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -empty -delete</span><br></pre></td></tr></table></figure><h1 id="查找最大的目录或文件"><a href="#查找最大的目录或文件" class="headerlink" title="查找最大的目录或文件"></a>查找最大的目录或文件</h1><p>如果您想快速确定系统上哪些文件或目录占用了最多的空间，则可以使用find进行递归搜索，并按文件和目录的大小输出排序的列表。<br>如何显示目录中最大的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -<span class="built_in">printf</span> <span class="string">&quot;%s\t%p\n&quot;</span> | sort -n | tail -1</span><br></pre></td></tr></table></figure><p>请注意，find命令已被排序到另外两个方便的Linux实用程序：sort和tail。 Sort将按文件的大小顺序排列文件列表，而tail将仅输出列表中的最后一个文件，该文件也是最大的。<br>如果您要输出例如最大的前5个文件，则可以调整tail命令。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -<span class="built_in">printf</span> <span class="string">&quot;%s\t%p\n&quot;</span> | sort -n | tail -5</span><br></pre></td></tr></table></figure><p>或者，您可以使用head命令来确定最小的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -<span class="built_in">printf</span> <span class="string">&quot;%s\t%p\n&quot;</span> | sort -n | head -5</span><br></pre></td></tr></table></figure><p>如果要搜索目录而不是文件，只需在类型选项中指定“ d”即可。如何显示最大目录：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> d -<span class="built_in">printf</span> <span class="string">&quot;%s\t%p\n&quot;</span> | sort -n | tail -1</span><br></pre></td></tr></table></figure><h1 id="查找setuid设置文件"><a href="#查找setuid设置文件" class="headerlink" title="查找setuid设置文件"></a>查找setuid设置文件</h1><p>Setuid是“set user ID on execution”的缩写，它是一种文件权限，允许普通用户运行具有升级特权（例如root）的程序。<br>出于明显的原因，这可能是一个安全问题，但是可以使用find命令和一些选项轻松隔离这些文件。<br>find命令有两个选项可帮助我们搜索具有特定权限的文件：-user和-perm。要查找普通用户能够以root特权执行的文件，可以使用以下命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -user root -perm /4000</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-20/setuid.png" alt="avatar"></p><p>在上面的屏幕截图中，我们包含了-exec选项，以便显示有关查找返回文件的更多输出。整个命令如下所示：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -user root -perm /4000 -<span class="built_in">exec</span> ls -l &#123;&#125; \;</span><br></pre></td></tr></table></figure><p>您也可以在此命令中用“ root”代替您要作为所有者搜索的任何其他用户。或者，您可以搜索具有SUID权限的所有文件，而根本不指定一个用户：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -perm /4000</span><br></pre></td></tr></table></figure><h1 id="查找sgid设置文件"><a href="#查找sgid设置文件" class="headerlink" title="查找sgid设置文件"></a>查找sgid设置文件</h1><p>查找具有SGID设置的文件与查找具有SUID的文件几乎相同，只是需要将4000的权限更改为2000：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -perm /2000</span><br></pre></td></tr></table></figure><p>您还可以通过在perms选项中指定6000来搜索，同时设置了SUID和SGID的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -perm /6000</span><br></pre></td></tr></table></figure><h1 id="列出文件未经允许被拒绝"><a href="#列出文件未经允许被拒绝" class="headerlink" title="列出文件未经允许被拒绝"></a>列出文件未经允许被拒绝</h1><p>使用find命令搜索文件时，您必须对要搜索的目录和子目录具有读取权限。如果您没有找到，find将输出一条错误消息，但会继续浏览您确实拥有权限的目录。<br>没有权限尽管这可能发生在许多不同的目录中，但在搜索根目录时肯定会发生。<br>这意味着，当您尝试在整个硬盘上搜索文件时，find命令将产生大量错误消息。<br>为避免看到这些错误，您可以将find的stderr输出重定向到stdout，并将其通过管道传递到grep。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find / -name <span class="string">&quot;myfile.txt&quot;</span> 2&gt;%1 | grep -v <span class="string">&quot;Permission denied&quot;</span></span><br></pre></td></tr></table></figure><p>此命令使用grep的-v（反向）选项来显示所有输出，除了显示“拒绝权限”之外的所有输出。</p><h1 id="在最近X天内查找修改过的文件"><a href="#在最近X天内查找修改过的文件" class="headerlink" title="在最近X天内查找修改过的文件"></a>在最近X天内查找修改过的文件</h1><p>使用find命令上的-mtime选项搜索最近X天内被修改的文件或目录。它也可以用于搜索X天之前的文件，或X天之前被完全修改过的的文件。<br>以下是一些如何在find命令上使用-mtime选项的示例：<br>搜索最近30天内修改过的所有文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -mtime -30</span><br></pre></td></tr></table></figure><p>搜索超过30天之前已修改的所有文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -mtime +30</span><br></pre></td></tr></table></figure><p>搜索30天前刚修改过的所有文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -mtime 30</span><br></pre></td></tr></table></figure><p>如果希望find命令输出有关找到的文件的更多信息，例如修改日期，则可以使用-exec选项并包含ls命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">type</span> f -mtime -30 -<span class="built_in">exec</span> ls -l &#123;&#125; \;</span><br></pre></td></tr></table></figure><h1 id="按时间排序"><a href="#按时间排序" class="headerlink" title="按时间排序"></a>按时间排序</h1><p>要按文件的修改时间对查找结果进行排序，您可以使用-printf选项以可排序的方式列出时间，然后将其输出到sort实用程序。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">printf</span> <span class="string">&quot;%T+\t%p\n&quot;</span> | sort</span><br></pre></td></tr></table></figure><p>此命令将对旧的文件进行排序。如果您希望较新的文件首先显示，只需传递-r（反向）选项即可进行排序。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find /path/to/search -<span class="built_in">printf</span> <span class="string">&quot;%T+\t%p\n&quot;</span> | sort -r</span><br></pre></td></tr></table></figure><h1 id="定位和查找之间的区别"><a href="#定位和查找之间的区别" class="headerlink" title="定位和查找之间的区别"></a>定位和查找之间的区别</h1><p>Linux上的locate命令是搜索系统上文件的另一种好方法。它没有像find命令那样包含过多的搜索选项，因此它的灵活性较差，但仍然很方便。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ locate myfile.txt</span><br></pre></td></tr></table></figure><p>locate命令通过搜索包含系统上所有文件名的数据库来工作。搜索到的数据库已使用upatedb命令进行更新。<br>由于locate命令不必实时搜索系统上的所有文件，因此它比find命令效率更高。但是，除了缺少选项之外，还有另一个缺点：文件数据库每天仅更新一次。<br>您可以通过运行updatedb命令手动更新此文件数据库：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ updatedb</span><br></pre></td></tr></table></figure><p>当您需要在整个硬盘驱动器中搜索文件时，locate命令特别有用，因为find命令自然需要更长的时间，因为它必须实时遍历每个目录。<br>如果搜索一个特定目录（已知其中不包含大量子目录），则最好坚持使用find命令。</p><h1 id="find命令的CPU负载"><a href="#find命令的CPU负载" class="headerlink" title="find命令的CPU负载"></a>find命令的CPU负载</h1><p>在搜索大量目录时，find命令可能会占用大量资源。它本来应该允许更重要的系统进程具有优先级，但是如果需要确保find命令占用生产服务器上的较少资源，则可以使用ionice或nice命令。<br>监视find命令的CPU使用情况：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ top</span><br></pre></td></tr></table></figure><p>降低find命令的输入/输出优先级：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ionice -c3 -n7 find /path/to/search -name <span class="string">&quot;myfile.txt&quot;</span></span><br></pre></td></tr></table></figure><p>降低find命令的CPU优先级：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ nice -n 19 find /path/to/search -name <span class="string">&quot;myfile.txt&quot;</span></span><br></pre></td></tr></table></figure><p>或结合使用这两个实用程序以真正确保低I / O和低CPU优先级：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ nice -n ionice -c2 -n7 find /path/to/search -name <span class="string">&quot;myfile.txt&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> Nginx的这些妙用，你肯定有不知道的 </title>
      <link href="/2019/12/19/2019-12-19-nginx-usage/"/>
      <url>/2019/12/19/2019-12-19-nginx-usage/</url>
      
        <content type="html"><![CDATA[<h1 id="Nginx-简介"><a href="#Nginx-简介" class="headerlink" title="Nginx 简介"></a>Nginx 简介</h1><p>Nginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件（IMAP/POP3）代理服务器，其特点是占有内存少，并发能力强。</p><p>Nginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。</p><p>Nginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：</p><ul><li><strong>核心模块：</strong>HTTP 模块、EVENT 模块和 MAIL 模块。</li><li><strong>基础模块：</strong>HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。</li><li><strong>第三方模块：</strong>HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。</li></ul><p>这样的设计使 Nginx 方便开发和扩展，也正因此才使得 Nginx 功能如此强大。</p><p>Nginx 的模块默认编译进 Nginx 中，如果需要增加或删除模块，需要重新编译 Nginx，这一点不如 Apache 的动态加载模块方便。</p><p>如果有需要动态加载模块，可以使用由淘宝网发起的 Web 服务器 Tengine，在 Nginx 的基础上增加了很多高级特性，完全兼容 Nginx，已被国内很多网站采用。</p><p>Nginx 有很多扩展版本：</p><ul><li><p><strong>开源版 nginx.org</strong></p></li><li><p><strong>商业版 NGINX Plus</strong></p></li><li><p><strong>淘宝网发起的 Web 服务器 Tengine</strong></p></li><li><p><strong>基于 Nginx 和 Lua 的 Web 平台 OpenResty</strong></p></li></ul><h1 id="Nginx-作为-Web-服务器"><a href="#Nginx-作为-Web-服务器" class="headerlink" title="Nginx 作为 Web 服务器"></a>Nginx 作为 Web 服务器</h1><p>Web 服务器也称为 WWW（World Wide Web）服务器，主要功能是提供网上信息浏览服务，常常以 B/S（Browser/Server）方式提供服务：</p><ul><li><strong>应用层使用 HTTP 协议。</strong></li><li><strong>HTML 文档格式。</strong></li><li><strong>浏览器统一资源定位器(URL)。</strong></li></ul><p>Nginx 可以作为静态页面的 Web 服务器，同时还支持 CGI 协议的动态语言，比如 Perl、PHP 等，但是不支持 Java。</p><p>Java 程序一般都通过与 Tomcat 配合完成。作为一名 Java 程序员，肯定要理解下 Nginx 和 Tomcat 的区别了。</p><p>Nginx、Apache 和 Tomcat：</p><ul><li><p><strong>Nginx：</strong>由俄罗斯程序员 Igor Sysoev 所开发的轻量级、高并发 HTTP 服务器。</p></li><li><p><strong>Apache HTTP Server Project：</strong>一个 Apache 基金会下的 HTTP 服务项目，和 Nginx 功能类似。</p></li><li><p><strong>Apache Tomcat：</strong>是 Apache 基金会下的另外一个项目，是一个 Application Server。</p><p>更准确的说是一个 Servlet 应用容器，与 Apache HTTP Server 和 Nginx 相比，Tomcat 能够动态的生成资源并返回到客户端。</p></li></ul><p>Apache HTTP Server 和 Nginx 本身不支持生成动态页面，但它们可以通过其他模块来支持（例如通过 Shell、PHP、Python 脚本程序来动态生成内容）。</p><p>一个 HTTP Server 关心的是 HTTP 协议层面的传输和访问控制，所以在 Apache/Nginx 上你可以看到代理、负载均衡等功能。</p><p>客户端通过 HTTP Server 访问服务器上存储的资源（HTML 文件、图片文件等等）。</p><p>通过 CGI 技术，也可以将处理过的内容通过 HTTP Server 分发，但是一个 HTTP Server 始终只是把服务器上的文件如实的通过 HTTP 协议传输给客户端。</p><p>而应用服务器，则是一个应用执行的容器。它首先需要支持开发语言的运行（对于 Tomcat 来说，就是 Java），保证应用能够在应用服务器上正常运行。</p><p>其次，需要支持应用相关的规范，例如类库、安全方面的特性。对于 Tomcat 来说，就是需要提供 JSP/Sevlet 运行需要的标准类库、Interface 等。</p><p>为了方便，应用服务器往往也会集成 HTTP Server 的功能，但是不如专业的 HTTP Server 那么强大。</p><p>所以应用服务器往往是运行在 HTTP Server 的背后，执行应用，将动态的内容转化为静态的内容之后，通过 HTTP Server 分发到客户端。</p><h2 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h2><p><strong>正向代理：</strong>如果把局域网外的 Internet 想象成一个巨大的资源库，则局域网中的客户端要访问 Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。</p><p>正向代理“代理”的是客户端。比如你想去 Google 看个“动作片”，可国内不允许呀，就需要找翻墙代理，这个就是所谓的“正向代理”。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/1.png" alt="avatar"></p><h2 id="反向代理与负载均衡"><a href="#反向代理与负载均衡" class="headerlink" title="反向代理与负载均衡"></a>反向代理与负载均衡</h2><p>反向代理正好与正向代理相反，反向代理是指以代理服务器来接收 Internet 上的连接请求，然后将请求转发到内部网络上的服务器，并将服务器上得到的结果返回给客户端。</p><p>此时代理服务器对外表现就是一个服务器，客户端对代理是无感知的。反向代理“代理”的是服务端。</p><p>再比如，你想本本分分的在“优酷”上看个“爱情片”，youku.com 会把你的请求分发到存放片片的那台机器上，这个就是所谓的“反向代理”。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/2.png" alt="avatar"></p><p>为什么使用反向代理，原因如下：</p><ul><li><strong>保护和隐藏原始资源服务器</strong></li><li><strong>加密和 SSL 加速</strong></li><li><strong>通过缓存静态资源，加速 Web 请求</strong></li><li><strong>实现负载均衡</strong></li></ul><p><strong>负载均衡：</strong>TODO: 留一个负载均衡详细介绍传送门。</p><p><strong>地址重定向：</strong>Nginx 的 Rewrite 主要的功能就是实现 URL 重写，比如输入 360.com  跳转到了 360.cn，baidu.cn 跳转到了 baidu.com。</p><h2 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h2><p>为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。</p><p>这里指的就是让动态程序（Java、PHP）去访问应用服务器，让缓存、图片、JS、CSS 等去访问 Nginx。</p><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>nginx.conf 配置文件主要分为三部分：</p><ul><li><strong>全局块</strong></li><li><strong>Events 块</strong></li><li><strong>HTTPS 块</strong></li></ul><p>Nginx 配置语法：</p><ul><li>配置文件由指令和指令块构成</li><li>每条指令以分号（;）结尾，指令和参数间以空格符分隔</li><li>指令块以大括号{}将多条指令组织在一起</li><li>include 语句允许组合多个配置文件以提高可维护性</li><li>使用 # 添加注释</li><li>使用 $ 定义变量</li><li>部分指令的参数支持正则表达式</li></ul><h3 id="全局块"><a href="#全局块" class="headerlink" title="全局块"></a>全局块</h3><p>全局配置部分用来配置对整个 Server 都有效的参数。主要会设置一些影响 Nginx 服务器整体运行的配置指令，包括配置运行 Nginx 服务器的用户（组）、允许生成的 Worker Process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。</p><p>示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">user nobody;</span><br><span class="line">worker_processes  4;</span><br><span class="line">error_log  /data/nginx/logs/error.log  notice;</span><br></pre></td></tr></table></figure><h3 id="Events-块"><a href="#Events-块" class="headerlink" title="Events 块"></a>Events 块</h3><p>Events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 Work Process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 Word Process 可以同时支持的最大连接数等。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">events &#123;</span><br><span class="line">    <span class="comment">#每个 work process 支持的最大连接数为 1024.</span></span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="HTTP-块"><a href="#HTTP-块" class="headerlink" title="HTTP 块"></a>HTTP 块</h3><p>这算是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 需要注意的是：HTTP 块也可以包括 HTTP 全局块、Server 块。</p><p><strong>①HTTP 全局块</strong></p><p>HTTP 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    sendfile        on;</span><br><span class="line">    keepalive_timeout  65;</span><br></pre></td></tr></table></figure><p><strong>②Server 块</strong></p><p>这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。</p><p>每个 HTTP 块可以包括多个 Server 块，而每个 Server 块就相当于一个虚拟主机。</p><p>而每个 Server 块也分为全局 Server 块，以及可以同时包含多个 Locaton 块。</p><p><strong>全局 Server 块：</strong>也被叫做“虚拟服务器”部分，它描述的是一组根据不同server_name指令逻辑分割的资源，这些虚拟服务器响应 HTTP 请求，因此都包含在 HTTP 部分。</p><p>最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">  listen       80;</span><br><span class="line">  <span class="comment">#server_name也支持通配符，*.example.com、www.example.*、.example.com</span></span><br><span class="line">  server_name  localhost;</span><br><span class="line">  <span class="comment">#charset koi8-r;</span></span><br><span class="line">  <span class="comment">#access_log  logs/host.access.log  main;</span></span><br></pre></td></tr></table></figure><p><strong>Location 块：</strong>一个 Server 块可以配置多个 Location 块。</p><p>这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称 （也可以是 IP 别名）之外的字符串（例如前面的 /uri-string）进行匹配，对特定的请求进行处理。</p><p>地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。</p><p><strong>Location 指令说明：</strong>该指令用于匹配 URL。</p><p>语法如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">location [ = | ~ | ~* | ^~] uri&#123;&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>= ：</strong>该修饰符使用精确匹配并且终止搜索。</li><li><strong>~：</strong>该修饰符使用区分大小写的正则表达式匹配。</li><li><strong>~*：</strong>该修饰符使用不区分大小写的正则表达式匹配。</li><li><strong>^~：</strong>用于不含正则表达式的 URI 前，要求 Nginx 服务器找到标识 URI 和请求字符串匹配度最高的 Location 后，立即使用此 Location 处理请求，而不再使用 Location 块中的正则 URI 和请求字符串做匹配。</li></ul><p>?&gt;Tip 注意：如果 URI 包含正则表达式，则必须要有 ~ 或者 ~* 标识。</p><p>当一个请求进入时，URI 将会被检测匹配一个最佳的 Location：</p><ul><li>没有正则表达式的 Location 被作为最佳的匹配，独立于含有正则表达式的 Location 顺序。</li><li>在配置文件中按照查找顺序进行正则表达式匹配。在查找到第一个正则表达式匹配之后结束查找。由这个最佳的 Location 提供请求处理。</li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">location / &#123;</span><br><span class="line">    root   html;</span><br><span class="line">   index  index.html index.htm;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">#error_page  404              /404.html;</span></span><br><span class="line"></span><br><span class="line"> <span class="comment"># redirect server error pages to the static page /50x.html</span></span><br><span class="line"> <span class="comment">#</span></span><br><span class="line"> error_page   500 502 503 504  /50x.html;</span><br><span class="line"> location = /50x.html &#123;</span><br><span class="line">     root   html;</span><br><span class="line"> &#125;</span><br><span class="line"> location / &#123;</span><br><span class="line">     <span class="comment">#try_files指令将会按照给定的参数顺序进行匹配尝试</span></span><br><span class="line">     try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ /index.html;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>nginx.conf 详细配置如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义Nginx运行的用户和用户组</span></span><br><span class="line">user www www;</span><br><span class="line"></span><br><span class="line"><span class="comment">#nginx进程数，通常设置成和cpu的数量相等</span></span><br><span class="line">worker_processes 4;</span><br><span class="line"></span><br><span class="line"><span class="comment">#全局错误日志定义类型，[debug | info | notice | warn | error | crit]</span></span><br><span class="line"><span class="comment">#error_log  /data/nginx/logs/error.log;</span></span><br><span class="line"><span class="comment">#error_log  /data/nginx/logs/error.log  notice;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#日志文件存放路径 access_log path [format [buffer=size | off]]</span></span><br><span class="line">access_log /data/nginx/logs/lazyegg.com/web/access.log combinedio;</span><br><span class="line"></span><br><span class="line"><span class="comment">#进程pid文件</span></span><br><span class="line"><span class="comment">#pid        logs/nginx.pid;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#指定进程可以打开的最大描述符：数目</span></span><br><span class="line"><span class="comment">#工作模式与连接数上限</span></span><br><span class="line"><span class="comment">##这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。</span></span><br><span class="line"><span class="comment">#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。</span></span><br><span class="line">worker_rlimit_nofile 65535;</span><br><span class="line"></span><br><span class="line"><span class="comment">#################################  events  ###############################</span></span><br><span class="line">events &#123;</span><br><span class="line">    <span class="comment">#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型</span></span><br><span class="line">    use epoll</span><br><span class="line">    <span class="comment">#单个进程最大连接数（最大连接数=连接数+进程数）</span></span><br><span class="line">    worker_connections  1024;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#keepalive 超时时间</span></span><br><span class="line">    keepalive_timeout 60;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#客户端请求头部的缓冲区大小。</span></span><br><span class="line">    client_header_buffer_size 4k;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。</span></span><br><span class="line">    open_file_cache max=65535 inactive=60s;</span><br><span class="line">    <span class="comment">#这个是指多长时间检查一次缓存的有效信息。</span></span><br><span class="line">    open_file_cache_valid 80s;</span><br><span class="line">        <span class="comment">#open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。</span></span><br><span class="line">    open_file_cache_min_uses 1;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误.</span></span><br><span class="line">    open_file_cache_errors on;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">##############################   http    ##################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设定http服务器，利用它的反向代理功能提供负载均衡支持</span></span><br><span class="line">http&#123;</span><br><span class="line">    <span class="comment">#文件扩展名与文件类型映射表</span></span><br><span class="line">    include mime.types;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#默认文件类型</span></span><br><span class="line">    default_type application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#默认编码</span></span><br><span class="line">    charset utf-8;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#服务器名字的hash表大小</span></span><br><span class="line">    server_names_hash_bucket_size 128;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#客户端请求头部的缓冲区大小。</span></span><br><span class="line">    client_header_buffer_size 32k;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#客户请求头缓冲大小。</span></span><br><span class="line">    large_client_header_buffers 4 64k;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#允许客户端请求的最大单个文件字节数</span></span><br><span class="line">    client_max_body_size 8m;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。</span></span><br><span class="line">    sendfile on;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启目录列表访问，适合下载服务器，默认关闭。</span></span><br><span class="line">    autoindex on;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用</span></span><br><span class="line">    tcp_nopush on;</span><br><span class="line"></span><br><span class="line">    tcp_nodelay on;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#长连接超时时间，单位是秒</span></span><br><span class="line">    keepalive_timeout 120;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。</span></span><br><span class="line">    fastcgi_connect_timeout 300;</span><br><span class="line">    fastcgi_send_timeout 300;</span><br><span class="line">    fastcgi_read_timeout 300;</span><br><span class="line">    fastcgi_buffer_size 64k;</span><br><span class="line">    fastcgi_buffers 4 64k;</span><br><span class="line">    fastcgi_busy_buffers_size 128k;</span><br><span class="line">    fastcgi_temp_file_write_size 128k;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#gzip模块设置</span></span><br><span class="line">    gzip on; <span class="comment">#开启gzip压缩输出</span></span><br><span class="line">    gzip_min_length 1k;    <span class="comment">#最小压缩文件大小</span></span><br><span class="line">    gzip_buffers 4 16k;    <span class="comment">#压缩缓冲区</span></span><br><span class="line">    gzip_http_version 1.0; <span class="comment">#压缩版本（默认1.1，前端如果是squid2.5请使用1.0）</span></span><br><span class="line">    gzip_comp_level 2;     <span class="comment">#压缩等级</span></span><br><span class="line">    gzip_types text/plain application/x-javascript text/css application/xml;    <span class="comment">#压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。</span></span><br><span class="line">    gzip_vary on;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启限制IP连接数的时候需要使用</span></span><br><span class="line">    <span class="comment">#limit_zone crawler $binary_remote_addr 10m;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#负载均衡配置</span></span><br><span class="line">    upstream lazyegg.net &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。</span></span><br><span class="line">        server 192.168.80.121:80 weight=3;</span><br><span class="line">        server 192.168.80.122:80 weight=2;</span><br><span class="line">        server 192.168.80.123:80 weight=3;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#nginx的upstream目前支持4种方式的分配</span></span><br><span class="line">        <span class="comment">#1、轮询（默认）</span></span><br><span class="line">        <span class="comment">#每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</span></span><br><span class="line">        <span class="comment">#2、weight</span></span><br><span class="line">        <span class="comment">#指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</span></span><br><span class="line">        <span class="comment">#例如：</span></span><br><span class="line">        <span class="comment">#upstream bakend &#123;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.14 weight=10;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.15 weight=10;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#2、ip_hash</span></span><br><span class="line">        <span class="comment">#每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</span></span><br><span class="line">        <span class="comment">#例如：</span></span><br><span class="line">        <span class="comment">#upstream bakend &#123;</span></span><br><span class="line">        <span class="comment">#    ip_hash;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.14:88;</span></span><br><span class="line">        <span class="comment">#    server 192.168.0.15:80;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#3、fair（第三方）</span></span><br><span class="line">        <span class="comment">#按后端服务器的响应时间来分配请求，响应时间短的优先分配。</span></span><br><span class="line">        <span class="comment">#upstream backend &#123;</span></span><br><span class="line">        <span class="comment">#    server server1;</span></span><br><span class="line">        <span class="comment">#    server server2;</span></span><br><span class="line">        <span class="comment">#    fair;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#4、url_hash（第三方）</span></span><br><span class="line">        <span class="comment">#按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</span></span><br><span class="line">        <span class="comment">#例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法</span></span><br><span class="line">        <span class="comment">#upstream backend &#123;</span></span><br><span class="line">        <span class="comment">#    server squid1:3128;</span></span><br><span class="line">        <span class="comment">#    server squid2:3128;</span></span><br><span class="line">        <span class="comment">#    hash $request_uri;</span></span><br><span class="line">        <span class="comment">#    hash_method crc32;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#tips:</span></span><br><span class="line">        <span class="comment">#upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123;</span></span><br><span class="line">        <span class="comment">#    ip_hash;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:9090 down;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:8080 weight=2;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:6060;</span></span><br><span class="line">        <span class="comment">#    server 127.0.0.1:7070 backup;</span></span><br><span class="line">        <span class="comment">#&#125;</span></span><br><span class="line">        <span class="comment">#在需要使用负载均衡的server中增加 proxy_pass http://bakend/;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#每个设备的状态设置为:</span></span><br><span class="line">        <span class="comment">#1.down表示单前的server暂时不参与负载</span></span><br><span class="line">        <span class="comment">#2.weight为weight越大，负载的权重就越大。</span></span><br><span class="line">        <span class="comment">#3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误</span></span><br><span class="line">        <span class="comment">#4.fail_timeout:max_fails次失败后，暂停的时间。</span></span><br><span class="line">        <span class="comment">#5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#nginx支持同时设置多组的负载均衡，用来给不用的server来使用。</span></span><br><span class="line">        <span class="comment">#client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug</span></span><br><span class="line">        <span class="comment">#client_body_temp_path设置记录文件的目录 可以设置最多3层目录</span></span><br><span class="line">        <span class="comment">#location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">#虚拟主机的配置</span></span><br><span class="line">    server &#123;</span><br><span class="line">        <span class="comment">#监听端口</span></span><br><span class="line">        listen 80;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#域名可以有多个，用空格隔开</span></span><br><span class="line">        server_name lazyegg.net;</span><br><span class="line">        <span class="comment">#默认入口文件名称</span></span><br><span class="line">        index index.html index.htm index.php;</span><br><span class="line">        root /data/www/lazyegg;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#对******进行负载均衡</span></span><br><span class="line">        location ~ .*.(php|php5)?$</span><br><span class="line">        &#123;</span><br><span class="line">            fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">            fastcgi_index index.php;</span><br><span class="line">            include fastcgi.conf;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#图片缓存时间设置</span></span><br><span class="line">        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$</span><br><span class="line">        &#123;</span><br><span class="line">            expires 10d;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#JS和CSS缓存时间设置</span></span><br><span class="line">        location ~ .*.(js|css)?$</span><br><span class="line">        &#123;</span><br><span class="line">            expires 1h;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#日志格式设定</span></span><br><span class="line">        <span class="comment">#$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；</span></span><br><span class="line">        <span class="comment">#$remote_user：用来记录客户端用户名称；</span></span><br><span class="line">        <span class="comment">#$time_local： 用来记录访问时间与时区；</span></span><br><span class="line">        <span class="comment">#$request： 用来记录请求的url与http协议；</span></span><br><span class="line">        <span class="comment">#$status： 用来记录请求状态；成功是200，</span></span><br><span class="line">        <span class="comment">#$body_bytes_sent ：记录发送给客户端文件主体内容大小；</span></span><br><span class="line">        <span class="comment">#$http_referer：用来记录从那个页面链接访问过来的；</span></span><br><span class="line">        <span class="comment">#$http_user_agent：记录客户浏览器的相关信息；</span></span><br><span class="line">        <span class="comment">#通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。</span></span><br><span class="line">        log_format access <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">        <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">        <span class="string">&#x27;&quot;$http_user_agent&quot; $http_x_forwarded_for&#x27;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#定义本虚拟主机的访问日志</span></span><br><span class="line">        access_log  /usr/<span class="built_in">local</span>/nginx/logs/host.access.log  main;</span><br><span class="line">        access_log  /usr/<span class="built_in">local</span>/nginx/logs/host.access.404.log  log404;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#对 &quot;/connect-controller&quot; 启用反向代理</span></span><br><span class="line">        location /connect-controller &#123;</span><br><span class="line">            proxy_pass http://127.0.0.1:88; <span class="comment">#请注意此处端口号不能与虚拟主机监听的端口号一样（也就是server监听的端口）</span></span><br><span class="line">            proxy_redirect off;</span><br><span class="line">            proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span></span><br><span class="line">            proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#以下是一些反向代理的配置，可选。</span></span><br><span class="line">            proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#允许客户端请求的最大单文件字节数</span></span><br><span class="line">            client_max_body_size 10m;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#缓冲区代理缓冲用户端请求的最大字节数，</span></span><br><span class="line">            <span class="comment">#如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。</span></span><br><span class="line">            <span class="comment">#无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误</span></span><br><span class="line">            client_body_buffer_size 128k;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#表示使nginx阻止HTTP应答代码为400或者更高的应答。</span></span><br><span class="line">            proxy_intercept_errors on;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#后端服务器连接的超时时间_发起握手等候响应超时时间</span></span><br><span class="line">            <span class="comment">#nginx跟后端服务器连接超时时间(代理连接超时)</span></span><br><span class="line">            proxy_connect_timeout 90;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#后端服务器数据回传时间(代理发送超时)</span></span><br><span class="line">            <span class="comment">#后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据</span></span><br><span class="line">            proxy_send_timeout 90;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#连接成功后，后端服务器响应时间(代理接收超时)</span></span><br><span class="line">            <span class="comment">#连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）</span></span><br><span class="line">            proxy_read_timeout 90;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#设置代理服务器（nginx）保存用户头信息的缓冲区大小</span></span><br><span class="line">            <span class="comment">#设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小</span></span><br><span class="line">            proxy_buffer_size 4k;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#proxy_buffers缓冲区，网页平均在32k以下的设置</span></span><br><span class="line">            <span class="comment">#设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k</span></span><br><span class="line">            proxy_buffers 4 32k;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#高负荷下缓冲大小（proxy_buffers*2）</span></span><br><span class="line">            proxy_busy_buffers_size 64k;</span><br><span class="line"></span><br><span class="line">            <span class="comment">#设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长</span></span><br><span class="line">            <span class="comment">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</span></span><br><span class="line">            proxy_temp_file_write_size 64k;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#本地动静分离反向代理配置</span></span><br><span class="line">        <span class="comment">#所有jsp的页面均交由tomcat或resin处理</span></span><br><span class="line">        location ~ .(jsp|jspx|<span class="keyword">do</span>)?$ &#123;</span><br><span class="line">            proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">            proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">            proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">            proxy_pass http://127.0.0.1:8080;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Nginx-配置：负载均衡"><a href="#Nginx-配置：负载均衡" class="headerlink" title="Nginx 配置：负载均衡"></a>Nginx 配置：负载均衡</h2><p>随着互联网信息的爆炸性增长，负载均衡（Load Balance）已经不再是一个很陌生的话题。</p><p>顾名思义，负载均衡即是将负载分摊到不同的服务单元，既保证服务的可用性，又保证响应足够快，给用户很好的体验。</p><p>快速增长的访问量和数据流量催生了各式各样的负载均衡产品，很多专业的负载均衡硬件提供了很好的功能，但却价格不菲。</p><p>这使得负载均衡软件大受欢迎，Nginx 就是其中的一个，在 Linux 下有 Nginx、LVS、Haproxy 等等服务可以提供负载均衡服务。</p><p>Nginx 的负载均衡是 Proxy 模块和 Upstream 模块搭配实现的。Upstream模块将会启用一个新的配置区段，在该区段定义了一组上游服务器。</p><p><strong>实现效果：配置负载均衡。</strong></p><p>①同时启动两个 Tomcat（为了方便验证效果，修改 Tomcat 端口号的同时，顺便将 Tomcat 默认欢迎页面 apache-tomcat-9.0.29/webapps/ROOR 目录下的 index.jsp 修改下，看下 8081 欢迎页的“蛋蛋”没）：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/3.png" alt="avatar"></p><p>②修改 nginx.conf：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    upstream myserver &#123;</span><br><span class="line">        server localhost:8080;</span><br><span class="line">        server localhost:8081;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        location / &#123;</span><br><span class="line">            proxy_pass http://myserver;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>③重启 Nginx，验证效果（默认轮询的方式，每次打开新窗口，8080 和 8081 会交替出现，同一个窗口的话需要关闭浏览器缓存)。</p><p>Nginx 分配策略：</p><ul><li>轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 Down 掉，能自动剔除。</li><li>Weight 代表权重，默认为 1，权重越高被分配的客户端越多，指定轮询几率，Weight 和访问比率成正比，用于后端服务器性能不均的情况。</li></ul><p>例如：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">upstream server_pool&#123;</span><br><span class="line">   server 192.168.5.21 weight=10;</span><br><span class="line">   server 192.168.5.22 weight=10; &#125;</span><br></pre></td></tr></table></figure><p>ip_hash 每个请求按访问 IP 的 Hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 Session 的问题。</p><p>例如：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">upstream server_pool&#123;</span><br><span class="line">    ip_hash; server 192.168.5.21:80;</span><br><span class="line">    server 192.168.5.22:80;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">upstream server_pool&#123;</span><br><span class="line">    server 192.168.5.21:80;</span><br><span class="line">    server 192.168.5.22:80; fair;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="Nginx-配置：动静分离"><a href="#Nginx-配置：动静分离" class="headerlink" title="Nginx 配置：动静分离"></a>Nginx 配置：动静分离</h2><p>Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。</p><p>严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。</p><p>动静分离从目前实现角度来讲大致分为两种：</p><ul><li>纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案；</li><li>动态跟静态文件混合在一起发布，通过 Nginx 来分开。</li></ul><p>通过 Location 指定不同的后缀名实现不同的请求转发。通过 Expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。</p><p><strong>具体 Expires 定义：</strong>是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可， 所以不会产生额外的流量。</p><p>此种方法非常适合不经常变动的资源（如果经常更新的文件， 不建议使用 Expires 来缓存）。</p><p>我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重新下载，返回状态码 200。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/4.png" alt="avatar"></p><p>①服务器找个目录存放自己的静态文件：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/12.png" alt="avatar"></p><p>②修改 nginx.conf：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost;</span><br><span class="line">    location /static/ &#123;</span><br><span class="line">        root   /usr/data/www;</span><br><span class="line">    &#125;</span><br><span class="line">    location /image/ &#123;</span><br><span class="line">         root /usr/data/;</span><br><span class="line">         autoindex on;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>③./nginx -s reload，验证效果：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/5.png" alt="avatar"></p><p>添加监听端口、访问名字重点是添加 Location，最后检查 Nginx 配置是否正确即可，然后测试动静分离是否成功，只需要删除后端 Tomcat 服务器上的某个静态文件，查看是否能访问，如果可以访问说明静态资源 Nginx 直接返回了，不走后端 Tomcat 服务器。</p><h2 id="Nginx-的-Rewrite"><a href="#Nginx-的-Rewrite" class="headerlink" title="Nginx 的 Rewrite"></a>Nginx 的 Rewrite</h2><p>Rewrite 是 Nginx 服务器提供的一个重要的功能，它可以实现 URL 重写和重定向功能。</p><p>场景如下：</p><ul><li>URL 访问跳转，支持开发设计。页面跳转、兼容性支持（新旧版本更迭）、展示效果（网址精简）等</li><li>SEO 优化（Nginx 伪静态的支持）</li><li>后台维护、流量转发等</li><li>安全（动态界面进行伪装）</li></ul><p>该指令是通过正则表达式的使用来改变 URI。可以同时存在一个或多个指令。需要按照顺序依次对 URL 进行匹配和处理。</p><p>该指令可以在 Server 块或 Location 块中配置，其基本语法结构如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rewrite regex replacement [flag];</span><br></pre></td></tr></table></figure><p>①采用反向代理 Demo2 中的例子，修改 nginx.conf（只多加了一行 Rewrite）：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location /java/ &#123;</span><br><span class="line">            proxy_pass http://127.0.0.1:8080;</span><br><span class="line">            rewrite ^/java /egg/ redirect;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location /egg/ &#123;</span><br><span class="line">            proxy_pass http://127.0.0.1:8081;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>②./nginx -s reload，验证效果（输入 ip/java/ 被重定向到了 egg）：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/6.png" alt="avatar"></p><p>Rewrite 指令可以在 Server 块或 Location 块中配置，其基本语法结构如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rewrite regex replacement [flag];</span><br></pre></td></tr></table></figure><ul><li><strong>rewrite 的含义：</strong>该指令是实现 URL 重写的指令。</li><li><strong>regex 的含义：</strong>用于匹配 URI 的正则表达式。</li><li><strong>replacement：</strong>将 regex 正则匹配到的内容替换成 replacement。</li><li><strong>flag：</strong>flag 标记。</li></ul><p>flag 有如下值：</p><ul><li><strong>last：</strong>本条规则匹配完成后，继续向下匹配新的 Location URI 规则。(不常用)</li><li><strong>break：</strong>本条规则匹配完成即终止，不再匹配后面的任何规则(不常用)。</li><li><strong>redirect：</strong>返回 302 临时重定向，浏览器地址会显示跳转新的 URL 地址。</li><li><strong>permanent：</strong>返回 301 永久重定向。浏览器地址会显示跳转新的 URL 地址。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rewrite ^/(.*) http://www.360.cn/$1 permanent;</span><br></pre></td></tr></table></figure><h2 id="Nginx-高可用"><a href="#Nginx-高可用" class="headerlink" title="Nginx 高可用"></a>Nginx 高可用</h2><p>如果将 Web 服务器集群当做一个城池，那么负载均衡服务器就相当于城门。如果“城门”关闭了，与外界的通道就断了。</p><p>如果只有一台 Nginx 负载服务器，当故障宕机的时候，就会导致整个网站无法访问。</p><p>所以我们需要两台以上 Nginx 来实现故障转移和高可用：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/7.png" alt="avatar"></p><p><strong>那么如何配置高可用?</strong></p><p><strong>①双机热备方案</strong></p><p>这种方案是国内企业中最为普遍的一种高可用方案，双机热备其实就是指一台服务器在提供服务，另一台为某服务的备用状态，当一台服务器不可用另外一台就会顶替上去。</p><p>Keepalived 是什么？Keepalived 软件起初是专为 LVS 负载均衡软件设计的，用来管理并监控 LVS 集群系统中各个服务节点的状态。</p><p>后来又加入了可以实现高可用的 VRRP (Virtual Router Redundancy Protocol ，虚拟路由器冗余协议）功能。</p><p>因此，Keepalived 除了能够管理 LVS 软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL 等）的高可用解决方案软件。</p><p><strong>②故障转移机制</strong></p><p>Keepalived 高可用服务之间的故障切换转移，是通过 VRRP 来实现的。</p><p>在 Keepalived服务正常工作时，主 Master 节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备 Backup 节点自己还活着。</p><p>当主 Master 节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主  Master 节点的心跳了，于是调用自身的接管程序，接管主 Master 节点的 IP 资源及服务。</p><p>而当主 Master节点恢复时，备 Backup 节点又会释放主节点故障时自身接管的 IP 资源及服务，恢复到原来的备用角色。</p><p>实现方法如下：</p><p>①准备两台安装 Nginx 和 Keepaliver(yum install keepalived -y)的服务器</p><p>②修改两台服务器上的 /etc/keepalived/keepalived.conf</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#主机</span></span><br><span class="line"><span class="comment">#检测脚本</span></span><br><span class="line">vrrp_script chk_http_port &#123;</span><br><span class="line">    script <span class="string">&quot;/usr/local/src/check_nginx.sh&quot;</span> <span class="comment">#心跳执行的脚本，检测nginx是否启动</span></span><br><span class="line">    interval 2                          <span class="comment">#（检测脚本执行的间隔，单位是秒）</span></span><br><span class="line">    weight 2                            <span class="comment">#权重</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#vrrp 实例定义部分</span></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER            <span class="comment"># 指定keepalived的角色，MASTER为主，BACKUP为备</span></span><br><span class="line">    interface ens33         <span class="comment"># 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡</span></span><br><span class="line">    virtual_router_id 66    <span class="comment"># 虚拟路由编号，主从要一直</span></span><br><span class="line">    priority 100            <span class="comment"># 优先级，数值越大，获取处理请求的优先级越高</span></span><br><span class="line">    advert_int 1            <span class="comment"># 检查间隔，默认为1s(vrrp组播周期秒数)</span></span><br><span class="line">    <span class="comment">#授权访问</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS <span class="comment">#设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信</span></span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        chk_http_port            <span class="comment">#（调用检测脚本）</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.16.150            <span class="comment"># 定义虚拟ip(VIP)，可多设，每行一个</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 备机</span></span><br><span class="line"><span class="comment">#检测脚本</span></span><br><span class="line">vrrp_script chk_http_port &#123;</span><br><span class="line">    script <span class="string">&quot;/usr/local/src/check_nginx.sh&quot;</span> <span class="comment">#心跳执行的脚本，检测nginx是否启动</span></span><br><span class="line">    interval 2                          <span class="comment">#（检测脚本执行的间隔）</span></span><br><span class="line">    weight 2                            <span class="comment">#权重</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#vrrp 实例定义部分</span></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP                        <span class="comment"># 指定keepalived的角色，MASTER为主，BACKUP为备</span></span><br><span class="line">    interface ens33                      <span class="comment"># 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡</span></span><br><span class="line">    virtual_router_id 66                <span class="comment"># 虚拟路由编号，主从要一直</span></span><br><span class="line">    priority 99                         <span class="comment"># 优先级，数值越大，获取处理请求的优先级越高</span></span><br><span class="line">    advert_int 1                        <span class="comment"># 检查间隔，默认为1s(vrrp组播周期秒数)</span></span><br><span class="line">    <span class="comment">#授权访问</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS <span class="comment">#设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信</span></span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        chk_http_port                   <span class="comment">#（调用检测脚本）</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.16.150                   <span class="comment"># 定义虚拟ip(VIP)，可多设，每行一个</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>③新建检测脚本(chmod 775 check_nginx.sh)：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#检测nginx是否启动了</span></span><br><span class="line">A=`ps -C nginx --no-header |wc -l`</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ];<span class="keyword">then</span>    <span class="comment">#如果nginx没有启动就启动nginx</span></span><br><span class="line">      systemctl start nginx                <span class="comment">#重启nginx</span></span><br><span class="line">      <span class="keyword">if</span> [ `ps -C nginx --no-header |wc -l` -eq 0 ];<span class="keyword">then</span>    <span class="comment">#nginx重启失败，则停掉keepalived服务，进行VIP转移</span></span><br><span class="line">              killall keepalived</span><br><span class="line">      <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p>④启动 Nginx 和 Keepalived（systemctl start keepalived.service）</p><p>⑤模拟 Nginx 故障（关闭主服务器 Nginx），验证，仍可以通过配置的虚拟 IP 访问，OK。</p><h1 id="Nginx-原理与优化参数配置"><a href="#Nginx-原理与优化参数配置" class="headerlink" title="Nginx 原理与优化参数配置"></a>Nginx 原理与优化参数配置</h1><p>Nginx 默认采用多进程工作方式，Nginx 启动后，会运行一个 Master 进程和多个 Worker 进程。</p><p>其中 Master 充当整个进程组与用户的交互接口，同时对进程进行监护，管理 Worker 进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。</p><p>Worker 用来处理基本的网络事件，Worker 之间是平等的，他们共同竞争来处理来自客户端的请求。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/8.png" alt="avatar"></p><p><strong>master-workers 的机制的好处：</strong></p><ul><li>可以使用 nginx-s reload 热部署。</li><li>每个 Worker 是独立的进程，不需要加锁，省掉了锁带来的开销。采用独立的进程，可以让互相之间不会影响，一个进程退出后，其他进程还在工作，服务不会中断，Master 进程则很快启动新的 Worker 进程。</li></ul><p><strong>需要设置多少个 Worker？</strong>Nginx 同 Redis 类似都采用了 IO 多路复用机制，每个 Worker 都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求，即使是成千上万个请求也不在话下。</p><p>每个 Worker 的线程可以把一个 CPU 的性能发挥到极致。所以 Worker 数和服务器的 CPU 数相等是最为适宜的。设少了会浪费 CPU，设多了会造成 CPU 频繁切换上下文带来的损耗。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#设置 worker 数量。</span></span><br><span class="line"> worker_processes 4</span><br><span class="line"><span class="comment">#work 绑定 cpu(4 work 绑定 4cpu)。</span></span><br><span class="line"> worker_cpu_affinity 0001 0010 0100 1000</span><br><span class="line"><span class="comment">#work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。</span></span><br><span class="line"> worker_cpu_affinity 0000001 00000010 00000100 00001000</span><br></pre></td></tr></table></figure><p><strong>连接数 worker_connection：</strong>这个值是表示每个 Worker 进程所能建立连接的最大值。</p><p>所以，一个 Nginx 能建立的最大连接数，应该是 worker_connections*worker_processes。</p><p>当然，这里说的是最大连接数，对于 HTTP 请 求 本 地 资 源 来 说 ， 能 够 支 持 的 最 大 并 发 数 量 是 worker_connections*worker_processes，如果是支持 http1.1 的浏览器每次访问要占两个连接。</p><p>所以普通的静态访问最大并发数是：worker_connections*worker_processes /2。</p><p>而如果是 HTTP 作为反向代理来说，最大并发数量应该是 worker_connections*worker_processes/4。</p><p>因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。</p><p><strong>Nginx 请求处理流程如下图：</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/9.png" alt="avatar"></p><h1 id="Nginx-模块开发"><a href="#Nginx-模块开发" class="headerlink" title="Nginx 模块开发"></a>Nginx 模块开发</h1><p>由于 Nginx 的模块化特性，所以可以支持模块配置，也可以自定义模块，Nginx 的模块开发，程序员目前还不需要太深入。</p><p>Nginx 模块分类如下图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/10.png" alt="avatar"></p><p><strong>Nginx配置选项，解压 Nginx 后的配置操作示例：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-pcre  --with-http_ssl_module</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/11.png" alt="avatar"></p><h1 id="Nginx-面试题"><a href="#Nginx-面试题" class="headerlink" title="Nginx 面试题"></a>Nginx 面试题</h1><p>①Nginx 功能，你们项目中用到的 Nginx？</p><ul><li><strong>反向代理服务器</strong></li><li><strong>实现负载均衡</strong></li><li><strong>做静态资源服务器</strong></li><li><strong>作为 HTTP Server</strong></li></ul><p>②Nginx 常用命令有哪些？</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">启动nginx    ./sbin/nginx</span><br><span class="line">停止nginx    ./sbin/nginx -s stop   ./sbin/nginx -s quit</span><br><span class="line">重载配置      ./sbin/nginx -s reload(平滑重启) service nginx reload</span><br><span class="line">重载指定配置文件    ./sbin/nginx -c  /usr/<span class="built_in">local</span>/nginx/conf/nginx.conf</span><br><span class="line">查看nginx版本  ./sbin/nginx -v</span><br><span class="line">检查配置文件是否正确  ./sbin/nginx -t</span><br><span class="line">显示帮助信息  ./sbin/nginx  -h</span><br></pre></td></tr></table></figure><p>③Nginx 常用配置？</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">worker_processes 4;   <span class="comment">#工作进程数</span></span><br><span class="line">work_connections 65535; <span class="comment">#每个进程的并发能力</span></span><br><span class="line">error_log  /data/nginx/logs/error.log;  <span class="comment">#错误日志</span></span><br></pre></td></tr></table></figure><p>④Nginx 是如何实现高并发的？</p><p>Nginx 采用的是多进程（单线程）&amp;多路 IO 复用模型，异步，非阻塞。</p><p>一个主进程 Master，多个工作进程 Worker，每个工作进程可以处理多个请求 ，Master 进程主要负责收集、分发请求。</p><p>每当一个请求过来时，Master 就拉起一个 Worker 进程负责处理这个请求。同时 Master 进程也负责监控 Woker 的状态，保证高可靠性。</p><p>在 Nginx 中的 Work 进程中，为了应对高并发场景，采取了 Reactor 模型（也就是 I/O 多路复用，NIO）。</p><p><strong>I/O 多路复用模型：</strong>在 I/O 多路复用模型中，最重要的系统调用函数就是 Select（其他的还有 epoll 等）。</p><p>该方法能够同时监控多个文件描述符的可读可写情况（每一个网络连接其实都对应一个文件描述符），当其中的某些文件描述符可读或者可写时，Select 方法就会返回可读以及可写的文件描述符个数。</p><p>Nginx Work 进程使用 I/O 多路复用模块同时监听多个 FD（文件描述符），当 Accept、Read、Write 和 Close 事件产生时，操作系统就会回调 FD 绑定的事件处理器。</p><p>这时候 Work 进程再去处理相应事件，而不是阻塞在某个请求连接上等待。</p><p>这样就可以实现一个进程同时处理多个连接。每一个 Worker 进程通过 I/O 多路复用处理多个连接请求。</p><p>为了减少进程切换（需要系统调用）的性能损耗，一般设置 Worker 进程数量和 CPU 数量一致。</p><p>⑤Nginx 和 Apache 的区别？</p><p>轻量级，同样起 Web 服务，比 Apache 占用更少的内存及资源抗并发，Nginx 处理请求是异步非阻塞的，而 Apache 则是阻塞型的。</p><p>在高并发下 Nginx 能保持低资源低消耗高性能高度模块化的设计，编写模块相对简单，最核心的区别在于 Apache 是同步多进程模型，一个连接对应一个进程；Nginx是异步的，多个连接（万级别）可以对应一个进程。</p><p>⑥Nginx 的 Upstream 支持的负载均衡方式？</p><ul><li><strong>轮询（默认）</strong></li><li><strong>weight：</strong>指定权重</li><li><strong>ip_hash：</strong>每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器</li><li><strong>第三方：</strong>fair、url_hash</li></ul><p>⑦Nginx 常见的优化配置有哪些?</p><ul><li><strong>调整 worker_processes：</strong>指 Nginx 要生成的 Worker 数量，最佳实践是每个 CPU 运行 1 个工作进程。</li><li><strong>最大化 worker_connections。</strong></li><li><strong>启用 Gzip 压缩：</strong>压缩文件大小，减少了客户端 HTTP 的传输带宽，因此提高了页面加载速度。</li><li><strong>为静态文件启用缓存。</strong></li><li><strong>禁用 access_logs：</strong>访问日志记录，它记录每个 Nginx 请求，因此消耗了大量 CPU 资源，从而降低了 Nginx 性能。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> GitLab 连接 K8S 集群 </title>
      <link href="/2019/12/16/2019-12-16-gitlab-k8s/"/>
      <url>/2019/12/16/2019-12-16-gitlab-k8s/</url>
      
        <content type="html"><![CDATA[<p>用 <code>GitLab</code> 连接 <code>Kubernetes</code> 需要明确以下几点内容：</p><ul><li>目标集群的 API 连接地址；</li><li>集群的 CA 证书；</li><li>基于RBAC 的特定 ServiceAccount 的 Token；</li><li>需要部署 pod 到哪个 NameSpace；</li></ul><p><strong>获取集群的 API 连接地址</strong></p><p>获取集群的 API 连接地址可以用如下命令查看：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl cluster-info</span><br><span class="line">Kubernetes master is running at https://59.110.217.141:6443</span><br><span class="line">metrics-server is running at https://59.110.217.141:6443/api/v1/namespaces/kube-system/services/heapster/proxy</span><br><span class="line">KubeDNS is running at https://59.110.217.141:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">命令输出内容可以很快知道集群的连接地址是：https://59.110.217.141:6443</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是，有时候集群的连接地址分为公网地址和内网地址，这个时候可以根据需求自己做取舍，轻课的 GitLab 和阿里云的 Kubernetes 集群没有打通，一般用的是公网地址</p></blockquote><p><strong>集群 CA 证书</strong></p><p>一般一个集群的 CA 证书是唯一的，所以只需弄一次即可，以后就可以重复利用。</p><p>比如说，我们要在某个集群中的 <code>gatlin</code> 命名空间中部署我们的微服务应用，我们需要创建一个 <code>ServiceAccount</code> 并绑定某个 <code>Role</code> 来获取该命名空间的特定权限。</p><p>一般情况下，在 <code>kubernetes</code> 集群中创建某个 <code>sa</code> 会对应生成该<code>sa</code> 的 <code>secret</code>，我们可以通过该 <code>secret</code> 的具体信息获取整个集群的 <code>CA</code> 证书和对应 <code>sa</code> 的 <code>token</code></p><p><strong>创建对应命名空间的 ServiceAccount</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl -n gatlin create sa gatlin-admin</span><br><span class="line">为了规范管理，以后所用 ns 的 sa 统一格式为 &lt;NS-NAME&gt;-admin</span><br></pre></td></tr></table></figure><p><strong>查看对应命名空间的 ServiceAccount</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl -n gatlin get serviceaccounts</span><br><span class="line">NAME                     SECRETS   AGE</span><br><span class="line">default                  1         20h</span><br><span class="line">gatlin-admin             1         103m</span><br></pre></td></tr></table></figure><p><strong>给新建的 SA 绑定 Role</strong></p><p>对于权限这块，我一般都是直接绑定名称为 admin 的集群角色，这样该 sa 就获得了该 ns 的管理员权限，而这个 sa 对其他 ns 是没有任何权限的，符合 ci 流程。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl -n gatlin create clusterrolebinding gatlin-ns-admin --clusterrole=admin --serviceaccount=gatlin:gatlin-admin</span><br></pre></td></tr></table></figure><p><strong>查看自动生成的 secret</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get secrets -n gatlin</span><br><span class="line">NAME                                 TYPE                                  DATA   AGE</span><br><span class="line">default-token-fgw4s                  kubernetes.io/service-account-token   3      20h</span><br><span class="line">gatlin-admin-token-78pqk             kubernetes.io/service-account-token   3      108m</span><br><span class="line">gatlin-service-account-token-nwhh2   kubernetes.io/service-account-token   3      88m</span><br><span class="line">gatlin-token                         kubernetes.io/service-account-token   3      88m</span><br><span class="line">然后用自动生成的 secret 查看集群 CA 证书就可以了：</span><br><span class="line">$ kubectl -n gatlin get secrets gatlin-admin-token-78pqk -o jsonpath=<span class="string">&quot;&#123;[&#x27;data&#x27;][&#x27;ca\.crt&#x27;]&#125;&quot;</span> | base64 -d</span><br><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">MIIDGjCCAgKgAwIBAgIBADANBgkqhkiG9w0BAQsFADA+MScwFAYDVQQKEw1hbGli</span><br><span class="line">YWJhIGNsb3VkMA8GA1UEChMIaGFuZ3pob3UxEzARBgNVBAMTCmt1YmVybmV0ZXMw</span><br><span class="line">HhcNMTkwNDIzMDkyMjI5WhcNMjkwNDIwMDkyMjI5WjA+MScwFAYDVQQKEw1hbGli</span><br><span class="line">YWJhIGNsb3VkMA8GA1UEChMIaGFuZ3pob3UxEzARBgNVBAMTCmt1YmVybmV0ZXMw</span><br><span class="line">ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCrNkXt3CB9HewGw6FLorrm</span><br><span class="line">rpYqLxsNhouv61d5nbyD1mxcIQAlK879yFmEfvs6Mo1kp0X/BalTBR6tLvXnQrv6</span><br><span class="line">t89n8sflmK5eaw4XVi+bpvVxyG2EyI0VBMzI77y5XYVkg0dD90lTfVyuLYx0h5e7</span><br><span class="line">g5/SQmXBvSFotN6+ci3eZDDHluOr72QPLnRukWZNfJfQa5njTb53AxyHEV/qk35N</span><br><span class="line">TfI7Er4GEAHniRjbg3zBHypIGc2XQlBROvON/CGehUI20agi+LZ6cNwDeYMQvbMa</span><br><span class="line">Vc3hMlQRrscfwKWwiHumdCv1B6ALoF6dtqJp3ry+MS4VTnMc5ZdCsBRa64aaA61/</span><br><span class="line">AgMBAAGjIzAhMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTADAQH/MA0GCSqG</span><br><span class="line">SIb3DQEBCwUAA4IBAQAetfaOvLN7eklSZRnWBOqZN30ohgN9na/q+vsdtrFSqpRi</span><br><span class="line">qeWCE0IIb0G8188J8ITLczgT3h3BrMOvh3KTrIre1+P6zH2bRdfhFD4upbYQRIpL</span><br><span class="line">WYaEPxsEihjQFGhpOrvgJVdYpMC1/m09Ili9C82f1hZQp1S0+a0lvRXfR/ox76mv</span><br><span class="line">Z2CKoXcP7n2uoh4cVbta8B1r4RSLwdBybWNAkD6NMPZ53LphRLdNaN1KvQJmAkOG</span><br><span class="line">X7MiAZeupX+jz0mW+m+cWN0ftiUAuqsaPAfMOg6JgxHpM44WU+wu2aduFxKXzzud</span><br><span class="line">Xns1hh44sDQ5vg5JhNd/06tyy2NiaqZRDRJ+ie1ewrwerjewrewj</span><br><span class="line">-----END CERTIFICATE-----</span><br></pre></td></tr></table></figure><p>然后就可以看到神奇的 CA 证书了，哈哈。</p><p><strong>获取特定 ServiceAccount 的 Token</strong></p><p>获取 token 的时候直接用上面的 secret 即可：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl -n gatlin get secrets gatlin-admin-token-78pqk -o jsonpath=&#123;.data.token&#125; | base64 -d</span><br></pre></td></tr></table></figure><p>记得将上述命令输出的 token 保存一下就可以，因为 token 太长而且没有自动换行，这里就不贴了。</p><p><strong>配置 GitLab</strong></p><p>上面的工作做完了，配置 GitLab 连接 Kubernetes 集群就简单多了，『运维』–『Kubernetes』–『Add existing cluster』,然后直接把上述信息复制粘贴到对应框框里就行了</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-16/gitlab-k8s.png" alt="avatar"></p><p><em><strong>需要注意的是每个命名空间对应的 token 都不一样，不要盲目复制粘贴，还有就是如果配置错误需要将添加的集群删掉重建，有时候可能因为缓存的问题导致连接集群失败，这是重点，切记！！！</strong></em></p>]]></content>
      
      
      
        <tags>
            
            <tag> Gitlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 执行力，才是拉开人与人差距的关键 </title>
      <link href="/2019/12/14/2019-12-14-execution/"/>
      <url>/2019/12/14/2019-12-14-execution/</url>
      
        <content type="html"><![CDATA[<h1 id="01-如果你想变得更好-首先要学会执行"><a href="#01-如果你想变得更好-首先要学会执行" class="headerlink" title="01 如果你想变得更好 首先要学会执行"></a>01 如果你想变得更好 首先要学会执行</h1><p>我们常常慨叹，为什么都是吃五谷杂粮长大的，人与人之间的差距怎么就那么大呢？</p><p>为什么毕业于同一个学校的人，几年后的差距也会变得那么大呢？</p><p>这其中有一个很重要的因素——<strong>执行力。</strong></p><p>那些能够超越同龄人的人，往往都有这样一个优点，他们除了有远见外，还特别肯吃苦，他们的勤奋和执行力往往能甩出同龄人几条街。</p><p>缺乏执行力，人就会焦虑、迷茫。</p><p>执行力是改变人生最直接有效的方法，没有之一。</p><p>当我们哀叹老板一直没有给自己涨工资，现在的工作不适合自己发展时，我们付出了多少行动？</p><p>一个人在舒适的环境待久了，无论他多么想改变，如果他不去执行，最终都很难取得大的成就。</p><p>马云有一句非常经典的名言：</p><p><strong>“晚上想想千条路，早上起来走原路。****”</strong></p><p><strong>说的就是一群人不去执行，只是空想，最终就只能是黄粱一梦。</strong></p><p>所以，想要变得更好，首先，你要学会去执行。</p><p>写出文章最好的办法，不是搜集资料，而是马上在键盘上敲下第一个字。提升演讲能力，突破演讲恐惧，最好的办法是，先冲上台再说。</p><p>等待、默默发力不是最好的准备，只有跨出第一步才叫执行。</p><p>我们常常看到很多曾经淡出人们视野的明星在某段时间后又重新成为人们谈论的话题，人们慨叹他们在年华逝去后还能保持美好的容颜，匀称的身材，仿佛岁月这把杀猪刀已经将他们遗忘。</p><p>其实，岁月并没有饶过谁，只是他们出色的自律力和执行力，让他们能够坚持自我锻炼，将自己塑造成了人们期待的样子。</p><h1 id="02-如何提升执行力？"><a href="#02-如何提升执行力？" class="headerlink" title="02  如何提升执行力？"></a>02  如何提升执行力？</h1><p>有人会说，如何才能练就这样的执行力呢？</p><p>最好的执行者从来都是自己主动去做，不是被动等待别人安排工作，自己才去做的人，而是能根据需求，主动去找事情做的人。</p><p>我们来看看香港的“珠宝大王”郑裕彤是怎么做的。</p><p>郑裕彤出身贫寒，为了养家糊口，小学毕业后，郑裕彤便到父亲的朋友周至元所开的“周大福金铺”去当学徒。</p><p>尽管做的是最底层的工作，但他丝毫不懈怠，每天都早早的赶到金铺，将金铺收拾打扫得干干净净。</p><p>往往是等他收拾完了之后，大伙计们才姗姗来迟。</p><p>店里的伙计，大多只知道埋头做本分事，而郑裕彤，除了做好本分事外，还特别爱动脑筋，经常琢磨和研究怎样做才能更有利于金铺的发展。</p><p>一天，老板让他到码头接一位亲戚。这时他看到有一位南洋侨商上了码头，并向人打听哪里可以兑换港币。</p><p>郑裕彤灵机一动，立即走上前去，说周大福金铺可以兑换，价格也最公道，并立即带路，将这位侨商带进了周大福，之后又马不停蹄地赶回码头接那位亲戚。</p><p>郑裕彤的这一做法，让周老板大为赞赏。</p><p>还有一次，伙计们开工好一会儿了，郑裕彤才气喘吁吁地跑进来。老板很生气，问他到哪里去了。</p><p>郑裕彤回答说，自己看别人家珠宝行做生意去了。</p><p>老板不禁有些好奇，于是问他看出了什么名堂没有。</p><p>“我看别家的生意，比我们店里做得精明，只要客人一踏进店门，店里老板、伙计总是笑脸相迎，有问必答；无论生意大小，一视同仁。</p><p>即使这回生意做不成，给人家留下一个好印象，下回他们自然还会光顾！”</p><p>“另外，店铺一定要开在做生意的旺地，门面装修也要讲究，特别是做珠宝生意，一定要显得十分气派。”</p><p><strong>郑裕彤的回答让老板不禁对这个小伙计有些刮目相看，他没想到这些经商诀窍能够从这个小学徒的口中总结出来。</strong></p><p>自那以后，老板开始有意识地培养他，还将女儿嫁给了他。</p><p>后来，他成为香港金行龙头老大“周大福”的掌门人。在郑裕彤的经营下，“周大福”已经成为了珠宝行和金铺的代名词。</p><p>假如郑裕彤面对那位兑换港元的南洋侨商，是这么想的：</p><p>“金铺又没多给我工钱，我主动去管什么闲事，多一事不如少一事。”</p><p>假如他不主动去琢磨怎么做生意，而是想：</p><p>“我一个小伙计，就算操这份心又有什么用？”</p><p>那么，结果又会怎样呢？</p><p><strong>一流的执行者，他首先会觉得那些问题就是自己的问题，要主动地创造性地去解决；</strong></p><p><strong>他会觉得好机会是单位的机会，也是自己的机会。</strong></p><p>无论这件事情与自己有没有直接关系，也无论自己的职位多么普通，他们都会当仁不让地去做。</p><p>而机会，往往就会因此而产生。</p><h1 id="03-执行力-拉开人与人差距的关键"><a href="#03-执行力-拉开人与人差距的关键" class="headerlink" title="03  执行力   拉开人与人差距的关键"></a>03  执行力   拉开人与人差距的关键</h1><p>皇明太阳能集团创始人、总裁黄鸣，就是一个非常典型的拥有超强执行力的人。</p><p>黄鸣大学毕业后被分到了石油钻井技术研究所，在技术装备室工作。工作两年后，地矿部有一个斥资几十亿元的“七五”大型设备改造项目，即为了提升钻井勘探的技术水平而要把所有的钻机都改造一遍。</p><p>当时部里把这个课题交给了比黄鸣所在装备室的级别和规模更高一级的装备研究所，为此还专门召开了钻机改造方案的评审会，黄鸣当时抱着学习的心态参加了评审会。</p><p>当时有几位年龄比较大的高工（高级工程师）在会上介绍方案，黄鸣听得非常仔细。</p><p>但听着听着，他觉得方案有问题。</p><p><strong>一是方案中有很多理论依据、设计计算跟大学的专业教科书和他所看到的国内外相关文献不符；</strong></p><p><strong>二是实施方案缺乏可操作性，设备改造方案与现场情况有很多不符之处。</strong></p><p>在大学期间，黄鸣的专业课程学得非常深入，每门都是优，实习期间，他又把整个井架、钻台、动力系统等摸得一清二楚，写了厚厚的实习报告，工作两年，他特别关注专业动态，写过几篇专业的文章，发表后引起了很大的关注。</p><p>正因为有对专业技术的深度把握，黄鸣快速捕捉到了方案的不足。</p><p>于是，他把自己认为不妥的地方逐条记下来，共列出了二十几条。等几位高工讲完方案让大家提意见的时候，黄鸣鼓起勇气一下讲了十几条。</p><p>讲的时候一气呵成，但讲完之后，他开始忐忑不安起来，毕竟在座的都是专家、司长、总工，自己不知深浅地提建议，会不会让别人感觉这个初出茅庐的小伙子太不知天高地厚了？</p><p>当天晚上，领导就把他叫到了办公室。当时他忐忑不安的心情可想而知。然而，让他没有想到的是，领导告诉他，听了他的意见之后，大家都很重视，为此特意开会进行讨论，认为他提的很多建议很重要，数据也很翔实，说明现在方案不成熟，存在漏洞，需要调整。</p><p>经过慎重考虑，领导决定把设备改造项目的任务分一半给他们科室，由他牵头，与另一科室共同完成，并正式通知他加入“七五”设备领导改造五人小组。</p><p>就这样，刚刚毕业两年的黄鸣获得了这个很多人想都不敢想的机会，他不负重托，带领课题小组顺利完成了任务，并获得了部里的科技进步二等奖。</p><p>从此，他不断承揽科研课题，年纪轻轻就当上了科研室副主任，成为所里的科研主力。这也为他以后的创业打下了坚实的基础。</p><p>黄鸣的做法，正是让执行力与创新力结合的典范。他的过人之处表现在以下两点：</p><p><strong>第一，不迷信权威，即使是众多专家的方案，如果有漏洞，他也敢于大胆说出自己的想法。</strong></p><p><strong>第二，虽然项目和自己无关，但还是主动去想创新的方案。</strong></p><p>工作中，很多人就像机器人一样，执行中很死板，被动地遵守常规。</p><p>其实，最好的执行者往往能够主动打破条条框框，并把创新力落实到执行中，主动为单位做出贡献。</p><p>只要你时刻围绕“如何将工作做得更好”去思考和琢磨，即使在平凡的岗位上，你也能做出有价值的创新。</p><p>这正是在更高的层面上去完善执行力。</p><p>所以，决定人生高度的，从来不是你的高谈阔论，而是你说做就做的执行力，没有执行力一切都是零。</p><p>执行力的不同，人与人的差距自然就拉开了，从开始的一点点到最后的相差甚远，最后会让你悔不当初。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 执行力 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title> 一行 Python 代码能实现这么多丧心病狂的功能？</title>
      <link href="/2019/12/13/2019-12-13-one-line-of-python-code/"/>
      <url>/2019/12/13/2019-12-13-one-line-of-python-code/</url>
      
        <content type="html"><![CDATA[<h1 id="一行代码打印乘法口诀"><a href="#一行代码打印乘法口诀" class="headerlink" title="一行代码打印乘法口诀"></a>一行代码打印乘法口诀</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>.join([<span class="string">&#x27; &#x27;</span>.join([<span class="string">&quot;%2s x%2s = %2s&quot;</span>%(j,i,i*j) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,i+<span class="number">1</span>)]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>)]))</span><br></pre></td></tr></table></figure><h1 id="一行代码打印迷宫"><a href="#一行代码打印迷宫" class="headerlink" title="一行代码打印迷宫"></a>一行代码打印迷宫</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(<span class="built_in">__import__</span>(<span class="string">&#x27;random&#x27;</span>).choice(<span class="string">&#x27;\u2571\u2572&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>*<span class="number">24</span>)))</span><br></pre></td></tr></table></figure><h1 id="一行代码表白爱情"><a href="#一行代码表白爱情" class="headerlink" title="一行代码表白爱情"></a>一行代码表白爱情</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>.join([<span class="string">&#x27;&#x27;</span>.join([(<span class="string">&#x27;Love&#x27;</span>[(x-y) % <span class="built_in">len</span>(<span class="string">&#x27;Love&#x27;</span>)] <span class="keyword">if</span> ((x*<span class="number">0.05</span>)**<span class="number">2</span>+(y*<span class="number">0.1</span>)**<span class="number">2</span>-<span class="number">1</span>)**<span class="number">3</span>-(x*<span class="number">0.05</span>)**<span class="number">2</span>*(y*<span class="number">0.1</span>)**<span class="number">3</span> &lt;= 0<span class="keyword">else</span><span class="string">&#x27; &#x27;</span>) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">30</span>, <span class="number">30</span>)]) <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>, -<span class="number">30</span>, -<span class="number">1</span>)]))！</span><br></pre></td></tr></table></figure><h1 id="一行代码打印小龟龟"><a href="#一行代码打印小龟龟" class="headerlink" title="一行代码打印小龟龟"></a>一行代码打印小龟龟</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>.join([<span class="string">&#x27;&#x27;</span>.join([<span class="string">&#x27;*&#x27;</span> <span class="keyword">if</span> <span class="built_in">abs</span>((<span class="keyword">lambda</span> a:<span class="keyword">lambda</span> z,c,n:a(a,z,c,n))(<span class="keyword">lambda</span> s,z,c,n:z <span class="keyword">if</span> n==<span class="number">0</span> <span class="keyword">else</span> s(s,z*z+c,c,n-<span class="number">1</span>))(<span class="number">0</span>,<span class="number">0.02</span>*x+<span class="number">0.05j</span>*y,<span class="number">40</span>))&lt;<span class="number">2</span> <span class="keyword">else</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">80</span>,<span class="number">20</span>)]) <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">20</span>,<span class="number">20</span>)]))</span><br></pre></td></tr></table></figure><h1 id="一行代码实现-1-100-的和"><a href="#一行代码实现-1-100-的和" class="headerlink" title="一行代码实现 1 - 100 的和"></a>一行代码实现 1 - 100 的和</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sum</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">101</span>))</span><br></pre></td></tr></table></figure><h1 id="一行代码实现数值交换"><a href="#一行代码实现数值交换" class="headerlink" title="一行代码实现数值交换"></a>一行代码实现数值交换</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line">a,b = b,a</span><br><span class="line"><span class="built_in">print</span>(a,b)</span><br></pre></td></tr></table></figure><h1 id="一行代码求奇偶数"><a href="#一行代码求奇偶数" class="headerlink" title="一行代码求奇偶数"></a>一行代码求奇偶数</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[x <span class="keyword">for</span>  x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">1</span>]</span><br></pre></td></tr></table></figure><h1 id="一行代码展开列表"><a href="#一行代码展开列表" class="headerlink" title="一行代码展开列表"></a>一行代码展开列表</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">list</span> = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]]</span><br><span class="line">[j <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">list</span> <span class="keyword">for</span> j <span class="keyword">in</span> i]</span><br></pre></td></tr></table></figure><h1 id="一行代码打乱列表"><a href="#一行代码打乱列表" class="headerlink" title="一行代码打乱列表"></a>一行代码打乱列表</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">lst = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">random.shuffle(lst)</span><br><span class="line">lst</span><br></pre></td></tr></table></figure><h1 id="一行代码反转字符串"><a href="#一行代码反转字符串" class="headerlink" title="一行代码反转字符串"></a>一行代码反转字符串</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">name = <span class="string">&#x27;byf4963cg&#x27;</span></span><br><span class="line">name = [::-<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h1 id="一行代码查看目录下所有文件"><a href="#一行代码查看目录下所有文件" class="headerlink" title="一行代码查看目录下所有文件"></a>一行代码查看目录下所有文件</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.listdir(<span class="string">&#x27;.&#x27;</span>)</span><br></pre></td></tr></table></figure><h1 id="一行代码去除字符串间的空格"><a href="#一行代码去除字符串间的空格" class="headerlink" title="一行代码去除字符串间的空格"></a>一行代码去除字符串间的空格</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">des = <span class="string">&#x27;My name is master123&#x27;</span></span><br><span class="line">des.replace(<span class="string">&quot;&quot;</span>,<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">des = <span class="string">&#x27;My name is master123&#x27;</span></span><br><span class="line"><span class="string">&quot;&quot;</span>.join(des.split(<span class="string">&quot; &quot;</span>))</span><br></pre></td></tr></table></figure><h1 id="一行代码实现字符串整数列表变成整数列表"><a href="#一行代码实现字符串整数列表变成整数列表" class="headerlink" title="一行代码实现字符串整数列表变成整数列表"></a>一行代码实现字符串整数列表变成整数列表</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="string">&#x27;5&#x27;</span>]</span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> a : <span class="built_in">int</span> (a),[<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>,<span class="string">&#x27;5&#x27;</span>]))</span><br></pre></td></tr></table></figure><h1 id="一行代码删除列表中重复的值"><a href="#一行代码删除列表中重复的值" class="headerlink" title="一行代码删除列表中重复的值"></a>一行代码删除列表中重复的值</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lst = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">5</span>]</span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">set</span>(lst))</span><br></pre></td></tr></table></figure><h1 id="一行代码找出两个列表中相同的元素"><a href="#一行代码找出两个列表中相同的元素" class="headerlink" title="一行代码找出两个列表中相同的元素"></a>一行代码找出两个列表中相同的元素</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>]</span><br><span class="line">b = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>]</span><br><span class="line"><span class="built_in">set</span>(a) &amp; <span class="built_in">set</span>(b)</span><br></pre></td></tr></table></figure><h1 id="一行代码找出两个列表中不同的元素"><a href="#一行代码找出两个列表中不同的元素" class="headerlink" title="一行代码找出两个列表中不同的元素"></a>一行代码找出两个列表中不同的元素</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>]</span><br><span class="line">b = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>]</span><br><span class="line"><span class="built_in">set</span>(a) ^ <span class="built_in">set</span>(b)</span><br></pre></td></tr></table></figure><h1 id="一行代码合并两个字典"><a href="#一行代码合并两个字典" class="headerlink" title="一行代码合并两个字典"></a>一行代码合并两个字典</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">des = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;john&#x27;</span>&#125;</span><br><span class="line">age = &#123;<span class="string">&#x27;age&#x27;</span>: <span class="string">&#x27;25&#x27;</span>&#125;</span><br><span class="line">des.update(age)</span><br><span class="line">des</span><br></pre></td></tr></table></figure><h1 id="一行代码实现字典键从小到大排序"><a href="#一行代码实现字典键从小到大排序" class="headerlink" title="一行代码实现字典键从小到大排序"></a>一行代码实现字典键从小到大排序</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">des = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;john&#x27;</span>,<span class="string">&#x27;age&#x27;</span>: <span class="string">&#x27;25&#x27;</span>,<span class="string">&#x27;like&#x27;</span>: <span class="string">&#x27;python&#x27;</span>&#125;</span><br><span class="line"><span class="built_in">sorted</span>(des.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx 配置参数中文说明 </title>
      <link href="/2019/12/12/2019-12-12-nginx-chinese/"/>
      <url>/2019/12/12/2019-12-12-nginx-chinese/</url>
      
        <content type="html"><![CDATA[<h1 id="Nginx-配置参数中文详细说明："><a href="#Nginx-配置参数中文详细说明：" class="headerlink" title="Nginx 配置参数中文详细说明："></a>Nginx 配置参数中文详细说明：</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#定义Nginx运行的用户和用户组</span></span><br><span class="line">user www www;</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#nginx进程数,建议设置为等于CPU总核心数.</span></span><br><span class="line">worker_processes 8;</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#全局错误日志定义类型,[ debug | info | notice | warn | error | crit ]</span></span><br><span class="line">error_log /var/<span class="built_in">log</span>/nginx/error.log info;</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#进程文件</span></span><br><span class="line">pid /var/run/nginx.pid;</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#一个nginx进程打开的最多文件描述符数目,理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除,但是nginx分配请求并不均匀,所以建议与ulimit -n的值保持一致.</span></span><br><span class="line">worker_rlimit_nofile 65535;</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#工作模式与连接数上限</span></span><br><span class="line">events</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">#参考事件模型,use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型,如果跑在FreeBSD上面,就用kqueue模型.</span></span><br><span class="line">    use epoll;</span><br><span class="line">    <span class="comment">#单个进程最大连接数（最大连接数=连接数*进程数）</span></span><br><span class="line">    worker_connections 65535;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#设定http服务器</span></span><br><span class="line">http</span><br><span class="line">&#123;</span><br><span class="line">    include mime.types; <span class="comment">#文件扩展名与文件类型映射表</span></span><br><span class="line">    default_type application/octet-stream; <span class="comment">#默认文件类型</span></span><br><span class="line">    <span class="comment">#charset utf-8; #默认编码</span></span><br><span class="line">    server_names_hash_bucket_size 128; <span class="comment">#服务器名字的hash表大小</span></span><br><span class="line">    client_header_buffer_size 32k; <span class="comment">#上传文件大小限制</span></span><br><span class="line">    large_client_header_buffers 4 64k; <span class="comment">#设定请求缓</span></span><br><span class="line">    client_max_body_size 8m; <span class="comment">#设定请求缓</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开启目录列表访问,合适下载服务器,默认关闭.</span></span><br><span class="line">    autoindex on; <span class="comment"># 显示目录</span></span><br><span class="line">    autoindex_exact_size on; <span class="comment"># 显示文件大小 默认为on,显示出文件的确切大小,单位是bytes 改为off后,显示出文件的大概大小,单位是kB或者MB或者GB</span></span><br><span class="line">    autoindex_localtime on; <span class="comment"># 显示文件时间 默认为off,显示的文件时间为GMT时间 改为on后,显示的文件时间为文件的服务器时间</span></span><br><span class="line"></span><br><span class="line">    sendfile on; <span class="comment"># 开启高效文件传输模式,sendfile指令指定nginx是否调用sendfile函数来输出文件,对于普通应用设为 on,如果用来进行下载等应用磁盘IO重负载应用,可设置为off,以平衡磁盘与网络I/O处理速度,降低系统的负载.注意：如果图片显示不正常把这个改成off.</span></span><br><span class="line">    tcp_nopush on; <span class="comment"># 防止网络阻塞</span></span><br><span class="line">    tcp_nodelay on; <span class="comment"># 防止网络阻塞</span></span><br><span class="line"></span><br><span class="line">    keepalive_timeout 120; <span class="comment"># (单位s)设置客户端连接保持活动的超时时间,在超过这个时间后服务器会关闭该链接</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># FastCGI相关参数是为了改善网站的性能：减少资源占用,提高访问速度.下面参数看字面意思都能理解.</span></span><br><span class="line">    fastcgi_connect_timeout 300;</span><br><span class="line">    fastcgi_send_timeout 300;</span><br><span class="line">    fastcgi_read_timeout 300;</span><br><span class="line">    fastcgi_buffer_size 64k;</span><br><span class="line">    fastcgi_buffers 4 64k;</span><br><span class="line">    fastcgi_busy_buffers_size 128k;</span><br><span class="line">    fastcgi_temp_file_write_size 128k;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gzip模块设置</span></span><br><span class="line">    gzip on; <span class="comment">#开启gzip压缩输出</span></span><br><span class="line">    gzip_min_length 1k; <span class="comment">#允许压缩的页面的最小字节数,页面字节数从header偷得content-length中获取.默认是0,不管页面多大都进行压缩.建议设置成大于1k的字节数,小于1k可能会越压越大</span></span><br><span class="line">    gzip_buffers 4 16k; <span class="comment">#表示申请4个单位为16k的内存作为压缩结果流缓存,默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果</span></span><br><span class="line">    gzip_http_version 1.1; <span class="comment">#压缩版本（默认1.1,目前大部分浏览器已经支持gzip解压.前端如果是squid2.5请使用1.0）</span></span><br><span class="line">    gzip_comp_level 2; <span class="comment">#压缩等级.1压缩比最小,处理速度快.9压缩比最大,比较消耗cpu资源,处理速度最慢,但是因为压缩比最大,所以包最小,传输速度快</span></span><br><span class="line">    gzip_types text/plain application/x-javascript text/css application/xml;</span><br><span class="line">    <span class="comment">#压缩类型,默认就已经包含text/html,所以下面就不用再写了,写上去也不会有问题,但是会有一个warn.</span></span><br><span class="line">    gzip_vary on;<span class="comment">#选项可以让前端的缓存服务器缓存经过gzip压缩的页面.例如:用squid缓存经过nginx压缩的数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#开启限制IP连接数的时候需要使用</span></span><br><span class="line">    <span class="comment">#limit_zone crawler $binary_remote_addr 10m;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">##upstream的负载均衡,四种调度算法(下例主讲)##</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#虚拟主机的配置</span></span><br><span class="line">    server</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment"># 监听端口</span></span><br><span class="line">        listen 80;</span><br><span class="line">        <span class="comment"># 域名可以有多个,用空格隔开</span></span><br><span class="line">        server_name ably.com;</span><br><span class="line">        <span class="comment"># HTTP 自动跳转 HTTPS</span></span><br><span class="line">        rewrite ^(.*) https://$server_name<span class="variable">$1</span> permanent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment"># 监听端口 HTTPS</span></span><br><span class="line">        listen 443 ssl;</span><br><span class="line">        server_name ably.com;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置域名证书</span></span><br><span class="line">        ssl_certificate      C:\WebServer\Certs\certificate.crt;</span><br><span class="line">        ssl_certificate_key  C:\WebServer\Certs\private.key;</span><br><span class="line">        ssl_session_cache    shared:SSL:1m;</span><br><span class="line">        ssl_session_timeout  5m;</span><br><span class="line">        ssl_protocols SSLv2 SSLv3 TLSv1;</span><br><span class="line">        ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;</span><br><span class="line">        ssl_prefer_server_ciphers  on;</span><br><span class="line"></span><br><span class="line">        index index.html index.htm index.php;</span><br><span class="line">        root /data/www/;</span><br><span class="line">        location ~ .*\.(php|php5)?$</span><br><span class="line">        &#123;</span><br><span class="line">            fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">            fastcgi_index index.php;</span><br><span class="line">            include fastcgi.conf;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置地址拦截转发，解决跨域验证问题</span></span><br><span class="line">        location /oauth/&#123;</span><br><span class="line">            proxy_pass https://localhost:13580/oauth/;</span><br><span class="line">            proxy_set_header HOST <span class="variable">$host</span>;</span><br><span class="line">            proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">            proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 图片缓存时间设置</span></span><br><span class="line">        location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ &#123;</span><br><span class="line">            expires 10d;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># JS和CSS缓存时间设置</span></span><br><span class="line">        location ~ .*\.(js|css)?$ &#123;</span><br><span class="line">            expires 1h;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 日志格式设定</span></span><br><span class="line">        log_format access <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">        <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">        <span class="string">&#x27;&quot;$http_user_agent&quot; $http_x_forwarded_for&#x27;</span>;</span><br><span class="line">        <span class="comment"># 定义本虚拟主机的访问日志</span></span><br><span class="line">        access_log /var/<span class="built_in">log</span>/nginx/access.log access;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设定查看Nginx状态的地址.StubStatus模块能够获取Nginx自上次启动以来的工作状态，此模块非核心模块，需要在Nginx编译安装时手工指定才能使用</span></span><br><span class="line">        location /NginxStatus &#123;</span><br><span class="line">            stub_status on;</span><br><span class="line">            access_log on;</span><br><span class="line">            auth_basic <span class="string">&quot;NginxStatus&quot;</span>;</span><br><span class="line">            auth_basic_user_file conf/htpasswd;</span><br><span class="line">            <span class="comment">#htpasswd文件的内容可以用apache提供的htpasswd工具来产生.</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Nginx负载均衡服务器的nginx-conf配置注释"><a href="#Nginx负载均衡服务器的nginx-conf配置注释" class="headerlink" title="Nginx负载均衡服务器的nginx.conf配置注释"></a>Nginx负载均衡服务器的<code>nginx.conf</code>配置注释</h1><p><strong>如下：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">events</span><br><span class="line">&#123;</span><br><span class="line">    use epoll;</span><br><span class="line">    worker_connections 65535;</span><br><span class="line">&#125;</span><br><span class="line">http</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">##upstream的负载均衡,四种调度算法##</span></span><br><span class="line">    <span class="comment">#调度算法1:轮询.每个请求按时间顺序逐一分配到不同的后端服务器,如果后端某台服务器宕机,故障系统被自动剔除,使用户访问不受影响</span></span><br><span class="line">    upstream webhost &#123;</span><br><span class="line">        server 192.168.0.5:6666 ;</span><br><span class="line">        server 192.168.0.7:6666 ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#调度算法2:weight(权重).可以根据机器配置定义权重.权重越高被分配到的几率越大</span></span><br><span class="line">    upstream webhost &#123;</span><br><span class="line">        server 192.168.0.5:6666 weight=2;</span><br><span class="line">        server 192.168.0.7:6666 weight=3;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#调度算法3:ip_hash. 每个请求按访问IP的hash结果分配,这样来自同一个IP的访客固定访问一个后端服务器,有效解决了动态网页存在的session共享问题</span></span><br><span class="line">    upstream webhost &#123;</span><br><span class="line">        ip_hash;</span><br><span class="line">        server 192.168.0.5:6666 ;</span><br><span class="line">        server 192.168.0.7:6666 ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#调度算法4:url_hash(需安装第三方插件).此方法按访问url的hash结果来分配请求,使每个url定向到同一个后端服务器,可以进一步提高后端缓存服务器的效率.Nginx本身是不支持url_hash的,如果需要使用这种调度算法,必须安装Nginx 的hash软件包</span></span><br><span class="line">    upstream webhost &#123;</span><br><span class="line">        server 192.168.0.5:6666 ;</span><br><span class="line">        server 192.168.0.7:6666 ;</span><br><span class="line">        <span class="built_in">hash</span> <span class="variable">$request_uri</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">#调度算法5:fair(需安装第三方插件).这是比上面两个更加智能的负载均衡算法.此种算法可以依据页面大小和加载时间长短智能地进行负载均衡,也就是根据后端服务器的响应时间来分配请求,响应时间短的优先分配.Nginx本身是不支持fair的,如果需要使用这种调度算法,必须下载Nginx的upstream_fair模块</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#虚拟主机的配置(采用调度算法3:ip_hash)</span></span><br><span class="line">    server</span><br><span class="line">    &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name mongo.demo.com;</span><br><span class="line">        <span class="comment">#对 &quot;/&quot; 启用反向代理</span></span><br><span class="line">        location / &#123;</span><br><span class="line">            proxy_pass http://webhost;</span><br><span class="line">            proxy_redirect off;</span><br><span class="line">            proxy_set_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">            <span class="comment">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span></span><br><span class="line">            proxy_set_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">            <span class="comment">#以下是一些反向代理的配置,可选.</span></span><br><span class="line">            proxy_set_header Host <span class="variable">$host</span>;</span><br><span class="line">            client_max_body_size 10m; <span class="comment">#允许客户端请求的最大单文件字节数</span></span><br><span class="line">            client_body_buffer_size 128k; <span class="comment">#缓冲区代理缓冲用户端请求的最大字节数,</span></span><br><span class="line">            proxy_connect_timeout 90; <span class="comment">#nginx跟后端服务器连接超时时间(代理连接超时)</span></span><br><span class="line">            proxy_send_timeout 90; <span class="comment">#后端服务器数据回传时间(代理发送超时)</span></span><br><span class="line">            proxy_read_timeout 90; <span class="comment">#连接成功后,后端服务器响应时间(代理接收超时)</span></span><br><span class="line">            proxy_buffer_size 4k; <span class="comment">#设置代理服务器（nginx）保存用户头信息的缓冲区大小</span></span><br><span class="line">            proxy_buffers 4 32k; <span class="comment">#proxy_buffers缓冲区,网页平均在32k以下的设置</span></span><br><span class="line">            proxy_busy_buffers_size 64k; <span class="comment">#高负荷下缓冲大小（proxy_buffers*2）</span></span><br><span class="line">            proxy_temp_file_write_size 64k;</span><br><span class="line">            <span class="comment">#设定缓存文件夹大小,大于这个值,将从upstream服务器传</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>参考链接：<a href="https://mp.weixin.qq.com/s/T0uXiWtvE9tYijVlEsCKLw">https://mp.weixin.qq.com/s/T0uXiWtvE9tYijVlEsCKLw</a></p><p>​                  <a href="http://www.cnblogs.com/xcloudbiz/articles/5234373.html">http://www.cnblogs.com/xcloudbiz/articles/5234373.html</a></p><p>​                  <a href="http://wangying.sinaapp.com/archives/931">http://wangying.sinaapp.com/archives/931</a></p><p>​                  <a href="http://www.php100.com/html/program/nginx/2013/0905/5525.html">http://www.php100.com/html/program/nginx/2013/0905/5525.html</a></p><p>​                  <a href="https://hub.docker.com/_/nginx/">https://hub.docker.com/_/nginx/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>