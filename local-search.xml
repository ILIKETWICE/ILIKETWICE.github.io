<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title> DNS基础知识 </title>
    <link href="/2021/06/01/2021-06-01-dns-basic-knowledge/"/>
    <url>/2021/06/01/2021-06-01-dns-basic-knowledge/</url>
    
    <content type="html"><![CDATA[<div class="note note-success">            <p>文章转载</p><p>作者：多米诺<br>链接：<a href="https://juejin.cn/post/6844903497494855687" target="_blank" rel="noopener">https://juejin.cn/post/6844903497494855687</a></p>          </div><h2 id="DNS-基础知识"><a href="#DNS-基础知识" class="headerlink" title="DNS 基础知识"></a>DNS 基础知识</h2><p>DNS（Domain Name System）， 也叫网域名称系统，是互联网的一项服务。它实质上是一个 域名 和 IP 相互映射的分布式数据库，有了它，我们就可以通过域名更方便的访问互联网。</p><p>DNS 有以下特点：</p><ul><li>分布式的</li><li>协议支持 TCP 和 UDP，常用端口是 53</li><li>每一级域名的长度限制是 63</li><li>域名总长度限制是 253</li></ul><p><strong>那么，什么情况下使用 TCP，什么情况下使用 UDP 呢?</strong></p><p>最早的时候，DNS 的 UDP 报文上限大小是 512 字节， 所以当某个 response 大小超过512 (返回信息太多)，DNS 服务就会使用 TCP 协议来传输。后来 DNS 协议扩展了自己的UDP 协议，DNS client 发出查询请求时，可以指定自己能接收超过512字节的 UDP 包， 这种情况下，DNS 还是会使用 UDP 协议。</p><h3 id="分层的数据库结构"><a href="#分层的数据库结构" class="headerlink" title="分层的数据库结构"></a>分层的数据库结构</h3><p>DNS 的结构跟 Linux 文件系统很相似，像一棵倒立的树。下面用站长之家的域名举例：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/1.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>最上面的.是根域名，接着是顶级域名com，再下来是站长之家域名 chinaz 依次类推。使用域名时，从下而上。s.tool.chinaz.com. 就是一个完整的域名，<a href="http://www.chinaz.com" target="_blank" rel="noopener">www.chinaz.com</a>. 也是。</p><p>之所以设计这样复杂的树形结构， 是为了防止名称冲突。这样一棵树结构，当然可以存储在一台机器上，但现实世界中完整的域名非常多，并且每天都在新增、删除大量的域名，存在一台机器上，对单机器的存储性能就是不小的挑战。另外，集中管理还有一个缺点就是管理不够灵活。可以想象一下，每次新增、删除域名都需要向中央数据库申请是多么麻烦。所以现实中的 DNS 都是分布式存储的。</p><p>根域名服务器只管理顶级域，同时把每个顶级域的管理委派给各个顶级域，所以当你想要申请com下的二级域名时，找 com 域名注册中心就好了。例如你申请了上图的 chinaz.com 二级域名，chinaz.com 再向下的域名就归你管理了。当你管理 chinaz.com 的子域名时，你可以搭建自己的 nameserver，在 .com 注册中心把 chinaz.com 的管理权委派给自己搭建的nameserver。自建nameserver 和不自建的结构图如下:</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/2.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>一般情况下，能不自建就不要自建，因为维护一个高可用的 DNS 也并非容易。据我所知，有两种情况需要搭建自己的 nameserver：</p><ol><li>搭建对内的 DNS。公司内部机器众多，通过 IP 相互访问太过凌乱，这时可以搭建对内的 nameserver，允许内部服务器通过域名互通</li><li>公司对域名厂商提供的 nameserver 性能不满意。虽然顶级域名注册商都有自己的nameserver，但注册商提供的 nameserver 并不专业，在性能和稳定性上无法满足企业需求，这时就需要企业搭建自己的高性能 nameserver，比如增加智能解析功能，让不同地域的用户访问最近的 IP，以此来提高服务质量</li></ol><p>概括一下 DNS 的分布式管理， 当把一个域委派给一个nameserver后，这个域下的管理权都交由此nameserver处理。这种设计一方面解决了存储压力，另一方面提高了域名管理的灵活性 (这种结构像极了Linux File System, 可以把任何一个子目录挂载到另一个磁盘，还可以把它下面的子目录继续挂载出去)</p><h3 id="顶级域名"><a href="#顶级域名" class="headerlink" title="顶级域名"></a>顶级域名</h3><p>像 com 这样的顶级域名，由 ICANN 严格控制，是不允许随便创建的。顶级域名分两类:</p><ul><li>通用顶级域名</li><li>国家顶级域名</li></ul><p>通用顶级域名常见的如.com、.org、.edu等， 国家顶级域名如我国的.cn， 美国的.us。一般公司申请公网域名时，如果是跨国产品，应该选择通用顶级域名；如果没有跨国业务，看自己喜好（可以对比各家顶级域的服务、稳定性等再做选择）。这里说一下几个比较热门的顶级域，完整的顶级域参见维基百科。</p><p><strong>me</strong><br>me顶级域其实是国家域名， 是黑山共和国的国家域名，只不过它对个人开发申请，所以很多个人博主就用它作为自己的博客域名</p><p><strong>io</strong><br>很多开源项目常用io做顶级域名，它也是国家域名。因为io 与计算机中的 input/output 缩写相同，和计算机二机制10也很像，给人一种geek的感觉。相较于.com域名，.io下的资源很多，更多选择。</p><h2 id="DNS-解析流程"><a href="#DNS-解析流程" class="headerlink" title="DNS 解析流程"></a>DNS 解析流程</h2><p>聊完了 DNS 的基本概念，我们再来聊一聊 DNS 的解析流程。当我们通过浏览器或者应用程序访问互联网时，都会先执行一遍 DNS 解析流程。标准 glibc 提供了 libresolv.so.2 动态库，我们的应用程序就是用它进行域名解析（也叫 resolving）的， 它还提供了一个配置文件<code>/etc/nsswitch.conf</code> 来控制 resolving 行为，配置文件中最关键的是这行：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">hosts:      files<span class="hljs-built_in"> dns </span>myhostname<br></code></pre></div></td></tr></table></figure><p>它决定了 resolving 的顺序，默认是先查找 hosts 文件，如果没有匹配到，再进行 DNS 解析。默认的解析流程如下图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/3.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>上图主要描述了 client 端的解析流程，我们可以看到最主要的是第四步请求本地 DNS 服务器去执行 resolving，它会根据本地 DNS 服务器配置，发送解析请求到递归解析服务器（稍后介绍什么是递归解析服务器)， 本地 DNS 服务器在 /etc/resolv.conf 中配置。下面我们再来看看服务端的 resolving 流程：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/4.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>我们分析一下解析流程：</p><ol><li><p>客户端向本地DNS服务器(递归解析服务器) 发出解析tool.chinaz.com域名的请求</p></li><li><p>本地dns服务器查看缓存，是否有缓存过tool.chinaz.com域名，如果有直接返回给客户端；</p><p>如果没有执行下一步</p></li><li><p>本地dns服务器向根域名服务器发送请求，查询com顶级域的nameserver 地址</p></li><li><p>拿到com域名的IP后，再向com nameserver发送请求，获取chinaz域名的nameserver地址</p></li><li><p>继续请求 chinaz 的nameserver，获取 tool 域名的地址，最终得到了tool.chinaz.com 的 IP，本地 dns 服务器把这个结果缓存起来，以供下次查询快速返回</p></li><li><p>本地dns服务器把把结果返回给客户端</p></li></ol><p><strong>递归解析服务器 vs 权威域名服务器</strong></p><p>我们在解析流程中发现两类 DNS 服务器，客户端直接访问的是递归解析服务器， 它在整个解析过程中也最忙。它的查询步骤是递归的，从根域名服务器开始，一直询问到目标域名。</p><p>递归解析服务器通过请求一级一级的权威域名服务器，获得下一目标的地址，直到找到目标域名的权威域名服务器</p><p>简单来说：递归解析服务器是负责解析域名的，权威域名服务器是负责存储域名记录的</p><p>递归解析服务器一般由 ISP 提供，除此之外也有一些比较出名的公共递归解析服务器， 如谷歌的 8.8.8.8，联通的 114，BAT 也都有推出公共递归解析服务器，但性能最好的应该还是你的ISP提供的，只是可能会有 DNS劫持的问题</p><p><strong>缓存</strong></p><p>由于整个解析过程非常复杂，所以 DNS 通过缓存技术来实现服务的鲁棒性。当递归nameserver 解析过 tool.chianaz.com 域名后，再次收到 tool.chinaz.com 查询时，它不会再走一遍递归解析流程，而是把上一次解析结果的缓存直接返回。并且它是分级缓存的，也就是说，当下次收到的是 <a href="http://www.chinaz.com" target="_blank" rel="noopener">www.chinaz.com</a> 的查询时， 由于这台递归解析服务器已经知道 chinaz.com 的权威 nameserver，所以它只需要再向 chinaz.com nameserver 发送一个查询 www 的请求就可以了。</p><p>根域名服务器递归解析服务器是怎么知道根域名服务器的地址的呢？根域名服务器的地址是固定的，目前全球有13个根域名解析服务器，这13条记录持久化在递归解析服务器中：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/5.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>为什么只有 13 个根域名服务器呢，不是应该越多越好来做负载均衡吗？之前说过 DNS 协议使用了 UDP 查询， 由于 UDP 查询中能保证性能的最大长度是 512 字节，要让所有根域名服务器数据能包含在512字节的UDP包中， 根服务器只能限制在13个， 而且每个服务器要使用字母表中单字母名。</p><p><strong>智能解析</strong></p><p>智能解析，就是当一个域名对应多个 IP 时，当你查询这个域名的 IP，会返回离你最近的 IP。</p><p>由于国内不同运营商之间的带宽很低，所以电信用户访问联通的IP就是一个灾难，而智能 DNS 解析就能解决这个问题。</p><p>智能解析依赖 EDNS 协议，这是 google 起草的 DNS 扩展协议， 修改比较简单，就是在 DNS 包里面添加 origin client IP, 这样 nameserver 就能根据 client IP 返回距离 client 比较近的 server IP 了</p><p>国内最新支持 EDNS 的就是 DNSPod 了，DNSPod 是国内比较流行的域名解析厂商，很多公司会把域名利用DNSPod 加速， 它已经被鹅厂收购</p><h2 id="域名注册商"><a href="#域名注册商" class="headerlink" title="域名注册商"></a>域名注册商</h2><p>一般我们要注册域名，都要需要找域名注册商，比如说我想注册 hello.com，那么我需要找com域名注册商注册hello域名。com的域名注册商不止一家， 这些域名注册商也是从ICANN 拿到的注册权， [参见如何申请成为.com域名注册商](<a href="https://www.zhihu.com/question/19578540" target="_blank" rel="noopener">GitHub (zhihu.com)</a>)</p><p>那么，域名注册商 和 权威域名解析服务器  有什么关系呢？</p><p>域名注册商都会自建权威域名解析服务器，比如你在狗爹上申请一个.com下的二级域名，你并不需要搭建nameserver， 直接在godaddy控制中心里管理你的域名指向就可以了， 原因就是你新域名的权威域名服务器默认由域名注册商提供。当然你也可以更换，比如从godaddy申请的境外域名，把权威域名服务器改成DNSPod，一方面加快国内解析速度，另一方面还能享受DNSPod 提供的智能解析功能</p><h2 id="用-bind-搭建域名解析服务器"><a href="#用-bind-搭建域名解析服务器" class="headerlink" title="用 bind 搭建域名解析服务器"></a>用 bind 搭建域名解析服务器</h2><p>由于网上介绍bind搭建的文章实在太多了，我就不再赘述了， 喜欢动手的朋友可以网上搜一搜搭建教程，一步步搭建一个本地的nameserver 玩一玩。这里主要介绍一下bind 的配置文件吧</p><p>bind 的配置文件分两部分: bind配置文件 和 zone配置文件</p><h3 id="bind-配置文件"><a href="#bind-配置文件" class="headerlink" title="bind 配置文件"></a>bind 配置文件</h3><p>bind 配置文件位于 <code>/etc/named.conf</code>，它主要负责 bind 功能配置，如 zone 路径、日志、安全、主从等配置</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/6.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>其中最主要的是添加zone的配置以及指定zone配置文件。recursion 开启递归解析功能， 这个如果是no， 那么此bind服务只能做权威解析服务，当你的bind服务对外时，打开它会有安全风险，如果防御不当，会让你的nameserver 被hacker 用来做肉鸡</p><h3 id="zone-配置文件"><a href="#zone-配置文件" class="headerlink" title="zone 配置文件"></a>zone 配置文件</h3><p>zone 的配置文件在 bind 配置文件中指定，下图是一份简单的 zone 配置：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/7.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>zone的配置是 nameserver 的核心配置， 它指定了 DNS 资源记录，如 SOA、A、CNAME、AAAA 等记录，各种记录的概念网上资料太多，我这里就不重复了。其中主要讲一下 SOA 和 CNAME 的作用。</p><p><strong>SOA记录</strong></p><p>SOA 记录表示此域名的权威解析服务器地址。上文讲了权威解析服务器和递归解析服务器的差别， 当所有递归解析服务器中有没你域名解析的缓存时，它们就会回源来请求此域名的SOA记录，也叫权威解析记录</p><p><strong>CNAME</strong></p><p>CNAME 的概念很像别名，它的处理逻辑也如此。一个server 执行resloving 时，发现 name 是一个 CNAME， 它会转而查询这个 CNAME 的A记录。一般来说，能使用CNAME的地方都可以用A记录代替， 那么为什么还要发明 CNAME 这样一个东西呢？它是让多个域名指向同一个 IP 的一种快捷手段， 这样当最低层的 CNAME 对应的IP换了之后，上层的 CNAME 不用做任何改动。就像我们代码中的硬编码，我们总会去掉这些硬编码，用一个变量来表示，这样当这个变量变化时，我们只需要修改一处</p><p>配置完之后可以用 <code>named-checkconf</code> 和 <code>named-checkzone</code> 两个命令来check我们的配置文件有没有问题， 之后就可以启动 bind 服务了：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">$&gt;<span class="hljs-built_in"> service </span>named start<br>Redirecting <span class="hljs-keyword">to</span> /bin/systemctl restart  named.service<br></code></pre></div></td></tr></table></figure><p>我们用 <code>netstat -ntlp</code> 来检查一下服务是否启动:</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/8.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>53 端口已启动，那么我们测试一下效果， 用 dig 解析一下 <a href="http://www.hello.com" target="_blank" rel="noopener">www.hello.com</a> 域名，使用127.0.0.1 作为递归解析服务器</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/9.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>我们看到 dig 的结果跟我们配置文件中配置的一样是 1.2.3.4，DNS 完成了它的使命，根据域名获取到 IP，但我们这里用来做示范的IP明显是个假IP。</p><h3 id="用-DNS-实现负载均衡"><a href="#用-DNS-实现负载均衡" class="headerlink" title="用 DNS 实现负载均衡"></a>用 DNS 实现负载均衡</h3><p>一个域名添加多条A记录，解析时使用轮询的方式返回随机一条，流量将会均匀分类到多个A记录。</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">www     IN      A       <span class="hljs-number">1.2</span><span class="hljs-number">.3</span><span class="hljs-number">.4</span><br>www     IN      A       <span class="hljs-number">1.2</span><span class="hljs-number">.3</span><span class="hljs-number">.5</span><br></code></pre></div></td></tr></table></figure><p>复制代码上面的配置中，我们给 www 域添加了两条A记录， 这种做法叫 multi-homed hosts， 它的效果是：当我们请求 nameserver 解析 <a href="http://www.hello.com" target="_blank" rel="noopener">www.hello.com</a> 域名时，返回的IP会在两个IP中轮转（默认行为，有些智能解析 DNS 会根据 IP 判断距离，返回一个离client近的IP）。</p><p>其实每次DNS解析请求时，nameserver都会返回全部IP，如上面配置，它会把1.2.3.4 和1.2.3.5 都返回给client端。那么它是怎么实现RR的呢？nameserver 只是每次返回的IP排序不同，客户端会把response里的第一个IP用来发请求。</p><p><strong>DNS负载均衡 vs LVS专业负载均衡</strong></p><p>和 LVS 这种专业负载均衡工具相比，在DNS层做负载均衡有以下特点:</p><ol><li>实现非常简单</li><li>默认只能通过RR方式调度</li><li>DNS 对后端服务不具备健康检查</li><li>DNS 故障恢复时间比较长（DNS 服务之间有缓存）</li><li>可负载的 rs 数量有限（受 DNS response 包大小限制)</li></ol><p>真实场景中，还需要根据需求选择相应的负载均衡策略</p><h3 id="子域授权"><a href="#子域授权" class="headerlink" title="子域授权"></a>子域授权</h3><p>我们从 .com 域下申请一个二级域名 hello.com 后， 发展到某一天我们的公司扩大了，需要拆分两个事业部A和B， 并且公司给他们都分配了三级域名  a.hello.com 和 b.hello.com， 域名结构如下图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/10.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>再发展一段时间，A部门和B部门内部业务太多，需要频繁的为新产品申请域名， 这个时候他们就想搭建自己的 namserver，并且需要上一级把相应的域名管理权交给自己，他们期望的结构如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/11.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>注意第一阶段和第二阶段的区别：第一阶段，A 部门想申请 a.hello.com 下的子域名，需要向上级申请，整个 a.hello.com 域的管理都在总公司；第二阶段，A 部门先自己搭建 nameserver，然后总公司把 a.hello.com 域管理权转交给自建的 nameserver， 这个转交管理权的行为，就叫子域授权</p><p>子域授权分两部操作:</p><ol><li>A部门自建 nameserver，并且在 zone 配置文件中指定 a.hello.com 的权威解析服务器为自己的 nameserver 地址</li><li>总公司在 nameserver 上增加一条 NS 记录， 把 a.hello.com 域授权给 A 部门的 nameserver</li></ol><p>第一步我们在用 bind 搭建域名解析服务器里讲过， 只要在 zone 配置文件里指定SOA记录就好:</p><ul><li><figure class="highlight stylus"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs stylus">@       IN     SOA      ns<span class="hljs-selector-class">.a</span><span class="hljs-selector-class">.hello</span><span class="hljs-selector-class">.com</span>    admin<span class="hljs-selector-class">.a</span><span class="hljs-selector-class">.hello</span><span class="hljs-selector-class">.com</span>. (……)复制代码<br></code></pre></div></td></tr></table></figure></li></ul><p>第二步，在 hello.com 域的 nameserver 上添加一条NS记录:</p><ul><li></li><li></li></ul><figure class="highlight stylus"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs stylus"><span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.hello</span><span class="hljs-selector-class">.com</span>      IN       NS       ns<span class="hljs-selector-class">.a</span><span class="hljs-selector-class">.hello</span>.com<br>ns<span class="hljs-selector-class">.a</span><span class="hljs-selector-class">.hello</span><span class="hljs-selector-class">.com</span>      IN      A        xx<span class="hljs-selector-class">.xx</span><span class="hljs-selector-class">.xx</span><span class="hljs-selector-class">.xx</span> (自建nameserver的IP)复制代码<br></code></pre></div></td></tr></table></figure><p>这样当解析 xx.a.hello.com 域名时，hello.com nameserver 发现配置中有 NS 记录，就会继续递归向下解析</p><h2 id="DNS-调试工具"><a href="#DNS-调试工具" class="headerlink" title="DNS 调试工具"></a>DNS 调试工具</h2><p>OPS 常用的 DNS 调试工具有：host，nslookup，dig</p><p>这三个命令都属于 bind-utils 包， 也就是 bind 工具集，它们的使用复杂度、功能 依次递增。关于它们的使用， man 手册和网上有太多教程，这里简单分析一下dig命令的输出吧：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-06-01/12.webp" srcset="/img/loading.gif" lazyload alt=""></p><p>dig 的参数非常多， 功能也很多，详细使用方法大家自行man吧</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="DNS-放大攻击"><a href="#DNS-放大攻击" class="headerlink" title="DNS 放大攻击"></a>DNS 放大攻击</h3><p>DNS 放大攻击属于DoS攻击的一种，是通过大量流量占满目标机带宽， 使得目标机对正常用户的请求拒绝连接从而挂掉。</p><p><strong>思路</strong></p><p>正常的流量攻击，hack 机向目标机建立大量 request-response，但这样存在的问题是需要大量的 hack 机器。因为服务器一般的带宽远大于家用网络， 如果我们自己的家用机用来做 hack 机器，还没等目标机的带宽占满，我们的带宽早超载了。</p><p><strong>原理</strong></p><p>DNS 递归解析的流程比较特殊， 我们可以通过几个字节的 query 请求，换来几百甚至几千字节的 resolving 应答（流量放大）， 并且大部分服务器不会对DNS服务器做防御。那么 hacker 们只要可以伪装 DNS query 包的 source IP， 从而让 DNS 服务器发送大量的 response 到目标机，就可以实现 DoS 攻击。</p><p>但一般常用的 DNS 服务器都会对攻击请求做过滤，所以找 DNS 服务器漏洞也是一个问题。详细的放大攻击方法大家有兴趣自行 google 吧，这里只做一个简单介绍 :)</p>]]></content>
    
    
    
    <tags>
      
      <tag>DNS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 面试的公司及其问题 </title>
    <link href="/2021/05/24/company-questions/"/>
    <url>/2021/05/24/company-questions/</url>
    
    <content type="html"><![CDATA[<h1 id="面试的公司及其问题"><a href="#面试的公司及其问题" class="headerlink" title="面试的公司及其问题"></a>面试的公司及其问题</h1><p><strong>之前的问题（公司没记录）</strong></p><ul><li><del>k8s service的调度算法</del></li><li>StatefulSet 可以挂在多个pvc吗？</li><li><del>prometheus 数据类型</del></li><li><del>docker 内部运行free -m看见的内存是宿主机还是容器的，为什么</del></li><li><del>查看容器内进程</del></li><li>使用nodeport 这台node没有对应的pod 怎么访问到的</li><li><del>ingress 转发过程</del></li><li><del>pod启动不了，排查思路</del></li><li>redis集群分片原理</li><li>mysql增量备份原理</li><li>git push -f会发生什么？如何结合git rebase合并分支</li><li><del>k8s所能识别的最小单元</del>  pod</li><li><del>不属于ansible的模块 scp ping copy k8s</del>   scp模块不属于</li><li>jenkins用户密码存在哪里，数据库还是文本文件</li><li><del>k8s secret的类型</del></li><li>mysql优化方法 硬件资源、增加slave、增大binlog保存天数、优化配置文件</li><li>redis适合的场景 session共享（单点登录）、页面缓存、队列、发布/订阅</li><li><del>nginx支不支持2层负载</del>  应该不支持</li><li><del>nginx默认监听localhost</del></li><li><del>flannel三种模式  udp、vxlan、host-gw</del></li><li>查看主机上连接不同mysql的总数</li><li>负载均衡的实现方式</li><li><del>docker kill和stop的区别</del></li><li>限制某个ip:port组合最多只能允许来自同一个ip的n个并发连接</li><li>某台机器升级内核无法启动，排查</li><li>nginx日志格式化 log-format，时间、主机、url</li><li>nginx低磁盘IO高并发的优化</li><li>nginx https禁用不安全的密码算法</li><li>通过nginx重写将url：<a href="http://www.abc.com/qi/api" target="_blank" rel="noopener">http://www.abc.com/qi/api</a> 重写为 <a href="https://www.abc.com/old_api" target="_blank" rel="noopener">https://www.abc.com/old_api</a></li><li><del>docker build如何传入参数</del></li><li>cdn是什么，什么情况下使用cdn</li><li>DANT和SANT的区别</li><li>sed grep awk</li><li><del>pv pvc是什么，区别</del></li><li>kafka zookeeper</li><li>ansible</li><li>算法对一组数字做取反。不让用python自带的for循环和语法糖</li><li>mysql存储引擎的数据结构用的啥</li><li><del>docker 容器间直接数据共享</del></li><li>nginx优化，全部参数看一遍，了解什么作用 </li><li>redis aof三种方式</li><li>redis主从触发机智 </li><li>mycat分库分表，根据地域，或者其他header头</li></ul><ul><li>python数字取反，不用自带的方法及for循环</li><li>python将ip地址转换成整数在数据库中存储</li><li>mysql存储引擎的数据结构</li><li>mysql索引原理</li><li>tcp和udp区别及应用场景</li><li>阿里云k8s和社区k8s的区别</li><li>ingress的类型</li><li></li></ul><h2 id="乘法云（龙域中心B座9层，2021-05-19）"><a href="#乘法云（龙域中心B座9层，2021-05-19）" class="headerlink" title="乘法云（龙域中心B座9层，2021-05-19）"></a>乘法云（龙域中心B座9层，2021-05-19）</h2><p><strong>笔试部分</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/interview/chengfayun/%E4%B9%98%E6%B3%95%E4%BA%91%E7%AC%94%E8%AF%951.jpg" srcset="/img/loading.gif" lazyload alt=""></p><p><img src="https://gitee.com/like-ycy/images/raw/master/interview/chengfayun/%E4%B9%98%E6%B3%95%E4%BA%91%E7%AC%94%E8%AF%952.jpg" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>对话部分</strong>（会问笔试中的题目）</p><ul><li>阿里云月消费多少</li><li>k8s集群多大，用的什么版本</li><li>平时shell脚本写的多吗，写过什么脚本</li><li>shell 参数$$ $# $@</li><li>手写shell脚本，遍历1-100</li><li>手写python代码，遍历一个元组中的数据，打印出来（面试官主要看的是代码格式是否正确）</li><li>浏览器访问百度，客户端和服务端之间https证书的流程</li><li>https建立TLS连接之后，会使用什么加密算法对数据进行加密</li><li><del>docker容器内执行uname -r查看到的内核信息是容器操作系统的还是宿主机操作系统的</del></li><li><del>docker容器内执行cat /etc/os-release看到的Linux版本信息是容器操作系统的还是宿主机器的</del></li><li><del>服务器安装docker有没有什么注意事项</del></li><li>如何查看mysql的慢查询。优化慢查询的思路是什么？</li><li>系统内核参数的优化，（说出部分参数即可）</li><li>TCP三次握手，四次挥手</li><li>系统盘/  30G (已经用满)，数据盘/data 200G（用了30%），找到占用最大的那个文件</li><li>tcpdump 抓取DNS的数据包，什么命令</li><li>你们公司的发版流程</li><li>gitlab-runner 执行器 shell，docker，k8s的区别</li><li>gitlab的升级，有没有升级过，怎么升级的</li><li>prometheus监控都监控哪些指标</li><li>prometheus获取数据的模式， pull，push两种的区别，第三方exporter的默认方式（默认为pull）</li><li>生产上有没有遇到什么问题</li><li>k8s node节点显示no reday，然后执行kubectl命令node会有响应吗？</li><li>cdn的数据请求流程，怎么找到的离客户端最近的那个节点？</li><li><del>k8s  service的四种类型，有什么区别</del></li><li><del>k8s 用的什么网络组件，我的回答flannel和calico，然后会问会有什么区别</del></li><li>假设基于git仓库开发了一个项目，开修改了10个文件，这时候紧急插入一个需求，请问可以使用什么git命令临时保存修改，去开发新的需求</li></ul><h2 id="女娲补天（中关村梦想实验室2层，2021-05-25）-强烈不建议"><a href="#女娲补天（中关村梦想实验室2层，2021-05-25）-强烈不建议" class="headerlink" title="女娲补天（中关村梦想实验室2层，2021-05-25）***强烈不建议"></a>女娲补天（中关村梦想实验室2层，2021-05-25）***强烈不建议</h2><p><strong>这个公司技术一般，直接跑war包，服务器30来台，没有容器</strong></p><p><strong>关键是有点大言不惭，居然说要搞私有云</strong></p><h2 id="新文达教育-（学院国际大厦20层，2021-05-25）-不建议"><a href="#新文达教育-（学院国际大厦20层，2021-05-25）-不建议" class="headerlink" title="新文达教育 （学院国际大厦20层，2021-05-25）**不建议"></a>新文达教育 （学院国际大厦20层，2021-05-25）**不建议</h2><p><strong>这个公司是996</strong></p><p><strong>这个公司在填表的时候写了多少钱，就是多少钱，后面跟人事谈钱的时候，多要，人事不会考虑</strong></p><p><strong>面试问题：</strong></p><p>k8s手动部署的经验</p><p>k8s1.12集群用的是kubedns还是coredns</p><p>cicd流程</p><p>ansible怎么用的，用来做什么</p><p>python写过什么程序</p><p>ingress是怎么使用的</p><p>elk的使用，怎么做的（收集日志的流程）</p><p>java后端服务架构是怎么做的（spring boot、eureka注册中心、zuul网关）</p><p>灰度发布有没有使用</p><p>上线流程</p><p>有接触过堡垒机吗</p><p>jenkins有用过吗（没深入问，建议深入了解些jenkins pipeline流程）</p><p>jenkins流水线脚本会编写吗</p><p>linux内核参数优化（说出部分参数）</p><p>nginx优化</p><p>jvm优化</p><p>k8s优化</p><h2 id="融云（视频面试，2021-05-28）"><a href="#融云（视频面试，2021-05-28）" class="headerlink" title="融云（视频面试，2021-05-28）"></a>融云（视频面试，2021-05-28）</h2><p><strong>注意：需要国外出差及英语交流</strong></p><p><strong>问题：</strong></p><p>k8s的优化，（在你运维的过程中，为了方便自己运维，所做的一些配置）</p><p>k8s 网络、存储、的使用及优化</p><p>mysql、redis、mongo的优化</p><p>ansible的playbook使用，比如服务器初始化，发布</p><p>k8s集群多云的经验（一个k8s集群分别部署在两个公有云中，）</p><p>prometheus</p><p>elk</p>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--Kubernetes2-60道常见的 Kubernetes 面试题总结 </title>
    <link href="/2021/05/21/interview-questions23-k8s2/"/>
    <url>/2021/05/21/interview-questions23-k8s2/</url>
    
    <content type="html"><![CDATA[<h1 id="60道常见的-Kubernetes-面试题总结"><a href="#60道常见的-Kubernetes-面试题总结" class="headerlink" title="60道常见的 Kubernetes 面试题总结"></a>60道常见的 Kubernetes 面试题总结</h1><h3 id="简述ETCD及其特点？"><a href="#简述ETCD及其特点？" class="headerlink" title="简述ETCD及其特点？"></a>简述ETCD及其特点？</h3><p>etcd 是 CoreOS 团队发起的开源项目，是一个管理配置信息和服务发现（service discovery）的项目，它的目标是构建一个高可用的分布式键值（key-value）数据库，基于 Go 语言实现。</p><p>特点：</p><ul><li>简单：支持 REST 风格的 HTTP+JSON API</li><li>安全：支持 HTTPS 方式的访问</li><li>快速：支持并发 1k/s 的写操作</li><li>可靠：支持分布式结构，基于 Raft 的一致性算法，Raft 是一套通过选举主节点来实现分布式系统一致性的算法。</li></ul><h3 id="简述ETCD适应的场景？"><a href="#简述ETCD适应的场景？" class="headerlink" title="简述ETCD适应的场景？"></a>简述ETCD适应的场景？</h3><p>etcd基于其优秀的特点，可广泛的应用于以下场景：</p><ul><li>服务发现(Service Discovery)：服务发现主要解决在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听udp或tcp端口，并且通过名字就可以查找和连接。</li><li>消息发布与订阅：在分布式系统中，最适用的一种组件间通信方式就是消息发布与订阅。即构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。通过这种方式可以做到分布式系统配置的集中式管理与动态更新。应用中用到的一些配置信息放到etcd上进行集中管理。</li><li>负载均衡：在分布式系统中，为了保证服务的高可用以及数据的一致性，通常都会把数据和服务部署多份，以此达到对等服务，即使其中的某一个服务失效了，也不影响使用。etcd本身分布式架构存储的信息访问支持负载均衡。etcd集群化以后，每个etcd的核心节点都可以处理用户的请求。所以，把数据量小但是访问频繁的消息数据直接存储到etcd中也可以实现负载均衡的效果。</li><li>分布式通知与协调：与消息发布和订阅类似，都用到了etcd中的Watcher机制，通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更做到实时处理。</li><li>分布式锁：因为etcd使用Raft算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。</li><li>集群监控与Leader竞选：通过etcd来进行监控实现起来非常简单并且实时性强。</li></ul><h3 id="简述什么是Kubernetes？"><a href="#简述什么是Kubernetes？" class="headerlink" title="简述什么是Kubernetes？"></a>简述什么是Kubernetes？</h3><p>Kubernetes是一个全新的基于容器技术的分布式系统支撑平台。是Google开源的容器集群管理系统（谷歌内部:Borg）。在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。并且具有完备的集群管理能力，多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。</p><h3 id="简述Kubernetes和Docker的关系？"><a href="#简述Kubernetes和Docker的关系？" class="headerlink" title="简述Kubernetes和Docker的关系？"></a>简述Kubernetes和Docker的关系？</h3><p>Docker 提供容器的生命周期管理和，Docker 镜像构建运行时容器。它的主要优点是将将软件/应用程序运行所需的设置和依赖项打包到一个容器中，从而实现了可移植性等优点。</p><p>Kubernetes 用于关联和编排在多个主机上运行的容器。</p><h3 id="简述Kubernetes中什么是Minikube、Kubectl、Kubelet？"><a href="#简述Kubernetes中什么是Minikube、Kubectl、Kubelet？" class="headerlink" title="简述Kubernetes中什么是Minikube、Kubectl、Kubelet？"></a>简述Kubernetes中什么是Minikube、Kubectl、Kubelet？</h3><p>Minikube 是一种可以在本地轻松运行一个单节点 Kubernetes 群集的工具。</p><p>Kubectl 是一个命令行工具，可以使用该工具控制Kubernetes集群管理器，如检查群集资源，创建、删除和更新组件，查看应用程序。</p><p>Kubelet 是一个代理服务，它在每个节点上运行，并使从服务器与主服务器通信。</p><h3 id="简述Kubernetes常见的部署方式？"><a href="#简述Kubernetes常见的部署方式？" class="headerlink" title="简述Kubernetes常见的部署方式？"></a>简述Kubernetes常见的部署方式？</h3><p>常见的Kubernetes部署方式有：</p><ul><li>kubeadm：也是推荐的一种部署方式；</li><li>二进制：</li><li>minikube：在本地轻松运行一个单节点 Kubernetes 群集的工具。</li></ul><h3 id="简述Kubernetes如何实现集群管理？"><a href="#简述Kubernetes如何实现集群管理？" class="headerlink" title="简述Kubernetes如何实现集群管理？"></a>简述Kubernetes如何实现集群管理？</h3><p>在集群管理方面，Kubernetes将集群中的机器划分为一个Master节点和一群工作节点Node。其中，在Master节点运行着集群管理相关的一组进程kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和纠错等管理能力，并且都是全自动完成的。</p><h3 id="简述Kubernetes的优势、适应场景及其特点？"><a href="#简述Kubernetes的优势、适应场景及其特点？" class="headerlink" title="简述Kubernetes的优势、适应场景及其特点？"></a>简述Kubernetes的优势、适应场景及其特点？</h3><p>Kubernetes作为一个完备的分布式系统支撑平台，其主要优势：</p><ul><li>容器编排</li><li>轻量级</li><li>开源</li><li>弹性伸缩</li><li>负载均衡</li></ul><p>Kubernetes常见场景：</p><ul><li>快速部署应用</li><li>快速扩展应用</li><li>无缝对接新的应用功能</li><li>节省资源，优化硬件资源的使用</li></ul><p>Kubernetes相关特点：</p><ul><li>可移植: 支持公有云、私有云、混合云、多重云（multi-cloud）。</li><li>可扩展: 模块化,、插件化、可挂载、可组合。</li><li>自动化: 自动部署、自动重启、自动复制、自动伸缩/扩展。</li></ul><h3 id="简述Kubernetes的缺点或当前的不足之处？"><a href="#简述Kubernetes的缺点或当前的不足之处？" class="headerlink" title="简述Kubernetes的缺点或当前的不足之处？"></a>简述Kubernetes的缺点或当前的不足之处？</h3><p>Kubernetes当前存在的缺点（不足）如下：</p><ul><li>安装过程和配置相对困难复杂。</li><li>管理服务相对繁琐。</li><li>运行和编译需要很多时间。</li><li>它比其他替代品更昂贵。</li><li>对于简单的应用程序来说，可能不需要涉及Kubernetes即可满足。</li></ul><h3 id="简述Kubernetes相关基础概念？"><a href="#简述Kubernetes相关基础概念？" class="headerlink" title="简述Kubernetes相关基础概念？"></a>简述Kubernetes相关基础概念？</h3><ul><li>master：k8s集群的管理节点，负责管理集群，提供集群的资源数据访问入口。拥有Etcd存储服务（可选），运行Api Server进程，Controller Manager服务进程及Scheduler服务进程。</li><li>node（worker）：Node（worker）是Kubernetes集群架构中运行Pod的服务节点，是Kubernetes集群操作的单元，用来承载被分配Pod的运行，是Pod运行的宿主机。运行docker eninge服务，守护进程kunelet及负载均衡器kube-proxy。</li><li>pod：运行于Node节点上，若干相关容器的组合。Pod内包含的容器运行在同一宿主机上，使用相同的网络命名空间、IP地址和端口，能够通过localhost进行通信。Pod是Kurbernetes进行创建、调度和管理的最小单位，它提供了比容器更高层次的抽象，使得部署和管理更加灵活。一个Pod可以包含一个容器或者多个相关容器。</li><li>label：Kubernetes中的Label实质是一系列的Key/Value键值对，其中key与value可自定义。Label可以附加到各种资源对象上，如Node、Pod、Service、RC等。一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上去。Kubernetes通过Label Selector（标签选择器）查询和筛选资源对象。</li><li>Replication Controller：Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。集群中副本的数量大于指定数量，则会停止指定数量之外的多余容器数量。反之，则会启动少于指定数量个数的容器，保证数量不变。Replication Controller是实现弹性伸缩、动态扩容和滚动升级的核心。</li><li>Deployment：Deployment在内部使用了RS来实现目的，Deployment相当于RC的一次升级，其最大的特色为可以随时获知当前Pod的部署进度。</li><li>HPA（Horizontal Pod Autoscaler）：Pod的横向自动扩容，也是Kubernetes的一种资源，通过追踪分析RC控制的所有Pod目标的负载变化情况，来确定是否需要针对性的调整Pod副本数量。</li><li>Service：Service定义了Pod的逻辑集合和访问该集合的策略，是真实服务的抽象。Service提供了一个统一的服务访问入口以及服务代理和发现机制，关联多个相同Label的Pod，用户不需要了解后台Pod是如何运行。</li><li>Volume：Volume是Pod中能够被多个容器访问的共享目录，Kubernetes中的Volume是定义在Pod上，可以被一个或多个Pod中的容器挂载到某个目录下。</li><li>Namespace：Namespace用于实现多租户的资源隔离，可将集群内部的资源对象分配到不同的Namespace中，形成逻辑上的不同项目、小组或用户组，便于不同的Namespace在共享使用整个集群的资源的同时还能被分别管理。</li></ul><h3 id="简述Kubernetes集群相关组件？"><a href="#简述Kubernetes集群相关组件？" class="headerlink" title="简述Kubernetes集群相关组件？"></a>简述Kubernetes集群相关组件？</h3><p>Kubernetes Master控制组件，调度管理整个系统（集群），包含如下组件:</p><ul><li>Kubernetes API Server：作为Kubernetes系统的入口，其封装了核心对象的增删改查操作，以RESTful API接口方式提供给外部客户和内部组件调用，集群内各个功能模块之间数据交互和通信的中心枢纽。</li><li>Kubernetes Scheduler：为新建立的Pod进行节点(node)选择(即分配机器)，负责集群的资源调度。</li><li>Kubernetes Controller：负责执行各种控制器，目前已经提供了很多控制器来保证Kubernetes的正常运行。</li><li>Replication Controller：管理维护Replication Controller，关联Replication Controller和Pod，保证Replication Controller定义的副本数量与实际运行Pod数量一致。</li><li>Node Controller：管理维护Node，定期检查Node的健康状态，标识出(失效|未失效)的Node节点。</li><li>Namespace Controller：管理维护Namespace，定期清理无效的Namespace，包括Namesapce下的API对象，比如Pod、Service等。</li><li>Service Controller：管理维护Service，提供负载以及服务代理。</li><li>EndPoints Controller：管理维护Endpoints，关联Service和Pod，创建Endpoints为Service的后端，当Pod发生变化时，实时更新Endpoints。</li><li>Service Account Controller：管理维护Service Account，为每个Namespace创建默认的Service Account，同时为Service Account创建Service Account Secret。</li><li>Persistent Volume Controller：管理维护Persistent Volume和Persistent Volume Claim，为新的Persistent Volume Claim分配Persistent Volume进行绑定，为释放的Persistent Volume执行清理回收。</li><li>Daemon Set Controller：管理维护Daemon Set，负责创建Daemon Pod，保证指定的Node上正常的运行Daemon Pod。</li><li>Deployment Controller：管理维护Deployment，关联Deployment和Replication Controller，保证运行指定数量的Pod。当Deployment更新时，控制实现Replication Controller和Pod的更新。</li><li>Job Controller：管理维护Job，为Jod创建一次性任务Pod，保证完成Job指定完成的任务数目</li><li>Pod Autoscaler Controller：实现Pod的自动伸缩，定时获取监控数据，进行策略匹配，当满足条件时执行Pod的伸缩动作。</li></ul><h3 id="简述Kubernetes-RC的机制？"><a href="#简述Kubernetes-RC的机制？" class="headerlink" title="简述Kubernetes RC的机制？"></a>简述Kubernetes RC的机制？</h3><p>Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。当定义了RC并提交至Kubernetes集群中之后，Master节点上的Controller Manager组件获悉，并同时巡检系统中当前存活的目标Pod，并确保目标Pod实例的数量刚好等于此RC的期望值，若存在过多的Pod副本在运行，系统会停止一些Pod，反之则自动创建一些Pod。</p><h3 id="简述Kubernetes-Replica-Set-和-Replication-Controller-之间有什么区别？"><a href="#简述Kubernetes-Replica-Set-和-Replication-Controller-之间有什么区别？" class="headerlink" title="简述Kubernetes Replica Set 和 Replication Controller 之间有什么区别？"></a>简述Kubernetes Replica Set 和 Replication Controller 之间有什么区别？</h3><p>Replica Set 和 Replication Controller 类似，都是确保在任何给定时间运行指定数量的 Pod 副本。不同之处在于RS 使用基于集合的选择器，而 Replication Controller 使用基于权限的选择器。</p><h3 id="简述kube-proxy作用？"><a href="#简述kube-proxy作用？" class="headerlink" title="简述kube-proxy作用？"></a>简述kube-proxy作用？</h3><p>kube-proxy 运行在所有节点上，它监听 apiserver 中 service 和 endpoint 的变化情况，创建路由规则以提供服务 IP 和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p><h3 id="简述kube-proxy-iptables原理？"><a href="#简述kube-proxy-iptables原理？" class="headerlink" title="简述kube-proxy iptables原理？"></a>简述kube-proxy iptables原理？</h3><p>Kubernetes从1.2版本开始，将iptables作为kube-proxy的默认模式。iptables模式下的kube-proxy不再起到Proxy的作用，其核心功能：通过API Server的Watch接口实时跟踪Service与Endpoint的变更信息，并更新对应的iptables规则，Client的请求流量则通过iptables的NAT机制“直接路由”到目标Pod。</p><h3 id="简述kube-proxy-ipvs原理？"><a href="#简述kube-proxy-ipvs原理？" class="headerlink" title="简述kube-proxy ipvs原理？"></a>简述kube-proxy ipvs原理？</h3><p>IPVS在Kubernetes1.11中升级为GA稳定版。IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张，因此被kube-proxy采纳为最新模式。</p><p>在IPVS模式下，使用iptables的扩展ipset，而不是直接调用iptables来生成规则链。iptables规则链是一个线性的数据结构，ipset则引入了带索引的数据结构，因此当规则很多时，也可以很高效地查找和匹配。</p><p>可以将ipset简单理解为一个IP（段）的集合，这个集合的内容可以是IP地址、IP网段、端口等，iptables可以直接添加规则对这个“可变的集合”进行操作，这样做的好处在于可以大大减少iptables规则的数量，从而减少性能损耗。</p><h3 id="简述kube-proxy-ipvs和iptables的异同？"><a href="#简述kube-proxy-ipvs和iptables的异同？" class="headerlink" title="简述kube-proxy ipvs和iptables的异同？"></a>简述kube-proxy ipvs和iptables的异同？</h3><p>iptables与IPVS都是基于Netfilter实现的，但因为定位不同，二者有着本质的差别：iptables是为防火墙而设计的；IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张。</p><p>与iptables相比，IPVS拥有以下明显优势：</p><ul><li>1、为大型集群提供了更好的可扩展性和性能；</li><li>2、支持比iptables更复杂的复制均衡算法（最小负载、最少连接、加权等）；</li><li>3、支持服务器健康检查和连接重试等功能；</li><li>4、可以动态修改ipset的集合，即使iptables的规则正在使用这个集合。</li></ul><h3 id="简述Kubernetes中什么是静态Pod？"><a href="#简述Kubernetes中什么是静态Pod？" class="headerlink" title="简述Kubernetes中什么是静态Pod？"></a>简述Kubernetes中什么是静态Pod？</h3><p>静态pod是由kubelet进行管理的仅存在于特定Node的Pod上，他们不能通过API Server进行管理，无法与ReplicationController、Deployment或者DaemonSet进行关联，并且kubelet无法对他们进行健康检查。静态Pod总是由kubelet进行创建，并且总是在kubelet所在的Node上运行。</p><h3 id="简述Kubernetes中Pod可能位于的状态？"><a href="#简述Kubernetes中Pod可能位于的状态？" class="headerlink" title="简述Kubernetes中Pod可能位于的状态？"></a>简述Kubernetes中Pod可能位于的状态？</h3><ul><li>Pending：API Server已经创建该Pod，且Pod内还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程。</li><li>Running：Pod内所有容器均已创建，且至少有一个容器处于运行状态、正在启动状态或正在重启状态。</li><li>Succeeded：Pod内所有容器均成功执行退出，且不会重启。</li><li>Failed：Pod内所有容器均已退出，但至少有一个容器退出为失败状态。</li><li>Unknown：由于某种原因无法获取该Pod状态，可能由于网络通信不畅导致。</li></ul><h3 id="简述Kubernetes创建一个Pod的主要流程？"><a href="#简述Kubernetes创建一个Pod的主要流程？" class="headerlink" title="简述Kubernetes创建一个Pod的主要流程？"></a>简述Kubernetes创建一个Pod的主要流程？</h3><p>Kubernetes中创建一个Pod涉及多个组件之间联动，主要流程如下：</p><ul><li>1、客户端提交Pod的配置信息（可以是yaml文件定义的信息）到kube-apiserver。</li><li>2、Apiserver收到指令后，通知给controller-manager创建一个资源对象。</li><li>3、Controller-manager通过api-server将pod的配置信息存储到ETCD数据中心中。</li><li>4、Kube-scheduler检测到pod信息会开始调度预选，会先过滤掉不符合Pod资源配置要求的节点，然后开始调度调优，主要是挑选出更适合运行pod的节点，然后将pod的资源配置单发送到node节点上的kubelet组件上。</li><li>5、Kubelet根据scheduler发来的资源配置单运行pod，运行成功后，将pod的运行信息返回给scheduler，scheduler将返回的pod运行状况的信息存储到etcd数据中心。</li></ul><h3 id="简述Kubernetes中Pod的重启策略？"><a href="#简述Kubernetes中Pod的重启策略？" class="headerlink" title="简述Kubernetes中Pod的重启策略？"></a>简述Kubernetes中Pod的重启策略？</h3><p>Pod重启策略（RestartPolicy）应用于Pod内的所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或者健康检查失败时，kubelet将根据RestartPolicy的设置来进行相应操作。</p><p>Pod的重启策略包括Always、OnFailure和Never，默认值为Always。</p><ul><li>Always：当容器失效时，由kubelet自动重启该容器；</li><li>OnFailure：当容器终止运行且退出码不为0时，由kubelet自动重启该容器；</li><li>Never：不论容器运行状态如何，kubelet都不会重启该容器。</li></ul><p>同时Pod的重启策略与控制方式关联，当前可用于管理Pod的控制器包括ReplicationController、Job、DaemonSet及直接管理kubelet管理（静态Pod）。</p><p>不同控制器的重启策略限制如下：</p><ul><li>RC和DaemonSet：必须设置为Always，需要保证该容器持续运行；</li><li>Job：OnFailure或Never，确保容器执行完成后不再重启；</li><li>kubelet：在Pod失效时重启，不论将RestartPolicy设置为何值，也不会对Pod进行健康检查。</li></ul><h3 id="简述Kubernetes中Pod的健康检查方式？"><a href="#简述Kubernetes中Pod的健康检查方式？" class="headerlink" title="简述Kubernetes中Pod的健康检查方式？"></a>简述Kubernetes中Pod的健康检查方式？</h3><p>对Pod的健康检查可以通过两类探针来检查：LivenessProbe和ReadinessProbe。</p><ul><li>LivenessProbe探针：用于判断容器是否存活（running状态），如果LivenessProbe探针探测到容器不健康，则kubelet将杀掉该容器，并根据容器的重启策略做相应处理。若一个容器不包含LivenessProbe探针，kubelet认为该容器的LivenessProbe探针返回值用于是“Success”。</li><li>ReadineeProbe探针：用于判断容器是否启动完成（ready状态）。如果ReadinessProbe探针探测到失败，则Pod的状态将被修改。Endpoint Controller将从Service的Endpoint中删除包含该容器所在Pod的Eenpoint。</li><li>startupProbe探针：启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉。</li></ul><h3 id="简述Kubernetes-Pod的LivenessProbe探针的常见方式？"><a href="#简述Kubernetes-Pod的LivenessProbe探针的常见方式？" class="headerlink" title="简述Kubernetes Pod的LivenessProbe探针的常见方式？"></a>简述Kubernetes Pod的LivenessProbe探针的常见方式？</h3><p>kubelet定期执行LivenessProbe探针来诊断容器的健康状态，通常有以下三种方式：</p><ul><li>ExecAction：在容器内执行一个命令，若返回码为0，则表明容器健康。</li><li>TCPSocketAction：通过容器的IP地址和端口号执行TCP检查，若能建立TCP连接，则表明容器健康。</li><li>HTTPGetAction：通过容器的IP地址、端口号及路径调用HTTP Get方法，若响应的状态码大于等于200且小于400，则表明容器健康。</li></ul><h3 id="简述Kubernetes-Pod的常见调度方式？"><a href="#简述Kubernetes-Pod的常见调度方式？" class="headerlink" title="简述Kubernetes Pod的常见调度方式？"></a>简述Kubernetes Pod的常见调度方式？</h3><p>Kubernetes中，Pod通常是容器的载体，主要有如下常见调度方式：</p><ul><li>Deployment或RC：该调度策略主要功能就是自动部署一个容器应用的多份副本，以及持续监控副本的数量，在集群内始终维持用户指定的副本数量。</li><li>NodeSelector：定向调度，当需要手动指定将Pod调度到特定Node上，可以通过Node的标签（Label）和Pod的nodeSelector属性相匹配。</li><li>NodeAffinity亲和性调度：亲和性调度机制极大的扩展了Pod的调度能力，目前有两种节点亲和力表达：</li><li>requiredDuringSchedulingIgnoredDuringExecution：硬规则，必须满足指定的规则，调度器才可以调度Pod至Node上（类似nodeSelector，语法不同）。</li><li>preferredDuringSchedulingIgnoredDuringExecution：软规则，优先调度至满足的Node的节点，但不强求，多个优先级规则还可以设置权重值。</li><li>Taints和Tolerations（污点和容忍）：</li><li>Taint：使Node拒绝特定Pod运行；</li><li>Toleration：为Pod的属性，表示Pod能容忍（运行）标注了Taint的Node。</li></ul><h3 id="简述Kubernetes初始化容器（init-container）？"><a href="#简述Kubernetes初始化容器（init-container）？" class="headerlink" title="简述Kubernetes初始化容器（init container）？"></a>简述Kubernetes初始化容器（init container）？</h3><p>init container的运行方式与应用容器不同，它们必须先于应用容器执行完成，当设置了多个init container时，将按顺序逐个运行，并且只有前一个init container运行成功后才能运行后一个init container。当所有init container都成功运行后，Kubernetes才会初始化Pod的各种信息，并开始创建和运行应用容器。</p><h3 id="简述Kubernetes-deployment升级过程？"><a href="#简述Kubernetes-deployment升级过程？" class="headerlink" title="简述Kubernetes deployment升级过程？"></a>简述Kubernetes deployment升级过程？</h3><ul><li>初始创建Deployment时，系统创建了一个ReplicaSet，并按用户的需求创建了对应数量的Pod副本。</li><li>当更新Deployment时，系统创建了一个新的ReplicaSet，并将其副本数量扩展到1，然后将旧ReplicaSet缩减为2。</li><li>之后，系统继续按照相同的更新策略对新旧两个ReplicaSet进行逐个调整。</li><li>最后，新的ReplicaSet运行了对应个新版本Pod副本，旧的ReplicaSet副本数量则缩减为0。</li></ul><h3 id="简述Kubernetes-deployment升级策略？"><a href="#简述Kubernetes-deployment升级策略？" class="headerlink" title="简述Kubernetes deployment升级策略？"></a>简述Kubernetes deployment升级策略？</h3><p>在Deployment的定义中，可以通过spec.strategy指定Pod更新的策略，目前支持两种策略：Recreate（重建）和RollingUpdate（滚动更新），默认值为RollingUpdate。</p><ul><li>Recreate：设置spec.strategy.type=Recreate，表示Deployment在更新Pod时，会先杀掉所有正在运行的Pod，然后创建新的Pod。</li><li>RollingUpdate：设置spec.strategy.type=RollingUpdate，表示Deployment会以滚动更新的方式来逐个更新Pod。同时，可以通过设置spec.strategy.rollingUpdate下的两个参数（maxUnavailable和maxSurge）来控制滚动更新的过程。</li></ul><h3 id="简述Kubernetes-DaemonSet类型的资源特性？"><a href="#简述Kubernetes-DaemonSet类型的资源特性？" class="headerlink" title="简述Kubernetes DaemonSet类型的资源特性？"></a>简述Kubernetes DaemonSet类型的资源特性？</h3><p>DaemonSet资源对象会在每个Kubernetes集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。因此，在定义yaml文件中，不支持定义replicas。</p><p>它的一般使用场景如下：</p><ul><li>在去做每个节点的日志收集工作。</li><li>监控每个节点的的运行状态。</li></ul><h3 id="简述Kubernetes自动扩容机制？"><a href="#简述Kubernetes自动扩容机制？" class="headerlink" title="简述Kubernetes自动扩容机制？"></a>简述Kubernetes自动扩容机制？</h3><p>Kubernetes使用Horizontal Pod Autoscaler（HPA）的控制器实现基于CPU使用率进行自动Pod扩缩容的功能。HPA控制器周期性地监测目标Pod的资源性能指标，并与HPA资源对象中的扩缩容条件进行对比，在满足条件时对Pod副本数量进行调整。</p><ul><li>HPA原理</li></ul><p>Kubernetes中的某个Metrics Server（Heapster或自定义Metrics Server）持续采集所有Pod副本的指标数据。HPA控制器通过Metrics Server的API（Heapster的API或聚合API）获取这些数据，基于用户定义的扩缩容规则进行计算，得到目标Pod副本数量。</p><p>当目标Pod副本数量与当前副本数量不同时，HPA控制器就向Pod的副本控制器（Deployment、RC或ReplicaSet）发起scale操作，调整Pod的副本数量，完成扩缩容操作。</p><h3 id="简述Kubernetes-Service类型？"><a href="#简述Kubernetes-Service类型？" class="headerlink" title="简述Kubernetes Service类型？"></a>简述Kubernetes Service类型？</h3><p>通过创建Service，可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发到后端的各个容器应用上。其主要类型有：</p><ul><li>ClusterIP：虚拟的服务IP地址，该地址用于Kubernetes集群内部的Pod访问，在Node上kube-proxy通过设置的iptables规则进行转发；</li><li>NodePort：使用宿主机的端口，使能够访问各Node的外部客户端通过Node的IP地址和端口号就能访问服务；</li><li>LoadBalancer：使用外接负载均衡器完成到服务的负载分发，需要在spec.status.loadBalancer字段指定外部负载均衡器的IP地址，通常用于公有云。</li></ul><h3 id="简述Kubernetes-Service分发后端的策略？"><a href="#简述Kubernetes-Service分发后端的策略？" class="headerlink" title="简述Kubernetes Service分发后端的策略？"></a>简述Kubernetes Service分发后端的策略？</h3><p>Service负载分发的策略有：RoundRobin和SessionAffinity</p><ul><li>RoundRobin：默认为轮询模式，即轮询将请求转发到后端的各个Pod上。</li><li>SessionAffinity：基于客户端IP地址进行会话保持的模式，即第1次将某个客户端发起的请求转发到后端的某个Pod上，之后从相同的客户端发起的请求都将被转发到后端相同的Pod上。</li></ul><h3 id="简述Kubernetes-Headless-Service？"><a href="#简述Kubernetes-Headless-Service？" class="headerlink" title="简述Kubernetes Headless Service？"></a>简述Kubernetes Headless Service？</h3><p>在某些应用场景中，若需要人为指定负载均衡器，不使用Service提供的默认负载均衡的功能，或者应用程序希望知道属于同组服务的其他实例。Kubernetes提供了Headless Service来实现这种功能，即不为Service设置ClusterIP（入口IP地址），仅通过Label Selector将后端的Pod列表返回给调用的客户端。</p><h3 id="简述Kubernetes外部如何访问集群内的服务？"><a href="#简述Kubernetes外部如何访问集群内的服务？" class="headerlink" title="简述Kubernetes外部如何访问集群内的服务？"></a>简述Kubernetes外部如何访问集群内的服务？</h3><p>对于Kubernetes，集群外的客户端默认情况，无法通过Pod的IP地址或者Service的虚拟IP地址:虚拟端口号进行访问。通常可以通过以下方式进行访问Kubernetes集群内的服务：</p><ul><li>映射Pod到物理机：将Pod端口号映射到宿主机，即在Pod中采用hostPort方式，以使客户端应用能够通过物理机访问容器应用。</li><li>映射Service到物理机：将Service端口号映射到宿主机，即在Service中采用nodePort方式，以使客户端应用能够通过物理机访问容器应用。</li><li>映射Sercie到LoadBalancer：通过设置LoadBalancer映射到云服务商提供的LoadBalancer地址。这种用法仅用于在公有云服务提供商的云平台上设置Service的场景。</li></ul><h3 id="简述Kubernetes-ingress？"><a href="#简述Kubernetes-ingress？" class="headerlink" title="简述Kubernetes ingress？"></a>简述Kubernetes ingress？</h3><p>Kubernetes的Ingress资源对象，用于将不同URL的访问请求转发到后端不同的Service，以实现HTTP层的业务路由机制。</p><p>Kubernetes使用了Ingress策略和Ingress Controller，两者结合并实现了一个完整的Ingress负载均衡器。使用Ingress进行负载分发时，Ingress Controller基于Ingress规则将客户端请求直接转发到Service对应的后端Endpoint（Pod）上，从而跳过kube-proxy的转发功能，kube-proxy不再起作用，全过程为：ingress controller + ingress 规则 —-&gt; services。</p><p>同时当Ingress Controller提供的是对外服务，则实际上实现的是边缘路由器的功能。</p><h3 id="简述Kubernetes镜像的下载策略？"><a href="#简述Kubernetes镜像的下载策略？" class="headerlink" title="简述Kubernetes镜像的下载策略？"></a>简述Kubernetes镜像的下载策略？</h3><p>K8s的镜像下载策略有三种：Always、Never、IFNotPresent。</p><ul><li>Always：镜像标签为latest时，总是从指定的仓库中获取镜像。</li><li>Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像。</li><li>IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载。默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent。</li></ul><h3 id="简述Kubernetes的负载均衡器？"><a href="#简述Kubernetes的负载均衡器？" class="headerlink" title="简述Kubernetes的负载均衡器？"></a>简述Kubernetes的负载均衡器？</h3><p>负载均衡器是暴露服务的最常见和标准方式之一。</p><p>根据工作环境使用两种类型的负载均衡器，即内部负载均衡器或外部负载均衡器。内部负载均衡器自动平衡负载并使用所需配置分配容器，而外部负载均衡器将流量从外部负载引导至后端容器。</p><h3 id="简述Kubernetes各模块如何与API-Server通信？"><a href="#简述Kubernetes各模块如何与API-Server通信？" class="headerlink" title="简述Kubernetes各模块如何与API Server通信？"></a>简述Kubernetes各模块如何与API Server通信？</h3><p>Kubernetes API Server作为集群的核心，负责集群各功能模块之间的通信。集群内的各个功能模块通过API Server将信息存入etcd，当需要获取和操作这些数据时，则通过API Server提供的REST接口（用GET、LIST或WATCH方法）来实现，从而实现各模块之间的信息交互。</p><p>如kubelet进程与API Server的交互：每个Node上的kubelet每隔一个时间周期，就会调用一次API Server的REST接口报告自身状态，API Server在接收到这些信息后，会将节点状态信息更新到etcd中。</p><p>如kube-controller-manager进程与API Server的交互：kube-controller-manager中的Node Controller模块通过API Server提供的Watch接口实时监控Node的信息，并做相应处理。</p><p>如kube-scheduler进程与API Server的交互：Scheduler通过API Server的Watch接口监听到新建Pod副本的信息后，会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑，在调度成功后将Pod绑定到目标节点上。</p><h3 id="简述Kubernetes-Scheduler作用及实现原理？"><a href="#简述Kubernetes-Scheduler作用及实现原理？" class="headerlink" title="简述Kubernetes Scheduler作用及实现原理？"></a>简述Kubernetes Scheduler作用及实现原理？</h3><p>Kubernetes Scheduler是负责Pod调度的重要功能模块，Kubernetes Scheduler在整个系统中承担了“承上启下”的重要功能，“承上”是指它负责接收Controller Manager创建的新Pod，为其调度至目标Node；“启下”是指调度完成后，目标Node上的kubelet服务进程接管后继工作，负责Pod接下来生命周期。</p><p>Kubernetes Scheduler的作用是将待调度的Pod（API新创建的Pod、Controller Manager为补足副本而创建的Pod等）按照特定的调度算法和调度策略绑定（Binding）到集群中某个合适的Node上，并将绑定信息写入etcd中。</p><p>在整个调度过程中涉及三个对象，分别是待调度Pod列表、可用Node列表，以及调度算法和策略。</p><p>Kubernetes Scheduler通过调度算法调度为待调度Pod列表中的每个Pod从Node列表中选择一个最适合的Node来实现Pod的调度。随后，目标节点上的kubelet通过API Server监听到Kubernetes Scheduler产生的Pod绑定事件，然后获取对应的Pod清单，下载Image镜像并启动容器。</p><h3 id="简述Kubernetes-Scheduler使用哪两种算法将Pod绑定到worker节点？"><a href="#简述Kubernetes-Scheduler使用哪两种算法将Pod绑定到worker节点？" class="headerlink" title="简述Kubernetes Scheduler使用哪两种算法将Pod绑定到worker节点？"></a>简述Kubernetes Scheduler使用哪两种算法将Pod绑定到worker节点？</h3><p>Kubernetes Scheduler根据如下两种调度算法将 Pod 绑定到最合适的工作节点：</p><ul><li>预选（Predicates）：输入是所有节点，输出是满足预选条件的节点。kube-scheduler根据预选策略过滤掉不满足策略的Nodes。如果某节点的资源不足或者不满足预选策略的条件则无法通过预选。如“Node的label必须与Pod的Selector一致”。</li><li>优选（Priorities）：输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的Nodes进行打分排名，选择得分最高的Node。例如，资源越富裕、负载越小的Node可能具有越高的排名。</li></ul><h3 id="简述Kubernetes-kubelet的作用？"><a href="#简述Kubernetes-kubelet的作用？" class="headerlink" title="简述Kubernetes kubelet的作用？"></a>简述Kubernetes kubelet的作用？</h3><p>在Kubernetes集群中，在每个Node（又称Worker）上都会启动一个kubelet服务进程。该进程用于处理Master下发到本节点的任务，管理Pod及Pod中的容器。每个kubelet进程都会在API Server上注册节点自身的信息，定期向Master汇报节点资源的使用情况，并通过cAdvisor监控容器和节点资源。</p><h3 id="简述Kubernetes-kubelet监控Worker节点资源是使用什么组件来实现的？"><a href="#简述Kubernetes-kubelet监控Worker节点资源是使用什么组件来实现的？" class="headerlink" title="简述Kubernetes kubelet监控Worker节点资源是使用什么组件来实现的？"></a>简述Kubernetes kubelet监控Worker节点资源是使用什么组件来实现的？</h3><p>kubelet使用cAdvisor对worker节点资源进行监控。在 Kubernetes 系统中，cAdvisor 已被默认集成到 kubelet 组件内，当 kubelet 服务启动时，它会自动启动 cAdvisor 服务，然后 cAdvisor 会实时采集所在节点的性能指标及在节点上运行的容器的性能指标。</p><h3 id="简述Kubernetes如何保证集群的安全性？"><a href="#简述Kubernetes如何保证集群的安全性？" class="headerlink" title="简述Kubernetes如何保证集群的安全性？"></a>简述Kubernetes如何保证集群的安全性？</h3><p>Kubernetes通过一系列机制来实现集群的安全控制，主要有如下不同的维度：</p><ul><li><p>基础设施方面：保证容器与其所在宿主机的隔离；</p></li><li><p>权限方面：</p></li><li><ul><li>最小权限原则：合理限制所有组件的权限，确保组件只执行它被授权的行为，通过限制单个组件的能力来限制它的权限范围。</li><li>用户权限：划分普通用户和管理员的角色。</li></ul></li><li><p>集群方面：</p></li><li><ul><li>API Server的认证授权：Kubernetes集群中所有资源的访问和变更都是通过Kubernetes API Server来实现的，因此需要建议采用更安全的HTTPS或Token来识别和认证客户端身份（Authentication），以及随后访问权限的授权（Authorization）环节。</li><li>API Server的授权管理：通过授权策略来决定一个API调用是否合法。对合法用户进行授权并且随后在用户访问时进行鉴权，建议采用更安全的RBAC方式来提升集群安全授权。</li><li>敏感数据引入Secret机制：对于集群敏感数据建议使用Secret方式进行保护。</li><li>AdmissionControl（准入机制）：对kubernetes api的请求过程中，顺序为：先经过认证 &amp; 授权，然后执行准入操作，最后对目标对象进行操作。</li></ul></li></ul><h3 id="简述Kubernetes准入机制？"><a href="#简述Kubernetes准入机制？" class="headerlink" title="简述Kubernetes准入机制？"></a>简述Kubernetes准入机制？</h3><p>在对集群进行请求时，每个准入控制代码都按照一定顺序执行。如果有一个准入控制拒绝了此次请求，那么整个请求的结果将会立即返回，并提示用户相应的error信息。</p><p>准入控制（AdmissionControl）准入控制本质上为一段准入代码，在对kubernetes api的请求过程中，顺序为：先经过认证 &amp; 授权，然后执行准入操作，最后对目标对象进行操作。常用组件（控制代码）如下：</p><ul><li>AlwaysAdmit：允许所有请求</li><li>AlwaysDeny：禁止所有请求，多用于测试环境。</li><li>ServiceAccount：它将serviceAccounts实现了自动化，它会辅助serviceAccount做一些事情，比如如果pod没有serviceAccount属性，它会自动添加一个default，并确保pod的serviceAccount始终存在。</li><li>LimitRanger：观察所有的请求，确保没有违反已经定义好的约束条件，这些条件定义在namespace中LimitRange对象中。</li><li>NamespaceExists：观察所有的请求，如果请求尝试创建一个不存在的namespace，则这个请求被拒绝。</li></ul><h3 id="简述Kubernetes-RBAC及其特点（优势）？"><a href="#简述Kubernetes-RBAC及其特点（优势）？" class="headerlink" title="简述Kubernetes RBAC及其特点（优势）？"></a>简述Kubernetes RBAC及其特点（优势）？</h3><p>RBAC是基于角色的访问控制，是一种基于个人用户的角色来管理对计算机或网络资源的访问的方法。</p><p>相对于其他授权模式，RBAC具有如下优势：</p><ul><li>对集群中的资源和非资源权限均有完整的覆盖。</li><li>整个RBAC完全由几个API对象完成， 同其他API对象一样， 可以用kubectl或API进行操作。</li><li>可以在运行时进行调整，无须重新启动API Server。</li></ul><h3 id="简述Kubernetes-Secret作用？"><a href="#简述Kubernetes-Secret作用？" class="headerlink" title="简述Kubernetes Secret作用？"></a>简述Kubernetes Secret作用？</h3><p>Secret对象，主要作用是保管私密数据，比如密码、OAuth Tokens、SSH Keys等信息。将这些私密信息放在Secret对象中比直接放在Pod或Docker Image中更安全，也更便于使用和分发。</p><h3 id="简述Kubernetes-Secret有哪些使用方式？"><a href="#简述Kubernetes-Secret有哪些使用方式？" class="headerlink" title="简述Kubernetes Secret有哪些使用方式？"></a>简述Kubernetes Secret有哪些使用方式？</h3><p>创建完secret之后，可通过如下三种方式使用：</p><ul><li>在创建Pod时，通过为Pod指定Service Account来自动使用该Secret。</li><li>通过挂载该Secret到Pod来使用它。</li><li>在Docker镜像下载时使用，通过指定Pod的spc.ImagePullSecrets来引用它。</li></ul><h3 id="简述Kubernetes-PodSecurityPolicy机制？"><a href="#简述Kubernetes-PodSecurityPolicy机制？" class="headerlink" title="简述Kubernetes PodSecurityPolicy机制？"></a>简述Kubernetes PodSecurityPolicy机制？</h3><p>Kubernetes PodSecurityPolicy是为了更精细地控制Pod对资源的使用方式以及提升安全策略。在开启PodSecurityPolicy准入控制器后，Kubernetes默认不允许创建任何Pod，需要创建PodSecurityPolicy策略和相应的RBAC授权策略（Authorizing Policies），Pod才能创建成功。</p><h3 id="简述Kubernetes-PodSecurityPolicy机制能实现哪些安全策略？"><a href="#简述Kubernetes-PodSecurityPolicy机制能实现哪些安全策略？" class="headerlink" title="简述Kubernetes PodSecurityPolicy机制能实现哪些安全策略？"></a>简述Kubernetes PodSecurityPolicy机制能实现哪些安全策略？</h3><p>在PodSecurityPolicy对象中可以设置不同字段来控制Pod运行时的各种安全策略，常见的有：</p><ul><li>特权模式：privileged是否允许Pod以特权模式运行。</li><li>宿主机资源：控制Pod对宿主机资源的控制，如hostPID：是否允许Pod共享宿主机的进程空间。</li><li>用户和组：设置运行容器的用户ID（范围）或组（范围）。</li><li>提升权限：AllowPrivilegeEscalation：设置容器内的子进程是否可以提升权限，通常在设置非root用户（MustRunAsNonRoot）时进行设置。</li><li>SELinux：进行SELinux的相关配置。</li></ul><h3 id="简述Kubernetes网络模型？"><a href="#简述Kubernetes网络模型？" class="headerlink" title="简述Kubernetes网络模型？"></a>简述Kubernetes网络模型？</h3><p>Kubernetes网络模型中每个Pod都拥有一个独立的IP地址，并假定所有Pod都在一个可以直接连通的、扁平的网络空间中。所以不管它们是否运行在同一个Node（宿主机）中，都要求它们可以直接通过对方的IP进行访问。设计这个原则的原因是，用户不需要额外考虑如何建立Pod之间的连接，也不需要考虑如何将容器端口映射到主机端口等问题。</p><p>同时为每个Pod都设置一个IP地址的模型使得同一个Pod内的不同容器会共享同一个网络命名空间，也就是同一个Linux网络协议栈。这就意味着同一个Pod内的容器可以通过localhost来连接对方的端口。</p><p>在Kubernetes的集群里，IP是以Pod为单位进行分配的。一个Pod内部的所有容器共享一个网络堆栈（相当于一个网络命名空间，它们的IP地址、网络设备、配置等都是共享的）。</p><h3 id="简述Kubernetes-CNI模型？"><a href="#简述Kubernetes-CNI模型？" class="headerlink" title="简述Kubernetes CNI模型？"></a>简述Kubernetes CNI模型？</h3><p>CNI提供了一种应用容器的插件化网络解决方案，定义对容器网络进行操作和配置的规范，通过插件的形式对CNI接口进行实现。CNI仅关注在创建容器时分配网络资源，和在销毁容器时删除网络资源。在CNI模型中只涉及两个概念：容器和网络。</p><ul><li>容器（Container）：是拥有独立Linux网络命名空间的环境，例如使用Docker或rkt创建的容器。容器需要拥有自己的Linux网络命名空间，这是加入网络的必要条件。</li><li>网络（Network）：表示可以互连的一组实体，这些实体拥有各自独立、唯一的IP地址，可以是容器、物理机或者其他网络设备（比如路由器）等。</li></ul><p>对容器网络的设置和操作都通过插件（Plugin）进行具体实现，CNI插件包括两种类型：CNI Plugin和IPAM（IP Address  Management）Plugin。CNI Plugin负责为容器配置网络资源，IPAM Plugin负责对容器的IP地址进行分配和管理。IPAM Plugin作为CNI Plugin的一部分，与CNI Plugin协同工作。</p><h3 id="简述Kubernetes网络策略？"><a href="#简述Kubernetes网络策略？" class="headerlink" title="简述Kubernetes网络策略？"></a>简述Kubernetes网络策略？</h3><p>为实现细粒度的容器间网络访问隔离策略，Kubernetes引入Network Policy。</p><p>Network Policy的主要功能是对Pod间的网络通信进行限制和准入控制，设置允许访问或禁止访问的客户端Pod列表。Network Policy定义网络策略，配合策略控制器（Policy Controller）进行策略的实现。</p><h3 id="简述Kubernetes网络策略原理？"><a href="#简述Kubernetes网络策略原理？" class="headerlink" title="简述Kubernetes网络策略原理？"></a>简述Kubernetes网络策略原理？</h3><p>Network Policy的工作原理主要为：policy controller需要实现一个API Listener，监听用户设置的Network Policy定义，并将网络访问规则通过各Node的Agent进行实际设置（Agent则需要通过CNI网络插件实现）。</p><h3 id="简述Kubernetes中flannel的作用？"><a href="#简述Kubernetes中flannel的作用？" class="headerlink" title="简述Kubernetes中flannel的作用？"></a>简述Kubernetes中flannel的作用？</h3><p>Flannel可以用于Kubernetes底层网络的实现，主要作用有：</p><ul><li>它能协助Kubernetes，给每一个Node上的Docker容器都分配互相不冲突的IP地址。</li><li>它能在这些IP地址之间建立一个覆盖网络（Overlay Network），通过这个覆盖网络，将数据包原封不动地传递到目标容器内。</li></ul><h3 id="简述Kubernetes-Calico网络组件实现原理？"><a href="#简述Kubernetes-Calico网络组件实现原理？" class="headerlink" title="简述Kubernetes Calico网络组件实现原理？"></a>简述Kubernetes Calico网络组件实现原理？</h3><p>Calico是一个基于BGP的纯三层的网络方案，与OpenStack、Kubernetes、AWS、GCE等云平台都能够良好地集成。</p><p>Calico在每个计算节点都利用Linux Kernel实现了一个高效的vRouter来负责数据转发。每个vRouter都通过BGP协议把在本节点上运行的容器的路由信息向整个Calico网络广播，并自动设置到达其他节点的路由转发规则。</p><p>Calico保证所有容器之间的数据流量都是通过IP路由的方式完成互联互通的。Calico节点组网时可以直接利用数据中心的网络结构（L2或者L3），不需要额外的NAT、隧道或者Overlay Network，没有额外的封包解包，能够节约CPU运算，提高网络效率。</p><h3 id="简述Kubernetes共享存储的作用？"><a href="#简述Kubernetes共享存储的作用？" class="headerlink" title="简述Kubernetes共享存储的作用？"></a>简述Kubernetes共享存储的作用？</h3><p>Kubernetes对于有状态的容器应用或者对数据需要持久化的应用，因此需要更加可靠的存储来保存应用产生的重要数据，以便容器应用在重建之后仍然可以使用之前的数据。因此需要使用共享存储。</p><h3 id="简述Kubernetes数据持久化的方式有哪些？"><a href="#简述Kubernetes数据持久化的方式有哪些？" class="headerlink" title="简述Kubernetes数据持久化的方式有哪些？"></a>简述Kubernetes数据持久化的方式有哪些？</h3><p>Kubernetes通过数据持久化来持久化保存重要数据，常见的方式有：</p><ul><li><p>EmptyDir（空目录）：没有指定要挂载宿主机上的某个目录，直接由Pod内保部映射到宿主机上。类似于docker中的manager volume。</p></li><li><p>场景：</p></li><li><ul><li>只需要临时将数据保存在磁盘上，比如在合并/排序算法中；</li><li>作为两个容器的共享存储。</li></ul></li><li><p>特性：</p></li><li><ul><li>同个pod里面的不同容器，共享同一个持久化目录，当pod节点删除时，volume的数据也会被删除。</li><li>emptyDir的数据持久化的生命周期和使用的pod一致，一般是作为临时存储使用。</li></ul></li><li><p>Hostpath：将宿主机上已存在的目录或文件挂载到容器内部。类似于docker中的bind mount挂载方式。</p></li><li><ul><li>特性：增加了pod与节点之间的耦合。</li></ul></li></ul><p>PersistentVolume（简称PV）：如基于NFS服务的PV，也可以基于GFS的PV。它的作用是统一数据持久化目录，方便管理。</p><h3 id="简述Kubernetes-PV和PVC？"><a href="#简述Kubernetes-PV和PVC？" class="headerlink" title="简述Kubernetes PV和PVC？"></a>简述Kubernetes PV和PVC？</h3><p>PV是对底层网络共享存储的抽象，将共享存储定义为一种“资源”。</p><p>PVC则是用户对存储资源的一个“申请”。</p><h3 id="简述Kubernetes-PV生命周期内的阶段？"><a href="#简述Kubernetes-PV生命周期内的阶段？" class="headerlink" title="简述Kubernetes PV生命周期内的阶段？"></a>简述Kubernetes PV生命周期内的阶段？</h3><p>某个PV在生命周期中可能处于以下4个阶段（Phaes）之一。</p><ul><li>Available：可用状态，还未与某个PVC绑定。</li><li>Bound：已与某个PVC绑定。</li><li>Released：绑定的PVC已经删除，资源已释放，但没有被集群回收。</li><li>Failed：自动资源回收失败。</li></ul><h3 id="简述Kubernetes所支持的存储供应模式？"><a href="#简述Kubernetes所支持的存储供应模式？" class="headerlink" title="简述Kubernetes所支持的存储供应模式？"></a>简述Kubernetes所支持的存储供应模式？</h3><p>Kubernetes支持两种资源的存储供应模式：静态模式（Static）和动态模式（Dynamic）。</p><ul><li>静态模式：集群管理员手工创建许多PV，在定义PV时需要将后端存储的特性进行设置。</li><li>动态模式：集群管理员无须手工创建PV，而是通过StorageClass的设置对后端存储进行描述，标记为某种类型。此时要求PVC对存储的类型进行声明，系统将自动完成PV的创建及与PVC的绑定。</li></ul><h3 id="简述Kubernetes-CSI模型？"><a href="#简述Kubernetes-CSI模型？" class="headerlink" title="简述Kubernetes CSI模型？"></a>简述Kubernetes CSI模型？</h3><p>Kubernetes CSI是Kubernetes推出与容器对接的存储接口标准，存储提供方只需要基于标准接口进行存储插件的实现，就能使用Kubernetes的原生存储机制为容器提供存储服务。CSI使得存储提供方的代码能和Kubernetes代码彻底解耦，部署也与Kubernetes核心组件分离，显然，存储插件的开发由提供方自行维护，就能为Kubernetes用户提供更多的存储功能，也更加安全可靠。</p><p>CSI包括CSI Controller和CSI Node：</p><ul><li>CSI Controller的主要功能是提供存储服务视角对存储资源和存储卷进行管理和操作。</li><li>CSI Node的主要功能是对主机（Node）上的Volume进行管理和操作。</li></ul><h3 id="简述Kubernetes-Worker节点加入集群的过程？"><a href="#简述Kubernetes-Worker节点加入集群的过程？" class="headerlink" title="简述Kubernetes Worker节点加入集群的过程？"></a>简述Kubernetes Worker节点加入集群的过程？</h3><p>通常需要对Worker节点进行扩容，从而将应用系统进行水平扩展。主要过程如下：</p><ul><li>1、在该Node上安装Docker、kubelet和kube-proxy服务；</li><li>2、然后配置kubelet和kubeproxy的启动参数，将Master URL指定为当前Kubernetes集群Master的地址，最后启动这些服务；</li><li>3、通过kubelet默认的自动注册机制，新的Worker将会自动加入现有的Kubernetes集群中；</li><li>4、Kubernetes Master在接受了新Worker的注册之后，会自动将其纳入当前集群的调度范围。</li></ul><h3 id="简述Kubernetes-Pod如何实现对节点的资源控制？"><a href="#简述Kubernetes-Pod如何实现对节点的资源控制？" class="headerlink" title="简述Kubernetes Pod如何实现对节点的资源控制？"></a>简述Kubernetes Pod如何实现对节点的资源控制？</h3><p>Kubernetes集群里的节点提供的资源主要是计算资源，计算资源是可计量的能被申请、分配和使用的基础资源。当前Kubernetes集群中的计算资源主要包括CPU、GPU及Memory。CPU与Memory是被Pod使用的，因此在配置Pod时可以通过参数CPU Request及Memory Request为其中的每个容器指定所需使用的CPU与Memory量，Kubernetes会根据Request的值去查找有足够资源的Node来调度此Pod。</p><p>通常，一个程序所使用的CPU与Memory是一个动态的量，确切地说，是一个范围，跟它的负载密切相关：负载增加时，CPU和Memory的使用量也会增加。</p><h3 id="简述Kubernetes-Requests和Limits如何影响Pod的调度？"><a href="#简述Kubernetes-Requests和Limits如何影响Pod的调度？" class="headerlink" title="简述Kubernetes Requests和Limits如何影响Pod的调度？"></a>简述Kubernetes Requests和Limits如何影响Pod的调度？</h3><p>当一个Pod创建成功时，Kubernetes调度器（Scheduler）会为该Pod选择一个节点来执行。对于每种计算资源（CPU和Memory）而言，每个节点都有一个能用于运行Pod的最大容量值。调度器在调度时，首先要确保调度后该节点上所有Pod的CPU和内存的Requests总和，不超过该节点能提供给Pod使用的CPU和Memory的最大容量值。</p><h3 id="简述Kubernetes-Metric-Service？"><a href="#简述Kubernetes-Metric-Service？" class="headerlink" title="简述Kubernetes Metric Service？"></a>简述Kubernetes Metric Service？</h3><p>在Kubernetes从1.10版本后采用Metrics Server作为默认的性能数据采集和监控，主要用于提供核心指标（Core Metrics），包括Node、Pod的CPU和内存使用指标。</p><p>对其他自定义指标（Custom Metrics）的监控则由Prometheus等组件来完成。</p><h3 id="简述Kubernetes中，如何使用EFK实现日志的统一管理？"><a href="#简述Kubernetes中，如何使用EFK实现日志的统一管理？" class="headerlink" title="简述Kubernetes中，如何使用EFK实现日志的统一管理？"></a>简述Kubernetes中，如何使用EFK实现日志的统一管理？</h3><p>在Kubernetes集群环境中，通常一个完整的应用或服务涉及组件过多，建议对日志系统进行集中化管理，通常采用EFK实现。</p><p>EFK是 Elasticsearch、Fluentd 和 Kibana 的组合，其各组件功能如下：</p><ul><li>Elasticsearch：是一个搜索引擎，负责存储日志并提供查询接口；</li><li>Fluentd：负责从 Kubernetes 搜集日志，每个node节点上面的fluentd监控并收集该节点上面的系统日志，并将处理过后的日志信息发送给Elasticsearch；</li><li>Kibana：提供了一个 Web GUI，用户可以浏览和搜索存储在 Elasticsearch 中的日志。</li></ul><p>通过在每台node上部署一个以DaemonSet方式运行的fluentd来收集每台node上的日志。Fluentd将docker日志目录/var/lib/docker/containers和/var/log目录挂载到Pod中，然后Pod会在node节点的/var/log/pods目录中创建新的目录，可以区别不同的容器日志输出，该目录下有一个日志文件链接到/var/lib/docker/contianers目录下的容器日志输出。</p><h3 id="简述Kubernetes如何进行优雅的节点关机维护？"><a href="#简述Kubernetes如何进行优雅的节点关机维护？" class="headerlink" title="简述Kubernetes如何进行优雅的节点关机维护？"></a>简述Kubernetes如何进行优雅的节点关机维护？</h3><p>由于Kubernetes节点运行大量Pod，因此在进行关机维护之前，建议先使用kubectl drain将该节点的Pod进行驱逐，然后进行关机维护。</p><h3 id="简述Kubernetes集群联邦？"><a href="#简述Kubernetes集群联邦？" class="headerlink" title="简述Kubernetes集群联邦？"></a>简述Kubernetes集群联邦？</h3><p>Kubernetes集群联邦可以将多个Kubernetes集群作为一个集群进行管理。因此，可以在一个数据中心/云中创建多个Kubernetes集群，并使用集群联邦在一个地方控制/管理所有集群。</p><h3 id="简述Helm及其优势？"><a href="#简述Helm及其优势？" class="headerlink" title="简述Helm及其优势？"></a>简述Helm及其优势？</h3><p>Helm 是 Kubernetes 的软件包管理工具。类似 Ubuntu 中使用的apt、Centos中使用的yum 或者Python中的 pip 一样。</p><p>Helm能够将一组K8S资源打包统一管理, 是查找、共享和使用为Kubernetes构建的软件的最佳方式。</p><p>Helm中通常每个包称为一个Chart，一个Chart是一个目录（一般情况下会将目录进行打包压缩，形成name-version.tgz格式的单一文件，方便传输和存储）。</p><ul><li>Helm优势</li></ul><p>在 Kubernetes中部署一个可以使用的应用，需要涉及到很多的 Kubernetes 资源的共同协作。使用helm则具有如下优势：</p><ul><li><p>统一管理、配置和更新这些分散的 k8s 的应用资源文件；</p></li><li><p>分发和复用一套应用模板；</p></li><li><p>将应用的一系列资源当做一个软件包管理。</p></li><li><p>对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。</p><p>对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--公司业务问题 </title>
    <link href="/2021/03/03/interview-questions1-company/"/>
    <url>/2021/03/03/interview-questions1-company/</url>
    
    <content type="html"><![CDATA[<h2 id="公司业务问题"><a href="#公司业务问题" class="headerlink" title="公司业务问题"></a>公司业务问题</h2><table><thead><tr><th>并发（系统同时处理的request/事务数）</th><th>3万</th></tr></thead><tbody><tr><td>QPS（每秒查询率）</td><td>2万</td></tr><tr><td>PV（点击量）</td><td>3千万</td></tr><tr><td>UV（用户量）</td><td>30万</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--Redis问题 </title>
    <link href="/2021/03/03/interview-questions10-redis/"/>
    <url>/2021/03/03/interview-questions10-redis/</url>
    
    <content type="html"><![CDATA[<h2 id="Redis-面试问题"><a href="#Redis-面试问题" class="headerlink" title="Redis 面试问题"></a>Redis 面试问题</h2><h3 id="1、redis的特点及优势"><a href="#1、redis的特点及优势" class="headerlink" title="1、redis的特点及优势"></a>1、redis的特点及优势</h3><p><strong>特点：</strong></p><ul><li>Redis 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。</li><li>Redis 支持数据的备份，即 master-slave 模式的数据备份。</li></ul><p><strong>优势：</strong></p><ul><li>性能极高：Redis 能读的速度是 110000 次/s，写的速度是 81000 次/s。</li><li>丰富的数据类型：Redis 支持二进制案例的 Strings，Lists，Hashes，Sets 及 Ordered Sets 数据类型操作。</li><li>原子：Redis 的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过 MULTI 和 EXEC 指令包起来。</li><li>丰富的特性：Redis 还支持 publish/subscribe，通知，key 过期等等特性。</li></ul><h3 id="2、redis的数据类型"><a href="#2、redis的数据类型" class="headerlink" title="2、redis的数据类型"></a>2、redis的数据类型</h3><p>Redis 支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及 zsetsorted set（有序集合）。</p><div class="note note-success">            <p>我们实际项目中比较常用的是 string，hash </p><p>如果你是 Redis 中高级用户，还需要加上下面几种数据结构 HyperLogLog、Geo、Pub/Sub。</p><p>如果你说还玩过 Redis Module，像 BloomFilter，RedisSearch，Redis-ML，面试官的眼睛就开始发亮了。</p>          </div><h3 id="3、redis是单进程单线程的？"><a href="#3、redis是单进程单线程的？" class="headerlink" title="3、redis是单进程单线程的？"></a>3、redis是单进程单线程的？</h3><p>Redis 是单进程单线程的，Redis 利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销。</p><div class="note note-success">            <p>redis4.0开始就有多线程的概念了，比如 Redis 通过多线程方式在后台删除对象、以及通过 Redis 模块实现的阻塞命</p><p>令等。</p><p>redis在6.0版本中引入了多线程，默认不开启，需要修改配置文件 io-threads-do-reads yes，io-threads 线程数</p><p>官方建议：4 核的机器建议设置为 2 或 3 个线程，8 核的建议设置为 6 个线程，线程数一定要小于机器核数，尽量不超过8个。</p>          </div><h3 id="4、一个字符串类型的智能存储最大容量是多少"><a href="#4、一个字符串类型的智能存储最大容量是多少" class="headerlink" title="4、一个字符串类型的智能存储最大容量是多少"></a>4、一个字符串类型的智能存储最大容量是多少</h3><p>512M</p><h3 id="5、redis主从同步原理-还有从从同步"><a href="#5、redis主从同步原理-还有从从同步" class="headerlink" title="5、redis主从同步原理(还有从从同步)"></a>5、redis主从同步原理(还有从从同步)</h3><ul><li>slave服务器向master发送psync命令（此时发送的是psync ? -1），告诉master我需要同步数据了；</li><li>master接收到psync命令后会进行BGSAVE命令生成RDB文件快照；</li><li>生成完后，会将RDB文件发送给slave；</li><li>slave接收到文件会载入RDB快照，并且将数据库状态变更为master在执行BGSAVE时的状态一致；</li><li>master会发送保存在缓冲区里的所有写命令，告诉slave可以进行同步了；</li><li>slave执行这些写命令。</li></ul><h3 id="6、redis-全量同步-部分同步"><a href="#6、redis-全量同步-部分同步" class="headerlink" title="6、redis 全量同步 部分同步"></a>6、redis 全量同步 部分同步</h3><ul><li><p>全量同步：<br>master服务器会开启一个后台进程用于将redis中的数据生成一个rdb文件，与此同时，服务器会缓存所有接收到的来自<br>客户端的写命令（包含增、删、改），当后台保存进程处理完毕后，会将该rdb文件传递给slave服务器，而slave服务器<br>会将rdb文件保存在磁盘并通过读取该文件将数据加载到内存，在此之后master服务器会将在此期间缓存的命令通过redis<br>传输协议发送给slave服务器，然后slave服务器将这些命令依次作用于自己本地的数据集上最终达到数据的一致性。</p></li><li><p>部分同步：<br>从redis 2.8版本以前，并不支持部分同步，当主从服务器之间的连接断掉之后，master服务器和slave服务器之间都<br>是进行全量数据同步，但是从redis 2.8开始，即使主从连接中途断掉，也不需要进行全量同步，因为从这个版本开始融<br>入了部分同步的概念。部分同步的实现依赖于在master服务器内存中给每个slave服务器维护了一份同步日志和同步标识，<br>每个slave服务器在跟master服务器进行同步时都会携带自己的同步标识和上次同步的最后位置。当主从连接断掉之后，<br>slave服务器隔断时间（默认1s）主动尝试和master服务器进行连接，如果从服务器携带的偏移量标识还在master服务<br>器上的同步备份日志中，那么就从slave发送的偏移量开始继续上次的同步操作，如果slave发送的偏移量已经不再master<br>的同步备份日志中（可能由于主从之间断掉的时间比较长或者在断掉的短暂时间内master服务器接收到大量的写操作），<br>则必须进行一次全量更新。在部分同步过程中，master会将本地记录的同步备份日志中记录的指令依次发送给slave服务器<br>从而达到数据一致。</p></li></ul><h3 id="7、redis的持久化方式"><a href="#7、redis的持久化方式" class="headerlink" title="7、redis的持久化方式"></a>7、redis的持久化方式</h3><p>aof，rdb 两种持久化方式</p><ul><li><h4 id="aof机制"><a href="#aof机制" class="headerlink" title="aof机制"></a>aof机制</h4><ul><li><p><strong>原理：</strong></p><ul><li>redis会将每一个收到的写命令都通过write函数追加到文件中。通俗的理解就是日志记录。</li></ul></li><li><p><strong>文件重写原理：</strong></p><ul><li>AOF的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。</li></ul></li><li><p><strong>AOF三种触发机制</strong></p><ul><li><p>每修改同步always：同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好</p></li><li><p>每秒同步everysec：异步操作，每秒记录 如果一秒内宕机，有数据丢失</p></li><li><p>不同no：从不同步</p></li></ul></li><li><p><strong>优点</strong></p><ul><li><p>AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。</p></li><li><p>AOF日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。</p></li><li><p>AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。</p></li><li><p>AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。</p></li></ul></li><li><p><strong>缺点</strong></p><ul><li><p>对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大</p></li><li><p>AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的</p></li><li><p>以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。</p></li></ul></li></ul></li><li><h4 id="RDB机制"><a href="#RDB机制" class="headerlink" title="RDB机制"></a>RDB机制</h4><ul><li><p><strong>原理</strong></p><ul><li>在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb</li></ul></li><li><p><strong>触发方式</strong></p><ul><li>save：该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止。</li><li>bgsave：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。基本上 Redis 内部所有的RDB操作都是采用 bgsave 命令。</li><li>自动触发：“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。</li></ul></li><li><p><strong>优点</strong></p><ul><li><p>RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。</p></li><li><p>生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</p></li><li><p>RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p></li></ul></li><li><p><strong>缺点</strong></p><ul><li>RDB快照是一次全量备份，存储的是内存数据的二进制序列化形式，存储上非常紧凑。当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据</li></ul></li></ul></li></ul><h3 id="8、redis两种持久化方式的对比及选择"><a href="#8、redis两种持久化方式的对比及选择" class="headerlink" title="8、redis两种持久化方式的对比及选择"></a>8、redis两种持久化方式的对比及选择</h3><ul><li><strong>对比</strong></li></ul><table><thead><tr><th>命令</th><th>RDB</th><th>AOF</th></tr></thead><tbody><tr><td>启动优先级</td><td>低</td><td>高</td></tr><tr><td>体积</td><td>小</td><td>大</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>丢数据</td><td>根据策略决定</td></tr><tr><td>轻重</td><td>重</td><td>轻</td></tr></tbody></table><ul><li><strong>选择</strong></li></ul><p><strong>建议两者同时使用</strong>，剩下的就是看自己的需求了，需求不同选择也不一定。</p><h3 id="9、Redis-常见性能问题和解决方案"><a href="#9、Redis-常见性能问题和解决方案" class="headerlink" title="9、Redis 常见性能问题和解决方案"></a>9、Redis 常见性能问题和解决方案</h3><ul><li>Master 最好不要写内存快照，如果 Master 写内存快照，save 命令调度 rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务。</li><li>如果数据比较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步一。</li><li>为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同一个局域网。</li><li>尽量避免在压力很大的主库上增加从。</li><li>主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1&lt;- Slave2 &lt;- Slave3……这样的结构方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master 挂了，可以立刻启用 Slave1 做 Master，其他不变。</li></ul><h3 id="10、Redis-过期键的删除策略？"><a href="#10、Redis-过期键的删除策略？" class="headerlink" title="10、Redis 过期键的删除策略？"></a>10、Redis 过期键的删除策略？</h3><ul><li>定时删除：在设置键的过期时间的同时，创建一个定时器 timer。让定时器在键的过期时间来临时，立即执行对键的删除操作。</li><li>惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键;如果没有过期，就返回该键。</li><li>定期删除：每隔一段时间程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。</li></ul><h3 id="11、Redis-的回收策略（淘汰策略）？"><a href="#11、Redis-的回收策略（淘汰策略）？" class="headerlink" title="11、Redis 的回收策略（淘汰策略）？"></a>11、Redis 的回收策略（淘汰策略）？</h3><ul><li>volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</li><li>volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li><li>volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li><li>allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰</li><li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li><li>no-enviction（驱逐）：禁止驱逐数据</li></ul><p>注意这里的 6 种机制，volatile 和 allkeys 规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的 lru、ttl 以及 random 是三种不同的淘汰策略，再加上一种 no-enviction 永不回收的策略。</p><p>使用策略规则：</p><ul><li>如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 allkeys-lru</li><li>如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用 allkeys-random</li></ul><h3 id="12、说说redis哈希槽的概念"><a href="#12、说说redis哈希槽的概念" class="headerlink" title="12、说说redis哈希槽的概念"></a>12、说说redis哈希槽的概念</h3><p>Redis 集群没有使用一致性 hash，而是引入了哈希槽的概念，Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。</p><h3 id="13、Redis-集群之间是如何复制的？"><a href="#13、Redis-集群之间是如何复制的？" class="headerlink" title="13、Redis 集群之间是如何复制的？"></a>13、Redis 集群之间是如何复制的？</h3><p>异步复制。</p><h3 id="14、Redis-集群最大节点个数是多少？"><a href="#14、Redis-集群最大节点个数是多少？" class="headerlink" title="14、Redis 集群最大节点个数是多少？"></a>14、Redis 集群最大节点个数是多少？</h3><p>16384 个。</p><h3 id="15、Redis-集群如何选择数据库？"><a href="#15、Redis-集群如何选择数据库？" class="headerlink" title="15、Redis 集群如何选择数据库？"></a>15、Redis 集群如何选择数据库？</h3><p>Redis 集群目前无法做数据库选择，默认在 0 数据库。只有0数据库可供使用</p><h3 id="16、Redis-如何做内存优化？"><a href="#16、Redis-如何做内存优化？" class="headerlink" title="16、Redis 如何做内存优化？"></a>16、Redis 如何做内存优化？</h3><p>尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的 Web 系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的 key,而是应该把这个用户的所有信息存储到一张散列表里面。</p><h3 id="17、MySQL-里有-2000w-数据，Redis-中只存-20w-的数据，如何保证-Redis-中的数据都是热点数据？"><a href="#17、MySQL-里有-2000w-数据，Redis-中只存-20w-的数据，如何保证-Redis-中的数据都是热点数据？" class="headerlink" title="17、MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据？"></a>17、MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据？</h3><p>Redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</p><p>相关知识：Redis 提供 6 种数据淘汰策略：</p><ul><li>volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</li><li>volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li><li>volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li><li>allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰</li><li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li><li>no-enviction（驱逐）：禁止驱逐数据</li></ul><h3 id="18、假如-Redis-里面有-1-亿个-key，其中有-10w-个-key-是以某个固定的已知的前缀开头的，如果将它们全部找出来？"><a href="#18、假如-Redis-里面有-1-亿个-key，其中有-10w-个-key-是以某个固定的已知的前缀开头的，如果将它们全部找出来？" class="headerlink" title="18、假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？"></a>18、假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？</h3><p>使用 keys 指令可以扫出指定模式的 key 列表。</p><p><strong>对方接着追问：如果这个 Redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？</strong></p><p>这个时候你要回答 Redis 关键的一个特性：Redis 的单线程的。keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞地提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。</p><h3 id="19、使用过-Redis-做异步队列么，你是怎么用的？"><a href="#19、使用过-Redis-做异步队列么，你是怎么用的？" class="headerlink" title="19、使用过 Redis 做异步队列么，你是怎么用的？"></a>19、使用过 Redis 做异步队列么，你是怎么用的？</h3><p>答：一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。如果对方追问可不可以不用 sleep 呢？list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。如果对方追问能不能生产一次消费多次呢？使用 pub/sub 主题订阅者模式，可以实现1:N 的消息队列。</p><p><strong>如果对方追问 pub/sub 有什么缺点？</strong></p><p>在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 RabbitMQ等。</p><p><strong>如果对方追问 Redis 如何实现延时队列？</strong></p><p>我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问得这么详细。但是你很克制，然后神态自若地回答道：使用 sortedset，拿时间戳作为score，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。</p><h3 id="20、使用过-Redis-分布式锁么，它是什么回事？"><a href="#20、使用过-Redis-分布式锁么，它是什么回事？" class="headerlink" title="20、使用过 Redis 分布式锁么，它是什么回事？"></a>20、使用过 Redis 分布式锁么，它是什么回事？</h3><p>先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。</p><p>这时候对方会告诉你说你回答得不错，然后接着问如果在 setnx 之后执行 expire之前进程意外 crash 或者要重启维护了，那会怎么样？这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己的脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得 set 指令有非常复杂的参数，这个应该是可以同时把 setnx 和expire 合成一条指令来用的！</p><h3 id="21、redis参数优化"><a href="#21、redis参数优化" class="headerlink" title="21、redis参数优化"></a>21、redis参数优化</h3><p>设置禁用命令：flushall，flushdb，keys</p><p>单个连接允许堆积的最大请求数</p><p>缓存数据的有效时间，单位为毫秒，取值：100~60000，默认值为1000。</p><p>设置Redis后台任务执行频率，建议取值不要超过100</p>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--Kubernetes </title>
    <link href="/2021/03/03/interview-questions13-k8s/"/>
    <url>/2021/03/03/interview-questions13-k8s/</url>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes面试问题"><a href="#Kubernetes面试问题" class="headerlink" title="Kubernetes面试问题"></a>Kubernetes面试问题</h1><h2 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h2><h3 id="1、kubernetes是什么？"><a href="#1、kubernetes是什么？" class="headerlink" title="1、kubernetes是什么？"></a>1、<strong>kubernetes是什么？</strong></h3><p>Kubernetes 是一个跨主机集群的开源的容器调度平台，它可以自动化应用容器的部署、扩展和操作, 提供以容器为中心的基础架构。</p><h3 id="2、k8s前身是谷歌的borg系统"><a href="#2、k8s前身是谷歌的borg系统" class="headerlink" title="2、k8s前身是谷歌的borg系统"></a>2、k8s前身是谷歌的borg系统</h3><h3 id="3、k8s可以干什么？"><a href="#3、k8s可以干什么？" class="headerlink" title="3、k8s可以干什么？"></a>3、<strong>k8s可以干什么？</strong></h3><ul><li>快速部署应用</li><li>快速扩展应用</li><li>无缝对接新的应用功能</li><li>节省资源，优化硬件资源的使用</li></ul><h3 id="4、Kubernetes-具有如下特点"><a href="#4、Kubernetes-具有如下特点" class="headerlink" title="4、Kubernetes 具有如下特点:"></a>4、<strong>Kubernetes 具有如下特点:</strong></h3><ul><li>便携性: 无论公有云、私有云、混合云还是多云架构都全面支持</li><li>可扩展: 它是模块化、可插拔、可挂载、可组合的，支持各种形式的扩展</li><li>自修复: 它可以自保持应用状态、可自重启、自复制、自缩放的，通过声明式语法提供了强大的自修复能力</li></ul><h3 id="5、k8s抽象对象"><a href="#5、k8s抽象对象" class="headerlink" title="5、k8s抽象对象"></a>5、k8s抽象对象</h3><p>pod、service、volum、job、replica set、deployment、secret、namespace …</p><h3 id="6、K8s集群初始有两个名称空间"><a href="#6、K8s集群初始有两个名称空间" class="headerlink" title="6、K8s集群初始有两个名称空间"></a>6、K8s集群初始有两个名称空间</h3><p>kube-system、default</p><h3 id="7、k8s滚动升级"><a href="#7、k8s滚动升级" class="headerlink" title="7、k8s滚动升级"></a>7、k8s滚动升级</h3><p>滚动升级一个服务，实际是创建一个新的RS，然后逐渐将新RS中副本数增加到理想状态，将旧RS中的副本数减小到0的复合操作<br>可以使用kubectl  scale命令</p><h3 id="8、Kubernetes主要由以下几个核心组件组成："><a href="#8、Kubernetes主要由以下几个核心组件组成：" class="headerlink" title="8、Kubernetes主要由以下几个核心组件组成："></a>8、Kubernetes主要由以下几个核心组件组成：</h3><ul><li>master节点<ul><li>etcd保存了整个集群的状态;</li><li>apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；</li><li>controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；</li><li>scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；</li></ul></li><li>node节点：<ul><li>kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；</li><li>Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）；</li><li>kube-proxy负责为Service提供cluster内部的服务发现和负载均衡；</li></ul></li></ul><p>除了核心组件，还有一些推荐的Add-ons：</p><ul><li>coredns负责为整个集群提供DNS服务</li><li>Ingress Controller为服务提供外网入口</li><li>Dashboard提供GUI</li></ul><h3 id="9、service四种type"><a href="#9、service四种type" class="headerlink" title="9、service四种type"></a>9、service四种type</h3><ul><li>ClusterIP（默认） - 在集群中内部IP上暴露服务。此类型使Service只能从群集中访问。</li><li>NodePort - 通过每个 Node 上的 IP 和静态端口（NodePort）暴露服务。NodePort 服务会路由到 ClusterIP 服务，这个ClusterIP 服务会自动创建。通过请求 <NodeIP>:<NodePort>，可以从集群的外部访问一个 NodePort 服务。</li><li>LoadBalancer - 使用云提供商的负载均衡器（如果支持），可以向外部暴露服务。外部的负载均衡器可以路由到 NodePort 服务和 ClusterIP 服务。 </li><li>ExternalName - 通过返回 CNAME 和它的值，可以将服务映射到 externalName 字段的内容，没有任何类型代理被创建。</li></ul><h3 id="10、volum支持类型"><a href="#10、volum支持类型" class="headerlink" title="10、volum支持类型"></a>10、volum支持类型</h3><p>hostPath、nfs、glusterfs、rbd、cephfs、local</p><h3 id="11、k8s-Controller-Manager"><a href="#11、k8s-Controller-Manager" class="headerlink" title="11、k8s Controller Manager"></a>11、k8s Controller Manager</h3><ul><li>Replication Controler                     保证pod副本数</li><li>Node controller                               通过API server定时获取Node的相关信息，实现管理和监控Node</li><li>ResourceQuota Controller            资源配额管理确保指定的资源对象在任何时候都不会超量占用系统物理资源</li><li>Namespace Controller                   Namespace Controller定时通过API Server读取用户创建的保存在etcd的namespace</li><li>endpoint controller                        负责生成和维护所有Endpoints对象的控制器</li><li>service controller                            监听Service变化 </li><li>serviceAccount controller   </li><li>Token controller </li></ul><h3 id="12、k8s-pod之间的通信"><a href="#12、k8s-pod之间的通信" class="headerlink" title="12、k8s pod之间的通信"></a>12、k8s pod之间的通信</h3><ul><li><p>同一个Pod中容器之间的通信<br>这种场景对于Kubernetes来说没有任何问题，根据Kubernetes的架构设计。Kubernetes创建Pod时，首先会创建一个pause容器，为Pod指派一个唯一的IP地址。然后，以pause的网络命名空间为基础，创建同一个Pod内的其它容器（–net=container:xxx）。因此，同一个Pod内的所有容器就会共享同一个网络命名空间，在同一个Pod之间的容器可以直接使用localhost进行通信。</p></li><li><p>不同Pod中容器之间的通信<br>对于此场景，情况现对比较复杂一些，这就需要解决Pod间的通信问题。在Kubernetes通过flannel、calic等网络插件解决Pod间的通信问题。本文以flannel为例说明在Kubernetes中网络模型，flannel是kubernetes默认提供网络插件。Flannel是由CoreOs团队开发社交的网络工具，CoreOS团队采用L3 Overlay模式设计flannel， 规定宿主机下各个Pod属于同一个子网，不同宿主机下的Pod属于不同的子网。<br>flannel会在每一个宿主机上运行名为flanneld代理，其负责为宿主机预先分配一个子网，并为Pod分配IP地址。Flannel使用Kubernetes或etcd来存储网络配置、分配的子网和主机公共IP等信息。数据包则通过VXLAN、UDP或host-gw这些类型的后端机制进行转发。</p></li></ul><h3 id="13、k8s-handless-service"><a href="#13、k8s-handless-service" class="headerlink" title="13、k8s handless service"></a>13、k8s handless service</h3><p>Headless 服务即不需要 Cluster IP 的服务，即在创建服务的时候指定 <code>spec.clusterIP=None</code>。包括两种类型</p><ul><li>不指定 Selectors，但设置 externalName，即上面的（2），通过 CNAME 记录处理</li><li>指定 Selectors，通过 DNS A 记录设置后端 endpoint 列表</li></ul><h3 id="14、kube-proxy的三种代理模式"><a href="#14、kube-proxy的三种代理模式" class="headerlink" title="14、kube-proxy的三种代理模式"></a>14、kube-proxy的三种代理模式</h3><ul><li>userspace：最早的负载均衡方案，它在用户空间监听一个端口，所有服务通过 iptables 转发到这个端口，然后在其内部负载均衡到实际的 Pod。该方式最主要的问题是效率低，有明显的性能瓶颈。</li><li>iptables：目前推荐的方案，完全以 iptables 规则的方式来实现 service 负载均衡。该方式最主要的问题是在服务多的时候产生太多的 iptables 规则，非增量式更新会引入一定的时延，大规模情况下有明显的性能问题</li><li>ipvs：为解决 iptables 模式的性能问题，v1.11 新增了 ipvs 模式（v1.8 开始支持测试版，并在 v1.11 GA），采用增量式更新，并可以保证 service 更新期间连接保持不断开</li></ul><p>注意：使用 ipvs 模式时，需要预先在每台 Node 上加载内核模块 <code>nf_conntrack_ipv4</code>, <code>ip_vs</code>, <code>ip_vs_rr</code>, <code>ip_vs_wrr</code>, <code>ip_vs_sh</code> 等。IPVS 模式也会使用 iptables 来执行 SNAT 和 IP 伪装（MASQUERADE），并使用 ipset 来简化 iptables 规则的管理。</p><h3 id="15、kube-proxy的不足"><a href="#15、kube-proxy的不足" class="headerlink" title="15、kube-proxy的不足"></a>15、kube-proxy的不足</h3><p>kube-proxy 目前仅支持 TCP 和 UDP，不支持 HTTP 路由，并且也没有健康检查机制。这些可以通过自定义 <a href="https://feisky.gitbooks.io/kubernetes/content/plugins/ingress.html" target="_blank" rel="noopener">Ingress Controller</a> 的方法来解决。</p><h3 id="16、k8s-pod内的pause容器的作用"><a href="#16、k8s-pod内的pause容器的作用" class="headerlink" title="16、k8s pod内的pause容器的作用"></a>16、k8s pod内的pause容器的作用</h3><p>pod内的其他容器会共用pause容器的网络栈和存储卷，保证pod内的其他容器的端口不能冲突，彼此都是通过localhost就可以访问，扮演PID1的角色,并在子进程称为”孤儿进程”的时候,通过调用wait()收割这个子进程,这样就不用担心我们的Pod的PID namespace里会堆满僵尸进程了。</p><p><strong>pause容器主要为每个业务容器提供以下功能：</strong></p><p>PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID。</p><p>网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围。</p><p>IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信。</p><p>UTS命名空间：Pod中的多个容器共享一个主机名；Volumes（共享存储卷）</p><h3 id="17、k8s-pod-init容器"><a href="#17、k8s-pod-init容器" class="headerlink" title="17、k8s pod init容器"></a>17、k8s pod init容器</h3><ul><li><p>Init 容器在所有容器运行之前执行（run-to-completion），常用来初始化配置。</p></li><li><p>如果为一个 Pod 指定了多个 Init 容器，那这些init容器会按顺序一次运行一个。 每个 Init 容器必须运行成功，下一个才能够运行。 当所有的 Init 容器运行完成时，Kubernetes 初始化 Pod 并像平常一样运行应用容器。</p></li></ul><h3 id="18、k8s-service和ingress的区别"><a href="#18、k8s-service和ingress的区别" class="headerlink" title="18、k8s service和ingress的区别"></a>18、k8s service和ingress的区别</h3><p>Service 虽然解决了服务发现和负载均衡的问题，但它在使用上还是有一些限制，比如</p><p>－ 只支持 4 层负载均衡，没有 7 层功能 － 对外访问的时候，NodePort 类型需要在外部搭建额外的负载均衡，而 LoadBalancer 要求 kubernetes 必须跑在支持的 cloud provider 上面</p><p>Ingress 就是为了解决这些限制而引入的新资源，主要用来将服务暴露到 cluster 外面，并且可以自定义服务的访问策略</p><h3 id="19、k8s-service的调度算法"><a href="#19、k8s-service的调度算法" class="headerlink" title="19、k8s service的调度算法"></a>19、k8s service的调度算法</h3><p><strong>预选策略</strong></p><ul><li>基础的检查项（GeneralPredicates）</li><li>volume相关</li><li>node相关<ul><li>是否准备好调度</li><li>是否能容忍污点</li></ul></li><li>pod相关<ul><li>亲和性与反亲和性</li></ul></li></ul><p><strong>优选策略</strong></p><p>选择cpu剩余量和memory剩余量的和最多的宿主机</p><h3 id="20、ingress-转发过程"><a href="#20、ingress-转发过程" class="headerlink" title="20、ingress 转发过程"></a>20、ingress 转发过程</h3><p>为了使得Ingress资源正常工作，集群中必须要有个Ingress Controller来解析Ingress的转发规则。Ingress Controller收到请求，匹配Ingress转发规则转发到后端Service，而Service转发到Pod，最终由Pod处理请求。Kubernetes中Service、Ingress与Ingress Controller有着以下关系：</p><ul><li>Service是后端真实服务的抽象，一个Service可以代表多个相同的后端服务。</li><li>Ingress是反向代理规则，用来规定HTTP/HTTPS请求应该被转发到哪个Service上。例如根据请求中不同的Host和URL路径，让请求落到不同的 Service上。</li><li>Ingress Controller是一个反向代理程序，负责解析Ingress的反向代理规则。如果Ingress有增删改的变动，Ingress Controller会及时更新自己相应的转发规则，当Ingress Controller收到请求后就会根据这些规则将请求转发到对应的Service。</li></ul><p>Ingress Controller通过API Server获取Ingress资源的变化，动态地生成Load Balancer（例如Nginx）所需的配置文件（例如nginx.conf），然后重新加载Load Balancer（例如执行<code>nginx -s load</code>重新加载Nginx。）来生成新的路由转发规则。</p><h3 id="21、k8s-secret三种类型"><a href="#21、k8s-secret三种类型" class="headerlink" title="21、k8s secret三种类型"></a>21、k8s secret三种类型</h3><ul><li>Service Account：用来访问Kubernetes API，由Kubernetes自动创建，并且会自动挂载到Pod的<code>/run/secrets/kubernetes.io/serviceaccount</code>目录中；</li><li>Opaque：base64编码格式的Secret，用来存储密码、密钥等；</li><li><code>kubernetes.io/dockerconfigjson</code>：用来存储私有docker registry的认证信息。</li></ul><h3 id="22、flannel三种网络模式的对比"><a href="#22、flannel三种网络模式的对比" class="headerlink" title="22、flannel三种网络模式的对比"></a>22、flannel三种网络模式的对比</h3><p>udp模式：使用设备flannel.0进行封包解包，不是内核原生支持，上下文切换较大，性能非常差<br>vxlan模式：使用flannel.1进行封包解包，内核原生支持，性能较强<br>host-gw模式：无需flannel.1这样的中间设备，直接宿主机当作子网的下一跳地址，性能最强<br>host-gw的性能损失大约在10%左右，而其他所有基于VXLAN“隧道”机制 的网络方案，性能损失在20%~30%左右</p><h3 id="23、PV、PVC-是什么，区别"><a href="#23、PV、PVC-是什么，区别" class="headerlink" title="23、PV、PVC 是什么，区别"></a>23、PV、PVC 是什么，区别</h3><ul><li>pv：Persistent Volume对具体的存储进行配置和分配，而Pods等则可以使用Persistent Volume抽象出来的存储资源，不需要知道集群的存储细节。</li><li>pvc：Persistent Volume Claim提出需要的存储标准，然后从现有存储资源中匹配或者动态建立新的资源，最后将两者进行绑定。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--Nginx、LVS </title>
    <link href="/2021/03/03/interview-questions11-nginx/"/>
    <url>/2021/03/03/interview-questions11-nginx/</url>
    
    <content type="html"><![CDATA[<h1 id="Nginx-LVS-Apache"><a href="#Nginx-LVS-Apache" class="headerlink" title="Nginx LVS Apache"></a>Nginx LVS Apache</h1><h2 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h2><h3 id="1、LVS的模式："><a href="#1、LVS的模式：" class="headerlink" title="1、LVS的模式："></a>1、LVS的模式：</h3><ul><li><p><strong>NAT模式</strong></p><ul><li>工作过程<ul><li>（1）：用户将请求发送至调度器上，此时LVS根据算法选择一个后端的真实服务器，将数据请求包转发给真实服务器，并在转发之前LVS会修改数据包中的目标地址以及目标端口，此时修改为后端服务器ip地址</li><li>（2）：后端服务器将响应的数据包返回给LVS调度器，调度器在响应数据包后会将源地址和源端口修改为vip及调度器相应端口，修改完成后，由调度器响应数据包发送给终端</li></ul></li><li>优点<ul><li>集群中的物理服务器可以使用任何支持TCP/IP操作系统，只有负载均衡器需要一个合法的IP地址。</li></ul></li><li>缺点<ul><li>扩展性有限。当服务器节点增长过多时，负载均衡器将成为整个系统的瓶颈，因为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时，大量的数据包都交汇在负载均衡器那，速度就会变慢</li></ul></li><li>注意：在NAT模式中，Real Server的网关必须指向LVS，否则报文无法送达客户端</li></ul></li><li><p><strong>TUN模式</strong></p><ul><li>工作过程<ul><li>（1）：用户将请求发送至调度器上，此时LVS根据算法选择一个后端的真实服务器，将数据请求包转发给后端服务器，并在转发之前LVS会修改数据包中的目标地址以及目标端口，此时修改为后端的服务器ip地址</li><li>（2）：后端服务器收到请求报文后，会首先拆开第一层封装,然后发现里面还有一层IP首部的目标地址是自己lo接口上的VIP，所以会处理次请求报文，并将响应报文通过lo接口送给eth0网卡直接发送给客户端。</li></ul></li><li>优点<ul><li>负载均衡器只负责将请求包分发给后端节点服务器，而RS将应答包直接发给用户。所以，减少了负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，就能处理很巨大的请求量。</li></ul></li><li>缺点<ul><li>隧道模式的RS节点需要合法IP，这种方式需要所有的服务器支持”IP Tunneling”(IP Encapsulation)协议，服务器可能只局限在部分Linux系统上。</li></ul></li></ul></li><li><p><strong>DR模式</strong></p><ul><li>工作过程<ul><li>（1）：用户将请求发送至调度器上，此时LVS根据算法选择一个后端的真实服务器，将数据请求包转发给后端服务器，并在转发之前LVS会修改数据包中的源MAC地址改为自己DIP的MAC地址，目标MAC改为了RIP的MAC地址，并将此包发送给RS</li><li>（2）：RS发现请求报文中的目的MAC是自己，就会将次报文接收下来，处理完请求报文后，将响应报文通过lo接口送给eth0网卡直接发送给客户端。</li></ul></li><li>优点<ul><li>和TUN（隧道模式）一样，负载均衡器也只是分发请求，应答包通过单独的路由方法返回给客户端。与VS-TUN相比，VS-DR这种实现方式不需要隧道结构，因此可以使用大多数操作系统做为物理服务器。</li></ul></li><li>缺点<ul><li>所有 RS 节点和调度器 LB 只能在一个局域网里面。</li></ul></li><li>注意：需要设置lo接口的VIP不能响应本地网络内的arp请求。</li></ul></li><li><p><strong>FULLNAT模式</strong></p><ul><li><p>无论是 DR 还是 NAT 模式，不可避免的都有一个问题：LVS 和 RS 必须在同一个 VLAN 下，否则 LVS 无法作为 RS 的网关。</p><p>​    这引发的两个问题是：</p><p>​    1、同一个 VLAN 的限制导致运维不方便，跨 VLAN 的 RS 无法接入。</p><p>​    2、LVS 的水平扩展受到制约。当 RS 水平扩容时，总有一天其上的单点 LVS 会成为瓶颈。</p></li><li><p>Full-NAT 由此而生，解决的是 LVS 和 RS 跨 VLAN 的问题，而跨 VLAN 问题解决后，LVS 和 RS 不再存在 VLAN 上的从属关系，可以做到多个 LVS 对应多个 RS，解决水平扩容的问题。</p><p>Full-NAT 相比 NAT 的主要改进是，在 SNAT/DNAT 的基础上，加上另一种转换：</p><ul><li><p>在包从 LVS 转到 RS 的过程中，源地址从客户端 IP 被替换成了 LVS 的内网 IP。</p></li><li><p>内网 IP 之间可以通过多个交换机跨 VLAN 通信。</p></li><li><p>当 RS 处理完接受到的包，返回时，会将这个包返回给 LVS 的内网 IP，这一步也不受限于 VLAN。</p></li><li><p>LVS 收到包后，在 NAT 模式修改源地址的基础上，再把 RS 发来的包中的目标地址从 LVS 内网 IP 改为客户端的 IP。</p></li></ul><p>Full-NAT 主要的思想是把网关和其下机器的通信，改为了普通的网络通信，从而解决了跨 VLAN 的问题。采用这种方式，LVS 和 RS 的部署在 VLAN 上将不再有任何限制，大大提高了运维部署的便利性。</p></li><li><p>总结：</p><ul><li>FULL NAT 模式也不需要 LBIP 和 realserver ip 在同一个网段； full nat 跟 nat 相比的优点是：保证 RS 回包一定能够回到 LVS；因为源地址就是 LVS–&gt; 不确定</li><li>full nat 因为要更新 sorce ip 所以性能正常比 nat 模式下降 10%</li></ul></li></ul></li></ul><h3 id="2、LVS的调度算法："><a href="#2、LVS的调度算法：" class="headerlink" title="2、LVS的调度算法："></a>2、LVS的调度算法：</h3><p>轮询，加权轮询，最小连接数，加权最小连接数，基于局部的最少连接，带复制的基于局部性的最少连接，目标地址散列调度，最短的期望的延迟，最少队列调度</p><h3 id="3、三大主流软件负载均衡器对比-LVS-VS-Nginx-VS-Haproxy）"><a href="#3、三大主流软件负载均衡器对比-LVS-VS-Nginx-VS-Haproxy）" class="headerlink" title="3、三大主流软件负载均衡器对比(LVS VS Nginx VS Haproxy）"></a>3、三大主流软件负载均衡器对比(LVS VS Nginx VS Haproxy）</h3><p>LVS：<br>  1、抗负载能力强。抗负载能力强、性能高，能达到F5硬件的60%；对内存和cpu资源消耗比较低<br>  2、工作在网络4层，通过vrrp协议转发（仅作分发之用），具体的流量由linux内核处理，因此没有流量的产生。<br>  2、稳定性、可靠性好，自身有完美的热备方案；（如：LVS+Keepalived）<br>  3、应用范围比较广，可以对所有应用做负载均衡；<br>  4、不支持正则处理，不能做动静分离。<br>  5、支持负载均衡算法：rr（轮循）、wrr（带权轮循）、lc（最小连接）、wlc（权重最小连接）<br>  6、配置 复杂，对网络依赖比较大，稳定性很高。</p><p>Ngnix：<br>  1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构；<br>  2、Nginx对网络的依赖比较小，理论上能ping通就就能进行负载功能；<br>  3、Nginx安装和配置比较简单，测试起来比较方便；<br>  4、也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发；<br>  5、对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。<br>  6、Nginx对请求的异步处理可以帮助节点服务器减轻负载；<br>  7、Nginx仅能支持http、https和Email协议，这样就在适用范围较小。<br>  8、不支持Session的直接保持，但能通过ip_hash来解决。、对Big request header的支持不是很好，<br>  9、支持负载均衡算法：Round-robin（轮循）、Weight-round-robin（带权轮循）、Ip-hash（Ip哈希）<br>  10、Nginx还能做Web服务器即Cache功能。</p><p>HAProxy的特点是：<br>  1、支持两种代理模式：TCP（四层）和HTTP（七层），支持虚拟主机；<br>  2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作<br>  3、支持url检测后端的服务器出问题的检测会有很好的帮助。<br>  4、更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现<br>  5、单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。<br>  6、HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。<br>  9、支持负载均衡算法：Round-robin（轮循）、Weight-round-robin（带权轮循）、source（原地址保持）、RI（请求URL）、rdp-cookie（根据cookie）<br>  10、不能做Web服务器即Cache。</p><h3 id="4、rewrite语法："><a href="#4、rewrite语法：" class="headerlink" title="4、rewrite语法："></a>4、rewrite语法：</h3><p>指令语法：rewrite 正则表达式 被替换内容[flag];</p><p>简单的小例子：</p><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">rewrite</span><span class="hljs-regexp"> ^/(.*)</span> http://www.baidu.com/ <span class="hljs-literal">permanent</span>; <span class="hljs-comment"># 匹配成功后跳转到百度，执行永久301跳转</span><br></code></pre></div></td></tr></table></figure><p><strong>常用正则表达式：</strong></p><table><thead><tr><th>字符</th><th>描述</th></tr></thead><tbody><tr><td>\</td><td>将后面接着的字符标记为一个特殊字符或者一个原义字符或一个向后引用</td></tr><tr><td>^</td><td>匹配输入字符串的起始位置</td></tr><tr><td>$</td><td>匹配输入字符串的结束位置</td></tr><tr><td>*</td><td>匹配前面的字符零次或者多次</td></tr><tr><td>+</td><td>匹配前面字符串一次或者多次</td></tr><tr><td>?</td><td>匹配前面字符串的零次或者一次</td></tr><tr><td>.</td><td>匹配除“\n”之外的所有单个字符</td></tr><tr><td>(pattern)</td><td>匹配括号内的pattern</td></tr></tbody></table><p> <strong>rewrite 最后一项flag参数：</strong></p><table><thead><tr><th>标记符号</th><th>说明</th></tr></thead><tbody><tr><td>last</td><td>本条规则匹配完成后继续向下匹配新的location URI规则</td></tr><tr><td>break</td><td>本条规则匹配完成后终止，不在匹配任何规则</td></tr><tr><td>redirect</td><td>返回302临时重定向</td></tr><tr><td>permanent</td><td>返回301永久重定向</td></tr></tbody></table><h3 id="5、location的规则"><a href="#5、location的规则" class="headerlink" title="5、location的规则"></a>5、location的规则</h3><figure class="highlight excel"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs excel">语法规则： location [=|~|~*|^~] /uri/ &#123; … &#125;<br>=  开头表示精确匹配<br>^~   开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/<span class="hljs-number">20%</span>/aa，可以被规则 ^~ /static/ /aa匹配到（注意是空格）。以xx开头<br>~  开头表示区分大小写的正则匹配                  以xx结尾<br>~*   开头表示不区分大小写的正则匹配                以xx结尾<br>!~和!~*分别为区分大小写不匹配及不区分大小写不匹配 的正则<br>/  通用匹配，任何请求都会匹配到。<br></code></pre></div></td></tr></table></figure><p>匹配顺序<br>首先精确匹配 =-》其次以xx开头匹配^~-》然后是按文件中顺序的正则匹配-》最后是交给 / 通用匹配。<br>当有匹配成功时候，停止匹配，按当前匹配规则处理请求。</p><h3 id="6、nginx-master-worker机制的好处"><a href="#6、nginx-master-worker机制的好处" class="headerlink" title="6、nginx master-worker机制的好处"></a>6、nginx master-worker机制的好处</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">可以使用 nginx<span class="hljs-_">-s</span> reload 热部署。<br><br>每个Worker 是独立的进程，不需要加锁，省掉了锁带来的开销。采用独立的进程，可以让互相之间不会影响，一个进程退出后，其他进程还在工作，服务不会中断，Master进程则很快启动新的Worker进程。<br></code></pre></div></td></tr></table></figure><h3 id="7、alias与root的区别"><a href="#7、alias与root的区别" class="headerlink" title="7、alias与root的区别"></a>7、alias与root的区别</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs livecodeserver">root    实际访问文件路径会拼接<span class="hljs-built_in">URL</span>中的路径<br><span class="hljs-built_in">alias</span>   实际访问文件路径不会拼接<span class="hljs-built_in">URL</span>中的路径，会把location后面配置的路径丢弃掉，把当前匹配到的目录指向到指定的目录<br></code></pre></div></td></tr></table></figure><blockquote><p>注意：</p><ol><li>使用alias时，目录名后面一定要加”/“。</li><li>alias在使用正则匹配时，必须捕捉要匹配的内容并在指定的内容处使用。</li><li>alias只能位于location块中。（root可以不放在location中）</li></ol></blockquote><h3 id="8、nginx日志切割脚本"><a href="#8、nginx日志切割脚本" class="headerlink" title="8、nginx日志切割脚本"></a>8、nginx日志切割脚本</h3><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros"><span class="hljs-comment"># /bin/bash</span><br> <br><span class="hljs-comment"># 日志保存位置</span><br><span class="hljs-attribute">base_path</span>=<span class="hljs-string">'/opt/nginx/logs'</span><br><span class="hljs-comment"># 获取当前年信息和月信息</span><br><span class="hljs-attribute">log_path</span>=$(date -d yesterday +<span class="hljs-string">"%Y%m"</span>)<br><span class="hljs-comment"># 获取昨天的日信息</span><br><span class="hljs-attribute">day</span>=$(date -d yesterday +<span class="hljs-string">"%d"</span>)<br><span class="hljs-comment"># 按年月创建文件夹</span><br>mkdir -p <span class="hljs-variable">$base_path</span>/<span class="hljs-variable">$log_path</span><br><span class="hljs-comment"># 备份昨天的日志到当月的文件夹</span><br>mv <span class="hljs-variable">$base_path</span>/access.log <span class="hljs-variable">$base_path</span>/<span class="hljs-variable">$log_path</span>/access_<span class="hljs-variable">$day</span>.log<br><span class="hljs-comment"># 输出备份日志文件名</span><br><span class="hljs-comment"># echo $base_path/$log_path/access_$day.log</span><br><span class="hljs-comment"># 通过Nginx信号量控制重读日志</span><br>kill -USR1 `cat /opt/nginx/logs/nginx.pid`<br><span class="hljs-comment">#删除7天前的日志</span><br>cd <span class="hljs-variable">$base_path</span>/<span class="hljs-variable">$log_path</span>/<br><span class="hljs-builtin-name">find</span> . -mtime +7 -name <span class="hljs-string">"*20[1-9][3-9]*"</span> | xargs rm -f<br></code></pre></div></td></tr></table></figure><h3 id="9、nginx优化"><a href="#9、nginx优化" class="headerlink" title="9、nginx优化"></a>9、nginx优化</h3><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript"><span class="hljs-number">1.</span> worker_processes <span class="hljs-number">8</span>;<br>nginx 进程数，建议按照cpu 数目来指定，一般为它的倍数 (如,<span class="hljs-number">2</span>个四核的cpu计为<span class="hljs-number">8</span>)。<br><span class="hljs-number">2.</span> worker_cpu_affinity <span class="hljs-number">00000001</span> <span class="hljs-number">00000010</span> <span class="hljs-number">00000100</span> <span class="hljs-number">00001000</span> <span class="hljs-number">00010000</span> <span class="hljs-number">00100000</span> <span class="hljs-number">01000000</span> <span class="hljs-number">10000000</span>;<br>为每个进程分配cpu，上例中将<span class="hljs-number">8</span> 个进程分配到<span class="hljs-number">8</span> 个cpu，当然可以写多个，或者将一<br>个进程分配到多个cpu。<br><span class="hljs-number">3.</span> worker_rlimit_nofile <span class="hljs-number">65535</span>;<br>这个指令是指当一个nginx 进程打开的最多文件描述符数目，理论值应该是最多打开文<br>件数（ulimit -n）与nginx 进程数相除，但是nginx 分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。<br><span class="hljs-number">4.</span> use epoll;<br>使用epoll 的I/O 模型<br><span class="hljs-number">5.</span> worker_connections <span class="hljs-number">65535</span>;<br>每个进程允许的最多连接数， 理论上每台nginx 服务器的最大连接数为worker_processes*worker_connections。<br><span class="hljs-number">6.</span> keepalive_timeout <span class="hljs-number">60</span>;<br>keepalive 超时时间。<br><span class="hljs-number">7.</span> client_header_buffer_size <span class="hljs-number">4</span>k;<br>客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过<span class="hljs-number">1</span>k，不过由于一般系统分页都要大于<span class="hljs-number">1</span>k，所以这里设置为分页大小。<br><span class="hljs-number">8.</span> open_file_cache max=<span class="hljs-number">65535</span> inactive=<span class="hljs-number">60</span>s;<br>这个将为打开文件指定缓存，默认是没有启用的，max 指定缓存数量，建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。<br><span class="hljs-number">9.</span> open_file_cache_valid <span class="hljs-number">80</span>s;<br>这个是指多长时间检查一次缓存的有效信息。<br><span class="hljs-number">10.</span> open_file_cache_min_uses <span class="hljs-number">1</span>;<br>open_file_cache 指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，它将被移除。<br><span class="hljs-number">11.</span> fastcgi_connect_timeout <span class="hljs-number">300</span>;<br>指定连接到后端FastCGI 的超时时间。<br><span class="hljs-number">12.</span> fastcgi_send_timeout <span class="hljs-number">300</span>;<br>向FastCGI 传送请求的超时时间，这个值是指已经完成两次握手后向FastCGI 传送请求的超时时间。<br><span class="hljs-number">13.</span> fastcgi_read_timeout <span class="hljs-number">300</span>;<br>接收FastCGI 应答的超时时间，这个值是指已经完成两次握手后接收FastCGI 应答的超时时间。<br><span class="hljs-number">14.</span> fastcgi_buffer_size <span class="hljs-number">4</span>k;<br>指定读取FastCGI 应答第一部分需要用多大的缓冲区，一般第一部分应答不会超过<span class="hljs-number">1</span>k，由于页面大小为<span class="hljs-number">4</span>k，所以这里设置为<span class="hljs-number">4</span>k。<br><span class="hljs-number">15.</span> fastcgi_buffers <span class="hljs-number">8</span> <span class="hljs-number">4</span>k;<br>指定本地需要用多少和多大的缓冲区来缓冲FastCGI 的应答。<br><span class="hljs-number">16.</span> fastcgi_busy_buffers_size <span class="hljs-number">8</span>k;<br>这个指令我也不知道是做什么用，只知道默认值是fastcgi_buffers 的两倍。<br><span class="hljs-number">17.</span> fastcgi_temp_file_write_size <span class="hljs-number">8</span>k;<br>在写入fastcgi_temp_path 时将用多大的数据块，默认值是fastcgi_buffers 的两倍。<br><span class="hljs-number">18.</span> fastcgi_cache TEST<br>开启FastCGI 缓存并且为其制定一个名称。个人感觉开启缓存非常有用，可以有效降低CPU 负载，并且防止<span class="hljs-number">502</span> 错误。<br></code></pre></div></td></tr></table></figure><h3 id="10、nginx-reload的流程"><a href="#10、nginx-reload的流程" class="headerlink" title="10、nginx reload的流程"></a>10、nginx reload的流程</h3><p><strong>详情请跳转至</strong>：<a href="https://like-ycy.github.io/2019/12/26/2019-12-26-nginx-reload/">nginx -s reload的流程</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--Docker </title>
    <link href="/2021/03/03/interview-questions12-docker/"/>
    <url>/2021/03/03/interview-questions12-docker/</url>
    
    <content type="html"><![CDATA[<h1 id="Docker-面试问题"><a href="#Docker-面试问题" class="headerlink" title="Docker 面试问题"></a>Docker 面试问题</h1><h3 id="Docker与LXC（Linux-Container）有何不同？"><a href="#Docker与LXC（Linux-Container）有何不同？" class="headerlink" title="Docker与LXC（Linux Container）有何不同？"></a>Docker与LXC（Linux Container）有何不同？</h3><figure class="highlight fortran"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs fortran">LXC利用Linux上相关技术实现容器，Docker则在如下的几个方面进行了改进：<br><br>移植性：通过抽象容器配置，容器可以实现一个平台移植到另一个平台；  镜像系统：基于AUFS的镜像系统为容器的分发带来了很多的便利，同时共同的镜像层只需要存储一份，实现高效率的存储；  版本管理：类似于GIT的版本管理理念，用户可以更方面的创建、管理镜像文件；  仓库系统：仓库系统大大降低了镜像的分发和管理的成本；  周边工具：各种现有的工具（配置管理、云平台）对Docker的支持，以及基于Docker的<span class="hljs-keyword">Pass</span>、CI等系统，让Docker的应用更加方便和多样化。<br></code></pre></div></td></tr></table></figure><h3 id="docker网络模式"><a href="#docker网络模式" class="headerlink" title="docker网络模式"></a>docker网络模式</h3><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">bridge：这是Docker默认的网络驱动，此模式会为每一个容器分配Network Namespace和设置IP等，并将容器连接到一个虚拟网桥上。如果未指定网络驱动，这默认使用此驱动。<br>host：此网络驱动直接使用宿主机的网络。<br>none：此驱动不构造网络环境。采用了none 网络驱动，那么就只能使用loopback网络设备，容器只能使用<span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>的本机网络。<br>overlay：此网络驱动可以使多个Docker daemons连接在一起，并能够使用swarm服务之间进行通讯。也可以使用overlay网络进行swarm服务和容器之间、容器之间进行通讯，<br>macvlan：此网络允许为容器指定一个MAC地址，允许容器作为网络中的物理设备，这样Docker daemon就可以通过MAC地址进行访问的路由。对于希望直接连接网络网络的遗留应用，这种网络驱动有时可能是最好的选择。<br></code></pre></div></td></tr></table></figure><h3 id="如何查看镜像支持的环境变量？"><a href="#如何查看镜像支持的环境变量？" class="headerlink" title="如何查看镜像支持的环境变量？"></a>如何查看镜像支持的环境变量？</h3><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile">docker <span class="hljs-keyword">run</span><span class="bash"> IMAGE env</span><br></code></pre></div></td></tr></table></figure><h3 id="本地的镜像文件都存放在哪里？"><a href="#本地的镜像文件都存放在哪里？" class="headerlink" title="本地的镜像文件都存放在哪里？"></a><strong>本地的镜像文件都存放在哪里</strong>？</h3><figure class="highlight crystal"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crystal">与Docker相关的本地资源存放在/var/<span class="hljs-class"><span class="hljs-keyword">lib</span>/<span class="hljs-title">docker</span>/目录下，其中<span class="hljs-title">container</span>目录存放容器信息， <span class="hljs-title">graph</span>目录存放镜像信息，<span class="hljs-title">aufs</span>目录下存放具体的镜像底层文件。</span><br></code></pre></div></td></tr></table></figure><h3 id="构建Docker镜像应该遵循哪些原则？"><a href="#构建Docker镜像应该遵循哪些原则？" class="headerlink" title="构建Docker镜像应该遵循哪些原则？"></a>构建Docker镜像应该遵循哪些原则？</h3><figure class="highlight vala"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs vala">整体原则上，尽量保持镜像功能的明确和内容的精简，要点包括：  <br><span class="hljs-meta"># 尽量选取满足需求但较小的基础系统镜像，建议选择debian:wheezy镜像，仅有86MB大小  </span><br><span class="hljs-meta"># 清理编译生成文件、安装包的缓存等临时文件  </span><br><span class="hljs-meta"># 安装各个软件时候要指定准确的版本号，并避免引入不需要的依赖  </span><br><span class="hljs-meta"># 从安全的角度考虑，应用尽量使用系统的库和依赖  </span><br><span class="hljs-meta"># 使用Dockerfile创建镜像时候要添加.dockerignore文件或使用干净的工作目录</span><br></code></pre></div></td></tr></table></figure><h3 id="如何获取某个容器的PID信息"><a href="#如何获取某个容器的PID信息" class="headerlink" title="如何获取某个容器的PID信息?"></a>如何获取某个容器的PID信息?</h3><figure class="highlight sqf"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs sqf">docker inspect --<span class="hljs-built_in">format</span> <span class="hljs-string">'&#123;&#123; .State.Pid &#125;&#125;'</span> &lt;CONTANINERID <span class="hljs-built_in">or</span> <span class="hljs-built_in">NAME</span>&gt;<br></code></pre></div></td></tr></table></figure><h3 id="如何获取某个容器的IP地址"><a href="#如何获取某个容器的IP地址" class="headerlink" title="如何获取某个容器的IP地址?"></a>如何获取某个容器的IP地址?</h3><figure class="highlight sqf"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs sqf">docker  inspect --<span class="hljs-built_in">format</span> <span class="hljs-string">'&#123;&#123; &gt;NetworkSettings.IPAddress &#125;&#125;'</span> &lt;CONTANINERID <span class="hljs-built_in">or</span> <span class="hljs-built_in">NAME</span>&gt;<br></code></pre></div></td></tr></table></figure><h3 id="如何控制容器占用系统资源（CPU，内存）的份额？"><a href="#如何控制容器占用系统资源（CPU，内存）的份额？" class="headerlink" title="如何控制容器占用系统资源（CPU，内存）的份额？"></a>如何控制容器占用系统资源（CPU，内存）的份额？</h3><figure class="highlight coq"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs coq">在使用docker create命令创建容器或使用docker run 创建并运行容器的时候， 可以使用-c|<span class="hljs-type">–cpu</span>-shares[=<span class="hljs-number">0</span>]参数来调整同期使用CPU的权重， 使用-m|<span class="hljs-type">–memory</span>参数来调整容器使用内存的大小。<br></code></pre></div></td></tr></table></figure><h3 id="docker-容器内部运行free-m看见的内存是容器的还是宿主机的，为什么"><a href="#docker-容器内部运行free-m看见的内存是容器的还是宿主机的，为什么" class="headerlink" title="docker 容器内部运行free -m看见的内存是容器的还是宿主机的，为什么"></a>docker 容器内部运行free -m看见的内存是容器的还是宿主机的，为什么</h3><p><strong>是宿主机的</strong></p><p>这是由于docker产生的容器的隔离性不足造成的。<br>docker创建容器时，会为容器提供一些必要的目录和文件，比如/proc下的若干文件。其中/proc/meminfo文件docker并没有直接提供其生成，而是将宿主机的/proc/meminfo挂载给了容器。<br>因此容器看到的/proc/meminfo与宿主机的/proc/meminfo的内容是一样的。而free命令也不过是查看该文件的信息而已。</p><p><strong>不止free命令。uname命令查看内核也为宿主机内核信息</strong></p><h3 id="在宿主机查看容器内进程"><a href="#在宿主机查看容器内进程" class="headerlink" title="在宿主机查看容器内进程"></a>在宿主机查看容器内进程</h3><p>docker top 容器id</p><h3 id="docker-kill和docker-stop的区别"><a href="#docker-kill和docker-stop的区别" class="headerlink" title="docker kill和docker stop的区别"></a>docker kill和docker stop的区别</h3><p>kill是不管容器同不同意，我直接执行kill -9，强行终止；stop的话，首先给容器发送一个TERM信号，让容器做一些退出前必须的保护性、安全性操作，然后让容器自动停止运行，如果在一段时间内，容器还是没有停止，再进行kill -9，强行终止。</p><h3 id="docker-build如何传入参数"><a href="#docker-build如何传入参数" class="headerlink" title="docker build如何传入参数"></a>docker build如何传入参数</h3><p>dockerfile文件中ARG参数</p><p>用户可以在创建镜像时使用–build-arg=参数将其传递给构建器</p><h3 id="dockerfile中env和arg的区别"><a href="#dockerfile中env和arg的区别" class="headerlink" title="dockerfile中env和arg的区别"></a>dockerfile中env和arg的区别</h3><p><strong>ENV</strong>变量可以在镜像构建阶段和容器启动的时候使用</p><p><strong>ARG</strong>变量是在镜像构建阶段使用</p><p>ENV指令定义的环境变量始终会覆盖同名的ARG指令</p><p>更多内容请看[dockerfile就是这么简单](<a href="https://like-ycy.github.io/2020/07/20/2020-07-20-dockerfile/">Dockerfile就这么简单 - 权掌天下 Blog (like-ycy.github.io)</a>)</p><h3 id="docker-容器与容器之间直接数据共享"><a href="#docker-容器与容器之间直接数据共享" class="headerlink" title="docker 容器与容器之间直接数据共享"></a>docker 容器与容器之间直接数据共享</h3><p>docker volume create命令创建数据卷</p>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--Linux问题 </title>
    <link href="/2021/03/03/interview-questions2-linux/"/>
    <url>/2021/03/03/interview-questions2-linux/</url>
    
    <content type="html"><![CDATA[<h2 id="linux系统"><a href="#linux系统" class="headerlink" title="linux系统"></a>linux系统</h2><h3 id="1、linux启动过程"><a href="#1、linux启动过程" class="headerlink" title="1、linux启动过程"></a>1、linux启动过程</h3><p>​    第一步：开机自检，加载BIOS</p><p>​    第二部：读取MBR</p><p>​    第三部：Boot Loader　grub引导菜单</p><p>​    第四步：加载kernel内核</p><p>​    第五步：init进程依据inittab文件夹来设定运行级别</p><p>​    第六步：init进程执行rc.sysinit</p><p>​    第七步：启动内核模块</p><p>​    第八步：执行不同运行级别的脚本程序</p><p>​    第九步：执行/etc/rc.d/rc.local</p><p>​    第十步：执行/bin/login程序，启动mingetty,进入登录状态</p><h3 id="2、统计8888端口连接数"><a href="#2、统计8888端口连接数" class="headerlink" title="2、统计8888端口连接数"></a>2、统计8888端口连接数</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">netstat -ant | grep 8888<br></code></pre></div></td></tr></table></figure><h3 id="3、top命令根据关键字查看CPU、内存信息"><a href="#3、top命令根据关键字查看CPU、内存信息" class="headerlink" title="3、top命令根据关键字查看CPU、内存信息"></a>3、top命令根据关键字查看CPU、内存信息</h3><figure class="highlight reasonml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs reasonml">top -c -p <span class="hljs-constructor">$(<span class="hljs-params">pgrep</span> -<span class="hljs-params">d</span>',' -<span class="hljs-params">f</span> <span class="hljs-params">java</span>)</span><br></code></pre></div></td></tr></table></figure><h3 id="4、分区工具-格式化工具"><a href="#4、分区工具-格式化工具" class="headerlink" title="4、分区工具 格式化工具"></a>4、分区工具 格式化工具</h3><figure class="highlight awk"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs awk">fdisk <span class="hljs-regexp">/dev/</span>sdb  按“p”，输入分区号，输入分区的大小，“w”保存<br>mkfs -t ext4 <span class="hljs-regexp">/dev/</span>sdb1<br></code></pre></div></td></tr></table></figure><h3 id="5、查看日志中访问次数最多的前10个IP"><a href="#5、查看日志中访问次数最多的前10个IP" class="headerlink" title="5、查看日志中访问次数最多的前10个IP"></a>5、查看日志中访问次数最多的前10个IP</h3><figure class="highlight coq"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs coq">cat access_log |<span class="hljs-type">cut</span> -d ' ' -f <span class="hljs-number">1</span> | <span class="hljs-type">sort</span> |<span class="hljs-type">uniq</span> -c | <span class="hljs-type">sort</span> -nr | <span class="hljs-type">awk</span> '&#123;print $<span class="hljs-number">0</span> &#125;' | <span class="hljs-type">head</span> -n <span class="hljs-number">10</span> | <span class="hljs-type">less</span><br></code></pre></div></td></tr></table></figure><h3 id="6、当前WEB服务器中连接次数最多的ip地址"><a href="#6、当前WEB服务器中连接次数最多的ip地址" class="headerlink" title="6、当前WEB服务器中连接次数最多的ip地址"></a>6、当前WEB服务器中连接次数最多的ip地址</h3><figure class="highlight coq"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs coq">netstat -ntu |<span class="hljs-type">awk</span> '&#123;print $<span class="hljs-number">5</span>&#125;' |<span class="hljs-type">sort</span> | <span class="hljs-type">uniq</span> -c| <span class="hljs-type">sort</span> -nr<br></code></pre></div></td></tr></table></figure><h3 id="7、用iptables添加一个规则允许192-168-0-123访问本机3306端口"><a href="#7、用iptables添加一个规则允许192-168-0-123访问本机3306端口" class="headerlink" title="7、用iptables添加一个规则允许192.168.0.123访问本机3306端口"></a>7、用iptables添加一个规则允许192.168.0.123访问本机3306端口</h3><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">iptables -I INPUT -p tcp -s <span class="hljs-number">192.168</span><span class="hljs-number">.0</span><span class="hljs-number">.123</span> -d <span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span> --dport <span class="hljs-number">3306</span> -j ACCEPT<br></code></pre></div></td></tr></table></figure><h3 id="8、将本地80端口的请求转发到8080端口，当前主机IP为192-168-16-1，其中本地网卡eth0"><a href="#8、将本地80端口的请求转发到8080端口，当前主机IP为192-168-16-1，其中本地网卡eth0" class="headerlink" title="8、将本地80端口的请求转发到8080端口，当前主机IP为192.168.16.1，其中本地网卡eth0"></a>8、将本地80端口的请求转发到8080端口，当前主机IP为192.168.16.1，其中本地网卡eth0</h3><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">iptables -t<span class="hljs-built_in"> nat </span>-A PREROUTING -p tcp -i eth0 -d 192.168.16.1 --dport 80 -j REDIRECT --to-port 8080<br></code></pre></div></td></tr></table></figure><h3 id="9、查看http的并发连接数与其TCP连接状态"><a href="#9、查看http的并发连接数与其TCP连接状态" class="headerlink" title="9、查看http的并发连接数与其TCP连接状态"></a>9、查看http的并发连接数与其TCP连接状态</h3><figure class="highlight vbnet"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs vbnet">netstat -n | awk <span class="hljs-comment">'/^tcp/ &#123;++b[$NF]&#125; END &#123;for(a in b) print a, b[a]&#125;'</span><br></code></pre></div></td></tr></table></figure><h3 id="10、统计出apache的access-log中访问量最多的5个IP"><a href="#10、统计出apache的access-log中访问量最多的5个IP" class="headerlink" title="10、统计出apache的access.log中访问量最多的5个IP:"></a>10、统计出apache的access.log中访问量最多的5个IP:</h3><figure class="highlight coq"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs coq">cat access_log | <span class="hljs-type">awk</span>  '&#123;print $<span class="hljs-number">1</span>&#125;' | <span class="hljs-type">sort</span> | <span class="hljs-type">uniq</span> -c | <span class="hljs-type">sort</span> -n -r | <span class="hljs-type">head</span> <span class="hljs-number">-5</span><br></code></pre></div></td></tr></table></figure><h3 id="11、通过apache访问日志access-log-统计IP和每个地址访问的次数，按访问量列出前10名。"><a href="#11、通过apache访问日志access-log-统计IP和每个地址访问的次数，按访问量列出前10名。" class="headerlink" title="11、通过apache访问日志access.log 统计IP和每个地址访问的次数，按访问量列出前10名。"></a>11、通过apache访问日志access.log 统计IP和每个地址访问的次数，按访问量列出前10名。</h3><figure class="highlight stata"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs stata"><span class="hljs-keyword">cat</span> /<span class="hljs-keyword">var</span>/<span class="hljs-keyword">log</span>/httpd/access_log |awk '&#123;<span class="hljs-keyword">print</span> <span class="hljs-variable">$1&#125;</span>'|<span class="hljs-keyword">sort</span> -r |head -10 |uniq -c<br></code></pre></div></td></tr></table></figure><h3 id="12、多进程与多线程，请问有什么区别？"><a href="#12、多进程与多线程，请问有什么区别？" class="headerlink" title="12、多进程与多线程，请问有什么区别？"></a>12、多进程与多线程，请问有什么区别？</h3><p>（1）进程：子进程是父进程的复制品。<br>（2）线程：一个进程可以容纳多个线程，相对进程而言，线程是一个更加接近与执行体的概念，它可以与同进程的其他线程共享资源，但拥有自己的栈空间，拥有独立的执行序列。 </p><p>两者都可以提高程序的并发度，提高程序运行效率和响应时间。<br>同时，线程适合于在SMP机器上运行，而进程则可以跨机器迁移。<br>根本区别就一点：用多进程每个进程有自己的地址空间(address space)，线程则共享地址空间。</p><p>所有其它区别都是由此而来的：<br>（1）速度：线程产生的速度快，线程间的通讯快、切换快等，因为他们在同一个地址空间内。<br>（2）资源利用率：线程的资源利用率比较好也是因为他们在同一个地址空间内。<br>（3）同步问题：线程使用公共变量/内存时需要使用同步机制还是因为他们在同一个地址空间内。</p><h3 id="13、linux下ext4和xfs文件系统的区别"><a href="#13、linux下ext4和xfs文件系统的区别" class="headerlink" title="13、linux下ext4和xfs文件系统的区别"></a>13、linux下ext4和xfs文件系统的区别</h3><p>EXT4是Linux系统下的日志文件系统，是EXT3文件系统的后继版本。</p><p>（1）Ext4的文件系统容量达到1EB，而文件容量则达到16TB</p><p>（2）理论上支持无限数量的子目录</p><p>（3）Ext4文件系统使用64位空间记录块数量和i-节点数量</p><p>（4）Ext4的多块分配器支持一次调用分配多个数据块</p><p>XFS</p><p>（1）根据所记录的日志在很短的时间内迅速恢复磁盘文件内容</p><p>（2）采用优化算法，日志记录对整体文件操作影响非常小</p><p>（3） 是一个全64-bit的文件系统，它可以支持上百万T字节的存储空间</p><p>（4）能以接近裸设备I/O的性能存储数据</p><h3 id="14、linux-top命令信息"><a href="#14、linux-top命令信息" class="headerlink" title="14、linux top命令信息"></a>14、linux top命令信息</h3><p>请看之前文章：<a href="https://like-ycy.github.io/2020/06/29/2020-06-29-linux-top/">Linux top命令参数详解</a></p><h3 id="15、端口time-wait过多，怎么解决"><a href="#15、端口time-wait过多，怎么解决" class="headerlink" title="15、端口time_wait过多，怎么解决"></a>15、端口time_wait过多，怎么解决</h3><p><strong>内核参数优化：</strong></p><figure class="highlight stylus"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs stylus">net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_syncookies</span> = <span class="hljs-number">1</span> 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为<span class="hljs-number">0</span>，表示关闭； <br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_tw_reuse</span> = <span class="hljs-number">1</span> 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为<span class="hljs-number">0</span>，表示关<br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_tw_recycle</span> = <span class="hljs-number">1</span> 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为<span class="hljs-number">0</span>，表示关闭。 <br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_fin_timeout</span> 修改系默认的 TIMEOUT 时间<br></code></pre></div></td></tr></table></figure><h3 id="16、linux-软，硬链接区别"><a href="#16、linux-软，硬链接区别" class="headerlink" title="16、linux 软，硬链接区别"></a>16、linux 软，硬链接区别</h3><ul><li>硬链接：在Linux系统中，多个文件名指向同一索引节点(Inode)是正常且允许的。一般这种链接就称为硬链接。硬链接的作用之一是允许一个文件拥有多个有效路径名，这样用户就可以建立硬链接到重要的文件，以防止“误删”源数据。</li><li>软链接： 软链接就是一个普通文件，只是数据块内容有点特殊，文件用户数据块中存放的内容是另一文件的路径名的指向，通过这个方式可以快速定位到软连接所指向的源文件实体。软链接可对文件或目录创建。</li></ul><p>软连接和硬链接的特点：</p><p><strong>软链接：</strong></p><ul><li>1.软链接是存放另一个文件的路径的形式存在。</li><li>2.软链接可以 跨文件系统 ，硬链接不可以。</li><li>3.软链接可以对一个不存在的文件名进行链接，硬链接必须要有源文件。</li><li>4.软链接可以对目录进行链接。</li></ul><p><strong>硬链接：</strong></p><ul><li><ol><li>硬链接，以文件副本的形式存在。但不占用实际空间。</li></ol></li><li><ol><li>不允许给目录创建硬链接。</li></ol></li><li><ol><li>硬链接只有在同一个文件系统中才能创建。</li></ol></li><li><ol><li>删除其中一个硬链接文件并不影响其他有相同 inode 号的文件。</li></ol></li></ul><h3 id="17、linux-kill进程退出指令"><a href="#17、linux-kill进程退出指令" class="headerlink" title="17、linux kill进程退出指令"></a>17、linux kill进程退出指令</h3><table><thead><tr><th>信号编号</th><th>信号名</th><th>含义</th></tr></thead><tbody><tr><td>0</td><td>EXIT</td><td>程序退出时收到该信息。</td></tr><tr><td>1</td><td>HUP</td><td>挂掉电话线或终端连接的挂起信号，这个信号也会造成某些进程在没有终止的情况下重新初始化。</td></tr><tr><td>2</td><td>INT</td><td>表示结束进程，但并不是强制性的，常用的 “Ctrl+C” 组合键发出就是一个 kill -2 的信号。</td></tr><tr><td>3</td><td>QUIT</td><td>退出。</td></tr><tr><td>9</td><td>KILL</td><td>杀死进程，即强制结束进程。</td></tr><tr><td>11</td><td>SEGV</td><td>段错误。</td></tr><tr><td>15</td><td>TERM</td><td>正常结束进程，是 kill 命令的默认信号。</td></tr></tbody></table><h3 id="18、Linux中CPU使用率-和-load的关系"><a href="#18、Linux中CPU使用率-和-load的关系" class="headerlink" title="18、Linux中CPU使用率 和 load的关系"></a>18、Linux中CPU使用率 和 load的关系</h3><ul><li>CPU使用率<br>一段时间之中，CPU用于执行任务占用的时间与总的时间的比率</li><li>load<br>Load average是指上一分钟同时处于就绪状态的平均进程数。在CPU中可以理解为CPU可以并行处理的任务数量，就是CPU个数X核数。如果CPU Load等于CPU个数乘以核数，那么就说CPU正好满负载，再多一点，可能就要出问题了</li></ul><p>对于CPU密集型任务 通常是 cpu使用率和load都很高<br>对于IO密集型任务 通常是cpu使用率不高 但load很高</p>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--Prometheus </title>
    <link href="/2021/03/03/interview-questions18-prometheus/"/>
    <url>/2021/03/03/interview-questions18-prometheus/</url>
    
    <content type="html"><![CDATA[<h1 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h1><h3 id="1、prometheus和zabbix的对比"><a href="#1、prometheus和zabbix的对比" class="headerlink" title="1、prometheus和zabbix的对比"></a>1、prometheus和zabbix的对比</h3><p><strong>如果公司需要对容器进行监控：不要犹豫，选择prometheus</strong></p><ul><li>zabbix<ul><li>更适合物理机器的监控</li><li>对容器的支持较差</li></ul></li><li>prometheus<ul><li>更适合容器服务，就这一条足够</li></ul></li></ul><h3 id="2、prometheus四种指标数据类型"><a href="#2、prometheus四种指标数据类型" class="headerlink" title="2、prometheus四种指标数据类型"></a>2、prometheus四种指标数据类型</h3><p><strong>Counter(计数器类型)</strong></p><p>只增不减（除非系统发生了重置），Counter一般用于累计值。</p><p><strong>Gauge(仪表盘类型)</strong></p><p>可增可减的指标类型，可以用于反应当前应用的状态。（cpu、内存）</p><p><strong>Histogram(直方图类型)</strong></p><p>主要用于表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图。</p><p><strong>Summary(摘要类型)</strong></p><p>Summary类型和Histogram类型相似，</p><p>存在如下区别：</p><ul><li>都包含 &lt; basename&gt;_sum和&lt; basename&gt;_count;</li><li>Histogram需要通过&lt; basename&gt;_bucket计算quantile，而Summary直接存储了quantile的值。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--Mysql问题 </title>
    <link href="/2021/03/03/interview-questions3-mysql/"/>
    <url>/2021/03/03/interview-questions3-mysql/</url>
    
    <content type="html"><![CDATA[<h1 id="Mysql面试问题"><a href="#Mysql面试问题" class="headerlink" title="Mysql面试问题"></a>Mysql面试问题</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><p>理论问题</p></li><li><p>SQL语句问题</p></li><li><p>思路分析题</p></li></ul><h2 id="理论问题"><a href="#理论问题" class="headerlink" title="理论问题"></a>理论问题</h2><h3 id="1、mysql主从同步原理"><a href="#1、mysql主从同步原理" class="headerlink" title="1、mysql主从同步原理"></a>1、mysql主从同步原理</h3><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh"><span class="hljs-literal">master</span>开启bin-log功能，日志文件用于记录数据库的读写增删，<br>需要开启<span class="hljs-number">3</span>个线程，<span class="hljs-literal">master</span>开启 IO线程，<span class="hljs-literal">slave</span>开启 IO线程 SQL线程，<br><span class="hljs-literal">Slave</span> 通过IO线程连接<span class="hljs-literal">master</span>，并且请求某个bin-log，position之后的内容。<br><span class="hljs-literal">MASTER</span>服务器收到<span class="hljs-literal">slave</span> IO线程发来的日志请求信息，io线程去将bin-log内容，position返回给<span class="hljs-literal">slave</span> IO线程。<br><span class="hljs-literal">slave</span>服务器收到bin-log日志内容，将bin-log日志内容写入relay-log中继日志，创建一个<span class="hljs-literal">master</span>.<span class="hljs-literal">inf</span>o的文件，该文件记录了<span class="hljs-keyword">master</span> <span class="hljs-title">ip</span> 用户名 密码 <span class="hljs-keyword">master</span> <span class="hljs-title">bin-log</span>名称，bin-log position。<br><span class="hljs-literal">slave</span>端开启SQL线程，实时监控relay-log日志内容是否有更新，解析文件中的SQL语句，在<span class="hljs-literal">slave</span>数据库中去执行。<br></code></pre></div></td></tr></table></figure><p><strong>简化版</strong></p><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh"><span class="hljs-literal">master</span>开启bin-log，<span class="hljs-literal">slave</span>的io线程连接<span class="hljs-keyword">master</span> <span class="hljs-title">bin-log</span>放入到relay-log中，<span class="hljs-literal">slave</span>的sql线程解析relay-log文件为SQL语句，在<span class="hljs-literal">slave</span>数据库中执行<br></code></pre></div></td></tr></table></figure><h3 id="2、mysql主从同步复制模式"><a href="#2、mysql主从同步复制模式" class="headerlink" title="2、mysql主从同步复制模式"></a>2、mysql主从同步复制模式</h3><figure class="highlight pgsql"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs pgsql">• 异步复制( Asynchronous <span class="hljs-keyword">replication</span> )<br>– 主库在执行完客户端提交的事务后会立即将结果返给客户端,并不关心从库是否已经接收并处理。<br><br>• 全同步复制( Fully synchronous <span class="hljs-keyword">replication</span> )<br>– 当主库执行完一个事务,所有的从库都执行了该事务才返回给客户端。<br><br>• 半同步复制( Semisynchronous <span class="hljs-keyword">replication</span> )<br>– 介于异步复制和全同步复制之间,主库在执行完客户端提交的事务后不是立刻返回给客户端,而是等待至少一个从库接收到并写到 relay <span class="hljs-keyword">log</span> 中才返回给客户端。<br></code></pre></div></td></tr></table></figure><h3 id="3、mysql主从复制的方式"><a href="#3、mysql主从复制的方式" class="headerlink" title="3、mysql主从复制的方式"></a>3、mysql主从复制的方式</h3><figure class="highlight pgsql"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs pgsql">基于 <span class="hljs-keyword">SQL</span> 语句的复制(<span class="hljs-keyword">statement</span>-based <span class="hljs-keyword">replication</span>, SBR)；<br>基于行的复制(<span class="hljs-keyword">row</span>-based <span class="hljs-keyword">replication</span>, RBR)；<br>混合模式复制(mixed-based <span class="hljs-keyword">replication</span>, MBR)；<br></code></pre></div></td></tr></table></figure><h3 id="4、mysql索引分类"><a href="#4、mysql索引分类" class="headerlink" title="4、mysql索引分类"></a>4、mysql索引分类</h3><figure class="highlight plain"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs plain">主键索引、唯一索引、普通索引、全文索引、组合索引<br></code></pre></div></td></tr></table></figure><h3 id="5、B-Tree索引和Hash索引区别？"><a href="#5、B-Tree索引和Hash索引区别？" class="headerlink" title="5、B+ Tree索引和Hash索引区别？"></a>5、B+ Tree索引和Hash索引区别？</h3><figure class="highlight asciidoc"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs asciidoc"><span class="hljs-bullet">- </span>哈希索引适合等值查询，但是无法进行范围查询 <br><span class="hljs-bullet">- </span>哈希索引没办法利用索引完成排序 <br><span class="hljs-bullet">- </span>哈希索引不支持多列联合索引的最左匹配规则 <br><span class="hljs-bullet">- </span>如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题<br></code></pre></div></td></tr></table></figure><h3 id="6、mysql两种引擎的区别"><a href="#6、mysql两种引擎的区别" class="headerlink" title="6、mysql两种引擎的区别"></a>6、mysql两种引擎的区别</h3><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript"><span class="hljs-number">1</span>、MyISAM是非事务安全的，而InnoDB是事务安全的<br><span class="hljs-number">2</span>、MyISAM锁的粒度是表级的，而InnoDB支持行级锁<br><span class="hljs-number">3</span>、MyISAM支持全文类型索引，而InnoDB不支持全文索引<br><span class="hljs-number">4</span>、MyISAM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyISAM<br><span class="hljs-number">5</span>、MyISAM表保存成文件形式，跨平台使用更加方便<br></code></pre></div></td></tr></table></figure><h3 id="7、两种引擎的应用场景"><a href="#7、两种引擎的应用场景" class="headerlink" title="7、两种引擎的应用场景"></a>7、两种引擎的应用场景</h3><figure class="highlight pgsql"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs pgsql">InnoDB：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的完整性要求比较高（比如银行），要求实现并发控制（比如售票），那选择InnoDB有很大的优势。如果需要频繁的更新、删除操作的数据库，也可以选择InnoDB，因为支持事务的提交（<span class="hljs-keyword">commit</span>）和回滚（<span class="hljs-keyword">rollback</span>）。 <br>MyISAM：插入数据快，空间和内存使用比较低。如果表主要是用于插入新记录和读出记录，那么选择MyISAM能实现处理高效率。如果应用的完整性、并发性要求比 较低，也可以使用。<br></code></pre></div></td></tr></table></figure><h3 id="mysql参数优化"><a href="#mysql参数优化" class="headerlink" title="mysql参数优化"></a>mysql参数优化</h3><p>最大允许传输包大小</p><p>最大允许错误连接数</p><p>7天自动清理binlog</p><p>临时表大小</p><p>最大连接数</p><p>最大打开文件数</p><p>临时文件大小</p><p>缓冲池大小</p><p>query cache内存大小</p><p>blok发送超时时间</p><p>并发查询数目</p><p>innodb_buffer_pool_size： 一般设置为内存的60%，缓冲池大小</p><p>back_log：处理大量短链接时设置的，默认3000，建议提高</p><p>innodb_autoinc_lock_mode：控制自增主键的锁机制，默认1，建议设置为2，表示所有情况插入都使用轻量级别的mutex锁，但是binlog的格式需要被设置为row</p><p>query_cache_size：控制MySQL query cache的内存大小。</p><p> net_write_timeout：等待将一个block发送给客户端的超时时间。默认60秒，建议提高</p><p>tmp_table_size：内部内存临时表的最大值。内存足够是建议提高</p><p>loose_rds_max_tmp_disk_space：MySQL能够使用的临时文件的大小</p><p>loose_tokudb_buffer_pool_ratio：TokuDB引擎能够使用的buffer内存大小</p><p>loose_max_statement_time：查询在MySQL的最长执行时间</p><p>loose_rds_threads_running_high_watermark：查询在MySQL的最长执行时间，</p><h2 id="SQL语句问题"><a href="#SQL语句问题" class="headerlink" title="SQL语句问题"></a>SQL语句问题</h2><ul><li>数据库根据学生表和分数表查学生的学号、姓名、课程，分数</li></ul><figure class="highlight plain"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs mysql">SELECT student.学号, student.姓名,score.课程, score.成绩 FROM student JOIN score ON student.学号&#x3D;score.学号;<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--JAVA问题 </title>
    <link href="/2021/03/03/interview-questions7-java/"/>
    <url>/2021/03/03/interview-questions7-java/</url>
    
    <content type="html"><![CDATA[<h4 id="java类型"><a href="#java类型" class="headerlink" title="java类型"></a>java类型</h4><ul><li>jvm分层 gc回收种类</li><li>java能否正确识别docker的资源限制</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--网络问题 </title>
    <link href="/2021/03/03/interview-questions8-network/"/>
    <url>/2021/03/03/interview-questions8-network/</url>
    
    <content type="html"><![CDATA[<h2 id="网络问题"><a href="#网络问题" class="headerlink" title="网络问题"></a>网络问题</h2><h3 id="1、当用户在浏览器当中输入一个网站，说说计算机对dns解释经过那些流程"><a href="#1、当用户在浏览器当中输入一个网站，说说计算机对dns解释经过那些流程" class="headerlink" title="1、当用户在浏览器当中输入一个网站，说说计算机对dns解释经过那些流程"></a>1、当用户在浏览器当中输入一个网站，说说计算机对dns解释经过那些流程</h3><ul><li>用户输入网址到浏览器 </li><li>浏览器发出DNS请求报文 </li><li>计算机首先查询本机HOSTS文件，看是否存在，存在直接返回结果，不存在，继续转发请求报文 </li><li>计算机按照本地DNS的顺序，向合法dns服务器查询IP结果，</li><li>合法dns返回dns结果给本地dns，管理该域的本地dns服务器缓存本结果，直到缓存时间过期，才再次查询此结果</li></ul><h3 id="2、dns的查询方式"><a href="#2、dns的查询方式" class="headerlink" title="2、dns的查询方式"></a>2、dns的查询方式</h3><p><strong>递归查询</strong>：客户机向dns服务器发送请求，DNS服务器会使用一个准确的查询结果回复给客户机，如果DNS服务器本地没有储存查询的DNS信息，那么它会查询其他的DNS服务器，并将查询结果提交给客户机</p><p><strong>迭代查询</strong>：客户机向dns服务器发送请求，如果该服务器本地没有储存查询的DNS信息，那么它会告诉客户机另一台DNS服务器的地址，客户机在向这台DNS服务器查询DNS信息，依次循环直到返回结果</p><h3 id="3、私有地址"><a href="#3、私有地址" class="headerlink" title="3、私有地址"></a>3、私有地址</h3><p>A类地址：10.0.0.0–10.255.255.255</p><p>B类地址：172.16.0.0–172.31.255.255 </p><p>C类地址：192.168.0.0–192.168.255.255</p><p>IP地址总范围：1.0.0.1——255.255.255.254</p><h3 id="4、ip地址的计算，例如-192-168-10-0-24-有几个可用ip，子网掩码换成23呢？"><a href="#4、ip地址的计算，例如-192-168-10-0-24-有几个可用ip，子网掩码换成23呢？" class="headerlink" title="4、ip地址的计算，例如:192.168.10.0/24 有几个可用ip，子网掩码换成23呢？"></a>4、ip地址的计算，例如:192.168.10.0/24 有几个可用ip，子网掩码换成23呢？</h3><h3 id="5、四层、七层负载均衡的区别"><a href="#5、四层、七层负载均衡的区别" class="headerlink" title="5、四层、七层负载均衡的区别"></a>5、四层、七层负载均衡的区别</h3><table><thead><tr><th></th><th>四层负载均衡</th><th>七层负载均衡</th></tr></thead><tbody><tr><td>基于</td><td>基于ip+prot</td><td>基于URL或主机ip</td></tr><tr><td>类似于</td><td>路由器</td><td>代理服务器</td></tr><tr><td>握手次数</td><td>1次</td><td>2次</td></tr><tr><td>复杂度</td><td>低</td><td>高</td></tr><tr><td>性能</td><td>高；无需解析内容</td><td>中；需要算法识别URL，cookie和HTTP head等信息</td></tr><tr><td>安全性</td><td>低，无法识别DDos等攻击</td><td>高，可以防御SYN cookie</td></tr><tr><td>额外功能</td><td>无</td><td>回话保持，图片压缩，防盗链</td></tr></tbody></table><h3 id="6、tcpdump抓包的内容都有哪些"><a href="#6、tcpdump抓包的内容都有哪些" class="headerlink" title="6、tcpdump抓包的内容都有哪些"></a>6、tcpdump抓包的内容都有哪些</h3><ul><li><p>数据链路层</p><p>目标MAC地址、源MAC地址、类型 (IPV4)</p></li><li><p>IP层</p><p>版本、ip包头长度、ip包总长度、TTL值、源IP地址、目标IP地址</p></li><li><p>协议层的一些信息</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--思路分析类问题 </title>
    <link href="/2021/03/03/interview-questions6-analysis/"/>
    <url>/2021/03/03/interview-questions6-analysis/</url>
    
    <content type="html"><![CDATA[<h1 id="思路分析类型"><a href="#思路分析类型" class="headerlink" title="思路分析类型"></a>思路分析类型</h1><h3 id="1、排查java进程cpu占用过高（内存占用高同理）"><a href="#1、排查java进程cpu占用过高（内存占用高同理）" class="headerlink" title="1、排查java进程cpu占用过高（内存占用高同理）"></a>1、排查java进程cpu占用过高（内存占用高同理）</h3><p>1、使用top命令查看占用CPU过高的进程，获取到其PID；</p><p>2、jstack pid &gt; java.txt  导出CPU占用高进程的线程栈；</p><p>3、top -H -p PID 查看对应进程的哪个线程占用CPU过高；</p><p>4、在java.txt文件中根据线程id找到对应的线程栈（需要将线程id转换为16进制）；</p><p>5、分析负载高的线程栈都是什么业务操作，优化程序。</p><h3 id="2、cpu负载高的分析"><a href="#2、cpu负载高的分析" class="headerlink" title="2、cpu负载高的分析"></a>2、cpu负载高的分析</h3><h5 id="情况1：CPU高、Load高"><a href="#情况1：CPU高、Load高" class="headerlink" title="情况1：CPU高、Load高"></a>情况1：CPU高、Load高</h5><ol><li>通过top命令查找占用CPU最高的进程PID；</li><li>通过top -Hp PID查找占用CPU最高的线程TID;</li><li>对于java程序，使用jstack打印线程堆栈信息（可联系业务进行排查定位）；</li><li>通过<code>printf %x tid</code>打印出最消耗CPU线程的十六进制；</li><li>在堆栈信息中查看该线程的堆栈信息；</li></ol><h5 id="情况2：CPU低、Load高"><a href="#情况2：CPU低、Load高" class="headerlink" title="情况2：CPU低、Load高"></a>情况2：CPU低、Load高</h5><ol><li>通过top命令查看CPU等待IO时间，即<code>%wa</code>；</li><li>通过<code>iostat -d -x -m 1 10</code>查看磁盘IO情况；(安装命令 <code>yum install -y sysstat</code>)</li><li>通过<code>sar -n DEV 1 10</code>查看网络IO情况；</li><li>通过如下命令查找占用IO的程序；</li></ol><figure class="highlight pf"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs pf">ps -e -L h o <span class="hljs-keyword">state</span>,cmd  | awk '&#123;if(<span class="hljs-variable">$1</span>==<span class="hljs-string">"R"</span>||<span class="hljs-variable">$1</span>==<span class="hljs-string">"D"</span>)&#123;print <span class="hljs-variable">$0</span>&#125;&#125;' | sort | uniq -c | sort -k <span class="hljs-number">1</span>nr<br></code></pre></div></td></tr></table></figure><p>详情查看<a href="https://www.cnblogs.com/liuyupen/p/13905967.html" target="_blank" rel="noopener">Linux系统中负载较高问题排查思路与解决方法</a></p><h3 id="3、linux系统负载怎么判断"><a href="#3、linux系统负载怎么判断" class="headerlink" title="3、linux系统负载怎么判断"></a>3、linux系统负载怎么判断</h3><p>1、登录服务器，uptime命令查看负载情况；</p><p>2、首先查看负载的三个数值，如果15分钟的高，1分钟的低，那可能为正常波动；</p><p>3、如果15分钟的低，1分钟的高，使用top命令查看cpu使用情况，然后根据2问题的步骤进行分析。</p><h3 id="4、linux系统执行命令很卡"><a href="#4、linux系统执行命令很卡" class="headerlink" title="4、linux系统执行命令很卡"></a>4、linux系统执行命令很卡</h3><p>1、系统cpu、内存占满，无法执行操作</p><p>2、系统磁盘挂载问题</p><h3 id="5、linux服务器ssh连接不通，怎么排查"><a href="#5、linux服务器ssh连接不通，怎么排查" class="headerlink" title="5、linux服务器ssh连接不通，怎么排查"></a>5、linux服务器ssh连接不通，怎么排查</h3><p>1、云服务器首先要排查是否开启安全组</p><p>2、ping命令测试、telnet命令测试</p><p>3、查看服务器防火墙状态</p><p>4、服务器资源被占满，机器出于卡死状态</p><h3 id="6、k8s-pod之间无法通信"><a href="#6、k8s-pod之间无法通信" class="headerlink" title="6、k8s pod之间无法通信"></a>6、k8s pod之间无法通信</h3><ul><li><p>CNI 网络插件配置错误，导致多主机网络不通，比如</p><ul><li>IP 网段与现有网络冲突</li><li>插件使用了底层网络不支持的协议</li><li>忘记开启 IP 转发等<ul><li><code>sysctl net.ipv4.ip_forward</code></li><li><code>sysctl net.bridge.bridge-nf-call-iptables</code></li></ul></li></ul></li><li><p>Pod 网络路由丢失，比如</p><ul><li>kubenet 要求网络中有 podCIDR 到主机 IP 地址的路由，这些路由如果没有正确配置会导致 Pod 网络通信等问题</li><li>在公有云平台上，kube-controller-manager 会自动为所有 Node 配置路由，但如果配置不当（如认证授权失败、超出配额等），也有可能导致无法配置路由</li></ul></li><li><p>Service NodePort 和 health probe 端口冲突</p><ul><li>在 1.10.4 版本之前的集群中，多个不同的 Service 之间的 NodePort 和 health probe 端口有可能会有重合 （已经在 <a href="https://github.com/kubernetes/kubernetes/pull/64468" target="_blank" rel="noopener">kubernetes#64468</a> 修复）</li></ul></li><li><p>主机内或者云平台的安全组、防火墙或者安全策略等阻止了 Pod 网络，比如</p><ul><li><p>非 Kubernetes 管理的 iptables 规则禁止了 Pod 网络</p></li><li><p>公有云平台的安全组禁止了 Pod 网络（注意 Pod 网络有可能与 Node 网络不在同一个网段）</p></li><li><p>交换机或者路由器的 ACL 禁止了 Pod 网络</p></li></ul></li></ul><p>  1、进入pod内互相发包，使用tcpdump抓包查看数据发送情况</p><p>  2、网络插件出现问题（flannel、calico）</p><p>  <strong>其他网络问题请查看</strong>： <a href="https://feisky.gitbooks.io/kubernetes/content/troubleshooting/network.html" target="_blank" rel="noopener">网络异常排错</a></p><h3 id="7、kube-proxy挂掉的影响"><a href="#7、kube-proxy挂掉的影响" class="headerlink" title="7、kube-proxy挂掉的影响"></a>7、kube-proxy挂掉的影响</h3><p>无法通过service访问到pod，业务将直接出于瘫痪状态</p><h3 id="8、k8s-pod一直处于pending状态、一直处于-Waiting-或-ContainerCreating-状态"><a href="#8、k8s-pod一直处于pending状态、一直处于-Waiting-或-ContainerCreating-状态" class="headerlink" title="8、k8s pod一直处于pending状态、一直处于 Waiting 或 ContainerCreating 状态"></a>8、k8s pod一直处于pending状态、一直处于 Waiting 或 ContainerCreating 状态</h3><p>1、资源不足，无法进行调度（pending）</p><p>2、镜像拉取失败</p><p>3、CNI 网络错误，一般需要检查 CNI 网络插件的配置</p><p>4、镜像打包是否正确或者是否配置了正确的参数</p><p><strong>其他pod问题请查看：<a href="https://feisky.gitbooks.io/kubernetes/content/troubleshooting/pod.html" target="_blank" rel="noopener">Pod 异常排错</a></strong></p><h3 id="9、redis在内存大（比如内存32G）的情况下应该注意哪些问题"><a href="#9、redis在内存大（比如内存32G）的情况下应该注意哪些问题" class="headerlink" title="9、redis在内存大（比如内存32G）的情况下应该注意哪些问题"></a>9、redis在内存大（比如内存32G）的情况下应该注意哪些问题</h3><p>1、主库宕机，因数据太大，导致从库恢复时间拉长</p><p>2、扩容时间拉长</p><p>3、如果网络不良，将导致从库重做，引发雪崩</p><p>4、 内存越大，触发持久化的操作阻塞主线程的时间越长</p><p><strong>解决办法：</strong></p><p>解决办法当然就是极力减少内存的使用了，一般情况下，我们都是这么做的：</p><p><strong>1 设置过期时间</strong></p><p>对具有时效性的key设置过期时间，通过redis自身的过期key清理策略来降低过期key对于内存的占用，同时也能够减少业务的麻烦，不需要定期清理了</p><p><strong>2 不存放垃圾到redis中</strong></p><p>这简直就是废话，但是，有跟我们同病相怜的人么?</p><p><strong>3 及时清理无用数据</strong></p><p>例如一个redis承载了3个业务的数据，一段时间后有2个业务下线了，那你就把这两个业务的相关数据清理了呗</p><p><strong>4 尽量对数据进行压缩</strong></p><p>例如一些长文本形式的数据，压缩能够大幅度降低内存占用</p><p><strong>5 关注内存增长并定位大容量key</strong></p><p>不管是DBA还是开发人员，你用redis，你就必须关注内存，否则，你其实就是不称职的，这里可以分析redis实例中哪些key比较大从而帮助业务快速定位异常key(非预期增长的key，往往是问题之源)</p><h3 id="10、如何处理访问量暴增"><a href="#10、如何处理访问量暴增" class="headerlink" title="10、如何处理访问量暴增"></a>10、如何处理访问量暴增</h3><p>不可预测的：网络攻击、恶意刷量</p><p>可预测的：突然爆发的社会热点，营销活动的宣传</p><p>解决方法：提前对应用进行扩容，使用CDN，减轻源站压力</p><h3 id="11、数据库表太大如何处理"><a href="#11、数据库表太大如何处理" class="headerlink" title="11、数据库表太大如何处理"></a>11、数据库表太大如何处理</h3><p>1、sql语句优化</p><ul><li>使用limit对查询结果的记录进行限定</li><li>避免select *，将需要查找的字段列出来</li><li>少用JOIN</li></ul><p>2、分表：水平分表、垂直分表</p><h3 id="12、mysql主从同步延迟"><a href="#12、mysql主从同步延迟" class="headerlink" title="12、mysql主从同步延迟"></a>12、mysql主从同步延迟</h3><p>最简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行。还有就是主库是写，对数据安全性较高，比如 sync_binlog=1，innodb_flush_log_at_trx_commit = 1 之类的设置，而slave则不需要这么高的数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog也 可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave。</p><h3 id="13、锁冲突与死锁问题"><a href="#13、锁冲突与死锁问题" class="headerlink" title="13、锁冲突与死锁问题"></a>13、锁冲突与死锁问题</h3><ul><li>尽量使用较低的隔离级别； 精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会；</li><li>选择合理的事务大小，小事务发生锁冲突的几率也更小；</li><li>给记录集显式加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁；</li><li>不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会；</li><li>尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响； 不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁；</li><li>对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维面试题系列--shell脚本问题 </title>
    <link href="/2021/03/03/interview-questions4-shell/"/>
    <url>/2021/03/03/interview-questions4-shell/</url>
    
    <content type="html"><![CDATA[<h1 id="shell脚本"><a href="#shell脚本" class="headerlink" title="shell脚本"></a>shell脚本</h1><h2 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h2><h3 id="1、在当前脚本中调用另一个脚本"><a href="#1、在当前脚本中调用另一个脚本" class="headerlink" title="1、在当前脚本中调用另一个脚本"></a>1、在当前脚本中调用另一个脚本</h3><ul><li><p>exec（exec /home/script.sh）：<br>使用exec来调用脚本，被执行的脚本会继承当前shell的环境变量。但事实上exec产生了新的进程，他会把主shell的进程资源占用并替换脚本内容，继承了原主shell的PID号，即原主shell剩下的内容不会执行。</p></li><li><p>source（source /home/script.sh）<br>使用source或者“.”来调用外部脚本，不会产生新的进程，继承当前shell环境变量，而且被调用的脚本运行结束后，它拥有的环境变量和声明变量会被当前shell保留，类似将调用脚本的内容复制过来直接执行。执行完毕后原主shell继续运行。</p></li><li><p>fork（/home/script.sh）<br>直接运行脚本，会以当前shell为父进程，产生新的进程，并且继承主脚本的环境变量和声明变量。执行完毕后，主脚本不会保留其环境变量和声明变量。</p></li></ul><h3 id="2、shell中的特殊变量"><a href="#2、shell中的特殊变量" class="headerlink" title="2、shell中的特殊变量"></a>2、shell中的特殊变量</h3><table><thead><tr><th>变量</th><th>含义</th></tr></thead><tbody><tr><td>$0</td><td>当前脚本的文件名</td></tr><tr><td>$n</td><td>传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。</td></tr><tr><td>$#</td><td>传递给脚本或函数的参数个数。</td></tr><tr><td>$*</td><td>传递给脚本或函数的所有参数。</td></tr><tr><td>$@</td><td>传递给脚本或函数的所有参数。被双引号(“ “)包含时，与 $* 稍有不同，下面将会讲到。</td></tr><tr><td>$?</td><td>上个命令的退出状态，或函数的返回值。</td></tr><tr><td>$$</td><td>当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。</td></tr></tbody></table><blockquote><h4 id="和-的区别"><a href="#和-的区别" class="headerlink" title="$* 和 $@ 的区别"></a>$* 和 $@ 的区别</h4><p>$* 和 $@ 都表示传递给函数或脚本的所有参数，不被双引号(“ “)包含时，都以”$1” “$2” … “$n” 的形式输出所有参数。</p><p>但是当它们被双引号(“ “)包含时，”$*” 会将所有的参数作为一个整体，以”$1 $2 … $n”的形式输出所有参数；”$@” 会将各个参数分开，以”$1” “$2” … “$n” 的形式输出所有参数。</p></blockquote><h2 id="实战部分"><a href="#实战部分" class="headerlink" title="实战部分"></a>实战部分</h2><h3 id="1、统计日志文件中访问时间超过50s"><a href="#1、统计日志文件中访问时间超过50s" class="headerlink" title="1、统计日志文件中访问时间超过50s"></a>1、统计日志文件中访问时间超过50s</h3><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">awk <span class="hljs-string">'$2 &gt;= 10 &#123;print $2&#125;'</span> yum.log | sort -nr | wc -l<br></code></pre></div></td></tr></table></figure><h3 id="2、编写个shell脚本将当前目录下大于10K的文件转移到-tmp目录下"><a href="#2、编写个shell脚本将当前目录下大于10K的文件转移到-tmp目录下" class="headerlink" title="2、编写个shell脚本将当前目录下大于10K的文件转移到/tmp目录下"></a>2、<strong>编写个shell脚本将当前目录下大于10K的文件转移到/tmp目录下</strong></h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>for FileName in `ls l | awk '$5&gt;10240 &#123;print $9&#125;'`;do mv $FileName /tmp;done<br></code></pre></div></td></tr></table></figure><h3 id="3、使用shell，建立classl用户组，再批量建立stu-1–stu30的用户，并指定用户组为classl"><a href="#3、使用shell，建立classl用户组，再批量建立stu-1–stu30的用户，并指定用户组为classl" class="headerlink" title="3、使用shell，建立classl用户组，再批量建立stu 1–stu30的用户，并指定用户组为classl"></a>3、使用shell，建立classl用户组，再批量建立stu 1–stu30的用户，并指定用户组为classl</h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs SHELL"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>groupadd class1<br>for((i=1;i&lt;=30;i=i+1))<br>do<br>useradd stu$i -G class1  <br>done<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 图解 Git 工作原理 </title>
    <link href="/2021/02/11/2021-02-11-visual-git-guide/"/>
    <url>/2021/02/11/2021-02-11-visual-git-guide/</url>
    
    <content type="html"><![CDATA[<h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>上面的四条命令在工作目录、暂存目录(也叫做索引)和仓库之间复制文件。</p><ul><li><code>git add files</code>把当前文件放入暂存区域。</li><li><code>git commit</code>给暂存区域生成快照并提交。</li><li><code>git reset</code> — files用来撤销最后一次git add files，你也可以用git reset撤销所有暂存区域文件。</li><li><code>git checkout</code> — files把文件从暂存区域复制到工作目录，用来丢弃本地修改。</li></ul><p>你可以用<code>git reset -p</code>，<code>git checkout -p</code>， or <code>git add -p</code>进入交互模式。</p><p>也可以跳过暂存区域直接从仓库取出文件或者直接提交代码。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/2.png" srcset="/img/loading.gif" lazyload alt=""></p><ul><li><code>git commit -a</code>相当于运行git add把所有当前目录下的文件加入暂存区域再运行。git commit.</li><li><code>git commit files</code>进行一次包含最后一次提交加上工作目录中文件快照的提交。并且文件被添加到暂存区域。</li><li><code>git checkout HEAD -- files</code>回滚到复制最后一次提交。</li></ul><h2 id="约定"><a href="#约定" class="headerlink" title="约定"></a>约定</h2><p>后文中以下面的形式使用图片。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/3.png" srcset="/img/loading.gif" lazyload alt=""></p><p>绿色的5位字符表示提交的 ID，分别指向父节点。分支用橘色显示，分别指向特定的提交。当前分支由附在其上的 HEAD 标识。这张图片里显示最后 5 次提交，ed489 是最新提交。master 分支指向此次提交，另一个 maint 分支指向祖父提交节点。</p><h2 id="命令详解"><a href="#命令详解" class="headerlink" title="命令详解"></a>命令详解</h2><h3 id="Diff"><a href="#Diff" class="headerlink" title="Diff"></a>Diff</h3><p>有许多种方法查看两次提交之间的变动。下面是一些示例。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/4.png" srcset="/img/loading.gif" lazyload alt=""></p><h3 id="Commit"><a href="#Commit" class="headerlink" title="Commit"></a>Commit</h3><p>提交时，git 用暂存区域的文件创建一个新的提交，并把此时的节点设为父节点。然后把当前分支指向新的提交节点。下图中，当前分支是 master。在运行命令之前，master 指向 ed489，提交后，master 指向新的节点 f0cec 并以 ed489 作为父节点。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/5.png" srcset="/img/loading.gif" lazyload alt=""></p><p>即便当前分支是某次提交的祖父节点，git会同样操作。下图中，在master分支的祖父节点maint分支进行一次提交，生成了1800b。这样，maint分支就不再是master分支的祖父节点。此时，合并 (或者 衍合) 是必须的。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/6.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果想更改一次提交，使用 git commit —amend。git 会使用与当前提交相同的父节点进行一次新提交，旧的提交会被取消。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/7.png" srcset="/img/loading.gif" lazyload alt=""></p><p>另一个例子是分离 HEAD 提交，后文讲。</p><h3 id="Checkout"><a href="#Checkout" class="headerlink" title="Checkout"></a>Checkout</h3><p>checkout 命令通常用来从仓库中取出文件，或者在分支中切换。</p><p>checkout 命令让 git 把文件复制到工作目录和暂存区域。比如 git checkout HEAD~ foo.c把文件从foo.c提交节点HEAD~ (当前提交节点的父节点)复制到工作目录并且生成索引。注意当前分支没有变化。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/8.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果没有指定文件名，而是一个本地分支，那么将切换到那个分支去。同时把索引和工作目录切换到那个分支对应的状态。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/9.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果既没有指定文件名，也没有指定分支名，而是一个标签、远程分支、SHA-1值或者是像master~3类似的东西，就得到一个匿名分支，称作detached HEAD。这样可以很方便的在历史版本之间互相切换。但是，这样的提交是完全不同的，详细的在下面。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/10.png" srcset="/img/loading.gif" lazyload alt=""></p><h3 id="用分离-HEAD-提交"><a href="#用分离-HEAD-提交" class="headerlink" title="用分离 HEAD 提交"></a>用分离 HEAD 提交</h3><p>HEAD是分离的时候, 提交可以正常进行, 但是没有更新已命名的分支. 。(可以看作是匿名分支。)</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/11.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果此时切换到别的分支，那么所做的工作会全部丢失。注意这个命令之后就不存在2eecb了。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/12.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果你想保存当前的状态，可以用这个命令创建一个新的分支：git checkout -b name。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/13.png" srcset="/img/loading.gif" lazyload alt=""></p><h3 id="Reset"><a href="#Reset" class="headerlink" title="Reset"></a>Reset</h3><p>reset 命令把当前分支指向另一个位置，并且有选择的变动工作目录和索引。也用来在从历史仓库中复制文件到索引，而不动工作目录。</p><p>如果不给选项，那么当前分支指向到那个提交。如果用—hard选项，那么工作目录也更新，如果用—soft选项，那么都不变。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/14.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果没有给出提交点的版本号，那么默认用 HEAD。这样，分支指向不变，但是索引会回滚到最后一次提交，如果用—hard选项，工作目录也同样。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/15.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果给了文件名(或者-p选项), 那么工作效果和带文件名的checkout差不多，除了索引被更新。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/16.png" srcset="/img/loading.gif" lazyload alt=""></p><h3 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h3><p>merge 命令把不同分支合并起来。合并前，索引必须和当前提交相同。如果另一个分支是当前提交的祖父节点，那么合并命令将什么也不做。另一种情况是如果当前提交是另一个分支的祖父节点，就导致fast-forward合并。指向只是简单的移动，并生成一个新的提交。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/17.png" srcset="/img/loading.gif" lazyload alt=""></p><p>否则就是一次真正的合并。默认把当前提交(ed489 如下所示)和另一个提交(33104)以及他们的共同祖父节点(b325c)进行一次三方合并。结果是先保存当前目录和索引，然后和父节点33104一起做一次新提交。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/18.png" srcset="/img/loading.gif" lazyload alt=""></p><h3 id="Cherry-Pick"><a href="#Cherry-Pick" class="headerlink" title="Cherry Pick"></a>Cherry Pick</h3><p>cherry-pick命令”复制”一个提交节点并在当前复制做一次完全一样的新提交。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/19.png" srcset="/img/loading.gif" lazyload alt=""></p><h3 id="Rebase"><a href="#Rebase" class="headerlink" title="Rebase"></a>Rebase</h3><p>衍合是合并命令的另一种选择。合并把两个父分支合并进行一次提交，提交历史不是线性的。衍合在当前分支上重演另一个分支的历史，提交历史是线性的。本质上，这是线性化的自动的 cherry-pick</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/20.png" srcset="/img/loading.gif" lazyload alt=""></p><p>上面的命令都在topic分支中进行，而不是master分支，在master分支上重演，并且把分支指向新的节点。注意旧提交没有被引用，将被回收。</p><p>要限制回滚范围，使用—onto选项。下面的命令在master分支上重演当前分支从169a6以来的最近几个提交，即2c33a。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-11/21.png" srcset="/img/loading.gif" lazyload alt=""></p><p>同样有 git rebase —interactive 让你更方便的完成一些复杂操作，比如丢弃、重排、修改、合并提交。没有图片体现着下，细节看这里:git-rebase(1)</p><h2 id="技术说明"><a href="#技术说明" class="headerlink" title="技术说明"></a>技术说明</h2><p>文件内容并没有真正存储在索引(.git/index)或者提交对象中，而是以blob的形式分别存储在数据库中 (.git/objects)，并用 SHA-1 值来校验。索引文件用识别码列出相关的blob文件以及别的数据。对于提交来说，以树(tree)的形式存储，同样用对于的哈希值识别。树对应着工作目录中的文件夹，树中包含的 树或者 blob 对象对应着相应的子目录和文件。每次提交都存储下它的上一级树的识别码。</p><p>如果用detached HEAD提交，那么最后一次提交会被the reflog for HEAD引用。但是过一段时间就失效，最终被回收，与git commit —amend或者git rebase很像。</p><p>转载自：微信公众号crossincode</p><p>原文地址：<a href="http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg" target="_blank" rel="noopener">http://marklodato.github.io/visual-git-guide/index-zh-cn.html?no-svg</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Redis高可用总结：Redis主从复制、哨兵集群、脑裂... </title>
    <link href="/2021/02/10/2021-02-10-redis-high-availability/"/>
    <url>/2021/02/10/2021-02-10-redis-high-availability/</url>
    
    <content type="html"><![CDATA[<p>在实际的项目中，服务高可用非常重要，如，当Redis作为缓存服务使用时， 缓解数据库的压力，提高数据的访问速度，提高网站的性能 ，但如果使用Redis 是单机模式运行 ，只要一个服务器宕机就不可以提供服务，这样会可能造成服务效率低下，甚至出现其相对应的服务应用不可用。</p><p>因此为了实现高可用，Redis 提供了哪些高可用方案？</p><ul><li>Redis主从复制</li><li>Redis持久化</li><li>哨兵集群</li><li>…</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>Redis基于一个Master主节点多Slave从节点的模式和Redis持久化机制，将一份数据保持在多个实例中实现增加副本冗余量，又使用哨兵机制实现主备切换， 在master故障时，自动检测，将某个slave切换为master，最终实现Redis高可用 。</p><hr><h3 id="Redis主从复制"><a href="#Redis主从复制" class="headerlink" title="Redis主从复制"></a><strong>Redis主从复制</strong></h3><p>Redis主从复制，主从库模式一个Master主节点多Slave从节点的模式，将一份数据保存在多Slave个实例中，增加副本冗余量，当某些出现宕机后，Redis服务还可以使用。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/2.png" srcset="/img/loading.gif" lazyload alt=""></p><p>但是这会存在数据不一致问题，那redis的副本集是如何数据一致性？</p><p>Redis为了保证数据副本的一致，主从库之间采用读写分离的方式：</p><ul><li><strong>读操作：主库、从库都可以执行处理；</strong></li><li><strong>写操作：先在主库执行，再由主库将写操作同步给从库。</strong></li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/3.png" srcset="/img/loading.gif" lazyload alt=""></p><p>使用读写分离方式的好处，可以避免当主从库都可以处理写操作时，主从库处理写操作加锁等一系列巨额的开销。</p><p>采用读写分离方式，写操作只会在主库中进行后同步到从库中，那主从库是如何同步数据的呢？</p><p>主从库是同步数据方式有两种：</p><ul><li><strong>全量同步：</strong>通常是主从服务器刚刚连接的时候，会先进行全量同步</li><li><strong>增量同步 ：</strong>一般在全同步结束后，进行增量同步，比如主从库间网络断，再进行数据同步。</li></ul><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h4 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a><strong>全量同步</strong></h4><p>主从库间第一次全量同步，具体分成三个阶段：</p><ul><li>当一个从库启动时，从库给主库发送 psync 命令进行数据同步（psync 命令包含：主库的 runID 和复制进度 offset 两个参数），</li><li>当主库接收到psync 命令后将会保存RDB 文件并发送给从库，发送期间会使用缓存区（replication buffer）记录后续的所有写操作 ，从库收到数据后，会先清空当前数据库，然后加载从主库获取的RDB 文件，</li><li>当主库完成 RDB 文件发送后，也会把将保存发送RDB文件期间写操作的replication buffer发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/4.png" srcset="/img/loading.gif" lazyload alt=""></p><p>另外，为了分担主库生成 RDB 文件和传输 RDB 文件压力，提高效率，可以使用 “主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/5.png" srcset="/img/loading.gif" lazyload alt=""></p><h4 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a><strong>增量同步</strong></h4><p>增量同步，基于环形缓冲区repl_backlog_buffer缓存区实现。</p><p>在环形缓冲区，主库会记录自己写到的位置 master_repl_offset ，从库则会记录自己已经读到的位置slave_repl_offset, 主库并通过master_repl_offset 和 slave_repl_offset的差值的数据同步到从库。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/6.png" srcset="/img/loading.gif" lazyload alt=""></p><p>主从库间网络断了， 主从库会采用增量复制的方式继续同步，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区，然后主库并通过master_repl_offset 和 slave_repl_offset的差值数据同步到从库。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/7.png" srcset="/img/loading.gif" lazyload alt=""></p><p>因为repl_backlog_buffer 是一个环形缓冲区，当在缓冲区写满后，主库会继续写入，此时，会出现什么情况呢？</p><p>覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。因此需要关注 repl_backlog_size参数，调整合适的缓冲空间大小，避免数据覆盖，主从数据不一致。</p><p>主从复制，除了会出现数据不一致外，甚至可能出现主库宕机的情况，Redis会有主从自主切换机制，那如何实现的呢？</p><hr><h3 id="Redis哨兵机制"><a href="#Redis哨兵机制" class="headerlink" title="Redis哨兵机制"></a><strong>Redis哨兵机制</strong></h3><p>当主库挂了，redis写操作和数据同步无法进行，为了避免这样情况，可以在主库挂了后重新在从库中选举出一个新主库，并通知到客户端，redis提供了 哨兵机制，哨兵为运行在特殊模式下的 Redis 进程。</p><h4 id="Redis会有主从自主切换机制，那如何实现的呢？"><a href="#Redis会有主从自主切换机制，那如何实现的呢？" class="headerlink" title="Redis会有主从自主切换机制，那如何实现的呢？"></a><strong>Redis会有主从自主切换机制，那如何实现的呢？</strong></h4><p>哨兵机制是实现主从库自动切换的关键机制，其主要分为三个阶段:</p><ul><li><strong>监控：哨兵进程会周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。</strong></li><li><strong>选主（选择主库）：主库挂了以后，哨兵基于一定规则评分选选举出一个从库实例新的主库 。</strong></li><li><strong>通知 ：哨兵会将新主库的信息发送给其他从库，让它们和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的信息广播通知给客户端，让它们把请求操作发到新主库上。</strong></li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/8.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>其中，在监控中如何判断主库是否处于下线状态？</strong></p><p>哨兵对主库的下线判断分为：</p><ul><li>主观下线：<strong>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态</strong>， 如果单哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”</li><li>客观下线：在哨兵集群中，基于少数服从多数，多数实例都判定主库已“主观下线”，则认为主库“客观下线”。</li></ul><p><strong>为什么会有这两种”主观下线”和“客观下线”的下线状态呢？</strong></p><p>由于单机哨兵很容易产生误判，误判后主从切换会产生一系列的额外开销，为了减少误判，避免这些不必要的开销，采用哨兵集群，引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况，</p><p>基于少数服从多数原则， 当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线” （可以自定义设置阙值）。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/9.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>那么哨兵之间是如何互相通信的呢？</strong></p><p>哨兵集群中哨兵实例之间可以相互发现，<strong>基于 Redis 提供的发布 / 订阅机制（pub/sub 机制）</strong>,</p><p>哨兵可以在主库中发布/订阅消息，在主库上有一个名为“_<em>sentinel_</em>:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的，而且只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/10.png" srcset="/img/loading.gif" lazyload alt=""></p><p>哨兵 1连接相关信息（IP端口）发布到“_<em>sentinel_</em>:hello”频道上，哨兵 2 和 3 订阅了该频道。</p><p>哨兵 2 和 3 就可以从这个频道直接获取哨兵 1连接信息，以这样的方式哨兵集群就形成了，实现各个哨兵互相通信。</p><p>哨兵集群中各个实现通信后，就可以判定主库是否已客观下线。</p><p><strong>在已判定主库已下线后，又如何选举出新的主库？</strong></p><p>新主库选举按照<strong>一定条件</strong>筛选出的符合条件的从库，并按照<strong>一定规则</strong>对其进行打分，最高分者为新主库。</p><p>通常<strong>一定条件</strong>包括：</p><ul><li>从库的当前在线状态，</li><li>判断它之前的网络连接状态，通过down-after-milliseconds * num(断开连接次数)，当断开连接次数超过阈值，不适合为新主库。</li></ul><p><strong>一定规则包括</strong></p><ul><li>从库优先级 ， 通过slave-priority 配置项，给不同的从库设置不同优先级，优先级最高的从库得分高</li><li>从库复制进度，和旧主库同步程度最接近的从库得分高，通过repl_backlog_buffer缓冲区记录主库 master_repl_offset 和从库slave_repl_offset 相差最小高分</li><li>从库 ID 号 ， ID 号小的从库得分高。</li></ul><p><strong>全都都基于在只有在一定规则中的某一轮评出最高分从库就选举结束，哨兵发起主从切换。</strong></p><h4 id="leader哨兵"><a href="#leader哨兵" class="headerlink" title="leader哨兵"></a><strong>leader哨兵</strong></h4><p><strong>选举完新的主库后，不能每个哨兵都发起主从切换，需要选举成leader哨兵，那如何选举leader哨兵执行主从切换？</strong></p><p>选举leader哨兵，也是基于少数服从多数原则”投票仲裁”选举出来，</p><ul><li>当任何一个从库判定主库“主观下线”后，发送命令 s-master-down-by-addr命令发送想要成为Leader的信号，</li><li>其他哨兵根据与主机连接情况作出相对的响应，赞成票Y，反对票N，而且如果有多个哨兵发起请求，每个哨兵的赞成票只能投给其中一个，其他只能为反对票。</li></ul><p>想要成为Leader 的哨兵，要满足两个条件：</p><ul><li>第一，获得半数以上的赞成票；</li><li>第二，获得的票数同时还需要大于等于哨兵配置文件中的quorum值。</li></ul><p><strong>选举完leader哨兵并新主库切换完毕之后，那么leader哨兵怎么通知客户端？</strong></p><p>还是基于哨兵自身的 pub/sub 功能，实现了客户端和哨兵之间的事件通知，客户端订阅哨兵自身消息频道 ，而且哨兵提供的消息订阅频道有很多，不同频道包含了：</p><table><thead><tr><th>事件</th><th>相关频道</th></tr></thead><tbody><tr><td>主库下线事件</td><td>+sdown（实例进入“主观下线”状态） -sdown（实例退出“主观下线”状态） +odown（实例进入“客观下线”状态） -odown（实例退出“客观下线”状态）</td></tr><tr><td>新主库切换</td><td>+ switch-master（主库地址发生变化）</td></tr></tbody></table><p>其中，当客户端从哨兵订阅消息主从库切换，当主库切换后，端户端就会接收到新主库的连接信息：</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml">switch-master <span class="hljs-tag">&lt;<span class="hljs-name">master</span> <span class="hljs-attr">name</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">oldip</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">oldport</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">newip</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">newport</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>在这样的方式哨兵就可以通知客户端切换了新库。</p><p>基于上述的机制和原理Redis实现了高可用，但也会带了一些潜在的风险，比如数据缺失。</p><hr><h3 id="数据问题"><a href="#数据问题" class="headerlink" title="数据问题"></a><strong>数据问题</strong></h3><p>Redis实现高可用，但实现期间可能产出一些风险：</p><ul><li><strong>主备切换的过程， 异步复制导致的数据丢失</strong></li><li><strong>脑裂导致的数据丢失</strong></li><li><strong>主备切换的过程，异步复制导致数据不一致</strong></li></ul><h4 id="-1"><a href="#-1" class="headerlink" title=""></a></h4><h4 id="数据丢失-主从异步复制"><a href="#数据丢失-主从异步复制" class="headerlink" title="数据丢失-主从异步复制"></a><strong>数据丢失-主从异步复制</strong></h4><p>因为master 将数据复制给slave是异步实现的，在复制过程中，这可能存在master有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了。</p><p><strong>总结：主库的数据还没有同步到从库，结果主库发生了故障，未同步的数据就丢失了。</strong></p><h4 id="数据丢失-脑裂"><a href="#数据丢失-脑裂" class="headerlink" title="数据丢失-脑裂"></a><strong>数据丢失-脑裂</strong></h4><p>何为脑裂？当一个集群中的 master 恰好网络故障，导致与 sentinal 通信不上了，sentinal会认为master下线，且sentinal选举出一个slave 作为新的 master，此时就存在两个 master了。</p><p>此时，可能存在client还没来得及切换到新的master，还继续写向旧master的数据，当master再次恢复的时候，会被作为一个slave挂到新的master 上去，自己的数据将会清空，重新从新的master 复制数据，这样就会导致数据缺失。</p><p><strong>总结：主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。</strong></p><h4 id="数据丢失解决方案"><a href="#数据丢失解决方案" class="headerlink" title="数据丢失解决方案"></a><strong>数据丢失解决方案</strong></h4><p>数据丢失可以通过合理地配置参数 min-slaves-to-write 和 min-slaves-max-lag 解决，比如</p><ul><li>min-slaves-to-write 1</li><li>min-slaves-max-lag 10</li></ul><p>如上两个配置：要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒，如果超过 1 个 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。</p><h4 id="数据不一致"><a href="#数据不一致" class="headerlink" title="数据不一致"></a><strong>数据不一致</strong></h4><p>在主从异步复制过程，当从库因为网络延迟或执行复杂度高命令阻塞导致滞后执行同步命令，这样就会导致数据不一致</p><p><strong>解决方案：可以开发一个外部程序来监控主从库间的复制进度（master_repl_offset 和 slave_repl_offset ），通过监控 master_repl_offset 与slave_repl_offset差值得知复制进度，当复制进度不符合预期设置的Client不再从该从库读取数据。</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2021-02-10/11.png" srcset="/img/loading.gif" lazyload alt=""></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>Redis使用主从复制、持久化、哨兵机制等实现高可用，需要理解其实现过程，也要明白其带了风险以及解决方案，才能在实际项目更好优化，提升系统的可靠性、稳定性。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Mysql面试题50道 </title>
    <link href="/2020/10/01/2020-10-01-mysql-interview-questions/"/>
    <url>/2020/10/01/2020-10-01-mysql-interview-questions/</url>
    
    <content type="html"><![CDATA[<p><strong>1、MySQL 中有哪几种锁？</strong></p><p>（1）表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最 高，并发度最低。</p><p>（2）行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最 低，并发度也最高。</p><p>（3）页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表 锁和行锁之间，并发度一般。</p><p><strong>2、MySQL 中有哪些不同的表格？</strong></p><p>共有 5 种类型的表格：</p><p>（1）MyISAM</p><p>（2）Heap</p><p>（3）Merge</p><p>（4）INNODB</p><p>（5）ISAM</p><p><strong>3、简述在 MySQL 数据库中 MyISAM 和 InnoDB 的区别</strong></p><p>MyISAM：</p><p>（1）不支持事务，但是每次查询都是原子的；</p><p>（2）支持表级锁，即每次操作是对整个表加锁；</p><p>（3）存储表的总行数；</p><p>（4）一个 MYISAM 表有三个文件：索引文件、表结构文件、数据文件；</p><p>（5）采用菲聚集索引，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性。</p><p>InnoDb：</p><p>（1）支持 ACID 的事务，支持事务的四种隔离级别；</p><p>（2）支持行级锁及外键约束：因此可以支持写并发；</p><p>（3）不存储总行数：</p><p>（4）一个 InnoDb 引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一个表可能分布在多个文件里），也有可能为多个（设置为独立表空，表大小受操作系统文件大小限制，一般为 2G），受操作系统文件大小的限制；</p><p>（5）主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；最好使用自增主键，防止插入数据时，为维持 B+树结构，文件的大调整。</p><p><strong>4、MySQL 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别</strong></p><p>SQL 标准定义的四个隔离级别为：</p><p>（1）read uncommited ：读到未提交数据</p><p>（2）read committed：脏读，不可重复读</p><p>（3）repeatable read：可重读</p><p>（4）serializable ：串行事物</p><p><strong>5、CHAR 和 VARCHAR 的区别？</strong></p><p>（1）CHAR 和 VARCHAR 类型在存储和检索方面有所不同</p><p>（2）CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255 当 CHAR值被存储时，它们被用空格填充到特定长度，检索 CHAR 值时需删除尾随空格。</p><p><strong>6、主键和候选键有什么区别？</strong></p><p>表格的每一行都由主键唯一标识,一个表只有一个主键。</p><p>主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。</p><p><strong>7、myisamchk 是用来做什么的？</strong></p><p>它用来压缩 MyISAM 表，这减少了磁盘或内存使用。</p><p>MyISAM Static 和 MyISAM Dynamic 有什么区别？</p><p>在 MyISAM Static 上的所有字段有固定宽度。动态 MyISAM 表将具有像 TEXT，BLOB 等字段，以适应不同长度的数据类型。</p><p>MyISAM Static 在受损情况下更容易恢复。</p><p><strong>8、如果一个表有一列定义为 TIMESTAMP，将发生什么？</strong></p><p>每当行被更改时，时间戳字段将获取当前时间戳。</p><p>列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？</p><p>它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。</p><p>怎样才能找出最后一次插入时分配了哪个自动增量？</p><p>LAST_INSERT_ID 将返回由 Auto_increment 分配的最后一个值，并且不需要指定表名称。</p><p><strong>9、你怎么看到为表格定义的所有索引？</strong></p><p>索引是通过以下方式为表格定义的：</p><p>SHOW INDEX FROM <tablename>;</p><p><strong>10、LIKE 声明中的％和_是什么意思？</strong></p><p>％对应于 0 个或更多字符，_只是 LIKE 语句中的一个字符。</p><p>如何在 Unix 和 MySQL 时间戳之间进行转换？</p><p>UNIX_TIMESTAMP 是从 MySQL 时间戳转换为 Unix 时间戳的命令</p><p>FROM_UNIXTIME 是从 Unix 时间戳转换为 MySQL 时间戳的命令</p><p><strong>11、列对比运算符是什么？</strong></p><p>在 SELECT 语句的列比较中使用=，&lt;&gt;，&lt;=，&lt;，&gt; =，&gt;，&lt;&lt;，&gt;&gt;，&lt;=&gt;，AND，OR 或 LIKE 运算符。</p><p><strong>12、BLOB 和 TEXT 有什么区别？</strong></p><p>BLOB 是一个二进制对象，可以容纳可变数量的数据。TEXT 是一个不区分大小写的 BLOB。</p><p>BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时区分大小写，对 TEXT 值不区分大小写。</p><p><strong>13、MySQL_fetch_array 和 MySQL_fetch_object 的区别是什么？</strong></p><p>以下是 MySQL_fetch_array 和 MySQL_fetch_object 的区别：</p><p>MySQL_fetch_array（） – 将结果行作为关联数组或来自数据库的常规数组返回。</p><p>MySQL_fetch_object – 从数据库返回结果行作为对象。</p><p><strong>14、MyISAM 表格将在哪里存储，并且还提供其存储格式？</strong></p><p>每个 MyISAM 表格以三种格式存储在磁盘上：</p><p>（1）·“.frm”文件存储表定义</p><p>（2）·数据文件具有“.MYD”（MYData）扩展名</p><p>（3）索引文件具有“.MYI”（MYIndex）扩展名</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1><p><strong>15、MySQL 如何优化 DISTINCT？</strong></p><p>DISTINCT 在所有列上转换为 GROUP BY，并与 ORDER BY 子句结合使用。</p><p>SELECT DISTINCT t1.a FROM t1,t2 where t1.a=t2.a;</p><p><strong>16、如何显示前 50 行？</strong></p><p>在 MySQL 中，使用以下代码查询显示前 50 行：</p><p>SELECT*FROM</p><p>LIMIT 0,50;</p><h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><p><strong>17、可以使用多少列创建索引？</strong></p><p>任何标准表最多可以创建 16 个索引列。</p><h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><p><strong>18、NOW（）和 CURRENT_DATE（）有什么区别？</strong></p><p>NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。</p><p>CURRENT_DATE（）仅显示当前年份，月份和日期。</p><h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><p><strong>19、什么是非标准字符串类型？</strong></p><p>（1）TINYTEXT</p><p>（2）TEXT</p><p>（3）MEDIUMTEXT</p><p>（4）LONGTEXT</p><h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><p><strong>20、什么是通用 SQL 函数？</strong></p><p>（1）CONCAT(A, B) – 连接两个字符串值以创建单个字符串输出。通常用于将两个或多个字段合并为一个字段。</p><p>（2）FORMAT(X, D)- 格式化数字 X 到 D 有效数字。</p><p>（3）CURRDATE(), CURRTIME()- 返回当前日期或时间。</p><p>（4）NOW（） – 将当前日期和时间作为一个值返回。</p><p>（5）MONTH（），DAY（），YEAR（），WEEK（），WEEKDAY（） – 从日期值中提取给定数据。</p><p>（6）HOUR（），MINUTE（），SECOND（） – 从时间值中提取给定数据。</p><p>（7）DATEDIFF（A，B） – 确定两个日期之间的差异，通常用于计算年龄</p><p>（8）SUBTIMES（A，B） – 确定两次之间的差异。</p><p>（9）FROMDAYS（INT） – 将整数天数转换为日期值。</p><h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><p><strong>21、MySQL 支持事务吗？</strong></p><p>在缺省模式下，MySQL 是 autocommit 模式的，所有的数据库更新操作都会即时提交，所以在缺省情况下，MySQL 是不支持事务的。</p><p>但是如果你的 MySQL 表类型是使用 InnoDB Tables 或 BDB tables 的话，你的MySQL 就可以使用事务处理,使用 SETAUTOCOMMIT=0 就可以使 MySQL 允许在非 autocommit 模式，在非autocommit 模式下，你必须使用 COMMIT 来提交你的更改，或者用 ROLLBACK来回滚你的更改。</p><h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><p><strong>22、MySQL 里记录货币用什么字段类型好</strong></p><p>NUMERIC 和 DECIMAL 类型被MySQL 实现为同样的类型，这在 SQL92 标准允许。他们被用于保存值，该值的准确精度是极其重要的值，例如与金钱有关的数据。当声明一个类是这些类型之一时，精度和规模的能被(并且通常是)指定。</p><p>例如：</p><p>salary DECIMAL(9,2)</p><p>在这个例子中，9(precision)代表将被用于存储值的总的小数位数，而 2(scale)代 表将被用于存储小数点后的位数。</p><p>因此，在这种情况下，能被存储在 salary 列中的值的范围是从-9999999.99 到9999999.99。</p><h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><p><strong>23、MySQL 有关权限的表都有哪几个？</strong></p><p>MySQL 服务器通过权限表来控制用户对数据库的访问，权限表存放在 MySQL 数据库里，由 MySQL_install_db 脚本初始化。这些权限表分别 user，db，table_priv，columns_priv 和 host。</p><h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><p><strong>24、列的字符串类型可以是什么？</strong></p><p>字符串类型是：</p><p>（1）SET2</p><p>（2）BLOB</p><p>（3）ENUM</p><p>（4）CHAR</p><p>（5）TEXT</p><h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><p><strong>25、MySQL 数据库作发布系统的存储，一天五万条以上的增量，预计运维三年,怎么优化？</strong></p><p>（1）设计良好的数据库结构，允许部分数据冗余，尽量避免 join 查询，提高效率。</p><p>（2）选择合适的表字段数据类型和存储引擎，适当的添加索引。</p><p>（3）MySQL 库主从读写分离。</p><p>（4）找规律分表，减少单表中的数据量提高查询速度。</p><p>（5）添加缓存机制，比如 memcached，apc 等。</p><p>（6）不经常改动的页面，生成静态页面。</p><p>（7）书写高效率的 SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE.</p><h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><p><strong>26、锁的优化策略</strong></p><p>（1）读写分离</p><p>（2）分段加锁</p><p>（3）减少锁持有的时间</p><p>（4）多个线程尽量以相同的顺序去获取资源</p><p>不能将锁的粒度过于细化，不然可能会出现线程的加锁和释放次数过多，反而效率不如一次加一把大锁。</p><h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><p><strong>27、索引的底层实现原理和优化</strong></p><p>B+树，经过优化的 B+树</p><p>主要是在所有的叶子结点中增加了指向下一个叶子节点的指针，因此 InnoDB 建议为大部分表使用默认自增的主键作为主索引。</p><h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><p><strong>28、什么情况下设置了索引但无法使用</strong></p><p>（1）以“%”开头的 LIKE 语句，模糊匹配</p><p>（2）OR 语句前后没有同时使用索引</p><p>（3）数据类型出现隐式转化（如 varchar 不加单引号的话可能会自动转换为 int 型）</p><h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><p><strong>29、实践中如何优化 MySQL</strong></p><p>最好是按照以下顺序优化：</p><p>（1）SQL 语句及索引的优化</p><p>（2）数据库表结构的优化</p><p>（3）系统配置的优化</p><p>（4）硬件的优化</p><h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><p><strong>30、优化数据库的方法</strong></p><p>（1）选取最适用的字段属性，尽可能减少定义字段宽度，尽量把字段设置 NOTNULL，例如’省份’、’性别’最好适用 ENUM</p><p>（2）使用连接(JOIN)来代替子查询</p><p>（3）适用联合(UNION)来代替手动创建的临时表</p><p>（4）事务处理</p><p>（5）锁定表、优化事务处理</p><p>（6）适用外键，优化锁定表</p><p>（7）建立索引</p><p>（8）优化查询语句</p><h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><p><strong>31、简单描述 MySQL 中，索引，主键，唯一索引，联合索引的区别，对数据库的性能有什么影响（从读写两方面）</strong></p><p>索引是一种特殊的文件(InnoDB 数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。</p><p>普通索引(由关键字 KEY 或 INDEX 定义的索引)的唯一任务是加快对数据的访问速度。</p><p>普通索引允许被索引的数据列包含重复的值。如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字 UNIQUE 把它定义为一个唯一索引。也就是说，唯一索引可以保证数据记录的唯一性。</p><p>主键，是一种特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录，使用关键字 PRIMARY KEY 来创建。</p><p>索引可以覆盖多个数据列，如像 INDEX(columnA, columnB)索引，这就是联合索引。</p><p>索引可以极大的提高数据的查询速度，但是会降低插入、删除、更新表的速度，因为在执行这些写操作时，还要操作索引文件。</p><h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><p><strong>32、数据库中的事务是什么?</strong></p><p>事务（transaction）是作为一个单元的一组有序的数据库操作。如果组中的所有操作都成功，则认为事务成功，即使只有一个操作失败，事务也不成功。如果所有操作完成，事务则提交，其修改将作用于所有其他数据库进程。如果一个操作失败，则事务将回滚，该事务所有操作的影响都将取消。</p><p>事务特性：</p><p>（1）原子性：即不可分割性，事务要么全部被执行，要么就全部不被执行。</p><p>（2）一致性或可串性。事务的执行使得数据库从一种正确状态转换成另一种正确状态。</p><p>（3）隔离性。在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务。</p><p>（4）持久性。事务正确提交后，其结果将永久保存在数据库中，即使在事务提交后有了其他故障，事务的处理结果也会得到保存。</p><p>或者这样理解：</p><p>事务就是被绑定在一起作为一个逻辑工作单元的 SQL 语句分组，如果任何一个语句操作失败那么整个操作就被失败，以后操作就会回滚到操作前状态，或者是上有个节点。为了确保要么执行，要么不执行，就可以使用事务。要将有组语句作为事务考虑，就需要通过 ACID 测试，即原子性，一致性，隔离性和持久性。</p><h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><p><strong>33、SQL 注入漏洞产生的原因？如何防止？</strong></p><p>SQL 注入产生的原因：程序开发过程中不注意规范书写 sql 语句和对特殊字符进行过滤，导致客户端可以通过全局变量 POST 和 GET 提交一些 sql 语句正常执行。</p><p>防止 SQL 注入的方式：</p><p>开启配置文件中的 magic_quotes_gpc 和 magic_quotes_runtime 设置</p><p>执行 sql 语句时使用 addslashes 进行 sql 语句转换</p><p>Sql 语句书写尽量不要省略双引号和单引号。</p><p>过滤掉 sql 语句中的一些关键词：update、insert、delete、select、 * 。</p><p>提高数据库表和字段的命名技巧，对一些重要的字段根据程序的特点命名，取不易被猜到的。</p><h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><p><strong>34、为表中得字段选择合适得数据类型</strong></p><p>字段类型优先级: 整形&gt;date,time&gt;enum,char&gt;varchar&gt;blob,text</p><p>优先考虑数字类型，其次是日期或者二进制类型，最后是字符串类型，同级别得数据类型，应该优先选择占用空间小的数据类型</p><h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1><p><strong>35、存储时期</strong></p><p>Datatime:以 YYYY-MM-DD HH:MM:SS 格式存储时期时间，精确到秒，占用 8 个字节得存储空间，datatime 类型与时区无关Timestamp:以时间戳格式存储，占用 4 个字节，范围小 1970-1-1 到 2038-1-19，显示依赖于所指定得时区，默认在第一个列行的数据修改时可以自动得修改timestamp 列得值</p><p>Date:（生日）占用得字节数比使用字符串.datatime.int 储存要少，使用 date 只需要 3 个字节，存储日期月份，还可以利用日期时间函数进行日期间得计算</p><p>Time:存储时间部分得数据</p><p>注意:不要使用字符串类型来存储日期时间数据（通常比字符串占用得储存空间小，在进行查找过滤可以利用日期得函数）</p><p>使用 int 存储日期时间不如使用 timestamp 类型</p><h1 id="-20"><a href="#-20" class="headerlink" title=""></a></h1><p><strong>36、对于关系型数据库而言，索引是相当重要的概念，请回答有关索引的几个问题：</strong></p><p>（1）索引的目的是什么？</p><p>快速访问数据表中的特定信息，提高检索速度</p><p>创建唯一性索引，保证数据库表中每一行数据的唯一性。</p><p>加速表和表之间的连接</p><p>使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间</p><p>（2）索引对数据库系统的负面影响是什么？</p><p>负面影响：</p><p>创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加；索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间；当对表进行增、删、改、的时候索引也要动态维护，这样就降低了数据的维护速度。</p><p>（3）为数据表建立索引的原则有哪些？</p><p>在最频繁使用的、用以缩小查询范围的字段上建立索引。</p><p>在频繁使用的、需要排序的字段上建立索引</p><p>（4）什么情况下不宜建立索引？</p><p>对于查询中很少涉及的列或者重复值比较多的列，不宜建立索引。</p><p>对于一些特殊的数据类型，不宜建立索引，比如文本字段（text）等</p><h1 id="-21"><a href="#-21" class="headerlink" title=""></a></h1><p><strong>37、解释 MySQL 外连接、内连接与自连接的区别</strong></p><p>先说什么是交叉连接: 交叉连接又叫笛卡尔积，它是指不使用任何条件，直接将一个表的所有记录和另一个表中的所有记录一一匹配。</p><p>内连接 则是只有条件的交叉连接，根据某个条件筛选出符合条件的记录，不符合条件的记录不会出现在结果集中，即内连接只连接匹配的行。</p><p>外连接 其结果集中不仅包含符合连接条件的行，而且还会包括左表、右表或两个表中的所有数据行，这三种情况依次称之为左外连接，右外连接，和全外连接。</p><p>左外连接，也称左连接，左表为主表，左表中的所有记录都会出现在结果集中，对于那些在右表中并没有匹配的记录，仍然要显示，右边对应的那些字段值以NULL 来填充。右外连接，也称右连接，右表为主表，右表中的所有记录都会出现在结果集中。左连接和右连接可以互换，MySQL 目前还不支持全外连接。</p><h1 id="-22"><a href="#-22" class="headerlink" title=""></a></h1><p><strong>38、Myql 中的事务回滚机制概述</strong></p><p>事务是用户定义的一个数据库操作序列，这些操作要么全做要么全不做，是一个不可分割的工作单位，事务回滚是指将该事务已经完成的对数据库的更新操作撤销。</p><p>要同时修改数据库中两个不同表时，如果它们不是一个事务的话，当第一个表修改完，可能第二个表修改过程中出现了异常而没能修改，此时就只有第二个表依旧是未修改之前的状态，而第一个表已经被修改完毕。而当你把它们设定为一个事务的时候，当第一个表修改完，第二表修改出现异常而没能修改，第一个表和第二个表都要回到未修改的状态，这就是所谓的事务回滚</p><h1 id="-23"><a href="#-23" class="headerlink" title=""></a></h1><p><strong>39、SQL 语言包括哪几部分？每部分都有哪些操作关键字？</strong></p><p>SQL 语言包括数据定义(DDL)、数据操纵(DML),数据控制(DCL)和数据查询（DQL） 四个部分。</p><p>数据定义：Create Table,Alter Table,Drop Table, Craete/Drop Index 等</p><p>数据操纵：Select ,insert,update,delete,</p><p>数据控制：grant,revoke</p><p>数据查询：select</p><p><strong>40、完整性约束包括哪些？</strong></p><p>数据完整性(Data Integrity)是指数据的精确(Accuracy)和可靠性(Reliability)。</p><p>分为以下四类：</p><p>（1）实体完整性：规定表的每一行在表中是惟一的实体。</p><p>（2）域完整性：是指表中的列必须满足某种特定的数据类型约束，其中约束又包括取值范围、精度等规定。</p><p>（3）参照完整性：是指两个表的主关键字和外关键字的数据应一致，保证了表之间的数据的一致性，防止了数据丢失或无意义的数据在数据库中扩散。</p><p>（4）用户定义的完整性：不同的关系数据库系统根据其应用环境的不同，往往还需要一些特殊的约束条件。用户定义的完整性即是针对某个特定关系数据库的约束条件，它反映某一具体应用必须满足的语义要求。</p><p>与表有关的约束：包括列约束(NOT NULL（非空约束）)和表约束(PRIMARY KEY、foreign key、check、UNIQUE) 。</p><h1 id="-24"><a href="#-24" class="headerlink" title=""></a></h1><p><strong>41、什么是锁？</strong></p><p>数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。</p><p>加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。</p><p>基本锁类型：锁包括行级锁和表级锁</p><h1 id="-25"><a href="#-25" class="headerlink" title=""></a></h1><p><strong>42、什么叫视图？游标是什么？</strong></p><p>视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，视图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易，相比多表查询。</p><p>游标：是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。</p><h1 id="-26"><a href="#-26" class="headerlink" title=""></a></h1><p><strong>43、什么是存储过程？用什么来调用？</strong></p><p>存储过程是一个预编译的 SQL 语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次 SQL，使用存储过程比单纯 SQL 语句执行要快。可以用一个命令对象来调用存储过程。</p><h1 id="-27"><a href="#-27" class="headerlink" title=""></a></h1><p><strong>44、如何通俗地理解三个范式？</strong></p><p>第一范式：1NF 是对属性的原子性约束，要求属性具有原子性，不可再分解；</p><p>第二范式：2NF 是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性；</p><p>第三范式：3NF 是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。。</p><p>范式化设计优缺点:</p><p>优点:可以尽量得减少数据冗余，使得更新快，体积小</p><p>缺点:对于查询需要多个表进行关联，减少写得效率增加读得效率，更难进行索引优化</p><p>反范式化:</p><p>优点:可以减少表得关联，可以更好得进行索引优化</p><p>缺点:数据冗余以及数据异常，数据得修改需要更多的成本</p><h1 id="-28"><a href="#-28" class="headerlink" title=""></a></h1><p><strong>45、什么是基本表？什么是视图？</strong></p><p>基本表是本身独立存在的表，在 SQL 中一个关系就对应一个表。视图是从一个或几个基本表导出的表。视图本身不独立存储在数据库中，是一个虚表</p><h1 id="-29"><a href="#-29" class="headerlink" title=""></a></h1><p><strong>46、试述视图的优点？</strong></p><p>(1) 视图能够简化用户的操作</p><p>(2) 视图使用户能以多种角度看待同一数据；</p><p>(3) 视图为数据库提供了一定程度的逻辑独立性；</p><p>(4)视图能够对机密数据提供安全保护。</p><h1 id="-30"><a href="#-30" class="headerlink" title=""></a></h1><p><strong>47、 NULL 是什么意思</strong></p><p>NULL 这个值表示 UNKNOWN(未知):它不表示“”(空字符串)。对 NULL 这个值的任何比较都会生产一个 NULL 值。您不能把任何值与一个 NULL 值进行比较，并在逻辑上希望获得一个答案。</p><p>使用 IS NULL 来进行 NULL 判断</p><h1 id="-31"><a href="#-31" class="headerlink" title=""></a></h1><p><strong>48、主键、外键和索引的区别？</strong></p><p>主键、外键和索引的区别</p><p>定义：</p><p>主键——唯一标识一条记录，不能有重复的，不允许为空</p><p>外键——表的外键是另一表的主键, 外键可以有重复的, 可以是空值</p><p>索引——该字段没有重复值，但可以有一个空值</p><p>作用：</p><p>主键——用来保证数据完整性</p><p>外键——用来和其他表建立联系用的</p><p>索引——是提高查询排序的速度</p><p>个数：</p><p>主键—— 主键只能有一个</p><p>外键—— 一个表可以有多个外键</p><p>索引—— 一个表可以有多个唯一索引</p><h1 id="-32"><a href="#-32" class="headerlink" title=""></a></h1><p><strong>49、你可以用什么来确保表格里的字段只接受特定范围里的值?</strong></p><p>Check 限制，它在数据库表格里被定义，用来限制输入该列的值。</p><p>触发器也可以被用来限制数据库表格里的字段能够接受的值，但是这种办法要求触发器在表格里被定义，这可能会在某些情况下影响到性能。</p><h1 id="-33"><a href="#-33" class="headerlink" title=""></a></h1><p><strong>50、说说对 SQL 语句优化有哪些方法？（选择几条）</strong></p><p>（1）Where 子句中：where 表之间的连接必须写在其他 Where 条件之前，那些可以过滤掉最大数量记录的条件必须写在 Where 子句的末尾.HAVING 最后。</p><p>（2）用 EXISTS 替代 IN、用 NOT EXISTS 替代 NOT IN。</p><p>（3） 避免在索引列上使用计算</p><p>（4）避免在索引列上使用 IS NULL 和 IS NOT NULL</p><p>（5）对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。</p><p>（6）应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描</p><p>（7）应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描</p>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 六种酷炫Python运行进度条 </title>
    <link href="/2020/09/29/2020-09-29-python-progressbar/"/>
    <url>/2020/09/29/2020-09-29-python-progressbar/</url>
    
    <content type="html"><![CDATA[<h2 id="1-普通进度条"><a href="#1-普通进度条" class="headerlink" title="1.普通进度条"></a>1.普通进度条</h2><p>在代码迭代运行中可以自己进行统计计算，并使用格式化字符串输出代码运行进度</p><figure class="highlight lua"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs lua">import sys<br>import <span class="hljs-built_in">time</span><br>def progress_bar():<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, <span class="hljs-number">101</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"\r"</span>, <span class="hljs-keyword">end</span>=<span class="hljs-string">""</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"Download progress: &#123;&#125;%: "</span>.<span class="hljs-built_in">format</span>(i), <span class="hljs-string">"▋"</span> * (i // <span class="hljs-number">2</span>), <span class="hljs-keyword">end</span>=<span class="hljs-string">""</span>)<br>        sys.<span class="hljs-built_in">stdout</span>.<span class="hljs-built_in">flush</span>()<br>        <span class="hljs-built_in">time</span>.sleep(<span class="hljs-number">0.05</span>)<br>progress_bar()<br></code></pre></div></td></tr></table></figure><h2 id="2-带时间进度条"><a href="#2-带时间进度条" class="headerlink" title="2.带时间进度条"></a>2.带时间进度条</h2><p>导入time模块来计算代码运行的时间，加上代码迭代进度使用格式化字符串来输出代码运行进度</p><figure class="highlight maxima"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs maxima">import <span class="hljs-built_in">time</span><br><span class="hljs-built_in">scale</span> = <span class="hljs-number">50</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"执行开始，祈祷不报错"</span>.<span class="hljs-built_in">center</span>(<span class="hljs-built_in">scale</span> // <span class="hljs-number">2</span>,<span class="hljs-string">"-"</span>))<br>start = <span class="hljs-built_in">time</span>.perf_counter()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">scale</span> + <span class="hljs-number">1</span>):<br>    a = <span class="hljs-string">"*"</span> * i<br>    b = <span class="hljs-string">"."</span> * (<span class="hljs-built_in">scale</span> - i)<br>    c = (i / <span class="hljs-built_in">scale</span>) * <span class="hljs-number">100</span><br>    dur = <span class="hljs-built_in">time</span>.perf_counter() - start<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"\r&#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.2f&#125;s"</span>.format(c,a,b,dur),end = <span class="hljs-string">""</span>)<br>    <span class="hljs-built_in">time</span>.sleep(<span class="hljs-number">0.1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"\n"</span>+<span class="hljs-string">"执行结束，万幸"</span>.<span class="hljs-built_in">center</span>(<span class="hljs-built_in">scale</span> // <span class="hljs-number">2</span>,<span class="hljs-string">"-"</span>))<br></code></pre></div></td></tr></table></figure><h2 id="3-tpdm进度条"><a href="#3-tpdm进度条" class="headerlink" title="3.tpdm进度条"></a>3.tpdm进度条</h2><p>这是一个专门生成进度条的工具包，可以使用pip在终端进行下载，当然还能切换进度条风格</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript"><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br># 这里同样的，tqdm就是这个进度条最常用的一个方法<br># 里面存一个可迭代对象<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(range(<span class="hljs-number">1</span>, <span class="hljs-number">500</span>)):<br>   # 模拟你的任务<br>   sleep(<span class="hljs-number">0.01</span>)<br>sleep(<span class="hljs-number">0.5</span>)<br></code></pre></div></td></tr></table></figure><h2 id="4-progress进度条"><a href="#4-progress进度条" class="headerlink" title="4.progress进度条"></a>4.progress进度条</h2><p>你只需要定义迭代的次数、进度条类型并在每次迭代时告知进度条即可，具体代码案例如下</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> progress.bar <span class="hljs-keyword">import</span> IncrementalBar<br>mylist = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>]<br>bar = IncrementalBar(<span class="hljs-string">'Countdown'</span>, max = len(mylist))<br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> mylist:<br>    bar.next()<br>    time.sleep(<span class="hljs-number">1</span>)<br>    bar.finish()<br></code></pre></div></td></tr></table></figure><h2 id="5-alive-progress进度条"><a href="#5-alive-progress进度条" class="headerlink" title="5.alive_progress进度条"></a>5.alive_progress进度条</h2><p>顾名思义，这个库可以使得进度条变得生动起来，它比原来我们见过的进度条多了一些动画效果，需要使用pip进行下载，代码案例如下：</p><figure class="highlight livecodeserver"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs livecodeserver"><span class="hljs-built_in">from</span> alive_progress import alive_bar<br><span class="hljs-keyword">items</span> = range(<span class="hljs-number">100</span>)                  <span class="hljs-comment"># retrieve your set of items</span><br><span class="hljs-keyword">with</span> alive_bar(<span class="hljs-built_in">len</span>(<span class="hljs-keyword">items</span>)) <span class="hljs-keyword">as</span> bar:   <span class="hljs-comment"># declare your expected total</span><br>    <span class="hljs-keyword">for</span> <span class="hljs-keyword">item</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">items</span>:               <span class="hljs-comment"># iterate as usual</span><br>        <span class="hljs-comment"># process each item</span><br>        bar()<br>        <span class="hljs-built_in">time</span>.sleep(<span class="hljs-number">0.1</span>)<br></code></pre></div></td></tr></table></figure><h2 id="6-可视化进度条"><a href="#6-可视化进度条" class="headerlink" title="6.可视化进度条"></a>6.可视化进度条</h2><p>用 PySimpleGUI 得到图形化进度条，我们可以加一行简单的代码，在命令行脚本中得到图形化进度条，也是使用pip进行下载，代码案例如下</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript"><span class="hljs-keyword">import</span> PySimpleGUI as sg<br><span class="hljs-keyword">import</span> time<br>mylist = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>]<br><span class="hljs-keyword">for</span> i, item <span class="hljs-keyword">in</span> enumerate(mylist):<br>    sg.one_line_progress_meter(<span class="hljs-string">'This is my progress meter!'</span>, i+<span class="hljs-number">1</span>, len(mylist), <span class="hljs-string">'-key-'</span>)<br>    time.sleep(<span class="hljs-number">1</span>)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Dockerfile就这么简单 </title>
    <link href="/2020/07/20/2020-07-20-dockerfile/"/>
    <url>/2020/07/20/2020-07-20-dockerfile/</url>
    
    <content type="html"><![CDATA[<p>当我们在使用docker时，最重要的就是镜像，只要有了镜像，我们就可以随时随地的根据镜像来创建一个容器，从而做到让我们的服务可以在任何时间任何地点任何环境下运行起来。那么镜像是怎么制作的呢？总体来讲，制作镜像有两种方法：</p><ol><li>根据一个已有的镜像运行容器，然后根据这个容器来制作我们自己的镜像；</li><li>使用DockerFile来制作一个镜像模板文件，使用这个文件来创建镜像；</li></ol><p>对于第一种方法，我们在上一篇文章中最后有提及，就是利用docker commit命令，将我们的变更打包成一个新的镜像。但是这种方法需要我们每次都运行一个容器，然后在容器中做更改后再打包，很明显这种方式效率很低，而且更改不方便。所以这种方式一般不建议大家采用。我们更多的要使用DockerFile的方式来定制我们的镜像，接下来，我们就详细的介绍一下DockerFile的制作方法。</p><h1 id="一、利用Dockerfile制作镜像的准备工作"><a href="#一、利用Dockerfile制作镜像的准备工作" class="headerlink" title="一、利用Dockerfile制作镜像的准备工作"></a>一、利用Dockerfile制作镜像的准备工作</h1><p>在制作Dockerfile前，我们需要做一系列的准备工作。首先，我们要创建一个目录，用来存储我们的Dockerfile，我们需要打包进镜像中的所有文件也都要放在这个这个目录下，我们制作镜像的时候也要在这个目录下来完成。其次，我们要创建一个文件名为Dockerfile，这个文件必须是大写开头，文件名必须为Dockerfile。当我们编写好我们的Dockerfile文件后，我们需要用docker build命令来执行创建镜像。</p><h1 id="二、Dockerfile指令"><a href="#二、Dockerfile指令" class="headerlink" title="二、Dockerfile指令"></a>二、Dockerfile指令</h1><p>我们准备好相关的目录和文件后，我们就可以开始编写我们的Dockerfile了，Dockerfile其实就是由一些指令组合成的，在Dockerfile中一行就是一条指令，每行开头的第一个单词就是指令本身，指令可以用大写也可以用小写，但是一般我们使用大写来表示指令。</p><h2 id="1-FROM指令"><a href="#1-FROM指令" class="headerlink" title="1. FROM指令"></a>1. FROM指令</h2><p>每一个Dockerfile的第一个非注释行都必须使用FROM指令，这个指令指明了我们制作镜像使用的基础镜像，格式如下：</p><figure class="highlight pf"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs pf">FROM <span class="hljs-variable">&lt;镜像仓库名&gt;</span>[:<span class="hljs-keyword">tag</span>]<br>FROM <span class="hljs-variable">&lt;镜像仓库名&gt;</span>@<span class="hljs-variable">&lt;镜像哈希值&gt;</span><br></code></pre></div></td></tr></table></figure><p>默认情况下，docker build命令会优先从本地查找我们使用到的基础镜像，如果找不到则自动去我们的镜像仓库中查找。我们在指定基础镜像的过程中可以使用镜像名，但是此时会出现一个问题，如果有人恶意更改了镜像名，用一个错误的镜像替换了我们正常的镜像，那么此时我们就会拉取到错误的镜像。为了避免这个问题的出现，我们可以使用镜像的哈希值来指定基础镜像，就是我们上面提到的使用@符号，这样一来我们使用的镜像就不会被恶意替换掉了。</p><p>FROM指令在使用镜像名时，可以省略标签名，默认会使用latest标签。</p><p>我们上面说了，每一个Dockerfile的第一个非注释行都必须使用FROM开头，但是ARG指令是唯一一个可以在FROM指令前出现的指令，这是一个例外的情况。</p><h2 id="2-LABEL指令"><a href="#2-LABEL指令" class="headerlink" title="2. LABEL指令"></a>2. LABEL指令</h2><p>LABEL指令用来指定一些元数据的，比如指定这个镜像文件的作者，联系方式，描述信息等等，格式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">LABEL <span class="hljs-attribute">key1</span>=value1 <span class="hljs-attribute">key2</span>=value2 <span class="hljs-built_in">..</span>. <span class="hljs-attribute">keyN</span>=valueN<br></code></pre></div></td></tr></table></figure><p>在docker的早期版本中并没有LABEL指令，而是使用MAINTAINER指令，MAINTAINER指令后面只能跟一个字符串，用来指定作者的信息，在新版的docker中，这个指令已经被弃用，官方推荐使用LABEL指令来实现。</p><h2 id="3-RUN指令"><a href="#3-RUN指令" class="headerlink" title="3. RUN指令"></a>3. RUN指令</h2><p>RUN指令用来在创建镜像过程中执行一些命令，RUN指令有两种格式：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">RUN</span><span class="bash"> &lt;<span class="hljs-built_in">command</span>&gt;      直接跟命令</span><br><span class="hljs-keyword">RUN</span><span class="bash"> [<span class="hljs-string">"executable"</span>, <span class="hljs-string">"param1"</span>, <span class="hljs-string">"param2"</span>]    命令和其参数作为一个列表传入</span><br></code></pre></div></td></tr></table></figure><p>这两种方式有不同的效果，RUN指令后直接跟一个命令，会将此命令运行在一个shell中，在linux中默认是/bin/sh，这也就意味着我们可以在命令字符串中引用一些shell变量。但是在第二种方式中，所有的命令和参数放在了一个列表中传入，此时就无法引用shell中的变量。</p><p>除此之外，还有一点需要注意，就是在列表中一定不要用单引号来包裹参数，每个元素都要用双引号，否则会出现docker镜像运行错误的问题。原因就是docker build时会把这些列表当做json来处理，所以要符合json字符串的规则。</p><p>RUN指令执行的命令的结果会被打包到镜像当中，而且Dockerfile中后续的指令也可以使用。使用SHELL指令可以改变默认使用的shell。</p><h2 id="4-CMD指令"><a href="#4-CMD指令" class="headerlink" title="4. CMD指令"></a>4. CMD指令</h2><p>CMD指令是用来指定基于我们的镜像创建容器时，容器中运行的命令的，和RUN不同的地方在于，RUN是在构建镜像时执行的命令，CDM是在创建容器时执行的命令。在一个Dockerfile中只可以有一个CDM指令，如果定义了多个CMD指令，那只有最后一个CMD指令会生效。CMD指令使用格式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">CMD [<span class="hljs-string">"executable"</span>,<span class="hljs-string">"param1"</span>,<span class="hljs-string">"param2"</span>] (exec form, this is the preferred form exec格式，这是推荐的格式)<br>CMD [<span class="hljs-string">"param1"</span>,<span class="hljs-string">"param2"</span>] (as<span class="hljs-built_in"> default </span>parameters <span class="hljs-keyword">to</span> ENTRYPOINT 为ENTRYPOINT参数提供参数)<br>CMD command param1 param2 (shell form shell格式的命令)<br></code></pre></div></td></tr></table></figure><p>CMD指令可以直接指定一个可执行命令，就是上述的第一和第三种方式，当创建容器时会去执行这个命令，而且需要注意的是，第三种方式是默认在shell中执行的，可以引用shell变量，而第一种方式并不会启动shell，所以就无法引用shell变量。</p><p>在采用第二种方式时，此时并没有指定可执行的命令，而是只指定了参数，此时，这些参数将作为ENTRYPOINT指令的参数，关于ENTRYPOINT指令，我们稍后介绍。</p><h2 id="5-ENTRYPOINT指令"><a href="#5-ENTRYPOINT指令" class="headerlink" title="5. ENTRYPOINT指令"></a>5. ENTRYPOINT指令</h2><p>ENTRYPOINT指令也是用来指定基于我们的镜像创建容器时需要执行的命令的，其使用格式如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">ENTRYPOINT</span><span class="bash"> [<span class="hljs-string">"executable"</span>, <span class="hljs-string">"param1"</span>, <span class="hljs-string">"param2"</span>] (<span class="hljs-built_in">exec</span> form, preferred 推荐格式，使用json)</span><br><span class="hljs-keyword">ENTRYPOINT</span><span class="bash"> <span class="hljs-built_in">command</span> param1 param2 (shell form shell格式)</span><br></code></pre></div></td></tr></table></figure><p>既然我们已经有了CMD指令了，那为什么我们还要弄一个ENTRYPOINT指令出来呢？这两者的区别在于，当我们使用CMD指令创建好镜像后，在使用这个镜像启动容器时，我们可以改变容器默认的命令，而自己定义启动容器时的命令，比如我们的CMD指令是启动nginx，但是我们在启动容器的时候可以指定命令来启动一个bash，此时，我们在命令行中指定的指令就替换掉了我们的CMD命令。但是我们如果使用ENTRYPOINT指令来指定执行的命令，那么在命令行中启动镜像时，在镜像名之后我们自己指定的命令将不会执行，而是作为参数传递给了ENTRYPOINT命令。而且，在命令行中指定的命令，第一个参数并没有被传递给<code>ENTRYPOINT</code>，这是因为我们的docker默认认为第一个参数是要执行的命令，而其之后的才是真正的参数，参见如下所示，我们的“echo” 字符串并没有被输出出来：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile">[root@localhost img1]<span class="hljs-comment"># cat Dockerfile </span><br><span class="hljs-keyword">FROM</span> centos:centos7<br><span class="hljs-keyword">ENTRYPOINT</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">"abc"</span> <span class="hljs-variable">$@</span></span><br>[root@localhost img1]<span class="hljs-comment"># docker run --rm centos:testv3 echo aaaaa bbbbb ccccc</span><br>abc aaaaa bbbbb ccccc<br>[root@localhost img1]<span class="hljs-comment">#</span><br></code></pre></div></td></tr></table></figure><p>这个特性可以使我们在运行容器时禁止自定义启动命令，保证了容器运行结果与我们的预期完全一致。但是，我们并不是完全不能更改这个命令，docker为我们提供了<code>--entrypoint</code>参数来修改这个命令。但是这个参数和命令要写在镜像名之前才会生效。</p><figure class="highlight autoit"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs autoit">[root<span class="hljs-symbol">@localhost</span> img1]<span class="hljs-meta"># cat Dockerfile </span><br>FROM centos:centos7<br>ENTRYPOINT echo <span class="hljs-string">"abc"</span><br>[root<span class="hljs-symbol">@localhost</span> img1]<span class="hljs-meta"># docker run -ti --rm centos:testv1 --entrypoint /bin/bash</span><br>abc<br>[root<span class="hljs-symbol">@localhost</span> img1]<span class="hljs-meta"># docker run -ti --rm --entrypoint /bin/bash centos:testv1</span><br>[root<span class="hljs-symbol">@a0c502e6ba2f</span> /]<span class="hljs-meta"># exit</span><br><span class="hljs-keyword">exit</span><br></code></pre></div></td></tr></table></figure><p>在上面CMD命令的部分，我们可以给<code>CMD</code>命令不指定执行的命令而只指定参数，此时这些参数就会被传递给ENTRYPOINT指令。</p><p>此外，还需要注意一点，我们使用列表的格式来编写命令时，要注意使用双引号来包裹各个参数，而不是单引号。</p><p>Shell形式可防止使用任何CMD或<code>run</code> 命令行参数覆盖掉我们的运行命令，但具有以下缺点：ENTRYPOINT将作为<code>/bin/sh -c</code>的子命令启动，该子命令不传递信号。这意味着可执行文件将不是容器的<code>PID 1</code>，并且不会接收Unix信号，因此您的可执行文件将不会从<code>docker stop &lt;container&gt;</code>接收到<code>SIGTERM</code>。</p><h2 id="6-EXPOSE指令"><a href="#6-EXPOSE指令" class="headerlink" title="6. EXPOSE指令"></a>6. EXPOSE指令</h2><p>EXPOSE指令是用来暴露容器的端口的，其使用格式如下：</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml">EXPOSE <span class="hljs-tag">&lt;<span class="hljs-name">port</span>&gt;</span> [<span class="hljs-tag">&lt;<span class="hljs-name">port</span>&gt;</span>/<span class="hljs-tag">&lt;<span class="hljs-name">protocol</span>&gt;</span>...]<br></code></pre></div></td></tr></table></figure><p>这个指令可以一次性指定暴露多个端口，且可以指定端口的协议，默认情况下是使用TCP协议，我们还可以自己定义使用的协议：</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">EXPOSE <span class="hljs-number">8080</span>/udp  暴露UDP协议的<span class="hljs-number">8080</span>端口<br></code></pre></div></td></tr></table></figure><p>但是需要注意的是，在使用了EXPOSE指令后指定的端口，在运行容器时并不会自动的建立容器和宿主机的映射关系，而是当我们运行容器时指定-P选项后其才会将这些端口映射到宿主机上，且我们在定义Dockerfile时不能指定容器端口映射到宿主机上的端口，只能是随机映射一个宿主机上的端口。</p><h2 id="7-ENV指令"><a href="#7-ENV指令" class="headerlink" title="7. ENV指令"></a>7. ENV指令</h2><p>ENV指令用于创建环境变量，这些环境变量可以在构建镜像阶段供Dockerfile之后的指令所引用，其格式如下：</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml">ENV <span class="hljs-tag">&lt;<span class="hljs-name">key</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span><br>ENV <span class="hljs-tag">&lt;<span class="hljs-name">key</span>&gt;</span>=<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span> ...<br></code></pre></div></td></tr></table></figure><p>第一种格式用来设置单个的环境变量，ENV指令后被空格分隔的第一个字符串会被当成是环境变量的KEY，后面的所有值都会被当成是该KEY的VALUE值，第二种格式可以一次设置多个环境变量，使用等号来声明KEY和VALUE，如果VALUE部分包含空格，我们可以用引号将VALUE部分引起来，也可以用反斜杠对空格做转义处理。例如：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros"><span class="hljs-comment"># 第一种格式，一行定义一对环境变量</span><br>ENV myName John Doe<br>ENV myDog Rex The Dog<br>ENV myCat fluffy<br><br><span class="hljs-comment"># 第二种方式，一行定义多对环境变量</span><br>ENV <span class="hljs-attribute">myName</span>=<span class="hljs-string">"John Doe"</span> <span class="hljs-attribute">myDog</span>=Rex\ The\ Dog \<br>    <span class="hljs-attribute">myCat</span>=fluffy<br></code></pre></div></td></tr></table></figure><p>通过ENV指令设置的环境变量将被保留在生成的镜像中，我们用此镜像创建容器后，可以用docker inspect 命令来查看，也可以在运行容器时，使用<code>docker run --env &lt;key&gt;=&lt;value&gt;</code>的方式来指定。</p><h2 id="8-ADD指令"><a href="#8-ADD指令" class="headerlink" title="8. ADD指令"></a>8. ADD指令</h2><p>ADD指令用来向镜像中添加文件，其有两种格式：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros"><span class="hljs-builtin-name">ADD</span> [<span class="hljs-attribute">--chown</span>=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;<span class="hljs-built_in">..</span>. &lt;dest&gt;<br><span class="hljs-builtin-name">ADD</span> [<span class="hljs-attribute">--chown</span>=&lt;user&gt;:&lt;group&gt;] [<span class="hljs-string">"&lt;src&gt;"</span>,<span class="hljs-built_in">..</span>. <span class="hljs-string">"&lt;dest&gt;"</span>]<br></code></pre></div></td></tr></table></figure><p><code>--chown</code>选项可以在添加文件时改变文件的属主和属组，但是需要注意，这个特性只支持Linux类型的容器，在windows容器上不起作用。</p><p>ADD指令可以从<code>&lt;src&gt;</code>指定的文件、目录或者URL拷贝文件到镜像文件系统中的<code>&lt;dest&gt;</code>路径下，并且可以指定多个<code>&lt;src&gt;</code>，在有多个<code>&lt;src&gt;</code>时，最后一个作为目的地址，其前面的字段都会作为<code>&lt;src&gt;</code>字段。同时，在原地址字段中，也支持正则匹配。并且，目的地址是一个绝对路径，或者当<code>WORKDIR</code>指令指定了工作目录后，也可以是这个目录下的相对路径。而原文件必须在Dockerfile所在的目录下或其子目录下。</p><p>添加包含特殊字符（例如[和]）的文件或目录时，您需要按照Golang规则转义那些路径，以防止将它们视为匹配模式。例如，要添加名为arr [0] .txt的文件，请使用以下命令：</p><figure class="highlight gradle"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs gradle">ADD arr[[]<span class="hljs-number">0</span>].txt <span class="hljs-regexp">/mydir/</span>    # <span class="hljs-keyword">copy</span> a <span class="hljs-keyword">file</span> named <span class="hljs-string">"arr[0].txt"</span> to <span class="hljs-regexp">/mydir/</span><br></code></pre></div></td></tr></table></figure><p>如果没有添加<code>--chown</code>标志，所有新添加的文件或目录属主属组默认是0。<code>--chown</code>标志允许提供属主名和属组名，如果提供了用户名或组名，则将使用容器的根文件系统<code>/etc/passwd</code>和<code>/etc/group</code>文件分别执行从名称到整数UID或GID的转换，也可以提供其对应的UID和GID，如果只提供了属主，则默认会使用和属主UID相同的GID来指定属组，如下都是正确的定义格式：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros"><span class="hljs-builtin-name">ADD</span> <span class="hljs-attribute">--chown</span>=55:mygroup files* /somedir/<br><span class="hljs-builtin-name">ADD</span> <span class="hljs-attribute">--chown</span>=bin files* /somedir/<br><span class="hljs-builtin-name">ADD</span> <span class="hljs-attribute">--chown</span>=1 files* /somedir/<br><span class="hljs-builtin-name">ADD</span> <span class="hljs-attribute">--chown</span>=10:11 files* /somedir/<br></code></pre></div></td></tr></table></figure><p>如果通过<code>--chown</code>标志使用用户名或者属主名来指定属主或属组，而在容器的文件系统中不存在 <code>/etc/passwd</code> 或者 <code>/etc/group</code> 文件，此时构建镜像时会在ADD操作时失败。但是使用数字来指定时，创建镜像的时候并不会去查找此UID或GID是否存在，也不会依赖容器的根文件系统。需要注意的是，如果源文件是一个URL，而这个URL需要登录认证的话，那么需要使用wget或者curl的方式来下载文件，ADD指令并不能完成登录认证。</p><p><strong>「ADD指令遵循如下的规则：」</strong></p><ol><li>如果是URL，并且不以斜杠结尾，则从URL下载文件并将其复制到;</li><li>如果是URL，并且以斜杠结尾，则从URL推断文件名，并将文件下载到/。例如，ADD <a href="http://example.com/foobar" target="_blank" rel="noopener">http://example.com/foobar</a> /，将创建文件 /foobar。该URL必须具有具体的路径及文件名，以便在这种情况下可以找到适当的文件名（例如这样的URL：<a href="http://example.com将不起作用）" target="_blank" rel="noopener">http://example.com将不起作用）</a>;</li><li>如果是目录，则将复制目录的整个内容，包括文件系统元数据。注意，此时目录本身并不会被复制，而是递归复制这个目录下的所有文件;</li><li>当是本地的一个通过gzip, bzip2 or xz压缩的tar压缩包，ADD指令会自动将这个包解压。但是如果是一个URL时则不会解压。</li></ol><blockquote><p>❝</p><p><strong>「注意」</strong>：文件是否被识别为压缩格式仅根据文件的内容而不是文件的名称来确定。例如，如果一个空文件碰巧以.tar.gz结尾，则该文件将不会被识别为压缩文件，并且不会生成任何类型的解压缩错误消息，而是会将文件简单地复制到目标位置。</p><p>❞</p></blockquote><ol><li>如果是任何其他类型的文件，则将其与其元数据一起单独复制。在这种情况下，如果以尾斜杠/结束，则它将被视为目录，并且的内容将写入/base();</li><li>如果直接或由于使用通配符而指定了多个资源，则必须是目录，并且必须以斜杠/结尾;</li><li>如果不以斜杠结尾，它将被视为常规文件，并且的内容将写入;</li><li>如果不存在，它将与路径中所有缺少的目录一起创建。</li></ol><h2 id="9-COPY指令"><a href="#9-COPY指令" class="headerlink" title="9. COPY指令"></a>9. COPY指令</h2><p>COPY用于向镜像中复制文件，用法与ADD指令类似，但是也有一些区别，其格式如下：</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml">COPY [--chown=<span class="hljs-tag">&lt;<span class="hljs-name">user</span>&gt;</span>:<span class="hljs-tag">&lt;<span class="hljs-name">group</span>&gt;</span>] <span class="hljs-tag">&lt;<span class="hljs-name">src</span>&gt;</span>... <span class="hljs-tag">&lt;<span class="hljs-name">dest</span>&gt;</span><br>COPY [--chown=<span class="hljs-tag">&lt;<span class="hljs-name">user</span>&gt;</span>:<span class="hljs-tag">&lt;<span class="hljs-name">group</span>&gt;</span>] ["<span class="hljs-tag">&lt;<span class="hljs-name">src</span>&gt;</span>",... "<span class="hljs-tag">&lt;<span class="hljs-name">dest</span>&gt;</span>"]<br></code></pre></div></td></tr></table></figure><p>COPY指令也可以复制多个文件，也支持通配符匹配，用法基本类似ADD指令，但是COPY指令只能接受一个本地文件或目录，不能COPY远程的URL。而且COPY的文件也必须放在Dockerfile同级目录或其同级目录之下的目录中。</p><p><strong>「COPY指令遵循如下规则：」</strong></p><ol><li>如果是目录，则将复制目录的整个内容，包括文件系统元数据。且目录本身不被复制，仅其内容被复制；</li><li>如果是任何其他类型的文件，则将其与其元数据一起单独复制。在这种情况下，如果以尾斜杠/结束，则它将被视为目录，并且的内容将写入/base()；</li><li>如果直接或由于使用通配符而指定了多个资源，则必须是目录，并且必须以斜杠/结尾；</li><li>如果不以斜杠结尾，它将被视为常规文件，并且的内容将写入；</li><li>如果不存在，它将与路径中所有缺少的目录一起创建；</li></ol><h2 id="10-VOLUME指令"><a href="#10-VOLUME指令" class="headerlink" title="10. VOLUME指令"></a>10. VOLUME指令</h2><p>VOLUME指令用于挂载宿主机上的目录到容器中，其格式如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">VOLUME</span><span class="bash"> [<span class="hljs-string">"/data"</span>]</span><br></code></pre></div></td></tr></table></figure><p>VOLUME指令创建具有指定名称的挂载点，并将其标记为保存来自本地主机或其他容器的外部安装的卷。该值可以是JSON数组，<code>VOLUME [&quot;/var/log/&quot;]</code> 或具有多个参数的纯字符串，例如<code>VOLUME /var/log</code> 或 <code>VOLUME /var/log/var/db</code>。在指定挂载点后，docker创建容器时，会把挂载点下已经存在的文件移动到卷中。</p><p>关于Dockerfile中的卷，请记住以下几点。</p><ol><li><p>基于Windows的容器上的卷：使用基于Windows的容器时，容器内的卷的目的地必须是以下之一：</p><p>a、不存在的或空目录</p><p>b、C盘以外的磁盘分区</p></li><li><p>从Dockerfile内更改卷：如果在声明了卷后有任何构建步骤更改了卷内的数据，则这些更改将被丢弃;</p></li><li><p>JSON格式：列表被解析为JSON数组。您必须用双引号（”）而不是单引号（’）括起单词;</p></li><li><p>主机目录在容器运行时声明：主机目录（挂载点）从本质上说是依赖于主机的。这是为了保留镜像的可移植性，因为不能保证给定的主机目录在所有主机上都可用。因此，您无法从Dockerfile中挂载主机目录。VOLUME指令不支持指定host-dir参数。创建或运行容器时，必须指定挂载点。</p></li></ol><h2 id="11-USER指令"><a href="#11-USER指令" class="headerlink" title="11. USER指令"></a>11. USER指令</h2><p>USER指令设置运行镜像时要使用的用户名（或UID）以及可选的用户组（或GID），以及Dockerfile中的所有RUN，CMD和ENTRYPOINT指令。其格式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">USER &lt;user&gt;[:&lt;group&gt;] <span class="hljs-keyword">or</span><br>USER &lt;UID&gt;[:&lt;GID&gt;]<br></code></pre></div></td></tr></table></figure><h2 id="12、WORKDIR指令"><a href="#12、WORKDIR指令" class="headerlink" title="12、WORKDIR指令"></a>12、WORKDIR指令</h2><p>WORKDIR指令为Dockerfile中跟在其后的所有RUN，CMD，ENTRYPOINT，COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使以后的Dockerfile指令中未使用，它也将被创建。其格式如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">WORKDIR</span><span class="bash"> /path/to/workdir</span><br></code></pre></div></td></tr></table></figure><p>WORKDIR指令可在Dockerfile中多次使用。如果提供了相对路径，则它将相对于上一个WORKDIR指令的路径。例如：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">WORKDIR</span><span class="bash"> /a</span><br><span class="hljs-keyword">WORKDIR</span><span class="bash"> b</span><br><span class="hljs-keyword">WORKDIR</span><span class="bash"> c</span><br><span class="hljs-keyword">RUN</span><span class="bash"> <span class="hljs-built_in">pwd</span></span><br></code></pre></div></td></tr></table></figure><p>该Dockerfile中最后一个pwd命令的输出为<code>/a/b/c</code>。</p><p>WORKDIR指令可以解析以前使用ENV设置的环境变量。你只能使用在Dockerfile中显式设置的环境变量。例如：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">ENV</span> DIRPATH /path<br><span class="hljs-keyword">WORKDIR</span><span class="bash"> <span class="hljs-variable">$DIRPATH</span>/<span class="hljs-variable">$DIRNAME</span></span><br><span class="hljs-keyword">RUN</span><span class="bash"> <span class="hljs-built_in">pwd</span></span><br></code></pre></div></td></tr></table></figure><p>pwd命令的运行结果就是<code>/path/$DIRNAME</code>。</p><h2 id="13-ARG指令"><a href="#13-ARG指令" class="headerlink" title="13. ARG指令"></a>13. ARG指令</h2><p>ARG指令定义了一个变量，用户可以在创建镜像时使用–build-arg=参数将其传递给构建器。如果用户指定了未在Dockerfile中定义的ARG变量，则构建会输出警告。其格式如下：</p><figure class="highlight fortran"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs fortran">ARG &lt;<span class="hljs-keyword">name</span>&gt;[=&lt;<span class="hljs-keyword">default</span> <span class="hljs-keyword">value</span>&gt;]<br></code></pre></div></td></tr></table></figure><p>在Dockerfile中可以包含一个或多个变量。</p><blockquote><p>❝</p><p><strong>「注意:」</strong> 不建议使用创建镜像时使用变量来传递诸如github密钥，用户凭据等机密。创建镜像时变量值对于使用docker history命令的镜像的任何用户都是可见的。</p><p>❞</p></blockquote><p>在定义ARG变量时，可以给变量赋初值，如果在创建镜像时没有传入变量值，那么就会使用这个初始值：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros"><span class="hljs-keyword">FROM</span> busybox<br>ARG <span class="hljs-attribute">user1</span>=someuser<br>ARG <span class="hljs-attribute">buildno</span>=1<br><span class="hljs-built_in">..</span>.<br></code></pre></div></td></tr></table></figure><p>ARG变量也遵从先定义后使用的惯例，而且，Dockerfile中后定义的同名变量会覆盖之前的变量的值。</p><p>可以使用ARG或ENV指令来指定RUN指令可用的变量。使用ENV指令定义的环境变量始终会覆盖同名的ARG指令。我们来看一个例子：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> ubuntu<br><span class="hljs-keyword">ARG</span> CONT_IMG_VER<br><span class="hljs-keyword">ENV</span> CONT_IMG_VER v1.<span class="hljs-number">0.0</span><br><span class="hljs-keyword">RUN</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-variable">$CONT_IMG_VER</span></span><br></code></pre></div></td></tr></table></figure><p>我们创建镜像时使用如下命令，给<code>CONT_IMG_VER</code>传入不同的变量值：</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">$ docker build --build-arg CONT_IMG_VER=v2<span class="hljs-number">.0</span><span class="hljs-number">.1</span> .<br></code></pre></div></td></tr></table></figure><p>在这种情况下，RUN指令使用v1.0.0而不是用户传递的ARG设置：v2.0.1，就是因为ENV指令定义的环境变量覆盖了同名的ARG变量。</p><p>Docker具有一组预定义的ARG变量，您可以在Dockerfile中使用它们而无需相应的ARG指令:</p><figure class="highlight ebnf"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs ebnf"><span class="hljs-attribute">HTTP_PROXY</span><br><span class="hljs-attribute">http_proxy</span><br><span class="hljs-attribute">HTTPS_PROXY</span><br><span class="hljs-attribute">https_proxy</span><br><span class="hljs-attribute">FTP_PROXY</span><br><span class="hljs-attribute">ftp_proxy</span><br><span class="hljs-attribute">NO_PROXY</span><br><span class="hljs-attribute">no_proxy</span><br></code></pre></div></td></tr></table></figure><p>默认情况下，这些预定义变量从Docker历史记录的输出中删除。删除它们可以降低意外泄漏<code>HTTP_PROXY</code>变量中的敏感身份验证信息的风险。如果需要在docker历史记录中输出这些默认变量值，则需要我们在Dockerfile中显示的使用ARG指令指定这个变量。</p><h2 id="14-ONBUILD指令"><a href="#14-ONBUILD指令" class="headerlink" title="14. ONBUILD指令"></a>14. ONBUILD指令</h2><p>当我们的镜像被作为基础镜像执行构建时，此时ONBUILD指令就会生效。其格式如下：</p><figure class="highlight apache"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs apache"><span class="hljs-attribute">ONBUILD</span><span class="hljs-meta"> [INSTRUCTION]</span><br></code></pre></div></td></tr></table></figure><p>运作方式如下：当它遇到<code>ONBUILD</code>指令时，构建器将触发器添加到正在构建的镜像的元数据中，该指令不会影响当前版本。构建结束时，所有触发器的列表都存储在镜像清单中的OnBuild键下。可以使用<code>docker inspect</code>命令查看它们。稍后，可以使用FROM指令将该镜像用作新构建的基础镜像，作为处理FROM指令的一部分，下游构建器将查找ONBUILD触发器，并以与注册时相同的顺序执行它们。如果任何触发器失败，那么FROM指令将中止，从而导致构建失败。如果所有触发器都成功，则FROM指令完成，并且构建照常继续。执行完触发器后，将从最终镜像中清除触发器。换句话说，它们不是<code>孙子代</code>版本所继承的。</p><blockquote><p>❝</p><p><strong>「注意」</strong>：在ONBUILD指令中再指定ONBUILD指令是不允许的，ONBUILD指令可能不会触发FROM或者MAINTAINER指令</p><p>❞</p></blockquote><h2 id="15-STOPSIGNAL指令"><a href="#15-STOPSIGNAL指令" class="headerlink" title="15. STOPSIGNAL指令"></a>15. STOPSIGNAL指令</h2><p><code>STOPSIGNAL</code>指令用来设置系统发送给容器的退出信号，该信号可以是内核syscall表中对应的无符号数字，例如9，也可以是SIGNAME格式的信号名称，例如SIGKILL。</p><figure class="highlight qml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs qml">STOPSIGNAL <span class="hljs-keyword">signal</span><span class="hljs-string"></span><br></code></pre></div></td></tr></table></figure><h2 id="16-HEALTHCHECK指令"><a href="#16-HEALTHCHECK指令" class="headerlink" title="16. HEALTHCHECK指令"></a>16. HEALTHCHECK指令</h2><p>HEALTHCHECK指令是用来做容器健康检查的，这个指令是在Docker 1.12版本被加入的，在早期版本中并不支持，这个指令可以让我们自定义容器健康状态检查的脚本或者命令。其格式如下：</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">HEALTHCHECK [OPTIONS] CMD command (check container<span class="hljs-built_in"> health </span>by running a command inside the container)<br>HEALTHCHECK NONE (<span class="hljs-builtin-name">disable</span> any healthcheck inherited <span class="hljs-keyword">from</span> the base image)<br></code></pre></div></td></tr></table></figure><p>我们为什么需要这样一个指令呢？是因为我们的容器是根据启动命令是否运行来判断容器是否健康的，这就导致一个问题，有时我们的应用程序确实在运行，进程并没有退出，但是此时由于bug或其他原因导致程序已经无法正常对外提供服务，那么此时我们就需要用一个命令或者脚本来检测我们的服务，这就是这个指令存在的意义。</p><p><strong>「HEALTHCHECK指令的OPTIONS字段可以有如下几个选项：」</strong></p><ol><li><code>--interval=DURATION (default: 30s)</code> 健康检测的命令将在容器启动后的DURATION秒后开始第一次运行，然后每隔DURATION秒运行一次，DURATION默认值是30秒;</li><li><code>--timeout=DURATION (default: 30s)</code> 健康检测的命令的超时时间，默认30秒;</li><li><code>--start-period=DURATION (default: 0s)</code> 此选项设置了当容器启动后的DURATION秒后的健康检测如果失败，不计入重试次数，这是为了给容器一个初始化的时间。但是如果这段时间中一旦健康检测为正常，则之后即使在初始化时间内，健康检测如果失败，此时会计入重试次数，默认是0秒;</li><li><code>--retries=N (default: 3)</code> 健康检测的重试次数，重试N次后容器被判断为异常，则退出进程。</li></ol><blockquote><p>❝</p><p><strong>「注意」</strong>：在一个Dockerfile中只能有一个HEALTHCHECK指令，如果指定了多个指令，则只有最后一个指令生效。</p><p>❞</p></blockquote><p>CMD关键字之后的命令可以是shell命令（例如<code>HEALTHCHECK CMD /bin/check-running</code>）或exec数组（与其他Dockerfile命令一样;有关详细信息，请参见ENTRYPOINT）。</p><p><strong>「命令的退出状态指示容器的健康状态。可能的值为：」</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript"><span class="hljs-number">0</span>：success-容器健康且可以使用<br><span class="hljs-number">1</span>：unhealthy-容器无法正常工作<br><span class="hljs-number">2</span>：reserved-请勿使用此退出码<br></code></pre></div></td></tr></table></figure><p>为了调试方便，健康检测的输出会被记录到健康状态内，我们可以通过docker inspect命令去查询，但是当前最多只能存储输出的前4096个字节，所以，健康检测的命令要尽可能简洁。</p><h2 id="17-SHELL指令"><a href="#17-SHELL指令" class="headerlink" title="17. SHELL指令"></a>17. SHELL指令</h2><p>SHELL指令允许覆盖用于命令的shell形式的默认shell。在Linux上，默认shell程序是<code>[&quot;/bin/sh&quot;,&quot;-c&quot;]</code>，在Windows上，默认shell程序是<code>[&quot;cmd&quot;,&quot;/S&quot;,&quot;/C&quot;]</code>。SHELL指令必须使用JSON形式编写。格式如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">SHELL</span><span class="bash"> [<span class="hljs-string">"executable"</span>, <span class="hljs-string">"parameters"</span>]</span><br></code></pre></div></td></tr></table></figure><p>SHELL指令可以有多个，每个SHELL指令都会覆盖之前的设置，并且影响其之后的指令。SHELL指令也是在Docker 1.12版本中加入的，所以在更早期的版本中是不支持的。</p><h2 id="18-注意"><a href="#18-注意" class="headerlink" title="18. 注意"></a>18. 注意</h2><p><strong>「很重要:」</strong></p><p>在我们编写Dockerfile时，每一行指令就会生成一个镜像的层，所以，我们应该尽量将相同的操作都写在同一行中，而且我们依然可以使用<code>\</code>来换行，这还是会被当成一层来处理。这样做的好处是可以减小我们的镜像文件的大小，加快容器创建的速度。</p><h1 id="三、构建镜像"><a href="#三、构建镜像" class="headerlink" title="三、构建镜像"></a>三、构建镜像</h1><p>当我们写好了Dockerfile之后，我们就可以使用docker build命令来构建镜像了。命令如下：</p><figure class="highlight gherkin"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs gherkin">docker build [OPTIONS] PATH |<span class="hljs-string"> URL </span>|<span class="hljs-string"> -</span><br></code></pre></div></td></tr></table></figure><p>在构建镜像时，我们可以添加各种参数来定制镜像，还可以直接为镜像打好标签。docker build命令支持的参数详见docker build命令官方文档，在此不再赘述。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Linux内核调优 </title>
    <link href="/2020/07/20/2020-07-20-linux-kernel-optimize/"/>
    <url>/2020/07/20/2020-07-20-linux-kernel-optimize/</url>
    
    <content type="html"><![CDATA[<p>以nginx 10k并发连接为优化目标，附简单介绍，不一一解释。</p><h3 id="tcp容量规划"><a href="#tcp容量规划" class="headerlink" title="tcp容量规划"></a>tcp容量规划</h3><figure class="highlight ini"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs ini"><span class="hljs-attr">net.ipv4.tcp_mem</span>  = <span class="hljs-number">262144</span>  <span class="hljs-number">524288</span> <span class="hljs-number">786432</span><br><span class="hljs-attr">net.core.wmem_max</span> = <span class="hljs-number">16777216</span><br><span class="hljs-attr">net.core.wmem_default</span> = <span class="hljs-number">131072</span><br><span class="hljs-attr">net.core.rmem_max</span> = <span class="hljs-number">16777216</span><br><span class="hljs-attr">net.core.rmem_default</span> = <span class="hljs-number">131072</span><br><span class="hljs-attr">net.ipv4.tcp_wmem</span> = <span class="hljs-number">4096</span>    <span class="hljs-number">131072</span>  <span class="hljs-number">16777216</span><br><span class="hljs-attr">net.ipv4.tcp_rmem</span> = <span class="hljs-number">4096</span>    <span class="hljs-number">131072</span>  <span class="hljs-number">16777216</span><br></code></pre></div></td></tr></table></figure><p>*<em>net.ipv4.tcp_mem *</em> 单位是内存页，一般是4k，三个值分别代表tcp内存使用的水平，低、中、高， 低表示无内存压力，中级表示内存压力状态，高表示内存吃紧，最高峰时系统将会拒绝分配内存。262144 代表1G内存，即（262144x4/1024/1024），其他类推。</p><p>下面的参数单位都是字节 net.core.wmem_max 和net.core.wmem_default 会覆盖net.ipv4.tcp_wmem 的第二第三个值， 同理，net.core.rmem_max 和 net.core.rmem_default 会覆盖net.ipv4.tcp_rmem 的第二第三个值。稍微提高tcp读写缓冲区的容量，可以增加tcp传输效率，比如上文默认值131072=128k，现有一个1M的文件传输，只需8次传输即可，比较适合图片类传输。但也不是越大越好，比如一个文字页面只有15k，使用128k的内存显然有些浪费。上文tcp压力状态下的容量为2G，对应tcp读写缓冲区128k，可应对的连接数为16384 (2048x1024/128)，可满足10k要求。</p><h3 id="tcp连接行为管理"><a href="#tcp连接行为管理" class="headerlink" title="tcp连接行为管理"></a>tcp连接行为管理</h3><figure class="highlight ini"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs ini"><span class="hljs-attr">net.ipv4.tcp_tw_reuse</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">net.ipv4.tcp_tw_recycle</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">net.ipv4.tcp_timestamps</span> = <span class="hljs-number">1</span><br><span class="hljs-attr">net.ipv4.tcp_fin_timeout</span> = <span class="hljs-number">30</span><br><span class="hljs-attr">net.ipv4.tcp_max_tw_buckets</span> = <span class="hljs-number">8192</span><br><span class="hljs-attr">net.ipv4.tcp_retries1</span> = <span class="hljs-number">3</span><br><span class="hljs-attr">net.ipv4.tcp_retries2</span> = <span class="hljs-number">5</span><br><span class="hljs-attr">net.ipv4.tcp_keepalive_time</span> = <span class="hljs-number">1800</span><br><span class="hljs-attr">net.ipv4.tcp_keepalive_probes</span> = <span class="hljs-number">5</span><br><span class="hljs-attr">net.ipv4.tcp_keepalive_intvl</span> = <span class="hljs-number">30</span><br><span class="hljs-attr">net.ipv4.tcp_max_syn_backlog</span> = <span class="hljs-number">8192</span><br><span class="hljs-attr">net.ipv4.tcp_max_orphans</span> = <span class="hljs-number">262144</span><br></code></pre></div></td></tr></table></figure><p>上面主要是tcp连接行为的伴随的参数，主要是tcp重用，增加队列，减少等待重试频率等等来提升效率。</p><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><figure class="highlight ini"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs ini"><span class="hljs-attr">vm.swappiness</span> = <span class="hljs-number">5</span><br><span class="hljs-attr">vm.dirty_ratio</span> = <span class="hljs-number">40</span><br><span class="hljs-attr">vm.min_free_kbytes</span> = <span class="hljs-number">524288</span><br><span class="hljs-attr">vm.vfs_cache_pressure</span> = <span class="hljs-number">100</span><br></code></pre></div></td></tr></table></figure><ul><li>vm.swappiness = 5 表示物理内存剩余5%时，才考虑使用swap，默认60，这显然非常不合理</li><li>•vm.dirty_ratio = 40 表示拿出物理内存的40%用于写缓存，而不立即将数据写入硬盘。由于硬盘是众所周知的瓶颈，扩大它可提升写的效率，40%是个比较合适的比例。</li><li>vm.min_free_kbytes = 524288 这个用于控制剩余内存的大小，524288=512M，可根据需要调整。如果某些任务临时需要大量内存，可临时将它调大然后调小，回收页面缓存。它比vm.drop_caches 要温和得多，后者更粗暴。</li><li>vm.vfs_cache_pressure = 100 ，如果要尽快将脏数据刷进硬盘，提高它，比如150 。</li></ul><h3 id="内核其他行为"><a href="#内核其他行为" class="headerlink" title="内核其他行为"></a>内核其他行为</h3><figure class="highlight stylus"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs stylus">net<span class="hljs-selector-class">.core</span><span class="hljs-selector-class">.somaxconn</span> = <span class="hljs-number">8192</span><br>net<span class="hljs-selector-class">.core</span><span class="hljs-selector-class">.netdev_max_backlog</span> = <span class="hljs-number">8192</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.ip_local_port_range</span> = <span class="hljs-number">15000</span> <span class="hljs-number">65000</span><br>net<span class="hljs-selector-class">.netfilter</span><span class="hljs-selector-class">.nf_conntrack_max</span> = <span class="hljs-number">131072</span><br>net<span class="hljs-selector-class">.nf_conntrack_max</span> = <span class="hljs-number">131072</span><br>net<span class="hljs-selector-class">.ipv6</span><span class="hljs-selector-class">.conf</span><span class="hljs-selector-class">.all</span><span class="hljs-selector-class">.disable_ipv6</span> =<span class="hljs-number">1</span><br>net<span class="hljs-selector-class">.netfilter</span><span class="hljs-selector-class">.nf_conntrack_tcp_timeout_established</span> =<span class="hljs-number">3600</span><br>net<span class="hljs-selector-class">.core</span><span class="hljs-selector-class">.rps_sock_flow_entries</span> = <span class="hljs-number">32768</span><br></code></pre></div></td></tr></table></figure><p>net.core.somaxconn 表示socket的最大连接数，默认128，对于php-fpm使用unix socket情况下，需要调大。</p><p>net.netfilter.nf_conntrack_tcp_timeout_established = 3600 默认2天时间，多数情况下，调小这个参数是有益的，如果是tcp长连接，这个参数可能不太合适。</p><p>net.core.rps_sock_flow_entries 这个参数启用RPS，自动将网卡中断均匀分配到多个CPU，改进网卡性能和系统负载。</p><p>RPS还需要脚本配合</p><figure class="highlight reasonml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs reasonml">for fileRfc <span class="hljs-keyword">in</span> <span class="hljs-constructor">$(<span class="hljs-params">ls</span> <span class="hljs-operator">/</span><span class="hljs-params">sys</span><span class="hljs-operator">/</span><span class="hljs-params">class</span><span class="hljs-operator">/</span><span class="hljs-params">net</span><span class="hljs-operator">/</span><span class="hljs-params">eth</span><span class="hljs-operator">*</span><span class="hljs-operator">/</span><span class="hljs-params">queues</span><span class="hljs-operator">/</span><span class="hljs-params">rx</span>-<span class="hljs-operator">*</span><span class="hljs-operator">/</span><span class="hljs-params">rps_flow_cnt</span>)</span>;<span class="hljs-keyword">do</span> echo <span class="hljs-number">2048</span> &gt; $fileRfc;<span class="hljs-keyword">done</span><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Nginx日志配置详解 </title>
    <link href="/2020/07/20/2020-07-20-nginx-logs/"/>
    <url>/2020/07/20/2020-07-20-nginx-logs/</url>
    
    <content type="html"><![CDATA[<p><strong>前言</strong></p><p>Nginx日志对于统计、系统服务排错很有用。</p><p><strong>Nginx日志主要分为两种：</strong>access_log(访问日志)和error_log(错误日志)。通过访问日志我们可以得到用户的IP地址、浏览器的信息，请求的处理时间等信息。错误日志记录了访问出错的信息，可以帮助我们定位错误的原因。</p><p><strong>本文将详细描述一下如何配置Nginx日志。</strong></p><h2 id="设置access-log"><a href="#设置access-log" class="headerlink" title="设置access_log"></a><strong>设置access_log</strong></h2><p>访问日志主要记录客户端的请求。客户端向Nginx服务器发起的每一次请求都记录在这里。客户端IP，浏览器信息，referer，请求处理时间，请求URL等都可以在访问日志中得到。当然具体要记录哪些信息，你可以通过log_format指令定义。</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight inform7"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs inform7">access_log path <span class="hljs-comment">[format <span class="hljs-comment">[buffer=size]</span> <span class="hljs-comment">[gzip<span class="hljs-comment">[=level]</span>]</span> <span class="hljs-comment">[flush=time]</span> <span class="hljs-comment">[if=condition]</span>]</span>; # 设置访问日志<br>access_log off; # 关闭访问日志<br></code></pre></div></td></tr></table></figure><blockquote><ul><li>path 指定日志的存放位置。</li><li>format 指定日志的格式。默认使用预定义的combined。</li><li>buffer 用来指定日志写入时的缓存大小。默认是64k。</li><li>gzip 日志写入前先进行压缩。压缩率可以指定，从1到9数值越大压缩比越高，同时压缩的速度也越慢。默认是1。</li><li>flush 设置缓存的有效时间。如果超过flush指定的时间，缓存中的内容将被清空。</li><li>if 条件判断。如果指定的条件计算为0或空字符串，那么该请求不会写入日志。</li></ul></blockquote><p>另外，还有一个特殊的值off。如果指定了该值，当前作用域下的所有的请求日志都被关闭。</p><h3 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h3><p>可以应用access_log指令的作用域分别有http，server，location，limit_except。也就是说，在这几个作用域外使用该指令，Nginx会报错。</p><p>以上是access_log指令的基本语法和参数的含义。下面我们看一几个例子加深一下理解。</p><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><figure class="highlight fortran"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs fortran">access_log /var/logs/nginx-<span class="hljs-keyword">access</span>.<span class="hljs-built_in">log</span><br></code></pre></div></td></tr></table></figure><p>该例子指定日志的写入路径为/var/logs/nginx-access.log，日志格式使用默认的combined。</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">access_log /var/logs/nginx-access.log <span class="hljs-attribute">buffer</span>=32k gzip <span class="hljs-attribute">flush</span>=1m<br></code></pre></div></td></tr></table></figure><p>该例子指定日志的写入路径为/var/logs/nginx-access.log，日志格式使用默认的combined，指定日志的缓存大小为32k，日志写入前启用gzip进行压缩，压缩比使用默认值1，缓存数据有效时间为1分钟。</p><h2 id="使用log-format自定义日志格式"><a href="#使用log-format自定义日志格式" class="headerlink" title="使用log_format自定义日志格式"></a><strong>使用log_format自定义日志格式</strong></h2><p>Nginx预定义了名为combined日志格式，如果没有明确指定日志格式默认使用该格式：</p><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">log_format</span> combined <span class="hljs-string">'<span class="hljs-variable">$remote_addr</span> - <span class="hljs-variable">$remote_user</span> [<span class="hljs-variable">$time_local</span>] '</span><br>                    <span class="hljs-string">'"<span class="hljs-variable">$request</span>" <span class="hljs-variable">$status</span> <span class="hljs-variable">$body_bytes_sent</span> '</span><br>                    <span class="hljs-string">'"<span class="hljs-variable">$http_referer</span>" "<span class="hljs-variable">$http_user_agent</span>"'</span>;<br></code></pre></div></td></tr></table></figure><p>如果不想使用Nginx预定义的格式，可以通过log_format指令来自定义。</p><h3 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h3><figure class="highlight qml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs qml">log_format name [<span class="hljs-built_in">escape</span>=<span class="hljs-keyword">default</span>|json] <span class="hljs-built_in">string</span> ...;<br></code></pre></div></td></tr></table></figure><blockquote><ul><li>name 格式名称。在access_log指令中引用。</li><li>escape 设置变量中的字符编码方式是json还是default，默认是default。</li><li>string 要定义的日志格式内容。该参数可以有多个。参数中可以使用Nginx变量。</li></ul></blockquote><p>下面是log_format指令中常用的一些变量：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-variable">$bytes_sent</span><br>发送给客户端的总字节数<br><br><span class="hljs-variable">$body_bytes_sent</span><br>发送给客户端的字节数，不包括响应头的大小<br><br><span class="hljs-variable">$connection</span><br>连接序列号<br><br><span class="hljs-variable">$connection_requests</span><br>当前通过连接发出的请求数量<br><br><span class="hljs-variable">$msec</span><br>日志写入时间，单位为秒，精度是毫秒<br><br><span class="hljs-variable">$pipe</span><br>如果请求是通过http流水线发送，则其值为<span class="hljs-string">"p"</span>，否则为“.<span class="hljs-string">"</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$request_length</span></span><br><span class="hljs-string">请求长度（包括请求行，请求头和请求体）</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$request_time</span></span><br><span class="hljs-string">请求处理时长，单位为秒，精度为毫秒，从读入客户端的第一个字节开始，直到把最后一个字符发送张客户端进行日志写入为止</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$status</span></span><br><span class="hljs-string">响应状态码</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$time_iso8601</span></span><br><span class="hljs-string">标准格式的本地时间,形如“2017-05-24T18:31:27+08:00”</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$time_local</span></span><br><span class="hljs-string">通用日志格式下的本地时间，如"</span>24/May/2017:18:31:27 +0800<span class="hljs-string">"</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$http_referer</span></span><br><span class="hljs-string">请求的referer地址。</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$http_user_agent</span></span><br><span class="hljs-string">客户端浏览器信息。</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$remote_addr</span></span><br><span class="hljs-string">客户端IP</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$http_x_forwarded_for</span></span><br><span class="hljs-string">当前端有代理服务器时，设置web节点记录客户端地址的配置，此参数生效的前提是代理服务器也要进行相关的x_forwarded_for设置。</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$request</span></span><br><span class="hljs-string">完整的原始请求行，如 "</span>GET / HTTP/1.1<span class="hljs-string">"</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$remote_user</span></span><br><span class="hljs-string">客户端用户名称，针对启用了用户认证的请求</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$request_uri</span></span><br><span class="hljs-string">完整的请求地址，如 "</span>https://daojia.com/<span class="hljs-string">"</span><br></code></pre></div></td></tr></table></figure><p>下面演示一下自定义日志格式的使用：</p><figure class="highlight dart"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dart">access_log /<span class="hljs-keyword">var</span>/logs/nginx-access.log main<br>log_format  main  <span class="hljs-string">'<span class="hljs-subst">$remote_addr</span> - <span class="hljs-subst">$remote_user</span> [<span class="hljs-subst">$time_local</span>] "<span class="hljs-subst">$request</span>" '</span><br>                  <span class="hljs-string">'<span class="hljs-subst">$status</span> <span class="hljs-subst">$body_bytes_sent</span> "<span class="hljs-subst">$http_referer</span>" '</span><br>                  <span class="hljs-string">'"<span class="hljs-subst">$http_user_agent</span>" "<span class="hljs-subst">$http_x_forwarded_for</span>"'</span>;<br></code></pre></div></td></tr></table></figure><p>我们使用log_format指令定义了一个main的格式，并在access_log指令中引用了它。假如客户端有发起请求：<a href="https://suyunfe.com/，我们看一下我截取的一个请求的日志记录" target="_blank" rel="noopener">https://suyunfe.com/，我们看一下我截取的一个请求的日志记录</a>:</p><figure class="highlight 1c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs 1c"><span class="hljs-number">112.195</span>.<span class="hljs-number">209.90</span> - - [<span class="hljs-number">20</span>/Feb/<span class="hljs-number">2018</span>:<span class="hljs-number">12</span>:<span class="hljs-number">12</span>:<span class="hljs-number">14</span> +<span class="hljs-number">0800</span>] <br><span class="hljs-string">"GET / HTTP/1.1"</span> <span class="hljs-number">200</span> <span class="hljs-number">190</span> <span class="hljs-string">"-"</span> <span class="hljs-string">"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) </span><br>AppleWebKit/<span class="hljs-number">537.36</span> (KHTML, like Gecko) Chrome/<span class="hljs-number">63.0</span>.<span class="hljs-number">3239.132</span> Mobile Safari/<span class="hljs-number">537.36</span><span class="hljs-string">" "</span>-<span class="hljs-string">"</span><br></code></pre></div></td></tr></table></figure><p>我们看到最终的日志记录中<code>$remote_user</code>、<code>$http_referer</code>、<code>$http_x_forwarded_for</code>都对应了一个<code>-</code>，这是因为这几个变量为空。</p><h2 id="设置error-log"><a href="#设置error-log" class="headerlink" title="设置error_log"></a><strong>设置error_log</strong></h2><p>错误日志在Nginx中是通过error_log指令实现的。该指令记录服务器和请求处理过程中的错误信息。</p><h3 id="语法-2"><a href="#语法-2" class="headerlink" title="语法"></a>语法</h3><p>配置错误日志文件的路径和日志级别。</p><figure class="highlight applescript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs applescript">error_log <span class="hljs-built_in">file</span> [level];<br>Default:    <br>error_log logs/<span class="hljs-keyword">error</span>.<span class="hljs-built_in">log</span> <span class="hljs-keyword">error</span>;<br></code></pre></div></td></tr></table></figure><p>第一个参数指定日志的写入位置。</p><p>第二个参数指定日志的级别。level可以是debug, info, notice, warn, error, crit, alert,emerg中的任意值。可以看到其取值范围是按紧急程度从低到高排列的。只有日志的错误级别等于或高于level指定的值才会写入错误日志中。默认值是error。</p><h3 id="基本用法-1"><a href="#基本用法-1" class="headerlink" title="基本用法"></a>基本用法</h3><figure class="highlight maxima"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs maxima">error_log /<span class="hljs-built_in">var</span>/logs/nginx/nginx-<span class="hljs-built_in">error</span>.<span class="hljs-built_in">log</span><br></code></pre></div></td></tr></table></figure><p>它可以配置在：main， http, mail, stream, server, location作用域。</p><p>例子中指定了错误日志的路径为：<code>/var/logs/nginx/nginx-error.log</code>，日志级别使用默认的error。</p><h2 id="open-log-file-cache"><a href="#open-log-file-cache" class="headerlink" title="open_log_file_cache"></a><strong>open_log_file_cache</strong></h2><p>每一条日志记录的写入都是先打开文件再写入记录，然后关闭日志文件。如果你的日志文件路径中使用了变量，如<code>access_log /var/logs/$host/nginx-access.log</code>，为提高性能，可以使用open_log_file_cache指令设置日志文件描述符的缓存。</p><h3 id="语法-3"><a href="#语法-3" class="headerlink" title="语法"></a>语法</h3><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">open_log_file_cache <span class="hljs-attribute">max</span>=N [<span class="hljs-attribute">inactive</span>=time] [<span class="hljs-attribute">min_uses</span>=N] [<span class="hljs-attribute">valid</span>=time];<br></code></pre></div></td></tr></table></figure><blockquote><ul><li>max 设置缓存中最多容纳的文件描述符数量，如果被占满，采用LRU算法将描述符关闭。</li><li>inactive 设置缓存存活时间，默认是10s。</li><li>min_uses 在inactive时间段内，日志文件最少使用几次，该日志文件描述符记入缓存，默认是1次。</li><li>valid：设置多久对日志文件名进行检查，看是否发生变化，默认是60s。</li><li>off：不使用缓存。默认为off。</li></ul></blockquote><h3 id="基本用法-2"><a href="#基本用法-2" class="headerlink" title="基本用法"></a>基本用法</h3><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">open_log_file_cache <span class="hljs-attribute">max</span>=1000 <span class="hljs-attribute">inactive</span>=20s <span class="hljs-attribute">valid</span>=1m <span class="hljs-attribute">min_uses</span>=2;<br></code></pre></div></td></tr></table></figure><p>它可以配置在http、server、location作用域中。</p><p>例子中，设置缓存最多缓存1000个日志文件描述符，20s内如果缓存中的日志文件描述符至少被被访问2次，才不会被缓存关闭。每隔1分钟检查缓存中的文件描述符的文件名是否还存在。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>Nginx中通过access_log和error_log指令配置访问日志和错误日志，通过log_format我们可以自定义日志格式。如果日志文件路径中使用了变量，我们可以通过open_log_file_cache指令来设置缓存，提升性能。</p><p>另外，在access_log和log_format中使用了很多变量，这些变量没有一一列举出来，详细的变量信息可以参考Nginx官方文档：<a href="http://nginx.org/en/docs/varindex.html" target="_blank" rel="noopener">http://nginx.org/en/docs/varindex.html</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 24个Jvm面试题总结 </title>
    <link href="/2020/07/07/2020-07-07-24-jvm/"/>
    <url>/2020/07/07/2020-07-07-24-jvm/</url>
    
    <content type="html"><![CDATA[<h3 id="1、JVN内存结构"><a href="#1、JVN内存结构" class="headerlink" title="1、JVN内存结构"></a>1、JVN内存结构</h3><p> <a href="http://blog.itpub.net/ueditor/php/upload/image/20190822/1566461580220068.jpg" target="_blank" rel="noopener"><img src="http://blog.itpub.net/ueditor/php/upload/image/20190822/1566461580220068.jpg" srcset="/img/loading.gif" lazyload alt="img"></a></p><p>方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。</p><ul><li>Java堆（Heap）,是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。</li><li>方法区（Method Area）,方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。</li><li>程序计数器（Program Counter Register）,程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。</li><li>JVM栈（JVM Stacks）,与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</li><li>本地方法栈（Native Method Stacks）,本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。</li></ul><h3 id="2、对象分配规则"><a href="#2、对象分配规则" class="headerlink" title="2、对象分配规则"></a>2、对象分配规则</h3><ul><li>对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。</li><li>大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。</li><li>长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，知道达到阀值对象进入老年区。</li><li>动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。</li><li>空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。</li></ul><h3 id="3、解释内存中的栈-stack-、堆-heap-和静态区-static-area-的用法"><a href="#3、解释内存中的栈-stack-、堆-heap-和静态区-static-area-的用法" class="headerlink" title="3、解释内存中的栈(stack)、堆(heap)和静态区(static area)的用法"></a>3、解释内存中的栈(stack)、堆(heap)和静态区(static area)的用法</h3><p>　　　　通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用内存中的栈空间；而通过new关键字和构造器创建的对象放在堆空间；程序中的字面量（literal）如直接书写的100、”hello”和常量都是放在静态区中。栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，理论上整个内存没有被其他进程使用的空间甚至硬盘上的虚拟内存都可以被当成堆空间来使用。</p><figure class="highlight processing"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs processing">　　　　<span class="hljs-keyword">String</span> <span class="hljs-built_in">str</span> = <span class="hljs-keyword">new</span> <span class="hljs-keyword">String</span>(<span class="hljs-string">"hello"</span>);<br></code></pre></div></td></tr></table></figure><p>上面的语句中变量str放在栈上，用new创建出来的字符串对象放在堆上，而”hello”这个字面量放在静态区。</p><h3 id="4、Perm-Space中保存什么数据？会引起OutOfMemory吗？"><a href="#4、Perm-Space中保存什么数据？会引起OutOfMemory吗？" class="headerlink" title="4、Perm Space中保存什么数据？会引起OutOfMemory吗？"></a>4、Perm Space中保存什么数据？会引起OutOfMemory吗？</h3><p>　　　　Perm Space中保存的是加载class文件。</p><p>　　　　会引起OutOfMemory，出现异常可以设置 -XX:PermSize 的大小。JDK 1.8后，字符串常量不存放在永久带，而是在堆内存中，JDK8以后没有永久代概念，而是用元空间替代，元空间不存在虚拟机中，二是使用本地内存。</p><h3 id="5、什么是类的加载"><a href="#5、什么是类的加载" class="headerlink" title="5、什么是类的加载"></a>5、什么是类的加载</h3><p>　　　　类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。</p><p>　　　　类加载器</p><p><a href="http://blog.itpub.net/ueditor/php/upload/image/20190822/1566461580890200.jpg" target="_blank" rel="noopener"><img src="http://blog.itpub.net/ueditor/php/upload/image/20190822/1566461580890200.jpg" srcset="/img/loading.gif" lazyload alt="img"></a></p><ul><li>启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库</li><li>扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载DK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。</li><li>应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器</li></ul><p>双亲委派机制：类加载器收到类加载请求，自己不加载，向上委托给父类加载，父类加载不了，再自己加载。优势就是避免Java核心API篡改。</p><h3 id="6、如何⾃定义⼀个类加载器？你使⽤过哪些或者你在什么场景下需要⼀个⾃-定义的类加载器吗？"><a href="#6、如何⾃定义⼀个类加载器？你使⽤过哪些或者你在什么场景下需要⼀个⾃-定义的类加载器吗？" class="headerlink" title="6、如何⾃定义⼀个类加载器？你使⽤过哪些或者你在什么场景下需要⼀个⾃ 定义的类加载器吗？"></a>6、如何⾃定义⼀个类加载器？你使⽤过哪些或者你在什么场景下需要⼀个⾃ 定义的类加载器吗？</h3><p>　　自定义类加载的意义：</p><ol><li>加载特定路径的class文件</li><li>加载一个加密的网络class文件</li><li>热部署加载class文件</li></ol><h3 id="7、描述一下JVM加载class文件的原理机制？"><a href="#7、描述一下JVM加载class文件的原理机制？" class="headerlink" title="7、描述一下JVM加载class文件的原理机制？"></a>7、描述一下JVM加载class文件的原理机制？</h3><p>　　　　JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。</p><p>　　　　由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。</p><p>　　　　类的加载是指把类的.class文件中的数据读入到内存中，通常是创建一个字节数组读入.class文件，然后产生与所加载类对应的Class对象。加载完成后，Class对象还不完整，所以此时的类还不可用。当类被加载后就进入连接阶段，这一阶段包括验证、准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。最后JVM对类进行初始化，包括：1)如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；2)如果类中存在初始化语句，就依次执行这些初始化语句。类的加载是由类加载器完成的，类加载器包括：根加载器（BootStrap）、扩展加载器（Extension）、系统加载器（System）和用户自定义类加载器（java.lang.ClassLoader的子类）。从Java 2（JDK 1.2）开始，类加载过程采取了父亲委托机制（PDM）。PDM更好的保证了Java平台的安全性，在该机制中，JVM自带的Bootstrap是根加载器，其他的加载器都有且仅有一个父类加载器。类的加载首先请求父类加载器加载，父类加载器无能为力时才由其子类加载器自行加载。JVM不会向Java程序提供对Bootstrap的引用。</p><p>　　　　下面是关于几个类加载器的说明：</p><ul><li><ul><li><ul><li>bootstrap：一般用本地代码实现，负责加载JVM基础核心类库（rt.jar）；</li><li>Extension：从java.ext.dirs系统属性所指定的目录中加载类库，它的父加载器是Bootstrap；</li><li>System：又叫应用类加载器，其父类是Extension。它是应用最广泛的类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中记载类，是用户自定义加载器的默认父加载器。</li></ul></li></ul></li></ul><p><strong><em>0\</em></strong>|<strong><em>1**</em></strong>8、Java对象创建过程**</p><ol><li>JVM遇到一条新建对象的指令时首先去检查这个指令的参数是否能在常量池中定义到一个类的符号引用。然后加载这个类（类加载过程在后边讲）</li><li>为对象分配内存。一种办法“指针碰撞”、一种办法“空闲列表”，最终常用的办法“本地线程缓冲分配(TLAB)”</li><li>将除对象头外的对象内存空间初始化为0</li><li>对对象头进行必要设置</li></ol><h3 id="9、类的生命周期"><a href="#9、类的生命周期" class="headerlink" title="9、类的生命周期"></a>9、类的生命周期</h3><p>　　　　类的生命周期包括这几个部分，加载、连接、初始化、使用和卸载，其中前三部是类的加载的过程,如下图:</p><p><a href="http://blog.itpub.net/ueditor/php/upload/image/20190822/1566461580839511.jpg" target="_blank" rel="noopener"><img src="http://blog.itpub.net/ueditor/php/upload/image/20190822/1566461580839511.jpg" srcset="/img/loading.gif" lazyload alt="img"></a></p><ul><li>加载，查找并加载类的二进制数据，在Java堆中也创建一个java.lang.Class类的对象</li><li>连接，连接又包含三块内容：验证、准备、初始化。 1）验证，文件格式、元数据、字节码、符号引用验证； 2）准备，为类的静态变量分配内存，并将其初始化为默认值； 3）解析，把类中的符号引用转换为直接引用</li><li>初始化，为类的静态变量赋予正确的初始值</li><li>使用，new出对象程序中使用</li><li>卸载，执行垃圾回收</li></ul><h3 id="10、Java-中会存在内存泄漏吗，请简单描述。"><a href="#10、Java-中会存在内存泄漏吗，请简单描述。" class="headerlink" title="10、Java 中会存在内存泄漏吗，请简单描述。"></a>10、Java 中会存在内存泄漏吗，请简单描述。</h3><p>　　　　理论上Java因为有垃圾回收机制（GC）不会存在内存泄露问题（这也是Java被广泛使用于服务器端编程的一个重要原因）；然而在实际开发中，可能会存在无用但可达的对象，这些对象不能被GC回收，因此也会导致内存泄露的发生。例如hibernate的Session（一级缓存）中的对象属于持久态，垃圾回收器是不会回收这些对象的，然而这些对象中可能存在无用的垃圾对象，如果不及时关闭（close）或清空（flush）一级缓存就可能导致内存泄露。下面例子中的代码也会导致内存泄露。</p><figure class="highlight arduino"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs arduino"><span class="hljs-keyword">import</span> java.util.Arrays;<br><span class="hljs-keyword">import</span> java.util.EmptyStackException;<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyStack</span>&lt;T&gt; &#123;</span><br>    <span class="hljs-keyword">private</span> T[] elements;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> <span class="hljs-built_in">size</span> = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> INIT_CAPACITY = <span class="hljs-number">16</span>;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">MyStack</span><span class="hljs-params">()</span> </span>&#123;<br>        elements = (T[]) <span class="hljs-keyword">new</span> Object[INIT_CAPACITY];<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">push</span><span class="hljs-params">(T elem)</span> </span>&#123;<br>        ensureCapacity();<br>        elements[<span class="hljs-built_in">size</span>++] = elem;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> T <span class="hljs-title">pop</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">size</span> == <span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> EmptyStackException();<br>        <span class="hljs-keyword">return</span> elements[--<span class="hljs-built_in">size</span>];<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">ensureCapacity</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(elements.length == <span class="hljs-built_in">size</span>) &#123;<br>            elements = Arrays.copyOf(elements, <span class="hljs-number">2</span> * <span class="hljs-built_in">size</span> + <span class="hljs-number">1</span>);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>　　　　上面的代码实现了一个栈（先进后出（FILO））结构，乍看之下似乎没有什么明显的问题，它甚至可以通过你编写的各种单元测试。 然而其中的pop方法却存在内存泄露的问题，当我们用pop方法弹出栈中的对象时，该对象不会被当作垃圾回收，即使使用栈的程序不再引用这些对象，因为栈内部维护着对这些对象的过期引用（obsolete reference）。在支持垃圾回收的语言中，内存泄露是很隐蔽的，这种内存泄露其实就是无意识的对象保持。 如果一个对象引用被无意识的保留起来了，那么垃圾回收器不会处理这个对象，也不会处理该对象引用的其他对象，即使这样的对象只有少数几个，也可能会导致很多的对象被排除在垃圾回收之外，从而对性能造成重大影响，极端情况下会引发Disk Paging（物理内存与硬盘的虚拟内存交换数据），甚至造成OutOfMemoryError。</p><h3 id="11、GC是什么？为什么要有GC？"><a href="#11、GC是什么？为什么要有GC？" class="headerlink" title="11、GC是什么？为什么要有GC？"></a>11、GC是什么？为什么要有GC？</h3><p>　　　　GC是垃圾收集的意思，内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。 Java程序员不用担心内存管理，因为垃圾收集器会自动进行管理。要请求垃圾收集，可以调用下面的方法之一：System.gc() 或Runtime.getRuntime().gc() ，但JVM可以屏蔽掉显示的垃圾回收调用。 垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低优先级的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。 在Java诞生初期，垃圾回收是Java最大的亮点之一，因为服务器端的编程需要有效的防止内存泄露问题，然而时过境迁，如今Java的垃圾回收机制已经成为被诟病的东西。移动智能终端用户通常觉得iOS的系统比Android系统有更好的用户体验，其中一个深层次的原因就在于Android系统中垃圾回收的不可预知性。</p><p>　　　　补充：垃圾回收机制有很多种，包括：分代复制垃圾回收、标记垃圾回收、增量垃圾回收等方式。标准的Java进程既有栈又有堆。栈保存了原始型局部变量，堆保存了要创建的对象。Java平台对堆内存回收和再利用的基本算法被称为标记和清除，但是Java对其进行了改进，采用“分代式垃圾收集”。这种方法会跟Java对象的生命周期将堆内存划分为不同的区域，在垃圾收集过程中，可能会将对象移动到不同区域：</p><ul><li>伊甸园（Eden）：这是对象最初诞生的区域，并且对大多数对象来说，这里是它们唯一存在过的区域。</li><li>幸存者乐园（Survivor）：从伊甸园幸存下来的对象会被挪到这里。</li><li>终身颐养园（Tenured）：这是足够老的幸存对象的归宿。年轻代收集（Minor-GC）过程是不会触及这个地方的。当年轻代收集不能把对象放进终身颐养园时，就会触发一次完全收集（Major-GC），这里可能还会牵扯到压缩，以便为大对象腾出足够的空间。</li></ul><p>与垃圾回收相关的JVM参数：</p><ul><li>-Xms / -Xmx — 堆的初始大小 / 堆的最大大小</li><li>-Xmn — 堆中年轻代的大小</li><li>-XX:-DisableExplicitGC — 让System.gc()不产生任何作用</li><li>-XX:+PrintGCDetails — 打印GC的细节</li><li>-XX:+PrintGCDateStamps — 打印GC操作的时间戳</li><li>-XX:NewSize / XX:MaxNewSize — 设置新生代大小/新生代最大大小</li><li>-XX:NewRatio — 可以设置老生代和新生代的比例</li><li>-XX:PrintTenuringDistribution — 设置每次新生代GC后输出幸存者乐园中对象年龄的分布</li><li>-XX:InitialTenuringThreshold / -XX:MaxTenuringThreshold：设置老年代阀值的初始值和最大值</li><li>-XX:TargetSurvivorRatio：设置幸存区的目标使用率</li></ul><h3 id="12、做GC时，⼀个对象在内存各个Space中被移动的顺序是什么？"><a href="#12、做GC时，⼀个对象在内存各个Space中被移动的顺序是什么？" class="headerlink" title="12、做GC时，⼀个对象在内存各个Space中被移动的顺序是什么？"></a>12、做GC时，⼀个对象在内存各个Space中被移动的顺序是什么？</h3><p>　　　　　　标记清除法，复制算法，标记整理、分代算法。</p><p>　　　　　　新生代一般采用复制算法 GC，老年代使用标记整理算法。</p><p>　　　　　　垃圾收集器：串行新生代收集器、串行老生代收集器、并行新生代收集器、并行老年代收集器。</p><p>　　　　　　CMS（Current Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，它是一种并发收集器，采用的是Mark-Sweep算法。</p><h3 id="13、你知道哪些垃圾回收算法？"><a href="#13、你知道哪些垃圾回收算法？" class="headerlink" title="13、你知道哪些垃圾回收算法？"></a>13、你知道哪些垃圾回收算法？</h3><p>GC最基础的算法有三种： 标记 -清除算法、复制算法、标记-压缩算法，我们常用的垃圾回收器一般都采用分代收集算法。</p><ul><li>标记-清除算法，“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。</li><li>复制算法，“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。</li><li>标记-压缩算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存</li><li>分代收集算法，“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。</li></ul><h3 id="14、垃圾回收器"><a href="#14、垃圾回收器" class="headerlink" title="14、垃圾回收器"></a>14、垃圾回收器</h3><ul><li>Serial收集器，串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。</li><li>ParNew收集器，ParNew收集器其实就是Serial收集器的多线程版本。</li><li>Parallel收集器，Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。</li><li>Parallel Old 收集器，Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法</li><li>CMS收集器，CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。</li><li>G1收集器，G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征</li></ul><h3 id="15、如何判断一个对象是否应该被回收"><a href="#15、如何判断一个对象是否应该被回收" class="headerlink" title="15、如何判断一个对象是否应该被回收"></a>15、如何判断一个对象是否应该被回收</h3><p>判断对象是否存活一般有两种方式：</p><ul><li>引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。</li><li>可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的，不可达对象。</li></ul><h3 id="16、JVM的永久代中会发生垃圾回收么？"><a href="#16、JVM的永久代中会发生垃圾回收么？" class="headerlink" title="16、JVM的永久代中会发生垃圾回收么？"></a>16、JVM的永久代中会发生垃圾回收么？</h3><p>垃圾回收不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收(Full GC)。如果你仔细查看垃圾收集器的输出信息，就会发现永久代也是被回收的。这就是为什么正确的永久代大小对避免Full GC是非常重要的原因。请参考下Java8：从永久代到元数据区 (注：Java8中已经移除了永久代，新加了一个叫做元数据区的native内存区)</p><h3 id="17、引用的分类"><a href="#17、引用的分类" class="headerlink" title="17、引用的分类"></a>17、引用的分类</h3><ul><li>强引用：GC时不会被回收</li><li>软引用：描述有用但不是必须的对象，在发生内存溢出异常之前被回收</li><li>弱引用：描述有用但不是必须的对象，在下一次GC时被回收</li><li>虚引用（幽灵引用/幻影引用）:无法通过虚引用获得对象，用PhantomReference实现虚引用，虚引用用来在GC时返回一个通知。</li></ul><h3 id="18、调优命令"><a href="#18、调优命令" class="headerlink" title="18、调优命令"></a>18、调优命令</h3><p>Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo</p><ul><li>jps，JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。</li><li>jstat，JVM statistics Monitoring是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。</li><li>jmap，JVM Memory Map命令用于生成heap dump文件</li><li>jhat，JVM Heap Analysis Tool命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看</li><li>jstack，用于生成java虚拟机当前时刻的线程快照。</li><li>jinfo，JVM Configuration info 这个命令作用是实时查看和调整虚拟机运行参数。</li></ul><h3 id="19、调优工具"><a href="#19、调优工具" class="headerlink" title="19、调优工具"></a>19、调优工具</h3><p>常用调优工具分为两类,jdk自带监控工具：jconsole和jvisualvm，第三方有：MAT(Memory Analyzer Tool)、GChisto。</p><ul><li>jconsole，Java Monitoring and Management Console是从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控</li><li>jvisualvm，jdk自带全能工具，可以分析内存快照、线程快照；监控内存变化、GC变化等。</li><li>MAT，Memory Analyzer Tool，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗</li><li>GChisto，一款专业分析gc日志的工具</li></ul><h3 id="20、jstack-是⼲什么的-jstat-呢？如果线上程序周期性地出现卡顿，你怀疑可-能是-GC-导致的，你会怎么来排查这个问题？线程⽇志⼀般你会看其中的什么部分？"><a href="#20、jstack-是⼲什么的-jstat-呢？如果线上程序周期性地出现卡顿，你怀疑可-能是-GC-导致的，你会怎么来排查这个问题？线程⽇志⼀般你会看其中的什么部分？" class="headerlink" title="20、jstack 是⼲什么的? jstat 呢？如果线上程序周期性地出现卡顿，你怀疑可 能是 GC 导致的，你会怎么来排查这个问题？线程⽇志⼀般你会看其中的什么部分？"></a>20、jstack 是⼲什么的? jstat 呢？如果线上程序周期性地出现卡顿，你怀疑可 能是 GC 导致的，你会怎么来排查这个问题？线程⽇志⼀般你会看其中的什么部分？</h3><p>　　　　jstack 用来查询 Java 进程的堆栈信息。</p><p>　　　　jvisualvm 监控内存泄露，跟踪垃圾回收、执行时内存、cpu分析、线程分析。</p><h3 id="21、Minor-GC与Full-GC分别在什么时候发生？"><a href="#21、Minor-GC与Full-GC分别在什么时候发生？" class="headerlink" title="21、Minor GC与Full GC分别在什么时候发生？"></a>21、Minor GC与Full GC分别在什么时候发生？</h3><p>　　　　新生代内存不够用时候发生MGC也叫YGC，JVM内存不够的时候发生FGC</p><h3 id="22、你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理-过程中有哪些收获？"><a href="#22、你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理-过程中有哪些收获？" class="headerlink" title="22、你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理 过程中有哪些收获？"></a>22、你有没有遇到过OutOfMemory问题？你是怎么来处理这个问题的？处理 过程中有哪些收获？</h3><p>　　　　permgen space、heap space 错误。</p><p>　　　　　　常见的原因</p><ul><li><ul><li><ul><li>内存加载的数据量太大：一次性从数据库取太多数据；　　</li><li>集合类中有对对象的引用，使用后未清空，GC不能进行回收；</li><li>代码中存在循环产生过多的重复对象；</li><li>启动参数堆内存值小。</li></ul></li></ul></li></ul><h3 id="23、JDK-1-8之后Perm-Space有哪些变动-MetaSpace⼤⼩默认是⽆限的么-还是你们会通过什么⽅式来指定⼤⼩？"><a href="#23、JDK-1-8之后Perm-Space有哪些变动-MetaSpace⼤⼩默认是⽆限的么-还是你们会通过什么⽅式来指定⼤⼩？" class="headerlink" title="23、JDK 1.8之后Perm Space有哪些变动? MetaSpace⼤⼩默认是⽆限的么? 还是你们会通过什么⽅式来指定⼤⼩？"></a>23、JDK 1.8之后Perm Space有哪些变动? MetaSpace⼤⼩默认是⽆限的么? 还是你们会通过什么⽅式来指定⼤⼩？</h3><p>　　　　JDK 1.8后用元空间替代了 Perm Space；字符串常量存放到堆内存中。</p><p>　　　　MetaSpace大小默认没有限制，一般根据系统内存的大小。JVM会动态改变此值。</p><p>　　　　-XX:MetaspaceSize：分配给类元数据空间（以字节计）的初始大小（Oracle逻辑存储上的初始高水位，the initial high-water-mark）。此值为估计值，MetaspaceSize的值设置的过大会延长垃圾回收时间。垃圾回收过后，引起下一次垃圾回收的类元数据空间的大小可能会变大。</p><p>　　　　-XX:MaxMetaspaceSize：分配给类元数据空间的最大值，超过此值就会触发Full GC，此值默认没有限制，但应取决于系统内存的大小。JVM会动态地改变此值。</p><h3 id="24、StackOverflow异常有没有遇到过？⼀般你猜测会在什么情况下被触发？如何指定⼀个线程的堆栈⼤⼩？⼀般你们写多少？"><a href="#24、StackOverflow异常有没有遇到过？⼀般你猜测会在什么情况下被触发？如何指定⼀个线程的堆栈⼤⼩？⼀般你们写多少？" class="headerlink" title="24、StackOverflow异常有没有遇到过？⼀般你猜测会在什么情况下被触发？如何指定⼀个线程的堆栈⼤⼩？⼀般你们写多少？"></a>24、StackOverflow异常有没有遇到过？⼀般你猜测会在什么情况下被触发？如何指定⼀个线程的堆栈⼤⼩？⼀般你们写多少？</h3><p>　　　　栈内存溢出，一般由栈内存的局部变量过爆了，导致内存溢出。出现在递归方法，参数个数过多，递归过深，递归没有出口。</p><blockquote><p>本文转载：</p><p><strong>作　　者</strong>：<strong><a href="https://www.cnblogs.com/JesseP" target="_blank" rel="noopener">JessePeng</a></strong><br><strong>出　　处</strong>：<a href="https://www.cnblogs.com/JesseP/p/11750847.html" target="_blank" rel="noopener">https://www.cnblogs.com/JesseP/p/11750847.html</a></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 用户访问网站慢，排查思路 </title>
    <link href="/2020/07/01/2020-07-01-user-slow-server/"/>
    <url>/2020/07/01/2020-07-01-user-slow-server/</url>
    
    <content type="html"><![CDATA[<p>当出现网站慢的时候我们脑子中要映出几点原因：</p><p>1.程序代码执行方面</p><p>2.大量数据库操作</p><p>3.域名DNS解析问题</p><p>4.服务器环境</p><p>5.网络的带宽</p><p>6.用许多javascript特效</p><p>7.访问的东西大</p><p>8.系统资源不足</p><p>9.防火墙的过多使用</p><p>10.网络中某个端口形成了瓶颈导致网速变慢</p><p>\1.打开访问慢的网站观察下情况，通过火狐的fixfox 插件 或者 IE的元素查看工具，你网站里面加载的信息会一览无遗的展现出来，并且那些元素加载耗时多少秒等等情况，如何解决能，把远程耗时久的js下载到本地，或者直接删除。</p><p>\2. 我看了下页面中有多处连接数据库操作的地方，并且有远程的数据库操作，并且还有多余的数据库连接代码，话不多说，改之.</p><p>   解决完了发现的确是快点了，但是还是不理想，于是我把页面执行数据库代码放到了数据库中执行没有耗慢的情况。</p><p>\3. 关于域名DNS的情况只是其中一种情况，不要急着找域名商的问题，你可以写个没有数据操作的页面放在同台服务器域名下，看看是不是访问同样慢，如果是才有可能，你还要让你周围的人也看看，最好别是你同公司的人。</p><p>\4. 我来看看服务器的情况吧，是不是CPU使用率过高造成的呢。</p><p>   a. top  发现cpu使用也不高啊，30% 左右，但是发现一个问题，sleeping 的进程数比较多。擦，最好别是僵尸进程，现在这样的东西不多了。</p><p>   b. 查看了下timewait的量: 发现有mysqld 和 httpd 的，大部分来自于 httpd  ； 命令 netstat -ae|grep TIME_WAIT</p><div class="hljs code-wrapper"><pre><code>如何来解决timewait的量问题呢？</code></pre></div><p>TIME_WAIT解决办法：</p><p>vi /etc/sysctl.conf</p><p>编辑文件，加入以下内容：<br>net.ipv4.tcp_syncookies = 1<br>net.ipv4.tcp_tw_reuse = 1<br>net.ipv4.tcp_tw_recycle = 1<br>net.ipv4.tcp_fin_timeout = 30<br>net.ipv4.tcp_keepalive_time = 30  保持连接的时间<br>net.ipv4.tcp_max_tw_buckets = 100 这个是设置服务器同时保持的time_wait的数目 </p><p>然后执行 /sbin/sysctl -p 让参数生效。</p><p>如果还不够满意可以 再设置下Ulimit参数<br>cat &gt;&gt;/etc/security/limits.conf&lt;&lt;EOF<br>* soft nofile 655350<br>* hard nofile 655350<br>EOF<br>然后ulimit -SHn 了 让生效。</p>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Linux top命令参数详解 </title>
    <link href="/2020/06/29/2020-06-29-linux-top/"/>
    <url>/2020/06/29/2020-06-29-linux-top/</url>
    
    <content type="html"><![CDATA[<h3 id="一、top前5行统计信息"><a href="#一、top前5行统计信息" class="headerlink" title="一、top前5行统计信息"></a>一、top前5行统计信息</h3><p><strong>第1行：top - 05:43:27 up 4:52, 2 users, load average: 0.58, 0.41, 0.30</strong><br>第1行是任务队列信息，其参数如下：</p><table><thead><tr><th align="left">内容</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">05:43:27</td><td align="left">表示当前时间</td></tr><tr><td align="left">up 4:52</td><td align="left">系统运行时间 格式为时：分</td></tr><tr><td align="left">2 users</td><td align="left">当前登录用户数</td></tr><tr><td align="left">load average: 0.58, 0.41, 0.30</td><td align="left">系统负载，即任务队列的平均长度。 三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。</td></tr></tbody></table><p>load average: 如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 </p><p><strong>第2行：Tasks: 159 total, 1 running, 158 sleeping, 0 stopped, 0 zombie</strong><br><strong>第3行：%Cpu(s): 37.0 us, 3.7 sy, 0.0 ni, 59.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st</strong><br>第2、3行为进程和CPU的信息<br>当有多个CPU时，这些内容可能会超过两行，其参数如下：</p><table><thead><tr><th align="left">内容</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">159 total</td><td align="left">进程总数</td></tr><tr><td align="left">1 running</td><td align="left">正在运行的进程数</td></tr><tr><td align="left">158 sleeping</td><td align="left">睡眠的进程数</td></tr><tr><td align="left">0 stopped</td><td align="left">停止的进程数</td></tr><tr><td align="left">0 zombie</td><td align="left">僵尸进程数</td></tr><tr><td align="left">37.0 us</td><td align="left">用户空间占用CPU百分比</td></tr><tr><td align="left">3.7 sy</td><td align="left">内核空间占用CPU百分比</td></tr><tr><td align="left"><strong>0.0 ni</strong></td><td align="left">用户进程空间内改变过优先级的进程占用CPU百分比</td></tr><tr><td align="left">59.3 id</td><td align="left">空闲CPU百分比</td></tr><tr><td align="left">0.0 wa</td><td align="left">等待输入输出的CPU时间百分比</td></tr><tr><td align="left"><strong>0.0 hi</strong></td><td align="left">硬中断（Hardware IRQ）占用CPU的百分比</td></tr><tr><td align="left"><strong>0.0 si</strong></td><td align="left">软中断（Software Interrupts）占用CPU的百分比</td></tr><tr><td align="left"><strong>0.0 st</strong></td><td align="left"></td></tr></tbody></table><p>第4行：KiB Mem: 1530752 total, 1481968 used, 48784 free, 70988 buffers<br>第5行：KiB Swap: 3905532 total, 267544 used, 3637988 free. 617312 cached Mem<br>第4、5行为内存信息<br>其参数如下：</p><table><thead><tr><th align="left">内容</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">KiB Mem: 1530752 total</td><td align="left">物理内存总量</td></tr><tr><td align="left">1481968 used</td><td align="left">使用的物理内存总量</td></tr><tr><td align="left">48784 free</td><td align="left">空闲内存总量</td></tr><tr><td align="left">70988 buffers（buff/cache）</td><td align="left">用作内核缓存的内存量</td></tr><tr><td align="left">KiB Swap: 3905532 total</td><td align="left">交换区总量</td></tr><tr><td align="left">267544 used</td><td align="left">使用的交换区总量</td></tr><tr><td align="left">3637988 free</td><td align="left">空闲交换区总量</td></tr><tr><td align="left">617312 cached Mem</td><td align="left">缓冲的交换区总量。</td></tr><tr><td align="left">3156100 avail Mem</td><td align="left">代表可用于进程下一次分配的物理内存数量</td></tr></tbody></table><p>上述最后提到的缓冲的交换区总量，这里解释一下，所谓缓冲的交换区总量，即内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，该数值即为这些内容已存在于内存中的交换区的大小。相应的内存再次被换出时可不必再对交换区写入。 </p><p>计算可用内存数有一个近似的公式：<br>第四行的free + 第四行的buffers + 第五行的cached</p><h3 id="二、进程信息"><a href="#二、进程信息" class="headerlink" title="二、进程信息"></a>二、进程信息</h3><table><thead><tr><th align="left">列名</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">PID</td><td align="left">进程id</td></tr><tr><td align="left">PPID</td><td align="left">父进程id</td></tr><tr><td align="left">RUSER</td><td align="left">Real user name</td></tr><tr><td align="left">UID</td><td align="left">进程所有者的用户id</td></tr><tr><td align="left">USER</td><td align="left">进程所有者的用户名</td></tr><tr><td align="left">GROUP</td><td align="left">进程所有者的组名</td></tr><tr><td align="left">TTY</td><td align="left">启动进程的终端名。不是从终端启动的进程则显示为 ?</td></tr><tr><td align="left">PR</td><td align="left">优先级</td></tr><tr><td align="left">NI</td><td align="left">nice值。负值表示高优先级，正值表示低优先级</td></tr><tr><td align="left">P</td><td align="left">最后使用的CPU，仅在多CPU环境下有意义</td></tr><tr><td align="left">%CPU</td><td align="left">上次更新到现在的CPU时间占用百分比</td></tr><tr><td align="left">TIME</td><td align="left">进程使用的CPU时间总计，单位秒</td></tr><tr><td align="left">TIME+</td><td align="left">进程使用的CPU时间总计，单位1/100秒</td></tr><tr><td align="left">%MEM</td><td align="left">进程使用的物理内存百分比</td></tr><tr><td align="left">VIRT</td><td align="left">进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES</td></tr><tr><td align="left">SWAP</td><td align="left">进程使用的虚拟内存中，被换出的大小，单位kb</td></tr><tr><td align="left">RES</td><td align="left">进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</td></tr><tr><td align="left">CODE</td><td align="left">可执行代码占用的物理内存大小，单位kb</td></tr><tr><td align="left">DATA</td><td align="left">可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb</td></tr><tr><td align="left">SHR</td><td align="left">共享内存大小，单位kb</td></tr><tr><td align="left">nFLT</td><td align="left">页面错误次数</td></tr><tr><td align="left">nDRT</td><td align="left">最后一次写入到现在，被修改过的页面数。</td></tr><tr><td align="left">S</td><td align="left">进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程</td></tr><tr><td align="left">COMMAND</td><td align="left">命令名/命令行</td></tr><tr><td align="left">WCHAN</td><td align="left">若该进程在睡眠，则显示睡眠中的系统函数名</td></tr><tr><td align="left">Flags</td><td align="left">任务标志</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> kafka和各MQ的优劣对比 </title>
    <link href="/2020/06/29/2020-06-29-kafka-vs-mq/"/>
    <url>/2020/06/29/2020-06-29-kafka-vs-mq/</url>
    
    <content type="html"><![CDATA[<h1 id="目前在业界有哪些比较知名的消息引擎"><a href="#目前在业界有哪些比较知名的消息引擎" class="headerlink" title="目前在业界有哪些比较知名的消息引擎"></a>目前在业界有哪些比较知名的消息引擎</h1><ul><li>ZeroMQ</li><li>推特的Distributedlog</li><li>ActiveMQ：Apache旗下的老牌消息引擎</li><li>RabbitMQ、Kafka</li><li>RocketMQ</li><li>Artemis：Apache的ActiveMQ下的子项目</li><li>Apollo：同样为Apache的ActiveMQ的子项目的号称下一代消息引擎</li><li>商业化的消息引擎IronMQ</li><li>以及实现了JMS(Java Message Service)标准的OpenMQ。</li></ul><h1 id="MQ消息队列的技术应用场景"><a href="#MQ消息队列的技术应用场景" class="headerlink" title="MQ消息队列的技术应用场景"></a>MQ消息队列的技术应用场景</h1><p><strong>1. 解耦</strong><br>   解耦是消息队列要解决的最本质问题。</p><p><strong>2. 最终一致性</strong><br>   最终一致性指的是<strong>两个系统的状态保持一致，要么都成功，要么都失败</strong>。最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。</p><p><strong>2. 广播</strong><br>   <strong>消息队列的基本功能之一是进行广播。</strong>有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。</p><p><strong>3. 错峰与流控</strong><br>   典型的使用场景就是秒杀业务用于流量削峰场景。</p><h1 id="Kafka、RocketMQ、RabbitMQ简单比较"><a href="#Kafka、RocketMQ、RabbitMQ简单比较" class="headerlink" title="Kafka、RocketMQ、RabbitMQ简单比较"></a>Kafka、RocketMQ、RabbitMQ简单比较</h1><h2 id="1-ActiveMQ"><a href="#1-ActiveMQ" class="headerlink" title="1. ActiveMQ"></a>1. ActiveMQ</h2><ul><li>优点<br>单机吞吐量：万级<br>topic数量都吞吐量的影响：<br>时效性：ms级<br>可用性：高，基于主从架构实现高可用性<br>消息可靠性：有较低的概率丢失数据<br>功能支持：MQ领域的功能极其完备</li><li>缺点<br>官方社区现在对ActiveMQ 5.x维护越来越少，较少在大规模吞吐的场景中使用。</li></ul><h2 id="2-Kafka"><a href="#2-Kafka" class="headerlink" title="2. Kafka"></a>2. Kafka</h2><p>   号称大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开Kafka，这款为大数据而生的消息中间件，以其百万级TPS的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。<br>Apache Kafka它最初由LinkedIn公司基于独特的设计实现为一个分布式的提交日志系统( a distributed commit log)，之后成为Apache项目的一部分。<br>目前已经被LinkedIn，Uber, Twitter, Netflix等大公司所采纳。</p><ul><li>优点<br>性能卓越，单机写入TPS约在百万条/秒，最大的优点，就是吞吐量高。<br>时效性：ms级<br>可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用<br>消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;<br>有优秀的第三方Kafka Web管理界面Kafka-Manager；<br>在日志领域比较成熟，被多家公司和多个开源项目使用；<br>功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用</li><li>缺点<br>Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长<br>使用短轮询方式，实时性取决于轮询间隔时间；<br>消费失败不支持重试；<br>支持消息顺序，但是一台代理宕机后，就会产生消息乱序；<br>社区更新较慢；</li></ul><h2 id="3-RabbitMQ"><a href="#3-RabbitMQ" class="headerlink" title="3. RabbitMQ"></a>3. RabbitMQ</h2><p>   RabbitMQ 2007年发布，是一个在AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。</p><ul><li>优点<br>由于erlang语言的特性，mq 性能较好，高并发；<br>吞吐量到万级，MQ功能比较完备<br>健壮、稳定、易用、跨平台、支持多种语言、文档齐全；<br>开源提供的管理界面非常棒，用起来很好用<br>社区活跃度高；</li><li>缺点<br>erlang开发，很难去看懂源码，基本职能依赖于开源社区的快速维护和修复bug，不利于做二次开发和维护。<br>RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。<br>需要学习比较复杂的接口和协议，学习和维护成本较高。</li></ul><h2 id="4-RocketMQ"><a href="#4-RocketMQ" class="headerlink" title="4. RocketMQ"></a>4. RocketMQ</h2><p>   RocketMQ出自 阿里公司的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。<br>   RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。</p><ul><li>优点<br>单机吞吐量：十万级<br>可用性：非常高，分布式架构<br>消息可靠性：经过参数优化配置，消息可以做到0丢失<br>功能支持：MQ功能较为完善，还是分布式的，扩展性好<br>支持10亿级别的消息堆积，不会因为堆积导致性能下降<br>源码是java，我们可以自己阅读源码，定制自己公司的MQ，可以掌控</li><li>缺点<br>支持的客户端语言不多，目前是java及c++，其中c++不成熟；<br>社区活跃度一般<br>没有在 mq 核心中去实现JMS等接口，有些系统要迁移需要修改大量代码</li></ul><h1 id="消息队列选择建议"><a href="#消息队列选择建议" class="headerlink" title="消息队列选择建议"></a>消息队列选择建议</h1><h2 id="1-Kafka"><a href="#1-Kafka" class="headerlink" title="1. Kafka"></a>1. Kafka</h2><p>   Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。<br>大型公司建议可以选用，如果有日志采集功能，肯定是首选kafka了。</p><h2 id="2-RocketMQ"><a href="#2-RocketMQ" class="headerlink" title="2. RocketMQ"></a>2. RocketMQ</h2><p>   天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。<br>RoketMQ在稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择RocketMQ。</p><h2 id="3-RabbitMQ-1"><a href="#3-RabbitMQ-1" class="headerlink" title="3. RabbitMQ"></a>3. RabbitMQ</h2><p>   RabbitMQ :结合erlang语言本身的并发优势，性能较好，社区活跃度也比较高，但是不利于做二次开发和维护。不过，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug。</p><p>   如果你的数据量没有那么大，小公司优先选择功能比较完备的RabbitMQ。</p><p>本文转载，原文地址： <a href="https://links.jianshu.com/go?to=http%3A%2F%2Fyouzhixueyuan.com%2Fcomparison-of-kafka-rocketmq-rabbitmq.html" target="_blank" rel="noopener">高并发架构系列：Kafka、RocketMQ、RabbitMQ的优劣势比较</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>消息队列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> linux运维面试问题总结 </title>
    <link href="/2020/06/29/2020-06-29-linux-devops/"/>
    <url>/2020/06/29/2020-06-29-linux-devops/</url>
    
    <content type="html"><![CDATA[<h3 id="K8S集群组件及作用"><a href="#K8S集群组件及作用" class="headerlink" title="K8S集群组件及作用"></a>K8S集群组件及作用</h3><ul><li><p><strong>API Server</strong>：集群资源操作的唯一入口，结果存储在etcd中</p></li><li><p><strong>etcd</strong>：保存集群的配置信息和各种资源的状态信息</p></li><li><p><strong>Controller Manager</strong>：责管理集群各种资源，保证资源处于预期的状态，Controller Manager由多种controller组成，包括replication controller、endpoints controller、namespace controller、serviceaccounts controller等</p></li><li><p><strong>Schedule</strong>：资源调度，负责决定将Pod放到哪个Node上运行</p></li><li><p><strong>Kubelet</strong>：创建和运行schedule调度过来的Pod，并向master报告运行状态</p></li><li><p><strong>Kube-proxy</strong>：负责将访问的service的数据流转发到后端的容器</p></li><li><p>网络组件：flannel，calico</p></li></ul><h3 id="K8S-CNI组件及其原理"><a href="#K8S-CNI组件及其原理" class="headerlink" title="K8S CNI组件及其原理"></a>K8S CNI组件及其原理</h3><ul><li><strong>flannel</strong></li></ul><p>Flannel 是一个overlay网络，工作在二层网络，flanneld进程会使用VXLAN协议把原始IP包加上目的MAC地址封装成二层数据帧，由linux内核把数据帧封装成UDP报文经过物理网络发送到另一台机器，然后另外一台机flanneld进行解包操作。</p><p>host-gw模式：直接把节点作为一个网关，比如节点node-02上的pod子网是10.64.1.0/24，那么集群中所有节点上都会增加一条路由指向node-02，要求宿主机在同一个二层网络</p><ul><li><strong>calico</strong></li></ul><p>Calico是一个基于BGP的纯三层的网络方案，Calico在每个计算节点都利用Linux Kernel实现了一个高效的vRouter来负责数据转发。每个vRouter都通过BGP1协议把在本节点上运行的容器的路由信息向整个Calico网络广播，并自动设置到达其他节点的路由转发规则，没有额外的封包解包，能够节约CPU运算，提高网络效率。</p><h3 id="K8S-pod之间无法通信，排查思路"><a href="#K8S-pod之间无法通信，排查思路" class="headerlink" title="K8S pod之间无法通信，排查思路"></a>K8S pod之间无法通信，排查思路</h3><p>跨主机pod之间无法通信：</p><ul><li><p>iptables问题，执行命令：</p><figure class="highlight tp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs tp">iptables -<span class="hljs-keyword">P</span> FORWARD <span class="hljs-keyword">ACC</span>EPT  <br>iptables -<span class="hljs-keyword">P</span> INPUT <span class="hljs-keyword">ACC</span>EPT<br></code></pre></div></td></tr></table></figure></li><li><p>docker配置问题，没连上flannel</p></li></ul><h3 id="kube-proxy的三种代理模式及原理"><a href="#kube-proxy的三种代理模式及原理" class="headerlink" title="kube-proxy的三种代理模式及原理"></a>kube-proxy的三种代理模式及原理</h3><ul><li><p><strong>userspace：</strong></p><p>1、为每个service在node上打开一个随机端口（代理端口）</p><p>2、建立iptables规则，将clusterip的请求重定向到代理端口</p><p>3、到达代理端口（用户空间）的请求再由kubeproxy转发到后端pod。</p><p>这里为什么需要建iptables规则，因为kube-proxy 监听的端口在用户空间，所以需要一层 iptables 把访问服务的连接重定向给 kube-proxy 服务，这里就存在内核态到用户态的切换，代价很大，因此就有了iptables。</p></li><li><p><strong>iptables：</strong></p><p>iptables由kube-proxy动态的管理，kube-proxy不再负责转发，数据包的走向完全由iptables规则决定，这样的过程不存在内核态到用户态的切换，效率明显会高很多。但是随着service的增加，iptables规则会不断增加，导致内核十分繁忙</p></li><li><p><strong>ipvs：</strong></p><p>用ipset存储iptables规则，这样规则的数量就能够得到有效控制，而在查找时就类似hash表的查找</p></li></ul><h3 id="kube-proxy挂掉的影响"><a href="#kube-proxy挂掉的影响" class="headerlink" title="kube-proxy挂掉的影响"></a>kube-proxy挂掉的影响</h3><p>service的访问请求将不会转发到Pod上，用户无法访问</p><h3 id="k8s-service涉及到的组件"><a href="#k8s-service涉及到的组件" class="headerlink" title="k8s service涉及到的组件"></a>k8s service涉及到的组件</h3><p>kube-proxy、pod、Replication Controller</p><h3 id="ingress和service的区别"><a href="#ingress和service的区别" class="headerlink" title="ingress和service的区别"></a>ingress和service的区别</h3><p>Service可以看作是一组提供相同服务的Pod对外的访问接口。借助Service，应用可以方便地实现服务发现和负载均衡。Ingress 是全局的，为了代理不同后端 Service 而设置的负载均衡服务。</p><p>Service 有三种对外暴露的方法，但是由于每个 Service 都要有一个负载均衡的服务，所以采用 Service 的话，会造成既浪费成本又高的现象。而ingress是一个全局的负载均衡器,然后我只需要通过访问 URL 就可以把请求转发给不同的后端 Service ，从而可以访问到界面，而不是每个 Service 都需要负载均衡。</p><h3 id="k8s设置node节点污点"><a href="#k8s设置node节点污点" class="headerlink" title="k8s设置node节点污点"></a>k8s设置node节点污点</h3><p>kubectl taint node [node] key=value[effect]<br>     其中[effect] 可取值: [ NoSchedule | PreferNoSchedule | NoExecute ]<br>      NoSchedule: 一定不能被调度<br>      PreferNoSchedule: 尽量不要调度<br>      NoExecute: 不仅不会调度, 还会驱逐Node上已有的Pod</p><h3 id="k8s的pause容器有什么用"><a href="#k8s的pause容器有什么用" class="headerlink" title="k8s的pause容器有什么用"></a>k8s的pause容器有什么用</h3><p>pod内的其他容器会共用pause容器的网络栈和存储卷，保证pod内的其他容器的端口不能冲突，彼此都是通过localhost就可以访问，扮演PID1的角色,并在子进程称为”孤儿进程”的时候,通过调用wait()收割这个子进程,这样就不用担心我们的Pod的PID namespace里会堆满僵尸进程了。</p><h3 id="kubernetes中的pause容器主要为每个业务容器提供以下功能："><a href="#kubernetes中的pause容器主要为每个业务容器提供以下功能：" class="headerlink" title="kubernetes中的pause容器主要为每个业务容器提供以下功能："></a>kubernetes中的pause容器主要为每个业务容器提供以下功能：</h3><p>PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID。</p><p>网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围。</p><p>IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信。</p><p>UTS命名空间：Pod中的多个容器共享一个主机名；Volumes（共享存储卷）：</p><p>Pod中的各个容器可以访问在Pod级别定义的Volumes。</p><h3 id="K8S-PLEG错误处理"><a href="#K8S-PLEG错误处理" class="headerlink" title="K8S PLEG错误处理"></a>K8S PLEG错误处理</h3><p><strong>问题</strong>：k8s node节点显示 no ready</p><p><strong>过程1</strong>：pleg是pod生命周期事件生成器，pleg在每次迭代检查中会 调用docker ps来检测容器状态的变化，并调用docker Inspect来获取这些容器的详细信息。在完成每次迭代之后，它更新一个时间戳。如果时间戳有一段时间没有更新(即3分钟)，则运行状况检查失败。</p><p><strong>过程2</strong>：执行docker ps果然很慢</p><p><strong>解决</strong>：因为是测试环境，跑了太多的pod，机器资源已被占用满，重启了机器，执行systemctl daemon-reexec，</p><p>临时解决了，systemctl的一个小bug。</p><h3 id="Mysql-主从不同步检查思路"><a href="#Mysql-主从不同步检查思路" class="headerlink" title="Mysql 主从不同步检查思路"></a>Mysql 主从不同步检查思路</h3><p>1、master，slave节点个执行show master status查看，如果有NO，重新做主从</p><p>2、也可能是在slave上进行了写操作，或者slave机器重启，或者事务回滚</p><p>3、解决方法：停掉主从同步，忽略一次错误，再开启同步：</p><h3 id="Mysql备份方案"><a href="#Mysql备份方案" class="headerlink" title="Mysql备份方案"></a>Mysql备份方案</h3><p>每三天做全量备份，中间每天做增量，增量根据position值或者时间点进行备份</p><h3 id="nginx状态码"><a href="#nginx状态码" class="headerlink" title="nginx状态码"></a>nginx状态码</h3><p>301 永久重定向</p><p>302 临时重定向</p><p>403 服务器拒绝请求</p><p>404 访问的资源不存咋</p><p>500 服务器内部错误</p><p>502 错误网关</p><p>503 服务不可达</p><h3 id="nginx获取用户真实ip"><a href="#nginx获取用户真实ip" class="headerlink" title="nginx获取用户真实ip"></a>nginx获取用户真实ip</h3><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">proxy_set_header</span>   Host             <span class="hljs-variable">$host</span>;<br><span class="hljs-attribute">proxy_set_header</span>   X-Real-IP        <span class="hljs-variable">$remote_addr</span>;<br><span class="hljs-attribute">proxy_set_header</span>   X-Forwarded-For  <span class="hljs-variable">$proxy_add_x_forwarded_for</span>;<br><span class="hljs-attribute">set_real_ip_from</span> <span class="hljs-number">0.0.0.0</span>/<span class="hljs-number">0</span>;         <span class="hljs-comment"># 额外增加的配置            </span><br><span class="hljs-attribute">real_ip_header</span>  X-Forwarded-For;    <span class="hljs-comment"># 额外增加的配置            </span><br><span class="hljs-attribute">real_ip_recursive</span>   <span class="hljs-literal">on</span>;             <span class="hljs-comment"># 额外增加的配置</span><br></code></pre></div></td></tr></table></figure><h3 id="端口time-wait解决"><a href="#端口time-wait解决" class="headerlink" title="端口time_wait解决"></a>端口time_wait解决</h3><figure class="highlight stylus"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs stylus">net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_syncookies</span> = <span class="hljs-number">1</span> 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为<span class="hljs-number">0</span>，表示关闭；<br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_tw_reuse</span> = <span class="hljs-number">1</span> 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为<span class="hljs-number">0</span>，表示关闭；<br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_tw_recycle</span> = <span class="hljs-number">1</span> 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为<span class="hljs-number">0</span>，表示关闭。<br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_fin_timeout</span> 修改系默认的 TIMEOUT 时间<br></code></pre></div></td></tr></table></figure><h3 id="linux系统执行命令很卡"><a href="#linux系统执行命令很卡" class="headerlink" title="linux系统执行命令很卡"></a>linux系统执行命令很卡</h3><ul><li>top命令查看系统资源使用情况，cpu、内存、负载</li><li>iostat命令查看磁盘IO使用情况</li></ul><h3 id="shell脚本的变量"><a href="#shell脚本的变量" class="headerlink" title="shell脚本的变量"></a>shell脚本的变量</h3><p>$0  文件名及路径</p><p>$1,$2  参数1，参数2</p><p>$#  传递给脚本或函数的参数个数</p><p>$$  当前Shell进程ID</p><p>$?  判断上个命令的执行成功与否，0为成功。</p><p>$@  传递脚本或函数的所有参数</p><p>$*  传递脚本或函数的所有参数</p><h3 id="linux-cpu-负载概念"><a href="#linux-cpu-负载概念" class="headerlink" title="linux cpu 负载概念"></a>linux cpu 负载概念</h3><p>这些数据来自于文件/proc/loadavg，内核会负责统计出这些数据。<br>top和uptime命令显示的内容就来自于这个文件，根据proc的帮助文件可知，这里的值就是单位时间内处于运行状态以及等待磁盘 I/O状态的平均job数量。这里的运行状态和job都是内核的概念，这里进行说明：<br>1、 对于内核而言，进程和线程都是job<br>2、 job处于运行状态指job处于内核的运行队列中，正在或等待被CPU调度（用户空间的进程正在运行不代表需要被CPU调度，有可能在等待I/O，也有可能在sleep等等）</p><h3 id="linux硬链接和软链接原理"><a href="#linux硬链接和软链接原理" class="headerlink" title="linux硬链接和软链接原理"></a>linux硬链接和软链接原理</h3><ul><li>硬链接：在Linux系统中，多个文件名指向同一索引节点(Inode)是正常且允许的。一般这种链接就称为硬链接。硬链接的作用之一是允许一个文件拥有多个有效路径名，这样用户就可以建立硬链接到重要的文件，以防止“误删”源数据。</li><li>软链接： 软链接就是一个普通文件，只是数据块内容有点特殊，文件用户数据块中存放的内容是另一文件的路径名的指向，通过这个方式可以快速定位到软连接所指向的源文件实体。软链接可对文件或目录创建。</li></ul><p>软连接和硬链接的特点：</p><p>软链接：</p><ul><li>1.软链接是存放另一个文件的路径的形式存在。</li><li>2.软链接可以 跨文件系统 ，硬链接不可以。</li><li>3.软链接可以对一个不存在的文件名进行链接，硬链接必须要有源文件。</li><li>4.软链接可以对目录进行链接。</li></ul><p>硬链接：</p><ul><li><ol><li>硬链接，以文件副本的形式存在。但不占用实际空间。</li></ol></li><li><ol start="2"><li>不允许给目录创建硬链接。</li></ol></li><li><ol start="3"><li>硬链接只有在同一个文件系统中才能创建。</li></ol></li><li><ol start="4"><li>删除其中一个硬链接文件并不影响其他有相同 inode 号的文件。</li></ol></li></ul><h3 id="linux进程退出指令"><a href="#linux进程退出指令" class="headerlink" title="linux进程退出指令"></a>linux进程退出指令</h3><p> INT（快速关闭）—-是当用户键入<Control-C>时由终端驱动程序发送的信号。这是一个终止当前操作的请求，如果捕获了这个信号，一些简单的程序应该退出，或者允许自给被终止，这也是程序没有捕获到这个信号时的默认处理方法。拥有命令行或者输入模式的那些程序应该停止它们在做的事情，清除状态，并等待用户的再次输入。</p><p>  TERM（快速关闭）—-是请求彻底终止某项执行操作，它期望接收进程清除自给的状态并退出。</p><p>  HUP—- 平滑启动。如果想要更改配置而不需停止并重新启动服务，请使用该命令。在对配置文件作必要的更改后，发出该命令以动态更新服务配置。</p><p>  QUIT：从容关闭。</p>]]></content>
    
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Nginx location匹配规则 </title>
    <link href="/2020/06/11/2020-06-11-nginx-config-location/"/>
    <url>/2020/06/11/2020-06-11-nginx-config-location/</url>
    
    <content type="html"><![CDATA[<p>#一、location语法</p><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh"><span class="hljs-keyword">location</span> <span class="hljs-title">[=|~|~*|^~] uri</span> &#123; … &#125;<br></code></pre></div></td></tr></table></figure><p>其中，方括号中的四种标识符是可选项，用来改变请求字符串和uri的匹配方式。uri是待匹配的请求字符串，可以是不包含正则的字符串，这种模式被称为“标准的uri”；也可以包含正则，这种模式被称为”正则uri”。例如：</p><p>location ~ .*.(php|php5)?$ {<br>　　root /var/www/html;<br>　　……<br>}</p><h1 id="二、四种可选标识符"><a href="#二、四种可选标识符" class="headerlink" title="二、四种可选标识符"></a>二、四种可选标识符</h1><table><thead><tr><th>标识符</th><th>描述</th></tr></thead><tbody><tr><td>=</td><td><strong>精确匹配：</strong>用于标准uri前，要求请求字符串和uri严格匹配。如果匹配成功就停止匹配，立即执行该location里面的请求。</td></tr><tr><td>~</td><td><strong>正则匹配：</strong>用于正则uri前，表示uri里面包含正则，并且区分大小写。</td></tr><tr><td>~*</td><td><strong>正则匹配：</strong>用于正则uri前，表示uri里面包含正则，不区分大小写。</td></tr><tr><td>^~</td><td><strong>非正则匹配；</strong>用于标准uri前，nginx服务器匹配到前缀最多的uri后就结束，该模式匹配成功后，不会使用正则匹配。</td></tr><tr><td>无</td><td><strong>普通匹配（最长字符匹配）；</strong>与location顺序无关，是按照匹配的长短来取匹配结果。若完全匹配，就停止匹配。</td></tr></tbody></table><h1 id="三、匹配标识符案例"><a href="#三、匹配标识符案例" class="headerlink" title="三、匹配标识符案例"></a>三、匹配标识符案例</h1><h2 id="1-“-”精准匹配"><a href="#1-“-”精准匹配" class="headerlink" title="1. “=”精准匹配"></a>1. “=”精准匹配</h2><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh"><span class="hljs-keyword">location</span> <span class="hljs-title">= /news</span>/ &#123;<br>            echo <span class="hljs-string">"test1"</span>;<br>        &#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span>/news/<br>test1<br></code></pre></div></td></tr></table></figure><h2 id="2-“-”区分大小写正则匹配"><a href="#2-“-”区分大小写正则匹配" class="headerlink" title="2. “~”区分大小写正则匹配"></a>2. “~”区分大小写正则匹配</h2><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">location</span> <span class="hljs-regexp">~ \.(html)</span> &#123;<br>    <span class="hljs-attribute">echo</span> <span class="hljs-string">'test2'</span>;<br>&#125;<br><span class="hljs-attribute">location</span> <span class="hljs-regexp">~ \.(htmL)</span> &#123;<br>    <span class="hljs-attribute">echo</span> <span class="hljs-string">'test3'</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span>/index.html<br>test2<br>[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span>/index.htmL<br>test3<br></code></pre></div></td></tr></table></figure><h2 id="3-“-”不区分大小写的正则匹配"><a href="#3-“-”不区分大小写的正则匹配" class="headerlink" title="3. “~*”不区分大小写的正则匹配"></a>3. “~*”不区分大小写的正则匹配</h2><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">location</span> <span class="hljs-regexp">~* \.(html)</span>&#123;<br>            <span class="hljs-attribute">echo</span> <span class="hljs-string">'test4'</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span>/index.htmL<br>test4<br>[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span>/index.html<br>test4<br></code></pre></div></td></tr></table></figure><h2 id="4-“-”不进行正则匹配的标准匹配，只匹配前缀"><a href="#4-“-”不进行正则匹配的标准匹配，只匹配前缀" class="headerlink" title="4. “^~”不进行正则匹配的标准匹配，只匹配前缀"></a>4. “^~”不进行正则匹配的标准匹配，只匹配前缀</h2><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">location</span><span class="hljs-regexp"> ^~</span> /index/ &#123;<br>            <span class="hljs-attribute">echo</span> <span class="hljs-string">'test5'</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span>/index/<br>test5<br>[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span>/index/heihei<br>test5<br>[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span>/index/asdnmkalsjd<br>test5<br></code></pre></div></td></tr></table></figure><h2 id="5-普通匹配"><a href="#5-普通匹配" class="headerlink" title="5. 普通匹配"></a>5. 普通匹配</h2><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh"><span class="hljs-keyword">location</span> <span class="hljs-title">/ &#123;</span><br><span class="hljs-title">            echo</span> 'test6';<br>&#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">[<span class="hljs-symbol">root@</span>test]# curl <span class="hljs-number">192.168</span><span class="hljs-number">.233</span><span class="hljs-number">.22</span><br>test6<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Nginx配置location中proxy_pass的&#39;/&#39;号的作用 </title>
    <link href="/2020/05/26/2020-05-26-nginx-config-location-proxypass/"/>
    <url>/2020/05/26/2020-05-26-nginx-config-location-proxypass/</url>
    
    <content type="html"><![CDATA[<p><strong>真实案例，就因为在配置时，少写了一个字符“/”，就造成访问不通报错，因而接到投诉。那么是怎么引起的呢？原因就是：Nginx在配置proxy_pass代理转接时，少些“/”字符造成的。有同学就有疑问，加不加“/”,区别真的那么大吗？我们带着这个疑问，来探究下这个问题。</strong></p><h1 id="location目录匹配详解"><a href="#location目录匹配详解" class="headerlink" title="location目录匹配详解"></a>location目录匹配详解</h1><p>nginx每个location都是一个匹配目录，nginx的策略是：访问请求来时，会对访问地址进行解析，从上到下逐个匹配，匹配上就执行对应location大括号中的策略，并根据策略对请求作出相应。</p><p>依访问地址：<a href="http://www.example.com/book/index.html" target="_blank" rel="noopener">http://www.example.com/book/index.html</a> 为例，nginx配置如下：</p><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">location</span> /book/  &#123;                    <br><span class="hljs-attribute">proxy_connect_timeout</span> <span class="hljs-number">18000</span>; <span class="hljs-comment">##修改成半个小时                        </span><br><span class="hljs-attribute">proxy_send_timeout</span> <span class="hljs-number">18000</span>;                    <br><span class="hljs-attribute">proxy_read_timeout</span> <span class="hljs-number">18000</span>;                    <br><span class="hljs-attribute">proxy_pass</span> http://127.0.0.1:8080;        <br>&#125;<br></code></pre></div></td></tr></table></figure><p>那访问时就会匹配这个location,从而把请求代理转发到本机的8080Tomcat服务中，Tomcat相应后，信息原路返回。总结：<strong>location如果没有“/”时，请求就可以模糊匹配以字符串开头的所有字符串，而有“/”时，只能精确匹配字符本身。</strong></p><p>下面举个例子说明：</p><p> 配置location /book可以匹配/bookdada请求，也可以匹配/book*/dada等等，只要以book开头的目录都可以匹配到。而location /book/必须精确匹配/book/这个目录的请求,不能匹配/bookdada/或/book*/dada等请求。</p><h1 id="proxy-pass有无“-”的四种区别探究"><a href="#proxy-pass有无“-”的四种区别探究" class="headerlink" title="proxy_pass有无“/”的四种区别探究"></a>proxy_pass有无“/”的四种区别探究</h1><p>访问地址都是以：<a href="http://www.book.com/bddd/index.html" target="_blank" rel="noopener">http://www.book.com/bddd/index.html</a> 为例。请求都匹配目录/bddd/</p><h2 id="第一种：加”-“"><a href="#第一种：加”-“" class="headerlink" title="第一种：加”/“"></a>第一种：加”/“</h2><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh"><span class="hljs-keyword">location</span>  <span class="hljs-title">/bddd</span>/ &#123;    <br>proxy_pass  http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8080</span>/;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>测试结果，请求被代理跳转到：<a href="http://127.0.0.1:8080/index.html" target="_blank" rel="noopener">http://127.0.0.1:8080/index.html</a></p><h2 id="第二种-不加”-“"><a href="#第二种-不加”-“" class="headerlink" title="第二种: 不加”/“"></a>第二种: 不加”/“</h2><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh"><span class="hljs-keyword">location</span>  <span class="hljs-title">/bddd</span>/ &#123;            <br>proxy_pass http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8080</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>测试结果，请求被代理跳转到：<a href="http://127.0.0.1:8080/bddd/index.html" target="_blank" rel="noopener">http://127.0.0.1:8080/bddd/index.html</a></p><p>3# 第三种: 增加目录加”/“</p><figure class="highlight awk"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs awk">location  <span class="hljs-regexp">/bddd/</span> &#123;            <br>proxy_pass http:<span class="hljs-regexp">//</span><span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8080</span><span class="hljs-regexp">/sun/</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>测试结果，请求被代理跳转到：<a href="http://127.0.0.1:8080/sun/index.html" target="_blank" rel="noopener">http://127.0.0.1:8080/sun/index.html</a></p><h2 id="第四种：增加目录不加”-“"><a href="#第四种：增加目录不加”-“" class="headerlink" title="第四种：增加目录不加”/“"></a>第四种：增加目录不加”/“</h2><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh"><span class="hljs-keyword">location</span>  <span class="hljs-title">/bddd</span>/ &#123;    <br>proxy_pass http://<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8080</span>/sun;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>测试结果，请求被代理跳转到：<a href="http://127.0.0.1:8080/sunindex.html" target="_blank" rel="noopener">http://127.0.0.1:8080/sunindex.html</a></p><p><strong>总结</strong></p><p>location目录后加”/“,只能匹配目录，不加“/”不仅可以匹配目录还对目录进行模糊匹配。而proxy_pass无论加不加“/”,代理跳转地址都直接拼接。</p><p>为了加深大家印象可以用下面的配置实验测试下：</p><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;   <br>  <span class="hljs-attribute">listen</span>       <span class="hljs-number">80</span>;   <br>  <span class="hljs-attribute">server_name</span>  localhost;   <span class="hljs-comment"># http://localhost/bddd01/xxx -&gt; http://localhost:8080/bddd01/xxx</span><br><br>  <span class="hljs-attribute">location</span> /bddd01/ &#123;           <br>    <span class="hljs-attribute">proxy_pass</span> http://localhost:8080;   <br>  &#125;<br><br>  <span class="hljs-comment"># http://localhost/bddd02/xxx -&gt; http://localhost:8080/xxx   </span><br>  <span class="hljs-attribute">location</span> /bddd02/ &#123;           <br>    <span class="hljs-attribute">proxy_pass</span> http://localhost:8080/;    <br>  &#125;<br><br>  <span class="hljs-comment"># http://localhost/bddd03/xxx -&gt; http://localhost:8080/bddd03*/xxx   </span><br>  <span class="hljs-attribute">location</span> /bddd03 &#123;           <br>    <span class="hljs-attribute">proxy_pass</span> http://localhost:8080;   <br>  &#125;<br>  <br>  <span class="hljs-comment"># http://localhost/bddd04/xxx -&gt; http://localhost:8080//xxx，请注意这里的双斜线，好好分析一下。</span><br>  <span class="hljs-attribute">location</span> /bddd04 &#123;           <br>    <span class="hljs-attribute">proxy_pass</span> http://localhost:8080/;   <br>  &#125;<br><br>  <span class="hljs-comment"># http://localhost/bddd05/xxx -&gt; http://localhost:8080/hahaxxx，请注意这里的haha和xxx之间没有斜杠，分析一下原因。</span><br>  <span class="hljs-attribute">location</span> /bddd05/ &#123;           <br>    <span class="hljs-attribute">proxy_pass</span> http://localhost:8080/haha;    <br>  &#125;<br><br>  <span class="hljs-comment"># http://localhost/bddd06/xxx -&gt; http://localhost:8080/haha/xxx   </span><br>  <span class="hljs-attribute">location</span> /bddd06/ &#123;           <br>    <span class="hljs-attribute">proxy_pass</span> http://localhost:8080/haha/;   <br>  &#125;<br><br>  <span class="hljs-comment"># http://localhost/bddd07/xxx -&gt; http://localhost:8080/haha/xxx   </span><br>  <span class="hljs-attribute">location</span> /bddd07 &#123;           <br>    <span class="hljs-attribute">proxy_pass</span> http://localhost:8080/haha;   <br>  &#125; <br>  <span class="hljs-comment"># http://localhost/bddd08/xxx -&gt; http://localhost:8080/haha//xxx，请注意这里的双斜杠。</span><br>  <span class="hljs-attribute">location</span> /bddd08 &#123;           <br>    <span class="hljs-attribute">proxy_pass</span> http://localhost:8080/haha/;   <br>  &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> MySQL常见面试题（后续的面试题会更新） </title>
    <link href="/2020/05/25/2020-05-25-mysql-examination-questions/"/>
    <url>/2020/05/25/2020-05-25-mysql-examination-questions/</url>
    
    <content type="html"><![CDATA[<p><strong>题目一</strong></p><p>MyISAM和InnoDB的区别，什么时候选择MyISAM</p><p><strong>参考回答</strong></p><p>InnoDB是目前MySQL主流版本(5.6、5.7、8.0)默认的存储引擎，支持事务、外键、行级锁，对于并发条件下要求数据的一致性，适用于对数据准确性要求高的场景。</p><p>MyISAM只支持表级锁、数据排列是按照插入顺序，没有做规则排序。适合应用以查询和插入为主，只有很少量的更新和删除操作，对事务的完整性和并发性要求不是很高的场景。</p><p><strong>实际运用</strong></p><p>看到很多人在选择存储引擎的时候会无脑的选择InnoDB，这个选择合理的一点是如果对数据准确性要求没有那么高，直接用NoSQL就好了。用MySQL就是为了可靠啊。</p><p>但是实际工作中，我设计的数据库中通常都会有几张MyISAM的数据表，通常用来存储历史记录，与使用InnoDB存储实时记录信息的配合使用。</p><p>举个例子：比如一条物流信息，在实时的表里存着目前物流的状态：比如配送中。这条物流在历史上经过了：正在通知快递公司取件、XXX已收揽等，这张记录表基本只有插入和查询，并且丢失一个中间状态不影响当前结果，这就很合适用MyISAM。</p><p><strong>题目二</strong></p><p>简述MySQL的MVCC多版本并发控制</p><p><strong>参考回答</strong></p><p>MVCC是对于事务隔离级别的读已提交RC和可重复读RR，基于乐观锁的实现。在LBCC(基于锁的并发控制)RC、RR和串行化分别是通过加行锁、间隙锁和表锁来基于悲观锁实现。而乐观锁的原理就是在特定的时间点(RC是每次读时，RR是事务开始时)生成一个当前快照，读数据读取快照，只在提交时判断是否有冲突，类似于git的branch和commit。</p><p>MVCC会在新开启一个事务时，给事务里包含的每行记录添加一个当前事务ID和回滚指针。并包含一个Read View，Read View里保存了当前活跃的事务列表，小于这些列表的最近的事务ID才是可见的。这样保证了读到的都是已提交的事务。</p><p><strong>实际运用</strong></p><p>MVCC不仅可以用于数据库，也是很常见的一种并发控制手段。比如使用有限状态自动机来控制的订单状态，在更新订单状态的时候先查询当前状态，比如当前状态是订单未提交，则更新时update XXX set status=’订单已提交’ where status=’订单未提交’，如果执行这条语句时，status已经发生了改变，这条语句就执行失败了。这样不通过数据库自身事务的MVCC，在业务逻辑里也实现了MVCC思想的乐观锁设计。</p><p><strong>题目三</strong></p><p>分布式锁的实现方式</p><p><strong>参考回答</strong></p><p>主流有三种</p><p>1&gt;基于数据库</p><p>1.1&gt;基于数据库主键：插入一条数据，指定主键。如果有两条插入会主键冲突，并发执行失败</p><p>1.2&gt;基于数据库排他锁：提交一个update事务，如果这个事务不提交，其他也对锁定范围内执行update就会阻塞，解决并发问题</p><p>2&gt;基于缓存比如redis的setNX</p><p>3&gt;基于zookeeper</p><p><strong>实际运用</strong></p><p>相信很多人选择分布式锁都是选择第二种，第三种虽然并发性差一下，如果本来就引入了zk，而没有缓存，而分布式锁应用量又不那么大，为了减少引入新组件带来的风险和维护成本，也有可能选择zk。很多人大概认为自己没有用过基于数据库的分布式锁，实际上在不使用MVCC的时代并不是这样。</p><p>在使用spring进行业务开发的时候，常见的一种场景就是使用spring配置事务。默认级别是Repeatable Read可重复读。在这里面如果使用的是LBCC，一进入事务就加入一个排他锁，比如insert、update、delete或者select XXX for update。然后做其他的，比如进行一个RPC调用。这时候一旦出现并发，只有一个能顺利执行，其他都会被阻塞。实际上就相当于使用了分布式锁。</p><p><strong>题目四</strong></p><p>为什么采用B+树作为索引结构?</p><p><strong><em>\</em>参考回答**</strong></p><p>如果采用Hash表，范围查找需要全表扫描；如果采用二叉查找树，由于无法保证平衡，可能退化为链表；如果采用平衡二叉树，通过旋转解决了平衡的问题，但是旋转操作效率太低；如果采用红黑树，树太高，IO次数多；如果采用普通B树，节点要存数索引和数据，一个内存页可存储的数据还是少，另外范围查找也需要多次IO；</p><p>而B+Tree有三个特性：</p><p>1&gt;非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引</p><p>2&gt;叶子节点包含所有索引字段</p><p>3&gt;叶子节点用指针链接，提高范围查询的性能</p><p><strong>实际运用</strong></p><p>在分布式场景下，我们的业务ID都是全局唯一的字符串。如果单纯从业务上来考虑，用业务ID作为数据库的主键就足够了。可以DBA往往要求使用整型的自增主键作为数据库主键，而这个主键对业务来说就是个浪费，没有任何业务含义。</p><p>如果了解了索引的底层结构就不难理解</p><p>1&gt;整型比字符串占用更少的空间</p><p>2&gt;同时大小比较也很快</p><p>3&gt;之所以要自增是每次插入新的记录，对于叶子节点来说：记录会顺序的添加到当前索引节点的后续位置，当一页写满，会自动开辟一个新的页。而如果使用非自增主键，就需要插入的时候移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要读回来。分页操作造成大量的碎片，必须通过优化操作重建表并优化填充页面。</p><p><strong>题目五</strong></p><p>什么叫做覆盖索引？</p><p><strong><em>\</em>参考回答**</strong></p><p>只需要在一棵辅助索引树上就可以获取SQL所需要的所有列数据，不需要回表。</p><p><strong>实际运用</strong></p><p>一些持久层框架比如mybatis的generator插件可以自动生成sql配置文件，这些配置文件往往效率很低。但是刚毕业的同学很多都不会去改这个文件，比如只需要个别列的时候会用java的lambda表达式等方式从逻辑上做处理。结果造成一些性能的问题。</p><p>我在根据一些条件进行范围查找的时候，如果只需要返回ID或者个别列，会自己去改mybatis的generator自动生成的文件，原因是尽量使用覆盖索引，较回表速度快。</p><p>想验证是否使用了覆盖索引，可以用explain执行计划，查看extra字段，如果只显示Using index说明正确使用了覆盖索引。如果extra为空或者除了using index还有filesort说明触发了回表。</p><p><strong>题目六</strong></p><p>查询在什么时候不走索引</p><p><strong><em>\</em>参考回答**</strong></p><p>主要三种情况</p><p>1&gt;不满足走索引的条件，常见的情况有</p><p>1.1&gt;不满足最左匹配原则</p><p>1.2&gt;查询条件使用了函数</p><p>1.3&gt;or操作有一个字段没有索引</p><p>1.4&gt;使用like条件以%开头</p><p>2&gt;走索引效率低于全表扫描，常见的情况有</p><p>2.1&gt;查询条件对null做判断，而null的值很多</p><p>2.2&gt;一个字段区分度很小，比如性别、状态</p><p>3&gt;需要回表的查询结果集过大，超过了配置的范围</p><p><strong>实际运用</strong></p><p>使用索引是为了对查询做优化，要衡量优化效果需要数据说话。所以需要一些工具来衡量，常用的有：</p><p>1&gt;慢查询日志</p><p>开启慢查询日志，可以针对慢SQL进行分析看看哪些可以用索引进行优化</p><p>2&gt;show processlist</p><p>show processlist 语句可以查看当前正在执行的SQL，如果一些SQL执行慢，block了其他的SQL，这是个很好的工具</p><p>3&gt;show profile分析SQL</p><p>支持的话，可以用select @@profiling 查看是否开启，如果结果为0说明未开启。需要先set @@profiling=1;</p><p>这时候就可以用show profiles查看每一条SQL语句耗费的时间</p><p>show profile for query XXID 可以查看具体耗费在哪个阶段</p><p>4&gt;Trace分析优化器的执行计划</p><p>使用set optimizer_trace=’enabled=on’,end_markers_in_json=on;可以打开trace分析，想查看具体的优化器执行计划，只要执行</p><p>select * from <code>information_schema</code>.optimizer_trace即可</p>]]></content>
    
    
    
    <tags>
      
      <tag>MYSQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> HTTP 面试问题 </title>
    <link href="/2020/05/19/2020-05-19-http-interviews/"/>
    <url>/2020/05/19/2020-05-19-http-interviews/</url>
    
    <content type="html"><![CDATA[<h1 id="HTTP-和-HTTPS-的区别"><a href="#HTTP-和-HTTPS-的区别" class="headerlink" title="HTTP 和 HTTPS 的区别"></a>HTTP 和 HTTPS 的区别</h1><p>HTTP 是一种 <code>超文本传输协议(Hypertext Transfer Protocol)</code>，<strong>HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http-content.png" srcset="/img/loading.gif" lazyload alt="http-content"></p><p>HTTP 主要内容分为三部分，<strong>超文本（Hypertext）、传输（Transfer）、协议（Protocol）</strong>。</p><ul><li>超文本就是不单单只是本文，它还可以传输图片、音频、视频，甚至点击文字或图片能够进行<code>超链接</code>的跳转。</li><li>上面这些概念可以统称为数据，传输就是数据需要经过一系列的物理介质从一个端系统传送到另外一个端系统的过程。通常我们把传输数据包的一方称为<code>请求方</code>，把接到二进制数据包的一方称为<code>应答方</code>。</li><li>而协议指的就是是网络中(包括互联网)传递、管理信息的一些规范。如同人与人之间相互交流是需要遵循一定的规矩一样，计算机之间的相互通信需要共同遵守一定的规则，这些规则就称为协议，只不过是网络协议。</li></ul><p>说到 HTTP，不得不提的就是 TCP/IP 网络模型，一般是五层模型。如下图所示</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-five.png" srcset="/img/loading.gif" lazyload alt="tcp-five"></p><p>但是也可以分为四层，就是<strong>把链路层和物理层都表示为网络接口层</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-four.png" srcset="/img/loading.gif" lazyload alt="tcp-four"></p><p>还有一种就是 OSI 七层网络模型，它就是在五层协议之上加了<strong>表示层和会话层</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/osi-seven.png" srcset="/img/loading.gif" lazyload alt="osi-seven"></p><p>而 HTTPS 的全称是 <code>Hypertext Transfer Protocol Secure</code>，从名称我们可以看出 HTTPS 要比 HTTPS 多了 secure 安全性这个概念，实际上， HTTPS 并不是一个新的应用层协议，它其实就是 HTTP + TLS/SSL 协议组合而成，而安全性的保证正是 TLS/SSL 所做的工作。</p><p>也就是说，<strong>HTTPS 就是身披了一层 SSL 的 HTTP</strong>。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http-https-content.png" srcset="/img/loading.gif" lazyload alt="http-https-content"></p><p>那么，HTTP 和 HTTPS 的主要区别是什么呢？</p><ul><li>最简单的，HTTP 在地址栏上的协议是以 <code>http://</code> 开头，而 HTTPS 在地址栏上的协议是以 <code>https://</code> 开头</li></ul><figure class="highlight dts"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dts"><span class="hljs-symbol">http:</span><span class="hljs-comment">//www.baidu.com/</span><br><span class="hljs-symbol">https:</span><span class="hljs-comment">//www.baidu.com/</span><br></code></pre></div></td></tr></table></figure><ul><li>HTTP 是未经安全加密的协议，它的传输过程容易被攻击者监听、数据容易被窃取、发送方和接收方容易被伪造；而 HTTPS 是安全的协议，它通过 <strong>密钥交换算法 - 签名算法 - 对称加密算法 - 摘要算法</strong> 能够解决上面这些问题。</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/chrome-ssl.png" srcset="/img/loading.gif" lazyload alt="chrome-ssl"></p><ul><li>HTTP 的默认端口是 80，而 HTTPS 的默认端口是 443。</li></ul><h1 id="HTTP-Get-和-Post-区别"><a href="#HTTP-Get-和-Post-区别" class="headerlink" title="HTTP Get 和 Post 区别"></a>HTTP Get 和 Post 区别</h1><p>HTTP 中包括许多方法，<strong>Get 和 Post 是 HTTP 中最常用的两个方法</strong>，基本上使用 HTTP 方法中有 99% 都是在使用 Get 方法和 Post 方法，所以有必要我们对这两个方法有更加深刻的认识。</p><ul><li><p>get 方法一般用于请求，比如你在浏览器地址栏输入 <code>www.cxuanblog.com</code> 其实就是发送了一个 get 请求，它的主要特征是请求服务器返回资源，而 post 方法一般用于``</p><p><code>表单</code>的提交，相当于是把信息提交给服务器，等待服务器作出响应，get 相当于一个是 pull/拉的操作，而 post 相当于是一个 push/推的操作。</p></li><li><p>get 方法是不安全的，因为你在发送请求的过程中，你的请求参数会拼在 URL 后面，从而导致容易被攻击者窃取，对你的信息造成破坏和伪造；</p></li></ul><figure class="highlight ceylon"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs ceylon">/test/demo<span class="hljs-number">_f</span>orm.asp?name<span class="hljs-number">1</span>=<span class="hljs-keyword">value</span><span class="hljs-number">1</span>&amp;name<span class="hljs-number">2</span>=<span class="hljs-keyword">value</span><span class="hljs-number">2</span><br></code></pre></div></td></tr></table></figure><p>而 post 方法是把参数放在请求体 body 中的，这对用户来说不可见。</p><figure class="highlight dts"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dts">POST <span class="hljs-meta-keyword">/test/</span>demo_form.asp HTTP/<span class="hljs-number">1.1</span><br><span class="hljs-symbol">Host:</span> w3schools.com<br>name1=value1<span class="hljs-variable">&amp;name2</span>=value2<br></code></pre></div></td></tr></table></figure><ul><li>get 请求的 URL 有长度限制，而 post 请求会把参数和值放在消息体中，对数据长度没有要求。</li><li>get 请求会被浏览器主动 cache，而 post 不会，除非手动设置。</li><li>get 请求在浏览器反复的 <code>回退/前进</code> 操作是无害的，而 post 操作会再次提交表单请求。</li><li>get 请求在发送过程中会产生一个 TCP 数据包；post 在发送过程中会产生两个 TCP 数据包。对于 get 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；而对于 post，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。</li></ul><h1 id="什么是无状态协议，HTTP-是无状态协议吗，怎么解决"><a href="#什么是无状态协议，HTTP-是无状态协议吗，怎么解决" class="headerlink" title="什么是无状态协议，HTTP 是无状态协议吗，怎么解决"></a>什么是无状态协议，HTTP 是无状态协议吗，怎么解决</h1><p><code>无状态协议(Stateless Protocol)</code> 就是指<strong>浏览器对于事务的处理没有记忆能力</strong>。举个例子来说就是比如客户请求获得网页之后关闭浏览器，然后再次启动浏览器，登录该网站，但是服务器并不知道客户关闭了一次浏览器。</p><p>HTTP 就是一种无状态的协议，他对用户的操作没有记忆能力。可能大多数用户不相信，他可能觉得每次输入用户名和密码登陆一个网站后，下次登陆就不再重新输入用户名和密码了。这其实不是 HTTP 做的事情，起作用的是一个叫做 <code>小甜饼(Cookie)</code> 的机制。它能够让浏览器具有<code>记忆</code>能力。</p><p>如果你的浏览器允许 cookie 的话，查看方式 <strong>chrome://settings/content/cookies</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/chrome-cookies-set.png" srcset="/img/loading.gif" lazyload alt="chrome-cookies-set"></p><p>也就说明你的记忆芯片通电了…… 当你向服务端发送请求时，服务端会给你发送一个认证信息，服务器第一次接收到请求时，开辟了一块 Session 空间（创建了Session对象），同时生成一个 sessionId ，并通过响应头的 Set-Cookie：JSESSIONID=XXXXXXX 命令，向客户端发送要求设置 Cookie 的响应；客户端收到响应后，在本机客户端设置了一个 JSESSIONID=XXXXXXX 的 Cookie 信息，该 Cookie 的过期时间为浏览器会话结束；</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/cookies-procedure.png" srcset="/img/loading.gif" lazyload alt="cookies-procedure"></p><p>接下来客户端每次向同一个网站发送请求时，请求头都会带上该 Cookie信息（包含 sessionId ）， 然后，服务器通过读取请求头中的 Cookie 信息，获取名称为 JSESSIONID 的值，得到此次请求的 sessionId。这样，你的浏览器才具有了记忆能力。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/cookies-session.png" srcset="/img/loading.gif" lazyload alt="cookies-session"></p><p>还有一种方式是使用 JWT 机制，它也是能够让你的浏览器具有记忆能力的一种机制。与 Cookie 不同，JWT 是保存在客户端的信息，它广泛的应用于单点登录的情况。JWT 具有两个特点</p><ul><li>JWT 的 Cookie 信息存储在<code>客户端</code>，而不是服务端内存中。也就是说，JWT 直接本地进行验证就可以，验证完毕后，这个 Token 就会在 Session 中随请求一起发送到服务器，通过这种方式，可以节省服务器资源，并且 token 可以进行多次验证。</li><li>JWT 支持跨域认证，Cookies 只能用在<code>单个节点的域</code>或者它的<code>子域</code>中有效。如果它们尝试通过第三个节点访问，就会被禁止。使用 JWT 可以解决这个问题，使用 JWT 能够通过<code>多个节点</code>进行用户认证，也就是我们常说的<code>跨域认证</code>。</li></ul><h1 id="UDP-和-TCP-的区别"><a href="#UDP-和-TCP-的区别" class="headerlink" title="UDP 和 TCP 的区别"></a>UDP 和 TCP 的区别</h1><p>TCP 和 UDP 都位于计算机网络模型中的运输层，它们负责传输应用层产生的数据。下面我们就来聊一聊 TCP 和 UDP 分别的特征和他们的区别</p><h2 id="UDP-是什么"><a href="#UDP-是什么" class="headerlink" title="UDP 是什么"></a>UDP 是什么</h2><p>UDP 的全称是 <code>User Datagram Protocol</code>，用户数据报协议。它不需要所谓的<code>握手</code>操作，从而加快了通信速度，允许网络上的其他主机在接收方同意通信之前进行数据传输。</p><blockquote><p>数据报是与分组交换网络关联的传输单元。</p></blockquote><p>UDP 的特点主要有</p><ul><li>UDP 能够支持容忍数据包丢失的带宽密集型应用程序</li><li>UDP 具有低延迟的特点</li><li>UDP 能够发送大量的数据包</li><li>UDP 能够允许 DNS 查找，DNS 是建立在 UDP 之上的应用层协议。</li></ul><h2 id="TCP-是什么"><a href="#TCP-是什么" class="headerlink" title="TCP 是什么"></a>TCP 是什么</h2><p>TCP 的全称是<code>Transmission Control Protocol</code> ，传输控制协议。它能够帮助你确定计算机连接到 Internet 以及它们之间的数据传输。通过三次握手来建立 TCP 连接，三次握手就是用来启动和确认 TCP 连接的过程。一旦连接建立后，就可以发送数据了，当数据传输完成后，会通过关闭虚拟电路来断开连接。</p><p>TCP 的主要特点有</p><ul><li>TCP 能够确保连接的建立和数据包的发送</li><li>TCP 支持错误重传机制</li><li>TCP 支持拥塞控制，能够在网络拥堵的情况下延迟发送</li><li>TCP 能够提供错误校验和，甄别有害的数据包。</li></ul><h2 id="TCP-和-UDP-的不同"><a href="#TCP-和-UDP-的不同" class="headerlink" title="TCP 和 UDP 的不同"></a>TCP 和 UDP 的不同</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-vs-udp.png" srcset="/img/loading.gif" lazyload alt="tcp-vs-udp"></p><p>下面为你罗列了一些 TCP 和 UDP 的不同点，方便理解，方便记忆。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-vs-udp2.png" srcset="/img/loading.gif" lazyload alt="tcp-vs-udp2"></p><h2 id="TCP-三次握手和四次挥手"><a href="#TCP-三次握手和四次挥手" class="headerlink" title="TCP 三次握手和四次挥手"></a>TCP 三次握手和四次挥手</h2><p>TCP 三次握手和四次挥手也是面试题的热门考点，它们分别对应 TCP 的连接和释放过程。下面就来简单认识一下这两个过程</p><h3 id="TCP-三次握手"><a href="#TCP-三次握手" class="headerlink" title="TCP 三次握手"></a>TCP 三次握手</h3><p>在了解具体的流程前，我们需要先认识几个概念</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-signals.png" srcset="/img/loading.gif" lazyload alt="tcp-signals"></p><ul><li>SYN：它的全称是 <code>Synchronize Sequence Numbers</code>，同步序列编号。是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立 TCP 连接时，首先会发送的一个信号。客户端在接受到 SYN 消息时，就会在自己的段内生成一个随机值 X。</li><li>SYN-ACK：服务器收到 SYN 后，打开客户端连接，发送一个 SYN-ACK 作为答复。确认号设置为比接收到的序列号多一个，即 X + 1，服务器为数据包选择的序列号是另一个随机数 Y。</li><li>ACK：<code>Acknowledge character</code>, 确认字符，表示发来的数据已确认接收无误。最后，客户端将 ACK 发送给服务器。序列号被设置为所接收的确认值即 Y + 1。</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-three-hand.png" srcset="/img/loading.gif" lazyload alt="tcp-three-hand"></p><p>如果用现实生活来举例的话就是</p><p>小明 - 客户端 小红 - 服务端</p><ul><li>小明给小红打电话，接通了后，小明说<strong>喂，能听到吗</strong>，这就相当于是连接建立。</li><li>小红给小明回应，<strong>能听到，你能听到我说的话吗</strong>，这就相当于是请求响应。</li><li>小明听到小红的回应后，<strong>好的</strong>，这相当于是连接确认。在这之后小明和小红就可以通话/交换信息了。</li></ul><h3 id="TCP-四次挥手"><a href="#TCP-四次挥手" class="headerlink" title="TCP 四次挥手"></a>TCP 四次挥手</h3><p>在连接终止阶段使用四次挥手，连接的每一端都会独立的终止。下面我们来描述一下这个过程。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tcp-four-hand.png" srcset="/img/loading.gif" lazyload alt="tcp-four-hand"></p><ul><li>首先，客户端应用程序决定要终止连接(这里服务端也可以选择断开连接)。这会使客户端将 FIN 发送到服务器，并进入 <code>FIN_WAIT_1</code> 状态。当客户端处于 FIN_WAIT_1 状态时，它会等待来自服务器的 ACK 响应。</li><li>然后第二步，当服务器收到 FIN 消息时，服务器会立刻向客户端发送 ACK 确认消息。</li><li>当客户端收到服务器发送的 ACK 响应后，客户端就进入 <code>FIN_WAIT_2</code> 状态，然后等待来自服务器的 <code>FIN</code> 消息</li><li>服务器发送 ACK 确认消息后，一段时间（可以进行关闭后）会发送 FIN 消息给客户端，告知客户端可以进行关闭。</li><li>当客户端收到从服务端发送的 FIN 消息时，客户端就会由 FIN_WAIT_2 状态变为 <code>TIME_WAIT</code> 状态。处于 TIME_WAIT 状态的客户端允许重新发送 ACK 到服务器为了防止信息丢失。客户端在 TIME_WAIT 状态下花费的时间取决于它的实现，在等待一段时间后，连接关闭，客户端上所有的资源（包括端口号和缓冲区数据）都被释放。</li></ul><p>还是可以用上面那个通话的例子来进行描述</p><ul><li>小明对小红说，我所有的东西都说完了，我要挂电话了。</li><li>小红说，收到，我这边还有一些东西没说。</li><li>经过若干秒后，小红也说完了，小红说，我说完了，现在可以挂断了</li><li>小明收到消息后，又等了若干时间后，挂断了电话。</li></ul><h1 id="简述-HTTP1-0-1-1-2-0-的区别"><a href="#简述-HTTP1-0-1-1-2-0-的区别" class="headerlink" title="简述 HTTP1.0/1.1/2.0 的区别"></a>简述 HTTP1.0/1.1/2.0 的区别</h1><h2 id="HTTP-1-0"><a href="#HTTP-1-0" class="headerlink" title="HTTP 1.0"></a>HTTP 1.0</h2><p>HTTP 1.0 是在 1996 年引入的，从那时开始，它的普及率就达到了惊人的效果。</p><ul><li>HTTP 1.0 仅仅提供了最基本的认证，这时候用户名和密码还未经加密，因此很容易收到窥探。</li><li>HTTP 1.0 被设计用来使用短链接，即每次发送数据都会经过 TCP 的三次握手和四次挥手，效率比较低。</li><li>HTTP 1.0 只使用 header 中的 If-Modified-Since 和 Expires 作为缓存失效的标准。</li><li>HTTP 1.0 不支持断点续传，也就是说，每次都会传送全部的页面和数据。</li><li>HTTP 1.0 认为每台计算机只能绑定一个 IP，所以请求消息中的 URL 并没有传递主机名（hostname）。</li></ul><h2 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP 1.1"></a>HTTP 1.1</h2><p>HTTP 1.1 是 HTTP 1.0 开发三年后出现的，也就是 1999 年，它做出了以下方面的变化</p><ul><li>HTTP 1.1 使用了摘要算法来进行身份验证</li><li>HTTP 1.1 默认使用长连接，长连接就是只需一次建立就可以传输多次数据，传输完成后，只需要一次切断连接即可。长连接的连接时长可以通过请求头中的 <code>keep-alive</code> 来设置</li><li>HTTP 1.1 中新增加了 E-tag，If-Unmodified-Since, If-Match, If-None-Match 等缓存控制标头来控制缓存失效。</li><li>HTTP 1.1 支持断点续传，通过使用请求头中的 <code>Range</code> 来实现。</li><li>HTTP 1.1 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。</li></ul><h2 id="HTTP-2-0"><a href="#HTTP-2-0" class="headerlink" title="HTTP 2.0"></a>HTTP 2.0</h2><p>HTTP 2.0 是 2015 年开发出来的标准，它主要做的改变如下</p><ul><li><code>头部压缩</code>，由于 HTTP 1.1 经常会出现 <strong>User-Agent、Cookie、Accept、Server、Range</strong> 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用 <code>HPACK</code> 算法进行压缩。</li><li><code>二进制格式</code>，HTTP 2.0 使用了更加靠近 TCP/IP 的二进制格式，而抛弃了 ASCII 码，提升了解析效率</li><li><code>强化安全</code>，由于安全已经成为重中之重，所以 HTTP2.0 一般都跑在 HTTPS 上。</li><li><code>多路复用</code>，即每一个请求都是是用作连接共享。一个请求对应一个id，这样一个连接上可以有多个请求。</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http1-vs-http2.png" srcset="/img/loading.gif" lazyload alt="http1.1-vs-http2"></p><h1 id="请你说一下-HTTP-常见的请求头"><a href="#请你说一下-HTTP-常见的请求头" class="headerlink" title="请你说一下 HTTP 常见的请求头"></a>请你说一下 HTTP 常见的请求头</h1><p>这个问题比较开放，因为 HTTP 请求头有很多，这里只简单举出几个例子。</p><p>HTTP 标头会分为四种，分别是 <code>通用标头</code>、<code>实体标头</code>、<code>请求标头</code>、<code>响应标头</code>。分别介绍一下</p><h2 id="通用标头"><a href="#通用标头" class="headerlink" title="通用标头"></a>通用标头</h2><p>通用标头主要有三个，分别是 <code>Date</code>、<code>Cache-Control</code> 和 <code>Connection</code></p><p><strong>Date</strong></p><p>Date 是一个通用标头，它可以出现在请求标头和响应标头中，它的基本表示如下</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">Date: Wed, <span class="hljs-number">21</span> Oct <span class="hljs-number">2015</span> <span class="hljs-number">07</span>:<span class="hljs-number">28</span>:<span class="hljs-number">00</span> GMT<br></code></pre></div></td></tr></table></figure><p>表示的是格林威治标准时间，这个时间要比北京时间慢八个小时</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/timezone-transform.png" srcset="/img/loading.gif" lazyload alt="timezone-transform"></p><p><strong>Cache-Control</strong></p><p>Cache-Control 是一个通用标头，他可以出现在<code>请求标头</code>和<code>响应标头</code>中，Cache-Control 的种类比较多，虽然说这是一个通用标头，但是有一些特性是请求标头具有的，有一些是响应标头才有的。主要大类有 <code>可缓存性</code>、<code>阈值性</code>、 <code>重新验证并重新加载</code> 和<code>其他特性</code></p><p><strong>Connection</strong></p><p>Connection 决定当前事务（一次三次握手和四次挥手）完成后，是否会关闭网络连接。Connection 有两种，一种是<code>持久性连接</code>，即一次事务完成后不关闭网络连接</p><figure class="highlight armasm"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs armasm"><span class="hljs-symbol">Connection</span>: <span class="hljs-meta">keep</span>-alive<br></code></pre></div></td></tr></table></figure><p>另一种是<code>非持久性连接</code>，即一次事务完成后关闭网络连接</p><figure class="highlight pgsql"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs pgsql"><span class="hljs-keyword">Connection</span>: <span class="hljs-keyword">close</span><br></code></pre></div></td></tr></table></figure><p>HTTP1.1 其他通用标头如下</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http1-1-head-content.png" srcset="/img/loading.gif" lazyload alt="http1-1-head-content"></p><h2 id="实体标头"><a href="#实体标头" class="headerlink" title="实体标头"></a>实体标头</h2><p>实体标头是描述消息正文内容的 HTTP 标头。实体标头用于 HTTP 请求和响应中。头部<code>Content-Length</code>、 <code>Content-Language</code>、 <code>Content-Encoding</code> 是实体头。</p><ul><li><p>Content-Length 实体报头指示实体主体的大小，以字节为单位，发送到接收方。</p></li><li><p>Content-Language 实体报头描述了客户端或者服务端能够接受的语言。</p></li><li><p>Content-Encoding 这又是一个比较麻烦的属性，这个实体报头用来压缩媒体类型。Content-Encoding 指示对实体应用了何种编码。</p><p>常见的内容编码有这几种： <strong>gzip、compress、deflate、identity</strong> ，这个属性可以应用在请求报文和响应报文中</p></li></ul><figure class="highlight groovy"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs groovy">Accept-<span class="hljs-string">Encoding:</span> gzip, deflate <span class="hljs-comment">//请求头</span><br>Content-<span class="hljs-string">Encoding:</span> gzip  <span class="hljs-comment">//响应头</span><br></code></pre></div></td></tr></table></figure><p>下面是一些实体标头字段</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/entity-header-column.png" srcset="/img/loading.gif" lazyload alt="entity-header-column"></p><h2 id="请求标头"><a href="#请求标头" class="headerlink" title="请求标头"></a>请求标头</h2><p><strong>Host</strong></p><p>Host 请求头指明了服务器的域名（对于虚拟主机来说），以及（可选的）服务器监听的 TCP 端口号。如果没有给定端口号，会自动使用被请求服务的默认端口（比如请求一个 HTTP 的 URL 会自动使用 80 作为端口）。</p><figure class="highlight avrasm"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs avrasm"><span class="hljs-symbol">Host:</span> developer.mozilla<span class="hljs-meta">.org</span><br></code></pre></div></td></tr></table></figure><p>上面的 <code>Accpet</code>、 <code>Accept-Language</code>、<code>Accept-Encoding</code> 都是属于内容协商的请求标头。</p><p><strong>Referer</strong></p><p>HTTP Referer 属性是请求标头的一部分，当浏览器向 web 服务器发送请求的时候，一般会带上 Referer，告诉服务器该网页是从哪个页面链接过来的，服务器因此可以获得一些信息用于处理。</p><figure class="highlight groovy"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs groovy"><span class="hljs-string">Referer:</span> <span class="hljs-string">https:</span><span class="hljs-comment">//developer.mozilla.org/testpage.html</span><br></code></pre></div></td></tr></table></figure><p><strong>If-Modified-Since</strong></p><p>If-Modified-Since 通常会与 If-None-Match 搭配使用，If-Modified-Since 用于确认代理或客户端拥有的本地资源的有效性。获取资源的更新日期时间，可通过确认首部字段 <code>Last-Modified</code> 来确定。</p><p>大白话说就是如果在 <code>Last-Modified</code> 之后更新了服务器资源，那么服务器会响应 200，如果在 <code>Last-Modified</code> 之后没有更新过资源，则返回 304。</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">If-Modified-Since: Mon, <span class="hljs-number">18</span> Jul <span class="hljs-number">2016</span> <span class="hljs-number">02</span>:<span class="hljs-number">36</span>:<span class="hljs-number">04</span> GMT<br></code></pre></div></td></tr></table></figure><p><strong>If-None-Match</strong></p><p>If-None-Match HTTP 请求标头使请求成为条件请求。对于 GET 和 HEAD 方法，仅当服务器没有与给定资源匹配的 <code>ETag</code> 时，服务器才会以 200 状态发送回请求的资源。对于其他方法，仅当最终现有资源的<code>ETag</code>与列出的任何值都不匹配时，才会处理请求。</p><figure class="highlight dart"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dart">If-None-<span class="hljs-built_in">Match</span>: <span class="hljs-string">"c561c68d0ba92bbeb8b0fff2a9199f722e3a621a"</span><br></code></pre></div></td></tr></table></figure><p><strong>Accept</strong></p><p>接受请求 HTTP 标头会通告客户端其能够理解的 MIME 类型</p><p><strong>Accept-Charset</strong></p><p>accept-charset 属性规定服务器处理表单数据所接受的字符集。</p><p>常用的字符集有：UTF-8 - Unicode 字符编码 ；ISO-8859-1 - 拉丁字母表的字符编码</p><p><strong>Accept-Language</strong></p><p>首部字段 Accept-Language 用来告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级。可一次指定多种自然语言集。</p><p>请求标头我们大概就介绍这几种，后面会有一篇文章详细深挖所有的响应头的，下面是一个响应头的汇总，基于 HTTP 1.1</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http1-1-request-header.png" srcset="/img/loading.gif" lazyload alt="http1-1-request-header"></p><h2 id="响应标头"><a href="#响应标头" class="headerlink" title="响应标头"></a>响应标头</h2><p><strong>Access-Control-Allow-Origin</strong></p><p>一个返回的 HTTP 标头可能会具有 Access-Control-Allow-Origin ，<code>Access-Control-Allow-Origin</code> 指定一个来源，它告诉浏览器允许该来源进行资源访问。</p><p><strong>Keep-Alive</strong></p><p>Keep-Alive 表示的是 Connection 非持续连接的存活时间，可以进行指定。</p><p><strong>Server</strong></p><p>服务器标头包含有关原始服务器用来处理请求的软件的信息。</p><p>应该避免使用过于冗长和详细的 Server 值，因为它们可能会泄露内部实施细节，这可能会使攻击者容易地发现并利用已知的安全漏洞。例如下面这种写法</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">Server: Apache/<span class="hljs-number">2.4</span><span class="hljs-number">.1</span> (Unix)<br></code></pre></div></td></tr></table></figure><p><strong>Set-Cookie</strong></p><p>Set-Cookie 用于服务器向客户端发送 sessionID。</p><p><strong>Transfer-Encoding</strong></p><p>首部字段 Transfer-Encoding 规定了传输报文主体时采用的编码方式。</p><p>HTTP /1.1 的传输编码方式仅对分块传输编码有效。</p><p><strong>X-Frame-Options</strong></p><p>HTTP 首部字段是可以自行扩展的。所以在 Web 服务器和浏览器的应用上，会出现各种非标准的首部字段。</p><p>首部字段 <code>X-Frame-Options</code> 属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（clickjacking）攻击。</p><p>下面是一个响应头的汇总，基于 HTTP 1.1</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/http1-1-response-header.png" srcset="/img/loading.gif" lazyload alt="http1-1-response-header"></p><h1 id="地址栏输入-URL-发生了什么"><a href="#地址栏输入-URL-发生了什么" class="headerlink" title="地址栏输入 URL 发生了什么"></a>地址栏输入 URL 发生了什么</h1><p>这道题也是一道经常会考的面试题。那么下面我们就来探讨一下从你输入 URL 后到响应，都经历了哪些过程。</p><ul><li>首先，你需要在浏览器中的 URL 地址上，输入你想访问的地址，如下</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/chrome-search.png" srcset="/img/loading.gif" lazyload alt="chrome-search"></p><p>你应该访问不到的，对不对~</p><ul><li>然后，浏览器会根据你输入的 URL 地址，去查找域名是否被本地 DNS 缓存，不同浏览器对 DNS 的设置不同，如果浏览器缓存了你想访问的 URL 地址，那就直接返回 ip。如果没有缓存你的 URL 地址，浏览器就会发起系统调用来查询本机 <code>hosts</code> 文件是否有配置 ip 地址，如果找到，直接返回。如果找不到，就向网络中发起一个 DNS 查询。</li></ul><blockquote><p>首先来看一下 DNS 是啥，互联网中识别主机的方式有两种，通过<code>主机名</code>和 <code>IP 地址</code>。我们人喜欢用名字的方式进行记忆，但是通信链路中的路由却喜欢定长、有层次结构的 IP 地址。所以就需要一种能够把主机名到 IP 地址的转换服务，这种服务就是由 DNS 提供的。DNS 的全称是 <code>Domain Name System</code> 域名系统。DNS 是一种由分层的 DNS 服务器实现的分布式数据库。DNS 运行在 UDP 上，使用 53 端口。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/dns1.png" srcset="/img/loading.gif" lazyload alt=""></p></blockquote><p>DNS 是一种分层数据库，它的主要层次结构如下</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/dns2.png" srcset="/img/loading.gif" lazyload alt="dns2"></p><p>一般域名服务器的层次结构主要是以上三种，除此之外，还有另一类重要的 DNS 服务器，它是 <code>本地 DNS 服务器(local DNS server)</code>。严格来说，本地 DNS 服务器并不属于上述层次结构，但是本地 DNS 服务器又是至关重要的。每个 <code>ISP(Internet Service Provider)</code> 比如居民区的 ISP 或者一个机构的 ISP 都有一台本地 DNS 服务器。当主机和 ISP 进行连接时，该 ISP 会提供一台主机的 IP 地址，该主机会具有一台或多台其本地 DNS 服务器的 IP地址。通过访问网络连接，用户能够容易的确定 DNS 服务器的 IP地址。当主机发出 DNS 请求后，该请求被发往本地 DNS 服务器，它起着代理的作用，并将该请求转发到 DNS 服务器层次系统中。</p><p>首先，查询请求会先找到本地 DNS 服务器来查询是否包含 IP 地址，如果本地 DNS 无法查询到目标 IP 地址，就会向根域名服务器发起一个 DNS 查询。</p><blockquote><p>注意：DNS 涉及两种查询方式：一种是<code>递归查询(Recursive query)</code> ，一种是<code>迭代查询(Iteration query)</code>。《计算机网络：自顶向下方法》竟然没有给出递归查询和迭代查询的区别，找了一下网上的资料大概明白了下。<br>如果根域名服务器无法告知本地 DNS 服务器下一步需要访问哪个顶级域名服务器，就会使用递归查询；<br>如果根域名服务器能够告知 DNS 服务器下一步需要访问的顶级域名服务器，就会使用迭代查询。</p></blockquote><p>在由根域名服务器 -&gt; 顶级域名服务器 -&gt; 权威 DNS 服务器后，由权威服务器告诉本地服务器目标 IP 地址，再有本地 DNS 服务器告诉用户需要访问的 IP 地址。</p><ul><li>第三步，浏览器需要和目标服务器建立 TCP 连接，需要经过三次握手的过程，具体的握手过程请参考上面的回答。</li><li>在建立连接后，浏览器会向目标服务器发起 <code>HTTP-GET</code> 请求，包括其中的 URL，HTTP 1.1 后默认使用长连接，只需要一次握手即可多次传输数据。</li><li>如果目标服务器只是一个简单的页面，就会直接返回。但是对于某些大型网站的站点，往往不会直接返回主机名所在的页面，而会直接重定向。返回的状态码就不是 200 ，而是 301,302 以 3 开头的重定向码，浏览器在获取了重定向响应后，在响应报文中 Location 项找到重定向地址，浏览器重新第一步访问即可。</li><li>然后浏览器重新发送请求，携带新的 URL，返回状态码 200 OK，表示服务器可以响应请求，返回报文。</li></ul><h1 id="HTTPS-的工作原理"><a href="#HTTPS-的工作原理" class="headerlink" title="HTTPS 的工作原理"></a>HTTPS 的工作原理</h1><p>我们上面描述了一下 HTTP 的工作原理，下面来讲述一下 HTTPS 的工作原理。因为我们知道 HTTPS 不是一种新出现的协议，而是</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/https-compose.png" srcset="/img/loading.gif" lazyload alt="https-compose"></p><p>所以，我们探讨 HTTPS 的握手过程，其实就是 SSL/TLS 的握手过程。</p><p>TLS 旨在为 Internet 提供通信安全的加密协议。TLS 握手是启动和使用 TLS 加密的通信会话的过程。在 TLS 握手期间，Internet 中的通信双方会彼此交换信息，验证密码套件，交换会话密钥。</p><p>每当用户通过 HTTPS 导航到具体的网站并发送请求时，就会进行 TLS 握手。除此之外，每当其他任何通信使用HTTPS（包括 API 调用和在 HTTPS 上查询 DNS）时，也会发生 TLS 握手。</p><p>TLS 具体的握手过程会根据所使用的<code>密钥交换算法的类型</code>和双方支持的<code>密码套件</code>而不同。我们以<code>RSA 非对称加密</code>来讨论这个过程。整个 TLS 通信流程图如下</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-05-19/tls-procedure.png" srcset="/img/loading.gif" lazyload alt="tls-procedure"></p><ul><li>在进行通信前，首先会进行 HTTP 的三次握手，握手完成后，再进行 TLS 的握手过程</li><li>ClientHello：客户端通过向服务器发送 <code>hello</code> 消息来发起握手过程。这个消息中会夹带着客户端支持的 <code>TLS 版本号(TLS1.0 、TLS1.2、TLS1.3)</code> 、客户端支持的密码套件、以及一串 <code>客户端随机数</code>。</li><li>ServerHello：在客户端发送 hello 消息后，服务器会发送一条消息，这条消息包含了服务器的 SSL 证书、服务器选择的密码套件和服务器生成的随机数。</li><li>认证(Authentication)：客户端的证书颁发机构会认证 SSL 证书，然后发送 <code>Certificate</code> 报文，报文中包含公开密钥证书。最后服务器发送 <code>ServerHelloDone</code> 作为 <code>hello</code> 请求的响应。第一部分握手阶段结束。</li><li><code>加密阶段</code>：在第一个阶段握手完成后，客户端会发送 <code>ClientKeyExchange</code> 作为响应，这个响应中包含了一种称为 <code>The premaster secret</code> 的密钥字符串，这个字符串就是使用上面公开密钥证书进行加密的字符串。随后客户端会发送 <code>ChangeCipherSpec</code>，告诉服务端使用私钥解密这个 <code>premaster secret</code> 的字符串，然后客户端发送 <code>Finished</code> 告诉服务端自己发送完成了。</li></ul><blockquote><p>Session key 其实就是用公钥证书加密的公钥。</p></blockquote><ul><li><code>实现了安全的非对称加密</code>：然后，服务器再发送 <code>ChangeCipherSpec</code> 和 <code>Finished</code> 告诉客户端解密完成，至此实现了 RSA 的非对称加密。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 详解 TCP 连接的“三次握手”与“四次挥手” </title>
    <link href="/2020/01/19/2020-01-19-tcp-second-talk/"/>
    <url>/2020/01/19/2020-01-19-tcp-second-talk/</url>
    
    <content type="html"><![CDATA[<h1 id="TCP-connection"><a href="#TCP-connection" class="headerlink" title="TCP connection"></a>TCP connection</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/1.png" srcset="/img/loading.gif" lazyload alt="1.png"></p><p><img src="https://image.my-blog.wang/2020-01-19-tcp-second-talk/2.png" srcset="/img/loading.gif" lazyload alt="2.png"></p><p>客户端与服务器之间数据的发送和返回的过程当中需要创建一个叫TCP connection的东西；</p><p>由于TCP不存在连接的概念，只存在请求和响应，请求和响应都是数据包，它们之间都是经过由TCP创建的一个从客户端发起，服务器接收的类似连接的通道，这个连接可以一直保持，http请求是在这个连接的基础上发送的；</p><p>在一个TCP连接上是可以发送多个http请求的，不同的版本这个模式不一样。</p><p>在HTTP/1.0中这个TCP连接是在http请求创建的时候同步创建的，http请求发送到服务器端，服务器端响应了之后，这个TCP连接就关闭了；</p><p>HTTP/1.1中可以以某种方式声明这个连接一直保持，一个请求传输完之后，另一个请求可以接着传输。这样的好处是：在创建一个TCP连接的过程中需要“三次握手”的消耗，“三次握手”代表有三次网络传输。</p><p>如果TCP连接保持，第二个请求发送就没有这“三次握手”的消耗。HTTP/2中同一个TCP连接里还可以并发地传输http请求。</p><h1 id="TCP报文格式简介"><a href="#TCP报文格式简介" class="headerlink" title="TCP报文格式简介"></a>TCP报文格式简介</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/3.png" srcset="/img/loading.gif" lazyload alt=""></p><p>其中比较重要的字段有：</p><p>（1）序号（sequence number）：Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。</p><p>（2）确认号（acknowledgement number）：Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。</p><p>（3）标志位（Flags）：共6个，即URG、ACK、PSH、RST、SYN、FIN等。具体含义如下：</p><blockquote><ul><li>URG：紧急指针（urgent pointer）有效。</li><li>ACK：确认序号有效。</li><li>PSH：接收方应该尽快将这个报文交给应用层。</li><li>RST：重置连接。</li><li>SYN：发起一个新连接。</li><li>FIN：释放一个连接。</li></ul></blockquote><p>需要注意的是：</p><blockquote><p>不要将确认序号Ack与标志位中的ACK搞混了。<br>确认方Ack=发起方Seq+1，两端配对。</p></blockquote><h1 id="TCP的三次握手（Three-Way-Handshake）"><a href="#TCP的三次握手（Three-Way-Handshake）" class="headerlink" title="TCP的三次握手（Three-Way Handshake）"></a>TCP的三次握手（Three-Way Handshake）</h1><h2 id="1-“三次握手”的详解"><a href="#1-“三次握手”的详解" class="headerlink" title="1.“三次握手”的详解"></a>1.“三次握手”的详解</h2><p>所谓的三次握手即TCP连接的建立。这个连接必须是一方主动打开，另一方被动打开的。<br>以下为客户端主动发起连接的图解：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/4.png" srcset="/img/loading.gif" lazyload alt=""></p><p>握手之前主动打开连接的客户端结束CLOSED阶段，被动打开的服务器端也结束CLOSED阶段，并进入LISTEN阶段。随后开始“三次握手”：</p><p>（1）首先客户端向服务器端发送一段TCP报文，其中：</p><ul><li>标记位为SYN，表示“请求建立新连接”;</li><li>序号为Seq=X（X一般为1）；</li><li>随后客户端进入SYN-SENT阶段。</li></ul><p>（2）服务器端接收到来自客户端的TCP报文之后，结束LISTEN阶段。并返回一段TCP报文，其中：</p><ul><li>标志位为SYN和ACK，表示“确认客户端的报文Seq序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接”（即告诉客户端，服务器收到了你的数据）；</li><li>序号为Seq=y；</li><li>确认号为Ack=x+1，表示收到客户端的序号Seq并将其值加1作为自己确认号Ack的值；随后服务器端进入SYN-RCVD阶段。</li></ul><p>（3）客户端接收到来自服务器端的确认收到数据的TCP报文之后，明确了从客户端到服务器的数据传输是正常的，结束SYN-SENT阶段。并返回最后一段TCP报文。其中：</p><ul><li>标志位为ACK，表示“确认收到服务器端同意连接的信号”（即告诉服务器，我知道你收到我发的数据了）；</li><li>序号为Seq=x+1，表示收到服务器端的确认号Ack，并将其值作为自己的序号值；</li><li>确认号为Ack=y+1，表示收到服务器端序号Seq，并将其值加1作为自己的确认号Ack的值；</li><li>随后客户端进入ESTABLISHED阶段。</li></ul><p>服务器收到来自客户端的“确认收到服务器数据”的TCP报文之后，明确了从服务器到客户端的数据传输是正常的。结束SYN-SENT阶段，进入ESTABLISHED阶段。</p><p>在客户端与服务器端传输的TCP报文中，双方的确认号Ack和序号Seq的值，都是在彼此Ack和Seq值的基础上进行计算的，这样做保证了TCP报文传输的连贯性。一旦出现某一方发出的TCP报文丢失，便无法继续”握手”，以此确保了”三次握手”的顺利完成。</p><p>此后客户端和服务器端进行正常的数据传输。这就是“三次握手”的过程。</p><h2 id="2-“三次握手”的动态过程"><a href="#2-“三次握手”的动态过程" class="headerlink" title="2.“三次握手”的动态过程"></a>2.“三次握手”的动态过程</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/5.gif" srcset="/img/loading.gif" lazyload alt=""></p><h2 id="3-“三次握手”的通俗理解"><a href="#3-“三次握手”的通俗理解" class="headerlink" title="3.“三次握手”的通俗理解"></a>3.“三次握手”的通俗理解</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/6.png" srcset="/img/loading.gif" lazyload alt=""></p><p>举个栗子：把客户端比作男孩，服务器比作女孩。用他们的交往来说明“三次握手”过程：</p><p>（1）男孩喜欢女孩，于是写了一封信告诉女孩：我爱你，请和我交往吧！;写完信之后，男孩焦急地等待，因为不知道信能否顺利传达给女孩。</p><p>（2）女孩收到男孩的情书后，心花怒放，原来我们是两情相悦呀！于是给男孩写了一封回信：我收到你的情书了，也明白了你的心意，其实，我也喜欢你！我愿意和你交往！;</p><p>写完信之后，女孩也焦急地等待，因为不知道回信能否能顺利传达给男孩。</p><p>（3）男孩收到回信之后很开心，因为发出的情书女孩收到了，并且从回信中知道了女孩喜欢自己，并且愿意和自己交往。然后男孩又写了一封信告诉女孩：你的心意和信我都收到了，谢谢你，还有我爱你！</p><p>女孩收到男孩的回信之后，也很开心，因为发出的情书男孩收到了。由此男孩女孩双方都知道了彼此的心意，之后就快乐地交流起来了~~</p><p>这就是通俗版的“三次握手”，期间一共往来了三封信也就是“三次握手”，以此确认两个方向上的数据传输通道是否正常。</p><h2 id="4-为什么要进行第三次握手？"><a href="#4-为什么要进行第三次握手？" class="headerlink" title="4.为什么要进行第三次握手？"></a>4.为什么要进行第三次握手？</h2><p>为了防止服务器端开启一些无用的连接增加服务器开销以及防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。</p><p>由于网络传输是有延时的(要通过网络光纤和各种中间代理服务器)，在传输的过程中，比如客户端发起了SYN=1创建连接的请求(第一次握手)。</p><p>如果服务器端就直接创建了这个连接并返回包含SYN、ACK和Seq等内容的数据包给客户端，这个数据包因为网络传输的原因丢失了，丢失之后客户端就一直没有接收到服务器返回的数据包。</p><p>客户端可能设置了一个超时时间，时间到了就关闭了连接创建的请求。再重新发出创建连接的请求，而服务器端是不知道的，如果没有第三次握手告诉服务器端客户端收的到服务器端传输的数据的话，</p><p>服务器端是不知道客户端有没有接收到服务器端返回的信息的。</p><p>这个过程可理解为：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/7.png" srcset="/img/loading.gif" lazyload alt=""></p><p>这样没有给服务器端一个创建还是关闭连接端口的请求，服务器端的端口就一直开着，等到客户端因超时重新发出请求时，服务器就会重新开启一个端口连接。那么服务器端上没有接收到请求数据的上一个端口就一直开着，长此以往，这样的端口多了，就会造成服务器端开销的严重浪费。</p><p>还有一种情况是已经失效的客户端发出的请求信息，由于某种原因传输到了服务器端，服务器端以为是客户端发出的有效请求，接收后产生错误。</p><p>所以我们需要“第三次握手”来确认这个过程，让客户端和服务器端能够及时地察觉到因为网络等一些问题导致的连接创建失败，这样服务器端的端口就可以关闭了不用一直等待。</p><p>也可以这样理解：“第三次握手”是客户端向服务器端发送数据，这个数据就是要告诉服务器，客户端有没有收到服务器“第二次握手”时传过去的数据。若发送的这个数据是“收到了”的信息，接收后服务器就正常建立TCP连接，否则建立TCP连接失败，服务器关闭连接端口。由此减少服务器开销和接收到失效请求发生的错误。</p><h2 id="5-抓包验证"><a href="#5-抓包验证" class="headerlink" title="5.抓包验证"></a>5.抓包验证</h2><p>下面是用抓包工具抓到的一些数据包，可用来分析TCP的三次握手：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/8.png" srcset="/img/loading.gif" lazyload alt=""></p><p>图中显示的就是完整的TCP连接的”三次握手”过程。在52528 -&gt; 80中，52528是本地(客户端)端口，80是服务器的端口。80端口和52528端口之间的三次来回就是”三次握手”过程。</p><p>注意到”第一次握手”客户端发送的TCP报文中以[SYN]作为标志位，并且客户端序号Seq=0；</p><p>接下来”第二次握手”服务器返回的TCP报文中以[SYN，ACK]作为标志位；并且服务器端序号Seq=0；确认号Ack=1(“第一次握手”中客户端序号Seq的值+1);</p><p>最后”第三次握手”客户端再向服务器端发送的TCP报文中以[ACK]作为标志位；</p><p>其中客户端序号Seq=1（“第二次握手”中服务器端确认号Ack的值）；确认号Ack=1(“第二次握手”中服务器端序号Seq的值+1)。</p><p>这就完成了”三次握手”的过程，符合前面分析的结果。</p><h1 id="TCP的四次挥手（Four-Way-Wavehand）"><a href="#TCP的四次挥手（Four-Way-Wavehand）" class="headerlink" title="TCP的四次挥手（Four-Way Wavehand）"></a>TCP的四次挥手（Four-Way Wavehand）</h1><h2 id="1、前言"><a href="#1、前言" class="headerlink" title="1、前言"></a>1、前言</h2><p>对于”三次握手”我们耳熟能详，因为其相对的简单。但是，我们却不常听见“四次挥手”，就算听过也未必能详细地说明白它的具体过程。下面就为大家详尽，直观，完整地介绍“四次挥手”的过程。</p><h2 id="2、“四次挥手”的详解"><a href="#2、“四次挥手”的详解" class="headerlink" title="2、“四次挥手”的详解"></a>2、“四次挥手”的详解</h2><p>所谓的四次挥手即TCP连接的释放(解除)。连接的释放必须是一方主动释放，另一方被动释放。以下为客户端主动发起释放连接的图解：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/9.png" srcset="/img/loading.gif" lazyload alt=""></p><blockquote><p>挥手之前主动释放连接的客户端结束ESTABLISHED阶段。随后开始“四次挥手”：</p></blockquote><p>（1）首先客户端想要释放连接，向服务器端发送一段TCP报文，其中：</p><ul><li>标记位为FIN，表示“请求释放连接“；</li><li>序号为Seq=U；</li><li>随后客户端进入FIN-WAIT-1阶段，即半关闭阶段。并且停止在客户端到服务器端方向上发送数据，但是客户端仍然能接收从服务器端传输过来的数据。</li></ul><p>注意：这里不发送的是正常连接时传输的数据(非确认报文)，而不是一切数据，所以客户端仍然能发送ACK确认报文。</p><p>（2）服务器端接收到从客户端发出的TCP报文之后，确认了客户端想要释放连接，随后服务器端结束ESTABLISHED阶段，进入CLOSE-WAIT阶段（半关闭状态）并返回一段TCP报文，其中：</p><ul><li>标记位为ACK，表示“接收到客户端发送的释放连接的请求”；</li><li>序号为Seq=V；</li><li>确认号为Ack=U+1，表示是在收到客户端报文的基础上，将其序号Seq值加1作为本段报文确认号Ack的值；</li><li>随后服务器端开始准备释放服务器端到客户端方向上的连接。</li></ul><p>客户端收到从服务器端发出的TCP报文之后，确认了服务器收到了客户端发出的释放连接请求，随后客户端结束FIN-WAIT-1阶段，进入FIN-WAIT-2阶段</p><blockquote><p>前”两次挥手”既让服务器端知道了客户端想要释放连接，也让客户端知道了服务器端了解了自己想要释放连接的请求。于是，可以确认关闭客户端到服务器端方向上的连接了</p></blockquote><p>（3）服务器端自从发出ACK确认报文之后，经过CLOSED-WAIT阶段，做好了释放服务器端到客户端方向上的连接准备，再次向客户端发出一段TCP报文，其中：</p><ul><li>标记位为FIN，ACK，表示“已经准备好释放连接了”。注意：这里的ACK并不是确认收到服务器端报文的确认报文。</li><li>序号为Seq=W；</li><li>确认号为Ack=U+1；表示是在收到客户端报文的基础上，将其序号Seq值加1作为本段报文确认号Ack的值。</li></ul><p>随后服务器端结束CLOSE-WAIT阶段，进入LAST-ACK阶段。并且停止在服务器端到客户端的方向上发送数据，但是服务器端仍然能够接收从客户端传输过来的数据。</p><p>（4）客户端收到从服务器端发出的TCP报文，确认了服务器端已做好释放连接的准备，结束FIN-WAIT-2阶段，进入TIME-WAIT阶段，并向服务器端发送一段报文，其中：</p><ul><li>标记位为ACK，表示“接收到服务器准备好释放连接的信号”。</li><li>序号为Seq=U+1；表示是在收到了服务器端报文的基础上，将其确认号Ack值作为本段报文序号的值。</li><li>确认号为Ack=W+1；表示是在收到了服务器端报文的基础上，将其序号Seq值作为本段报文确认号的值。</li></ul><p>随后客户端开始在TIME-WAIT阶段等待2MSL</p><blockquote><p>为什么要客户端要等待2MSL呢？见后文。</p></blockquote><p>服务器端收到从客户端发出的TCP报文之后结束LAST-ACK阶段，进入CLOSED阶段。由此正式确认关闭服务器端到客户端方向上的连接。</p><p>客户端等待完2MSL之后，结束TIME-WAIT阶段，进入CLOSED阶段，由此完成“四次挥手”。</p><blockquote><p>后“两次挥手”既让客户端知道了服务器端准备好释放连接了，也让服务器端知道了客户端了解了自己准备好释放连接了。于是，可以确认关闭服务器端到客户端方向上的连接了，由此完成“四次挥手”。</p></blockquote><p>与“三次挥手”一样，在客户端与服务器端传输的TCP报文中，双方的确认号Ack和序号Seq的值，都是在彼此Ack和Seq值的基础上进行计算的，这样做保证了TCP报文传输的连贯性，一旦出现某一方发出的TCP报文丢失，便无法继续”挥手”，以此确保了”四次挥手”的顺利完成。</p><h2 id="3、“四次挥手”的通俗理解"><a href="#3、“四次挥手”的通俗理解" class="headerlink" title="3、“四次挥手”的通俗理解"></a>3、“四次挥手”的通俗理解</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/10.png" srcset="/img/loading.gif" lazyload alt=""></p><blockquote><p>举个栗子：把客户端比作男孩，服务器比作女孩。通过他们的分手来说明“四次挥手”过程。</p></blockquote><ul><li>“第一次挥手”：日久见人心，男孩发现女孩变成了自己讨厌的样子，忍无可忍，于是决定分手，随即写了一封信告诉女孩。</li><li>“第二次挥手”：女孩收到信之后，知道了男孩要和自己分手，怒火中烧，心中暗骂：你算什么东西，当初你可不是这个样子的！于是立马给男孩写了一封回信：分手就分手，给我点时间，我要把你的东西整理好，全部还给你！<br>男孩收到女孩的第一封信之后，明白了女孩知道自己要和她分手。随后等待女孩把自己的东西收拾好。</li><li>“第三次挥手”：过了几天，女孩把男孩送的东西都整理好了，于是再次写信给男孩：你的东西我整理好了，快把它们拿走，从此你我恩断义绝！</li><li>“第四次挥手”：男孩收到女孩第二封信之后，知道了女孩收拾好东西了，可以正式分手了，于是再次写信告诉女孩：我知道了，这就去拿回来！</li></ul><blockquote><p>这里双方都有各自的坚持。</p><ul><li>女孩自发出第二封信开始，限定一天内收不到男孩回信，就会再发一封信催促男孩来取东西！</li><li>男孩自发出第二封信开始，限定两天内没有再次收到女孩的信就认为，女孩收到了自己的第二封信；若两天内再次收到女孩的来信，就认为自己的第二封信女孩没收到，需要再写一封信，再等两天…..</li></ul></blockquote><p>倘若双方信都能正常收到，最少只用四封信就能彻底分手！这就是“四次挥手”。</p><h2 id="4-为什么“握手”是三次，“挥手”却要四次？"><a href="#4-为什么“握手”是三次，“挥手”却要四次？" class="headerlink" title="4.为什么“握手”是三次，“挥手”却要四次？"></a>4.为什么“握手”是三次，“挥手”却要四次？</h2><p>TCP建立连接时之所以只需要”三次握手”，是因为在第二次”握手”过程中，服务器端发送给客户端的TCP报文是以SYN与ACK作为标志位的。SYN是请求连接标志，表示服务器端同意建立连接；ACK是确认报文，表示告诉客户端，服务器端收到了它的请求报文。</p><p>即SYN建立连接报文与ACK确认接收报文是在同一次”握手”当中传输的，所以”三次握手”不多也不少，正好让双方明确彼此信息互通。</p><p>TCP释放连接时之所以需要“四次挥手”,是因为FIN释放连接报文与ACK确认接收报文是分别由第二次和第三次”握手”传输的。为何建立连接时一起传输，释放连接时却要分开传输？</p><blockquote><ul><li>建立连接时，被动方服务器端结束CLOSED阶段进入“握手”阶段并不需要任何准备，可以直接返回SYN和ACK报文，开始建立连接。</li><li>释放连接时，被动方服务器，突然收到主动方客户端释放连接的请求时并不能立即释放连接，因为还有必要的数据需要处理，所以服务器先返回ACK确认收到报文，经过CLOSE-WAIT阶段准备好释放连接之后，才能返回FIN释放连接报文。</li></ul></blockquote><p>所以是“三次握手”，“四次挥手”。</p><h2 id="5-为什么客户端在TIME-WAIT阶段要等2MSL"><a href="#5-为什么客户端在TIME-WAIT阶段要等2MSL" class="headerlink" title="5.为什么客户端在TIME-WAIT阶段要等2MSL?"></a>5.为什么客户端在TIME-WAIT阶段要等2MSL?</h2><p>为的是确认服务器端是否收到客户端发出的ACK确认报文</p><p>当客户端发出最后的ACK确认报文时，并不能确定服务器端能够收到该段报文。所以客户端在发送完ACK确认报文之后，会设置一个时长为2MSL的计时器。MSL指的是Maximum Segment Lifetime：一段TCP报文在传输过程中的最大生命周期。2MSL即是服务器端发出为FIN报文和客户端发出的ACK确认报文所能保持有效的最大时长。</p><p>服务器端在1MSL内没有收到客户端发出的ACK确认报文，就会再次向客户端发出FIN报文；</p><blockquote><ul><li>如果客户端在2MSL内，再次收到了来自服务器端的FIN报文，说明服务器端由于各种原因没有接收到客户端发出的ACK确认报文。客户端再次向服务器端发出ACK确认报文，计时器重置，重新开始2MSL的计时；</li><li>否则客户端在2MSL内没有再次收到来自服务器端的FIN报文，说明服务器端正常接收了ACK确认报文，客户端可以进入CLOSED阶段，完成“四次挥手”。</li></ul></blockquote><p>所以，客户端要经历时长为2SML的TIME-WAIT阶段；这也是为什么客户端比服务器端晚进入CLOSED阶段的原因</p><h2 id="6-抓包验证"><a href="#6-抓包验证" class="headerlink" title="6.抓包验证"></a>6.抓包验证</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-19/11.png" srcset="/img/loading.gif" lazyload alt=""></p><p>图中显示的就是完整的TCP连接释放的”四次挥手”过程。在 80 -&gt; 55389 中，假设80是本地(客户端)端口，55389是服务器端口。80端口与55389之间的四次来回就是”四次挥手”过程。</p><ul><li>”第一次挥手”客户端发送的FIN请求释放连接报文以[FIN，ACK]作为标志位，其中报文序号Seq=2445；确认号Ack=558；<br>注意：这里与“第三次握手”的ACK并不是表示确认的ACK报文。</li><li>”第二次挥手”服务器端返回的ACK确认报文以[ACK]作为标志位；其中报文序号Seq=558；确认号Ack=2246；</li><li>”第三次挥手”服务器端继续返回的FIN同意释放连接报文以[FIN，ACK]作为标志位；其中报文序号Seq=558；确认号Ack=2246；</li><li>”第四次挥手”客户端发出的ACK确认接收报文以[ACK]作为标志位；其中报文序号Seq=2446；确认号Ack=559。</li></ul><blockquote><p>后一次“挥手”传输报文中的序号Seq值等于前一次”握手”传输报文中的确认号Ack值；<br>后一次“挥手”传输报文中的确认号Ack值等于前一次”握手”传输报文中的序号Seq值；</p></blockquote><p>故这是连续的“四次挥手”过程，与前面的分析相符。</p>]]></content>
    
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 为什么 TCP 建立连接需要三次握手 </title>
    <link href="/2020/01/17/2020-01-17-why-tcp-third-hand/"/>
    <url>/2020/01/17/2020-01-17-why-tcp-third-hand/</url>
    
    <content type="html"><![CDATA[<blockquote><p>为什么这么设计（Why’s THE Design）是一系列关于计算机领域中程序设计决策的文章，我们在这个系列的每一篇文章中都会提出一个具体的问题并从不同的角度讨论这种设计的优缺点、对具体实现造成的影响。如果你有想要了解的问题，可以在文章下面留言。</p></blockquote><p>TCP 协议是我们几乎每天都会接触到的网络协议，绝大多数网络连接的建立都是基于 TCP 协议的，学过计算机网络或者对 TCP 协议稍有了解的人都知道 —— 使用 TCP 协议建立连接需要经过三次握手（three-way handshake）。</p><p>如果让我们简单说说 TCP 建立连接的过程，相信很多准备过面试的人都会非常了解，但是一旦想要深究『为什么 TCP 建立连接需要三次握手？』，作者相信大多数人都没有办法回答这个问题或者会给出错误的答案，这边文章就会讨论究竟为什么我们需要三次握手才能建立 TCP 连接？</p><blockquote><p>需要注意的是我们会将重点放到为什么需要 TCP 建立连接需要<strong>『三次握手』</strong>，而<em>不仅仅</em>是为什么需要<strong>『三次』</strong>握手。</p></blockquote><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>在具体分析今天的问题之前，我们首先可以了解一下最常见的错误类比，这个对 TCP 连接过程的错误比喻误导了很多人，作者在比较长的一段时间内也认为它能够很好地描述 TCP 建立连接为什么需要三次握手：</p><ol><li>你听得到吗？</li><li>我能听到，你听得到？</li><li>我也能听到；</li></ol><p>这种用类比来解释问题往往就会面临『十个类比九个错』的尴尬局面，如果别人用类比回答你的为什么，你需要仔细想一想它的类比里究竟哪里有漏洞；类比带来的解释往往只能有片面的相似性，我们永远也无法找到绝对正确的类比，它只在我们想要通俗易懂地展示事物的特性时才能发挥较大的作用，我们在文章的后面会介绍为什么这里的类比有问题，各位读者也可以带着疑问来阅读剩下的内容。</p><p>很多人尝试回答或者思考这个问题的时候其实关注点都放在了三次握手中的<strong>三次</strong>上面，这确实很重要，但是如果重新审视这个问题，我们对于『什么是连接』真的清楚？只有知道<strong>连接的定义</strong>，我们才能去尝试回答为什么 TCP 建立连接需要三次握手。</p><blockquote><p>The reliability and flow control mechanisms described above require that TCPs initialize and maintain certain status information for each data stream. The combination of this information, including sockets, sequence numbers, and window sizes, is called a connection.</p></blockquote><p>RFC 793 - Transmission Control Protocol 文档中非常清楚地定义了 TCP 中的连接是什么，我们简单总结一下：用于保证可靠性和流控制机制的信息，包括 Socket、序列号以及窗口大小叫做连接。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-17/01.png" srcset="/img/loading.gif" lazyload alt=""></p><p>所以，建立 TCP 连接就是通信的双方需要对上述的三种信息达成共识，连接中的一对 Socket 是由互联网地址标志符和端口组成的，窗口大小主要用来做流控制，最后的序列号是用来追踪通信发起方发送的数据包序号，接收方可以通过序列号向发送方确认某个数据包的成功接收。</p><p>到这里，我们将原有的问题转换成了『为什么需要通过三次握手才可以初始化 Sockets、窗口大小和初始序列号？』，那么接下来我们就开始对这个细化的问题进行分析并寻找解释。</p><h1 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h1><p>这篇文章主要会从以下几个方面介绍为什么我们需要通过三次握手才可以初始化 Sockets、窗口大小、初始序列号并建立 TCP 连接：</p><ul><li>通过三次握手才能阻止重复历史连接的初始化；</li><li>通过三次握手才能对通信双方的初始序列号进行初始化；</li><li>讨论其他次数握手建立连接的可能性；</li></ul><p>这几个论点中的第一个是 TCP 选择使用三次握手的最主要原因，其他的几个原因相比之下都是次要的原因，我们在这里对它们的讨论只是为了让整个视角更加丰富，通过多方面理解这一有趣的设计决策。</p><h2 id="历史连接"><a href="#历史连接" class="headerlink" title="历史连接"></a>历史连接</h2><p>RFC 793 - Transmission Control Protocol 其实就指出了 TCP 连接使用三次握手的首要原因 —— 为了阻止历史的重复连接初始化造成的混乱问题，防止使用 TCP 协议通信的双方建立了错误的连接。</p><blockquote><p>The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.</p></blockquote><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-17/02.png" srcset="/img/loading.gif" lazyload alt=""></p><p>想象一下这个场景，如果通信双方的通信次数只有两次，那么发送方一旦发出建立连接的请求之后它就没有办法撤回这一次请求，如果在网络状况复杂或者较差的网络中，发送方连续发送多次建立连接的请求，如果 TCP 建立连接只能通信两次，那么接收方只能选择接受或者拒绝发送方发起的请求，它并不清楚这一次请求是不是由于网络拥堵而早早过期的连接。</p><p>所以，TCP 选择使用三次握手来建立连接并在连接引入了 <code>RST</code> 这一控制消息，接收方当收到请求时会将发送方发来的 <code>SEQ+1</code> 发送回接收方，这时由发送方来判断当前连接是否是历史连接：</p><ul><li>如果当前连接是历史连接，即 <code>SEQ</code> 过期或者超时，那么发送方就会直接发送 <code>RST</code> 控制消息中止这一次连接；</li><li>如果当前连接不是历史连接，那么发送方就会发送 <code>ACK</code> 控制消息，通信双方就会成功建立连接；</li></ul><p>使用三次握手和 <code>RST</code> 控制消息将是否建立连接的最终控制权交给了发送方，因为只有发送方有足够的上下文来判断当前连接是否是错误的或者过期的，这也是 TCP 使用三次握手建立连接的最主要原因。</p><h2 id="初始序列号"><a href="#初始序列号" class="headerlink" title="初始序列号"></a>初始序列号</h2><p>另一个使用三次握手的重要的原因就是通信双方都需要获得一个用于发送信息的初始化序列号，作为一个可靠的传输层协议，TCP 需要在不稳定的网络环境中构建一个可靠的传输层，网络的不确定性可能会导致数据包的缺失和顺序颠倒等问题，常见的问题可能包括：</p><ul><li>数据包被发送方多次发送造成数据的重复；</li><li>数据包在传输的过程中被路由或者其他节点丢失；</li><li>数据包到达接收方可能无法按照发送顺序；</li></ul><p>为了解决上述这些可能存在的问题，TCP 协议要求发送方在数据包中加入『序列号』字段，有了数据包对应的序列号，我们就可以：</p><ul><li>接收方可以通过序列号对重复的数据包进行去重；</li><li>发送方会在对应数据包未被 ACK 时进行重复发送；</li><li>接收方可以根据数据包的序列号对它们进行重新排序；</li></ul><p>序列号在 TCP 连接中有着非常重要的作用，初始序列号作为 TCP 连接的一部分也需要在三次握手期间进行初始化，由于 TCP 连接通信的双方都需要获得初始序列号，所以它们其实需要向对方发送 <code>SYN</code> 控制消息并携带自己期望的初始化序列号 <code>SEQ</code>，对方在收到 <code>SYN</code> 消息之后会通过 <code>ACK</code> 控制消息以及 <code>SEQ+1</code> 来进行确认。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-17/03.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如上图所示，通信双方的两个 <code>TCP A/B</code> 分别向对方发送 <code>SYN</code> 和 <code>ACK</code> 控制消息，等待通信双方都获取到了自己期望的初始化序列号之后就可以开始通信了，由于 TCP 消息头的设计，我们可以将中间的两次通信合成一个，<code>TCP B</code> 可以向 <code>TCP A</code> 同时发送 <code>ACK</code> 和 <code>SYN</code> 控制消息，这也就帮助我们将四次通信减少至三次。</p><blockquote><p>A three way handshake is necessary because sequence numbers are not tied to a global clock in the network, and TCPs may have different mechanisms for picking the ISN’s. The receiver of the first SYN has no way of knowing whether the segment was an old delayed one or not, unless it remembers the last sequence number used on the connection (which is not always possible), and so it must ask the sender to verify this SYN. The three way handshake and the advantages of a clock-driven scheme are discussed in [3].</p></blockquote><p>除此之外，网络作为一个分布式的系统，其中并不存在一个用于计数的全局时钟，而 TCP 可以通过不同的机制来初始化序列号，作为 TCP 连接的接收方我们无法判断对方传来的初始化序列号是否过期，所以我们需要交由对方来判断，TCP 连接的发起方可以通过保存发出的序列号判断连接是否过期，如果让接收方来保存并判断序列号却是不现实的，这也再一次强化了我们在上一节中提出的观点 —— 避免历史错连接的初始化。</p><h2 id="通信次数"><a href="#通信次数" class="headerlink" title="通信次数"></a>通信次数</h2><p>当我们讨论 TCP 建立连接需要的通信次数时，我们经常会执着于为什么通信三次才可以建立连接，而不是两次或者四次；讨论使用更多的通信次数来建立连接往往是没有意义的，因为我们总可以<strong>使用更多的通信次数交换相同的信息</strong>，所以使用四次、五次或者更多次数建立连接在技术上都是完全可以实现的。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-17/04.png" srcset="/img/loading.gif" lazyload alt=""></p><p>这种增加 TCP 连接通信次数的问题往往没有讨论的必要性，我们追求的其实是用更少的通信次数（理论上的边界）完成信息的交换，也就是为什么我们在上两节中也一再强调使用『两次握手』没有办法建立 TCP 连接，使用三次握手是建立连接所需要的最小次数。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我们在这篇文章中讨论了为什么 TCP 建立连接需要经过三次握手，在具体分析这个问题之前，我们首先重新思考了 TCP 连接究竟是什么，RFC 793 - Transmission Control Protocol - IETF Tools 对 TCP 连接有着非常清楚的定义 —— 用于保证可靠性和流控制机制的数据，包括 Socket、序列号以及窗口大小。</p><p>TCP 建立连接时通过三次握手可以有效地避免历史错误连接的建立，减少通信双方不必要的资源消耗，三次握手能够帮助通信双方获取初始化序列号，它们能够保证数据包传输的不重不丢，还能保证它们的传输顺序，不会因为网络传输的问题发生混乱，到这里不使用『两次握手』和『四次握手』的原因已经非常清楚了：</p><ul><li>『两次握手』：无法避免历史错误连接的初始化，浪费接收方的资源；</li><li>『四次握手』：TCP 协议的设计可以让我们同时传递 <code>ACK</code> 和 <code>SYN</code> 两个控制信息，减少了通信次数，所以不需要使用更多的通信次数传输相同的信息；</li></ul><p>我们重新回到在文章开头提的问题，为什么使用类比解释 TCP 使用三次握手是错误的？这主要还是因为，这个类比没有解释清楚核心问题 —— 避免历史上的重复连接。到最后，我们还是来看一些比较开放的相关问题，有兴趣的读者可以仔细想一下下面的问题：</p><ul><li>除了使用序列号是否还有其他方式保证消息的不重不丢？</li><li>UDP 协议有连接的概念么，它能保证数据传输的可靠么？</li></ul><p><strong>来源：</strong>微信公众号<strong>『真没什么逻辑』</strong>，作者 Draveness</p>]]></content>
    
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 听上去超酷的 Service Mesh 到底是什么？ </title>
    <link href="/2020/01/16/2020-01-16-what-is-servicemesh/"/>
    <url>/2020/01/16/2020-01-16-what-is-servicemesh/</url>
    
    <content type="html"><![CDATA[<p>Service Mesh 作为下一代微服务技术的代名词，初出茅庐却深得人心一鸣惊人，大有一统微服务时代的趋势。那么到底什么是Service Mesh？</p><p>一言以蔽之：<strong>Service Mesh是微服务时代的TCP协议。</strong></p><p>有了这样一个感性的初步认知，我们再来看到底什么是Service Mesh。提到Service Mesh，就不得不提微服务。根据维基百科的定义：</p><blockquote><p>微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通信。</p></blockquote><p>目前业界跟微服务相关的开发平台和框架更是不胜枚举：Spring Cloud， Service Fabric，Linkerd，Envoy，Istio … 这些纷繁的产品和Sevice Mesh有什么样的关联？哪些属于Service Mesh的范畴？</p><p>为了理清这些繁复的产品和概念，我们先来了解下微服务和Service Mesh技术的历史发展脉络。了解清楚了技术的主要脉络，就能清晰的知道上述的各个平台、框架属于技术脉络中的哪个结点，其间的关系也就一目了然。</p><p>Phil Calçado的文章《Pattern: Service Mesh》详细的介绍了从开发者视角来看，服务开发模式和Service Mesh技术的演化过程，个人认为是非常经典的学习Service Mesh的资料。</p><p>这里借用文章的脉络，结合自己的理解并予以简化，试图说清楚ServiceMesh的概念和这项技术诞生的历史必然性。</p><p>时代0：开发人员想象中，不同服务间通信的方式，抽象表示如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/developer.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>时代1：原始通信时代</strong><br>然而现实远比想象的复杂，在实际情况中，通信需要底层能够传输字节码和电子信号的物理层来完成，在TCP协议出现之前，服务需要自己处理网络通信所面临的丢包、乱序、重试等一系列流控问题，因此服务实现中，除了业务逻辑外，还夹杂着对网络传输问题的处理逻辑。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time1.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>时代2：TCP时代</strong><br>为了避免每个服务都需要自己实现一套相似的网络传输处理逻辑，TCP协议出现了，它解决了网络传输中通用的流量控制问题，将技术栈下移，从服务的实现中抽离出来，成为操作系统网络层的一部分。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time2.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>时代3：第一代微服务</strong><br>在TCP出现之后，机器之间的网络通信不再是一个难题，以GFS/BigTable/MapReduce为代表的分布式系统得以蓬勃发展。这时，分布式系统特有的通信语义又出现了，如熔断策略、负载均衡、服务发现、认证和授权、quota限制、trace和监控等等，于是服务根据业务需求来实现一部分所需的通信语义。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time3.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>时代4：第二代微服务</strong><br>为了避免每个服务都需要自己实现一套分布式系统通信的语义功能，随着技术的发展，一些面向微服务架构的开发框架出现了，如Twitter的Finagle、Facebook的Proxygen以及Spring Cloud等等，这些框架实现了分布式系统通信需要的各种通用语义功能：如负载均衡和服务发现等，因此一定程度上屏蔽了这些通信细节，使得开发人员使用较少的框架代码就能开发出健壮的分布式系统。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time4.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>时代5：第一代Service Mesh</strong><br>第二代微服务模式看似完美，但开发人员很快又发现，它也存在一些本质问题：</p><ul><li>其一，虽然框架本身屏蔽了分布式系统通信的一些通用功能实现细节，但开发者却要花更多精力去掌握和管理复杂的框架本身，在实际应用中，去追踪和解决框架出现的问题也绝非易事；</li><li>其二，开发框架通常只支持一种或几种特定的语言，回过头来看文章最开始对微服务的定义，一个重要的特性就是语言无关，但那些没有框架支持的语言编写的服务，很难融入面向微服务的架构体系，想因地制宜的用多种语言实现架构体系中的不同模块也很难做到；</li><li>其三，框架以lib库的形式和服务联编，复杂项目依赖时的库版本兼容问题非常棘手，同时，框架库的升级也无法对服务透明，服务会因为和业务无关的lib库升级而被迫升级；</li></ul><p>因此以Linkerd，Envoy，Ngixmesh为代表的代理模式（边车模式）应运而生，这就是第一代Service Mesh，它将分布式服务的通信抽象为单独一层，在这一层中实现负载均衡、服务发现、认证授权、监控追踪、流量控制等等分布式系统所需要的功能，作为一个和服务对等的代理服务，和服务部署在一起，接管服务的流量，通过代理之间的通信间接完成服务之间的通信请求，这样上边所说的三个问题也迎刃而解。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time5-1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果我们从一个全局视角来看，就会得到如下部署图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time5-2.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果我们暂时略去服务，只看Service Mesh的单机组件组成的网络：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time5-3.png" srcset="/img/loading.gif" lazyload alt=""></p><p>相信现在，大家已经理解何所谓Service Mesh，也就是服务网格了。<strong>它看起来确实就像是一个由若干服务代理所组成的错综复杂的网格。</strong></p><p><strong>时代6：第二代Service Mesh</strong><br>第一代Service Mesh由一系列独立运行的单机代理服务构成，为了提供统一的上层运维入口，演化出了集中式的控制面板，所有的单机代理组件通过和控制面板交互进行网络拓扑策略的更新和单机数据的汇报。这就是以Istio为代表的第二代Service Mesh。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time6-1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>只看单机代理组件(数据面板)和控制面板的Service Mesh全局部署视图如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-16/time6-2.png" srcset="/img/loading.gif" lazyload alt=""></p><p>至此，见证了6个时代的变迁，大家一定清楚了Service Mesh技术到底是什么，以及是如何一步步演化到今天这样一个形态。</p><p>现在，我们再回过头来看Buoyant的CEO William Morgan，也就是Service Mesh这个词的发明人，对Service Mesh的定义：</p><blockquote><p>服务网格是一个基础设施层，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证请求在这些拓扑中可靠地穿梭。在实际应用当中，服务网格通常是由一系列轻量级的网络代理组成的，它们与应用程序部署在一起，但对应用程序透明。</p></blockquote><p>这个定义中，有四个关键词：</p><p><strong>基础设施层+请求在这些拓扑中可靠穿梭</strong>：这两个词加起来描述了Service Mesh的定位和功能，是不是似曾相识？没错，你一定想到了TCP；</p><p><strong>网络代理</strong>：这描述了Service Mesh的实现形态；</p><p><strong>对应用透明</strong>：这描述了Service Mesh的关键特点，正是由于这个特点，Service Mesh能够解决以Spring Cloud为代表的第二代微服务框架所面临的三个本质问题；</p><p>总结一下，Service Mesh具有如下优点：</p><ul><li>屏蔽分布式系统通信的复杂性(负载均衡、服务发现、认证授权、监控追踪、流量控制等等)，服务只用关注业务逻辑；</li><li>真正的语言无关，服务可以用任何语言编写，只需和Service Mesh通信即可；</li><li>对应用透明，Service Mesh组件可以单独升级；</li></ul><p>当然，Service Mesh目前也面临一些挑战：</p><ul><li>Service Mesh组件以代理模式计算并转发请求，一定程度上会降低通信系统性能，并增加系统资源开销；</li><li>Service Mesh组件接管了网络流量，因此服务的整体稳定性依赖于Service Mesh，同时额外引入的大量Service Mesh服务实例的运维和管理也是一个挑战；</li></ul><p>历史总是惊人的相似。为了解决端到端的字节码通信问题，TCP协议诞生，让多机通信变得简单可靠；微服务时代，Service Mesh 应运而生，屏蔽了分布式系统的诸多复杂性，让开发者可以回归业务，聚焦真正的价值。</p><p>原文链接：<a href="https://smwyzi.github.io/post/what-is-service-mesh/" target="_blank" rel="noopener">https://smwyzi.github.io/post/what-is-service-mesh/</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>ServerMesh</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 为什么执行自己的程序要在前面加./ </title>
    <link href="/2020/01/15/2020-01-15-why-exec-program/"/>
    <url>/2020/01/15/2020-01-15-why-exec-program/</url>
    
    <content type="html"><![CDATA[<p>在Linux中，我们执行内置命令时，直接输入命令名称即可，如：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ mv a b <span class="hljs-comment">#将a重命名为b</span><br></code></pre></div></td></tr></table></figure><p>而在执行自己写好的程序时，却要带上./，例如：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hello<br>hello: <span class="hljs-built_in">command</span> not found<br>$ ./hello<br>hello world<br></code></pre></div></td></tr></table></figure><p>这是为什么呢？它们有什么区别呢？</p><h1 id="shell是如何运行程序的"><a href="#shell是如何运行程序的" class="headerlink" title="shell是如何运行程序的"></a>shell是如何运行程序的</h1><p>在说明清楚问题之前，我们必须了解shell是如何运行程序的。首先我们必须要清楚的是，执行一条Linux命令，本质是在运行一个程序，如执行ls命令，它执行的是ls程序。那么在shell中输入一条命令，到底发生了什么？如果没有给出当前路径或绝对路径，它会经历哪几个查找过程？</p><h2 id="alias中查找"><a href="#alias中查找" class="headerlink" title="alias中查找"></a>alias中查找</h2><p>alias命令可用来设置命令别名，而单独输入alias可以查看到已设置的别名：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">alias</span><br><span class="hljs-built_in">alias</span> egrep=<span class="hljs-string">'egrep --color=auto'</span><br><span class="hljs-built_in">alias</span> fgrep=<span class="hljs-string">'fgrep --color=auto'</span><br><span class="hljs-built_in">alias</span> grep=<span class="hljs-string">'grep --color=auto'</span><br><span class="hljs-built_in">alias</span> l=<span class="hljs-string">'ls -CF'</span><br><span class="hljs-built_in">alias</span> la=<span class="hljs-string">'ls -A'</span><br><span class="hljs-built_in">alias</span> ll=<span class="hljs-string">'ls -alF'</span><br><span class="hljs-built_in">alias</span> ls=<span class="hljs-string">'ls --color=auto'</span><br></code></pre></div></td></tr></table></figure><p>如果这里没有找到你执行的命令，那么就会接下去查找。如果找到了，那么就会执行下去。</p><h2 id="内置命令中查找"><a href="#内置命令中查找" class="headerlink" title="内置命令中查找"></a>内置命令中查找</h2><p>不同的shell包含一些不同的内置命令，通常不需要shell到磁盘中去搜索。通过help命令可以看到有哪些内置命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">help</span><br></code></pre></div></td></tr></table></figure><p>通过type 命令可以查看命令类型：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">type</span> <span class="hljs-built_in">echo</span><br><span class="hljs-built_in">echo</span> is a shell <span class="hljs-built_in">builtin</span><br></code></pre></div></td></tr></table></figure><p>如果是内置命令，则会直接执行，否则继续查找。</p><h2 id="PATH中查找"><a href="#PATH中查找" class="headerlink" title="PATH中查找"></a>PATH中查找</h2><p>以ls为例，在shell输入ls时，首先它会从PATH环境变量中查找，PATH内容是什么呢，我们看看：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">echo</span> <span class="hljs-variable">$PATH</span><br>/usr/<span class="hljs-built_in">local</span>/sbin:/usr/<span class="hljs-built_in">local</span>/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/<span class="hljs-built_in">local</span>/games<br></code></pre></div></td></tr></table></figure><p>所以它会在这些路径下去寻找ls程序，按照路径找到的第一个ls程序就会被执行。使用whereis也能确定ls的位置：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ whereis ls<br>ls: /bin/ls /usr/share/man/man1/ls.1.g<br></code></pre></div></td></tr></table></figure><p>既然它是在bin目录下，那么我把ls从bin目录下移走是不是就找不到了呢？是的。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ mv /bin/ls /temp/ls_bak  <span class="hljs-comment">#测试完后记得改回来奥</span><br></code></pre></div></td></tr></table></figure><p>现在再来执行ls命令看看：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ ls <br>The program <span class="hljs-string">'ls'</span> is currently not installed. You can install it by typing:<br>apt install coreutils<br></code></pre></div></td></tr></table></figure><p>没错，它会提示你没有安装这个程序或者命令没有找到。</p><p>所以你现在明白为什么你第一次安装jdk或者python的时候要设置环境变量了吧？不设置的话行不行？</p><p>行。这个时候你就需要指定路径了。怎么指定路径？无非就是那么几种，相对路径，绝对路径等等。<br>比如：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">cd</span> /temp<br>$ ./ls_bak<br></code></pre></div></td></tr></table></figure><p>或者：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ /temp/ls_bak<br></code></pre></div></td></tr></table></figure><p>是不是发现和运行自己的普通程序方式没什么差别呢？</p><p>到这里，如果还没有找到你要执行的命令，那么就会报错。</p><h2 id="确定解释程序"><a href="#确定解释程序" class="headerlink" title="确定解释程序"></a>确定解释程序</h2><p>在找到程序之后呢，需要确定解释程序。什么意思呢？<br>shell通常可以执行两种程序，一种是二进制程序，一种是脚本程序。</p><p>而一旦发现要执行的程序文件是文本文件，且文本未指定解释程序，那么就会默认当成shell脚本来执行。例如，假设有test.txt内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> -e <span class="hljs-string">"hello world"</span><br></code></pre></div></td></tr></table></figure><p>赋予执行权限并执行：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ chmod +x test.txt<br>$ ./test.txt<br>hello world<br></code></pre></div></td></tr></table></figure><p>当然了，我们通常会在shell脚本程序的来头带上下面这句：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br></code></pre></div></td></tr></table></figure><p>这是告诉shell，你要用bash程序来解释执行test.txt。作为一位调皮的开发者，如果开头改成下面这样呢？</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#!/usr/bin/python</span><br></code></pre></div></td></tr></table></figure><p>再次执行之后结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ ./test.txt<br>  File <span class="hljs-string">"./test.txt"</span>, line 2<br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"hello world"</span><br>                        ^<br>SyntaxError: invalid syntax<br></code></pre></div></td></tr></table></figure><p>是的，它被当成python脚本来执行了，自然就会报错了。</p><p>那么如果是二进制程序呢？就会使用execl族函数去创建一个新的进程来运行新的程序了。</p><p>小结一下前面的内容，就是说，如果是文本程序，且开头没有指定解释程序，则按照shell脚本处理，如果指定了解释程序，则使用解释程序来解释运行；对于二进制程序，则直接创建新的进程即可。</p><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><p>前面我们也已经看到了运行方式，设置环境变量或者使用相对路径，绝对路径即可。不过对于shell脚本，你还可以像下面这样执行：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ sh test.txt<br>$ . test.txt<br></code></pre></div></td></tr></table></figure><p>即便test.txt没有执行权限，也能够正常执行。</p><p>什么？你说为什么txt也能执行？注意，Linux下的文件后缀不过是为了方便识别文件类型罢了，以.txt结尾，并不代表一定是文本。当然在这里它确实是，而且还是ASCII text executable：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ file test.txt<br>test.txt: Bourne-Again shell script, ASCII text executable<br>$ file hello<br>hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/l, <span class="hljs-keyword">for</span> GNU/Linux 2.6.32, BuildID[sha1]=8ae48f0f84912dec98511581c876aa042824efdb, not stripped<br></code></pre></div></td></tr></table></figure><h1 id="扩展一下"><a href="#扩展一下" class="headerlink" title="扩展一下"></a>扩展一下</h1><p>那么如果让我们自己的程序也能够像Linux内置命令一样输入即可被识别呢？</p><h2 id="将程序放到PATH路径下"><a href="#将程序放到PATH路径下" class="headerlink" title="将程序放到PATH路径下"></a>将程序放到PATH路径下</h2><p>第一种方法就是将我们自己的程序放到PATH中的路径中去，这样在shell输入hello时，也能找到，例如我们将其放在/bin目录下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ hello<br>hello world<br>$ whereis hello<br>hello: /bin/hello<br></code></pre></div></td></tr></table></figure><p>也就是说，如果你的程序安装在了PATH指定的路径，就需要配置PATH环境变量，在命令行输入就可以直接找到了。</p><h2 id="设置PATH环境变量"><a href="#设置PATH环境变量" class="headerlink" title="设置PATH环境变量"></a>设置PATH环境变量</h2><p>那么如果想在指定的目录能够直接运行呢？很简单，那就是添加环境变量，例如将当前路径加入到PATH中：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ PATH=<span class="hljs-variable">$PATH</span>:./   <span class="hljs-comment">#这种方式只在当前shell有效，所有shell生效可修改/etc/profile文件</span><br>$ hello<br>hello world<br></code></pre></div></td></tr></table></figure><h2 id="设置别名"><a href="#设置别名" class="headerlink" title="设置别名"></a>设置别名</h2><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">alias</span> hello=<span class="hljs-string">"/temp/hello"</span><br>$ hello<br>hello world<br></code></pre></div></td></tr></table></figure><p>以上三种方法都可以达到目的。</p><h1 id="执行顺序"><a href="#执行顺序" class="headerlink" title="执行顺序"></a>执行顺序</h1><p>那么假设我写了一个自己的printf程序，当执行printf的时候，到底执行的是哪一个呢？</p><p>实际上它的查找顺序可以可以通过type -a来查看：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">type</span> -a <span class="hljs-built_in">printf</span><br><span class="hljs-built_in">printf</span> is aliased to `<span class="hljs-built_in">printf</span> <span class="hljs-string">"hello</span><br><span class="hljs-string">"</span><span class="hljs-string">'</span><br><span class="hljs-string">printf is a shell builtin</span><br><span class="hljs-string">printf is /usr/bin/printf</span><br><span class="hljs-string">printf is ./printf</span><br></code></pre></div></td></tr></table></figure><p>这里就可以很清楚地看到查找顺序了。也就是说，如果你输入printf，它执行的是：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ <span class="hljs-built_in">printf</span><br>hello<br></code></pre></div></td></tr></table></figure><p>而如果删除别名：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-built_in">unalias</span> <span class="hljs-built_in">printf</span><br></code></pre></div></td></tr></table></figure><p>它执行的将会是内置命令printf。<br>以此类推。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>说到这里，想必标题的问题以及下面的问题你都清楚了：</p><ul><li>安装Python或者Jdk程序为什么要设置PATH环境变量？如果不设置，该如何运行？</li><li>除了./方式运行自己的程序还有什么方式？</li><li>如果让自己的程序能够像内置命令一样被识别？</li><li>如何查看文件类型？</li><li>执行一条命令，如何确定是哪里的命令被执行</li></ul><p>本文涉及命令：</p><ul><li>mv 移动/重命名</li><li>file 查看文件信息</li><li>whereis 查看命令或者手册位置</li><li>type 查看命令类别</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 分布式和集群的区别 </title>
    <link href="/2020/01/14/2020-01-14-distributed-and-cluster-difference/"/>
    <url>/2020/01/14/2020-01-14-distributed-and-cluster-difference/</url>
    
    <content type="html"><![CDATA[<p>分布式开发的时代实际上早已悄悄地成为了时代的主流，吵得很热的云计算实际上只是包装在分布式之外的商业概念，很多开发者（包括我）都想加入研究云计算这个潮流，在 Google 上通过 “云计算” 这个关键词来查询资料，查到的都是些概念性或商业性的宣传资料，其实真正需要深入的还是那个早以被人熟知的概念——分布式。</p><p>分布式可繁也可以简，最简单的分布式就是大家最常用的，在负载均衡服务器后加一堆 Web 服务器，然后在上面搞一个缓存服务器来保存临时状态，后面共享一个数据库，其实很多号称分布式专家的人也就停留于此，大致结构如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-14/1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>这种环境下真正进行分布式的只是 Web Server 而已，并且 Web Server 之间没有任何联系，所以结构和实现都非常简单。</p><p>有些情况下，对分布式的需求就没这么简单，在每个环节上都有分布式的需求，比如 Load Balance、DB、Cache 和文件等等，并且当分布式节点之间有关联时，还得考虑之间的通讯，另外，节点非常多的时候，得有监控和管理来支撑。这样看起来，分布式是一个非常庞大的体系，只不过你可以根据具体需求进行适当地裁剪。按照最完备的分布式体系来看，可以由以下模块组成：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-14/2.png" srcset="/img/loading.gif" lazyload alt=""></p><ul><li>分布式任务处理服务：负责具体的业务逻辑处理</li><li>分布式节点注册和查询：负责管理所有分布式节点的命名和物理信息的注册与查询，是节点之间联系的桥梁</li><li>分布式 DB：分布式结构化数据存取</li><li>分布式 Cache：分布式缓存数据（非持久化）存取</li><li>分布式文件：分布式文件存取</li><li>网络通信：节点之间的网络数据通信</li><li>监控管理：搜集、监控和诊断所有节点运行状态</li><li>分布式编程语言：用于分布式环境下的专有编程语言，比如 Elang、Scala</li><li>分布式算法：为解决分布式环境下一些特有问题的算法，比如解决一致性问题的 Paxos 算法</li></ul><p>因此，若要深入研究云计算和分布式，就得深入研究以上领域，而这些领域每一块的水都很深，都需要很底层的知识和技术来支撑，所以说，对于想提升技术的开发者来说，以分布式来作为切入点是非常好的，可以以此为线索，探索计算机世界的各个角落。</p><p>集群是个物理形态，分布式是个工作方式。</p><p>只要是一堆机器，就可以叫集群，他们是不是一起协作着干活，这个谁也不知道；一个程序或系统，只要运行在不同的机器上，就可以叫分布式，嗯，C/S 架构也可以叫分布式。</p><p>集群一般是物理集中、统一管理的，而分布式系统则不强调这一点。</p><p>所以，集群可能运行着一个或多个分布式系统，也可能根本没有运行分布式系统；分布式系统可能运行在一个集群上，也可能运行在不属于一个集群的多台（2 台也算多台）机器上。</p><p>布式是相对中心化而来，强调的是任务在多个物理隔离的节点上进行。中心化带来的主要问题是可靠性，若中心节点宕机则整个系统不可用，分布式除了解决部分中心化问题，也倾向于分散负载，但分布式会带来很多的其他问题，最主要的就是一致性。</p><p>集群就是逻辑上处理同一任务的机器集合，可以属于同一机房，也可分属不同的机房。分布式这个概念可以运行在某个集群里面，某个集群也可作为分布式概念的一个节点。</p><p>一句话，就是：“分头做事” 与 “一堆人” 的区别。</p><p>分布式是指将不同的业务分布在不同的地方。而集群指的是将几台服务器集中在一起，实现同一业务。</p><p>分布式中的每一个节点，都可以做集群。而集群并不一定就是分布式的。</p><p>举例：就比如新浪网，访问的人多了，他可以做一个群集，前面放一个响应服务器，后面几台服务器完成同一业务，如果有业务访问的时候，响应服务器看哪台服务器的负载不是很重，就将给哪一台去完成。</p><p>而分布式，从窄意上理解，也跟集群差不多， 但是它的组织比较松散，不像集群，有一个组织性，一台服务器垮了，其它的服务器可以顶上来。</p><p>分布式的每一个节点，都完成不同的业务，一个节点垮了，哪这个业务就不可访问了。</p><p>简单说，分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。</p><p>例如：如果一个任务由 10 个子任务组成，每个子任务单独执行需 1 小时，则在一台服务器上执行该任务需 10 小时。</p><p>采用分布式方案，提供 10 台服务器，每台服务器只负责处理一个子任务，不考虑子任务间的依赖关系，执行完这个任务只需一个小时。(这种工作模式的一个典型代表就是 Hadoop 的 Map/Reduce 分布式计算模型）</p><p>而采用集群方案，同样提供 10 台服务器，每台服务器都能独立处理这个任务。假设有 10 个任务同时到达，10 个服务器将同时工作，1 小时后，10 个任务同时完成，这样，整身来看，还是 1 小时内完成一个任务！</p><p>集群一般被分为三种类型，高可用集群如 RHCS、LifeKeeper 等，负载均衡集群如 LVS 等、高性能运算集群;分布式应该是高性能运算集群范畴内。</p><ul><li>分布式：不同的业务模块部署在不同的服务器上或者同一个业务模块分拆多个子业务，部署在不同的服务器上，解决高并发的问题</li><li>集群：同一个业务部署在多台机器上，提高系统可用性</li></ul><p>大白话讲：</p><p>小饭店原来只有一个厨师，切菜洗菜备料炒菜全干。后来客人多了，厨房一个厨师忙不过来，又请了个厨师，两个厨师都能炒一样的菜，这两个厨师的关系是集群。为了让厨师专心炒菜，把菜做到极致，又请了个配菜师负责切菜，备菜，备料，厨师和配菜师的关系是分布式，一个配菜师也忙不过来了，又请了个配菜师，两个配菜师关系是集群。</p>]]></content>
    
    
    
    <tags>
      
      <tag>架构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>为什么需要微服务网关</title>
    <link href="/2020/01/13/2020-01-13-why-microservice-gateway/"/>
    <url>/2020/01/13/2020-01-13-why-microservice-gateway/</url>
    
    <content type="html"><![CDATA[<h1 id="一、什么是服务网关"><a href="#一、什么是服务网关" class="headerlink" title="一、什么是服务网关"></a>一、什么是服务网关</h1><p>服务网关 = 路由转发 + 过滤器</p><p>1、路由转发：接收一切外界请求，转发到后端的微服务上去；</p><p>2、过滤器：在服务网关中可以完成一系列的横切功能，例如权限校验、限流以及监控等，这些都可以通过过滤器完成（其实路由转发也是通过过滤器实现的）。</p><h1 id="二、为什么需要服务网关"><a href="#二、为什么需要服务网关" class="headerlink" title="二、为什么需要服务网关"></a>二、为什么需要服务网关</h1><p>上述所说的横切功能（以权限校验为例）可以写在三个位置：</p><ul><li>每个服务自己实现一遍</li><li>写到一个公共的服务中，然后其他所有服务都依赖这个服务</li><li>写到服务网关的前置过滤器中，所有请求过来进行权限校验</li></ul><p>第一种，缺点太明显，基本不用；第二种，相较于第一点好很多，代码开发不会冗余，但是有两个缺点：</p><ul><li>由于每个服务引入了这个公共服务，那么相当于在每个服务中都引入了相同的权限校验的代码，使得每个服务的jar包大小无故增加了一些，尤其是对于使用docker镜像进行部署的场景，jar越小越好；</li><li>由于每个服务都引入了这个公共服务，那么我们后续升级这个服务可能就比较困难，而且公共服务的功能越多，升级就越难，而且假设我们改变了公共服务中的权限校验的方式，想让所有的服务都去使用新的权限校验方式，我们就需要将之前所有的服务都重新引包，编译部署。</li></ul><p>而服务网关恰好可以解决这样的问题：</p><ul><li>将权限校验的逻辑写在网关的过滤器中，后端服务不需要关注权限校验的代码，所以服务的jar包中也不会引入权限校验的逻辑，不会增加jar包大小；</li><li>如果想修改权限校验的逻辑，只需要修改网关中的权限校验过滤器即可，而不需要升级所有已存在的微服务。</li></ul><p>所以，需要服务网关！！！</p><h1 id="三、服务网关技术选型"><a href="#三、服务网关技术选型" class="headerlink" title="三、服务网关技术选型"></a>三、服务网关技术选型</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-13/1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>引入服务网关后的微服务架构如上，总体包含三部分：服务网关、open-service和service。</p><h2 id="1、总体流程"><a href="#1、总体流程" class="headerlink" title="1、总体流程"></a>1、总体流程</h2><ul><li>服务网关、open-service和service启动时注册到注册中心上去；</li><li>用户请求时直接请求网关，网关做智能路由转发（包括服务发现，负载均衡）到open-service，这其中包含权限校验、监控、限流等操作</li><li>open-service聚合内部service响应，返回给网关，网关再返回给用户</li></ul><h2 id="2、引入网关的注意点"><a href="#2、引入网关的注意点" class="headerlink" title="2、引入网关的注意点"></a>2、引入网关的注意点</h2><ul><li>增加了网关，多了一层转发（原本用户请求直接访问open-service即可），性能会下降一些（但是下降不大，通常，网关机器性能会很好，而且网关与open-service的访问通常是内网访问，速度很快）；</li><li>网关的单点问题：在整个网络调用过程中，一定会有一个单点，可能是网关、nginx、dns服务器等。防止网关单点，可以在网关层前边再挂一台nginx，nginx的性能极高，基本不会挂，这样之后，网关服务就可以不断的添加机器。但是这样一个请求就转发了两次，所以最好的方式是网关单点服务部署在一台牛逼的机器上（通过压测来估算机器的配置），而且nginx与zuul的性能比较，根据国外的一个哥们儿做的实验来看，其实相差不大，zuul是netflix开源的一个用来做网关的开源框架；</li><li>网关要尽量轻。</li></ul><h2 id="3、服务网关基本功能"><a href="#3、服务网关基本功能" class="headerlink" title="3、服务网关基本功能"></a>3、服务网关基本功能</h2><ul><li><p>智能路由：接收</p><p>外部一切请求，并转发到后端的对外服务open-service上去；</p></li><li><p>注意：我们只转发外部请求，服务之间的请求不走网关，这就表示全链路追踪、内部服务API监控、内部服务之间调用的容错、智能路由不能在网关完成；当然，也可以将所有的服务调用都走网关，那么几乎所有的功能都可以集成到网关中，但是这样的话，网关的压力会很大，不堪重负。</p></li><li><p>权限校验：只校验用户向open-service服务的请求，不校验服务内部的请求。服务内部的请求有必要校验吗？</p></li><li><p>API监控：只监控经过网关的请求，以及网关本身的一些性能指标（例如，gc等）；</p></li><li><p>限流：与监控配合，进行限流操作；</p></li><li><p>API日志统一收集：类似于一个aspect切面，记录接口的进入和出去时的相关日志</p></li><li><p>。。。后续补充</p></li></ul><p>上述功能是网关的基本功能，网关还可以实现以下功能：</p><ul><li>A|B测试：A|B测试时一块比较大的东西，包含后台实验配置、数据埋点（看转化率）以及分流引擎，在服务网关中，可以实现分流引擎，但是实际上分流引擎会调用内部服务，所以如果是按照上图的架构，分流引擎最好做在open-service中，不要做在服务网关中。</li><li>。。。后续补充</li></ul><h2 id="4、技术选型"><a href="#4、技术选型" class="headerlink" title="4、技术选型"></a>4、技术选型</h2><p>笔者准备自建一个轻量级的服务网关，技术选型如下：</p><ul><li>开发语言：java + groovy，groovy的好处是网关服务不需要重启就可以动态的添加filter来实现一些功能；</li><li>微服务基础框架：springboot；</li><li>网关基础组件：netflix zuul；</li><li>服务注册中心：consul；</li><li>权限校验：jwt；</li><li>API监控：prometheus + grafana；</li><li>API统一日志收集：logback + ELK；</li><li>压力测试：Jmeter；</li><li>。。。后续补充</li></ul><p>在后续的介绍中，会逐渐介绍各个知识点，并完成一个轻量级的服务网关！！！</p>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 迄今为止把同步/异步/阻塞/非阻塞/BIO/NIO/AIO讲的这么清楚的好文章 </title>
    <link href="/2020/01/10/2020-01-10-sync-async/"/>
    <url>/2020/01/10/2020-01-10-sync-async/</url>
    
    <content type="html"><![CDATA[<p><strong>常规的误区</strong></p><p>假设有一个展示用户详情的需求，分两步，先调用一个HTTP接口拿到详情数据，然后使用适合的视图展示详情数据。</p><p>如果网速很慢，代码发起一个HTTP请求后，就卡住不动了，直到十几秒后才拿到HTTP响应，然后继续往下执行。</p><p>这个时候你问别人，刚刚代码发起的这个请求是不是一个同步请求，对方一定回答是。这是对的，它确实是。</p><p>但你要问它为什么是呢？对方一定是这样回答的，“因为发起请求后，代码就卡住不动了，直到拿到响应后才可以继续往下执行”。</p><p>我相信很多人也都是这样认为的，其实这是不对的，是把因果关系搞反了：</p><p>不是因为代码卡住不动了才叫同步请求，而是因为它是同步请求所以代码才卡住不动了。</p><p>至于为什么能卡住不动，这是由操作系统和CPU决定的：</p><p>因为内核空间里的对应函数会卡住不动，造成用户空间发起的系统调用卡住不动，继而使程序里的用户代码卡住不动了。</p><p>因此卡住不动了只是同步请求的一个副作用，并不能用它来定义同步请求，那该如何定义呢？</p><p><strong>同步和异步</strong></p><p>所谓同步，指的是协同步调。既然叫协同，所以至少要有2个以上的事物存在。协同的结果就是：</p><p>多个事物不能同时进行，必须一个一个的来，上一个事物结束后，下一个事物才开始。</p><p>那当一个事物正在进行时，其它事物都在干嘛呢？</p><p>严格来讲这个并没有要求，但一般都是处于一种“等待”的状态，因为通常后面事物的正常进行都需要依赖前面事物的结果或前面事物正在使用的资源。</p><p>因此，可以认为，同步更希望关注的是从宏观整体来看，多个事物是一种逐个逐个的串行化关系，绝对不会出现交叉的情况。</p><p>所以，自然也不太会去关注某个瞬间某个具体事物是处于一个什么状态。</p><p>把这个理论应用的出神入化的非“排队”莫属。凡是在资源少需求多的场景下都会用到排队。</p><p>比如排队买火车票这件事：</p><p>其实售票大厅更在意的是旅客一个一个的到窗口去买票，因为一次只能卖一张票。</p><p>即使大家一窝蜂的都围上去，还是一次只能卖一张票，何必呢？挤在一起又不安全。</p><p>只是有些人素质太差，非要往上挤，售票大厅迫不得已，采用排队这种形式来达到自己的目的，即一个一个的买票。</p><p>至于每个旅客排队时的状态，是看手机呀还是说话呀，根本不用去在意。</p><p>除了这种由于资源导致的同步外，还存在一种由于逻辑上的先后顺序导致的同步。</p><p>比如，先更新代码，然后再编译，接着再打包。这些操作由于后一步要使用上一步的结果，所以只能按照这种顺序一个一个的执行。</p><p>关于同步还需知道两个小的点：</p><p>一是范围，并不需要在全局范围内都去同步，只需要在某些关键的点执行同步即可。</p><p>比如食堂只有一个卖饭窗口，肯定是同步的，一个人买完，下一个人再买。但吃饭的时候也是一个人吃完，下一个人才开始吃吗？当然不是啦。</p><p>二是粒度，并不是只有大粒度的事物才有同步，小粒度的事物也有同步。</p><p>只不过小粒度的事物同步通常是天然支持的，而大粒度的事物同步往往需要手工处理。</p><p>比如两个线程的同步就需要手工处理，但一个线程里的两个语句天然就是同步的。</p><p>所谓异步，就是步调各异。既然是各异，那就是都不相同。所以结果就是：</p><p>多个事物可以你进行你的、我进行我的，谁都不用管谁，所有的事物都在同时进行中。</p><p>一言以蔽之，同步就是多个事物不能同时开工，异步就是多个事物可以同时开工。</p><p>注：一定要去体会“多个事物”，多个线程是多个事物，多个方法是多个事物，多个语句是多个事物，多个CPU指令是多个事物。等等等等。</p><p><strong>阻塞和非阻塞</strong></p><p>所谓阻塞，指的是阻碍堵塞。它的本意可以理解为由于遇到了障碍而造成的动弹不得。</p><p>所谓非阻塞，自然是和阻塞相对，可以理解为由于没有遇到障碍而继续畅通无阻。</p><p>对这两个词最好的诠释就是，当今中国一大交通难题，堵车：</p><p>汽车可以正常通行时，就是非阻塞。一旦堵上了，全部趴窝，一动不动，就是阻塞。</p><p>因此阻塞关注的是不能动，非阻塞关注的是可以动。</p><p>不能动的结果就是只能等待，可以动的结果就是继续前行。</p><p>因此和阻塞搭配的词一定是等待，和非阻塞搭配的词一定是进行。</p><p>回到程序里，阻塞同样意味着停下来等待，非阻塞表明可以继续向下执行。</p><p><strong>阻塞和等待</strong></p><p>等待只是阻塞的一个副作用而已，表明随着时间的流逝，没有任何有意义的事物发生或进行。</p><p>阻塞的真正含义是你关心的事物由于某些原因无法继续进行，因此让你等待。但没必要干等，你可以做一些其它无关的事物，因为这并不影响你对相关事物的等待。</p><p>在堵车时，你可以干等。也可以玩手机、和别人聊天，或者打牌、甚至先去吃饭都行。因为这些事物并不影响你对堵车的等待。不过你的车必须呆在原地。</p><p>在计算机里，是没有人这么灵活的，一般在阻塞时，选在干等，因为这最容易实现，只需要挂起线程，让出CPU即可。在条件满足时，会重新调度该线程。</p><p><strong>两两组合</strong></p><p>所谓同步/异步，关注的是能不能同时开工。</p><p>所谓阻塞/非阻塞，关注的是能不能动。</p><p>通过推理进行组合：</p><p>同步阻塞，不能同时开工，也不能动。只有一条小道，一次只能过一辆车，可悲的是还TMD的堵上了。</p><p>同步非阻塞，不能同时开工，但可以动。只有一条小道，一次只能过一辆车，幸运的是可以正常通行。</p><p>异步阻塞，可以同时开工，但不可以动。有多条路，每条路都可以跑车，可气的是全都TMD的堵上了。</p><p>异步非阻塞，可以工时开工，也可以动。有多条路，每条路都可以跑车，很爽的是全都可以正常通行。</p><p>是不是很容易理解啊。其实它们的关注点是不同的，只要搞明白了这点，组合起来也不是事儿。</p><p>回到程序里，把它们和线程关联起来：</p><p>同步阻塞，相当于一个线程在等待。</p><p>同步非阻塞，相当于一个线程在正常运行。</p><p>异步阻塞，相当于多个线程都在等待。</p><p>异步非阻塞，相当于多个线程都在正常运行。</p><p><strong>I/O</strong></p><p>IO指的就是读入/写出数据的过程，和<strong>等待</strong>读入/写出数据的过程。一旦拿到数据后就变成了数据操作了，就不是IO了。</p><p>拿网络IO来说，等待的过程就是数据从网络到网卡再到内核空间。读写的过程就是内核空间和用户空间的相互拷贝。</p><p>所以IO就包括两个过程，一个是等待数据的过程，一个是读写（拷贝）数据的过程。而且还要明白，一定<strong>不</strong>能包括操作数据的过程。</p><p><strong>阻塞IO和非阻塞IO</strong></p><p>应用程序都是运行在用户空间的，所以它们能操作的数据也都在用户空间。按照这样子来理解，只要数据没有到达用户空间，用户线程就操作不了。</p><p>如果此时用户线程已经参与，那它一定会被阻塞在IO上。这就是常说的阻塞IO。用户线程被阻塞在等待数据上或拷贝数据上。</p><p>非阻塞IO就是用户线程不参与以上两个过程，即数据已经拷贝到用户空间后，才去通知用户线程，一上来就可以直接操作数据了。</p><p>用户线程没有因为IO的事情出现阻塞，这就是常说的非阻塞IO。</p><p><strong>同步IO和同步阻塞IO</strong></p><p>按照上文中对同步的理解，同步IO是指发起IO请求后，必须拿到IO的数据才可以继续执行。</p><p>按照程序的表现形式又分为两种：</p><p>在等待数据的过程中，和拷贝数据的过程中，线程都在阻塞，这就是同步阻塞IO。</p><p>在等待数据的过程中，线程采用死循环式轮询，在拷贝数据的过程中，线程在阻塞，这其实还是同步阻塞IO。</p><p>网上很多文章把第二种归为同步非阻塞IO，这肯定是<strong>错误</strong>的，它一定是阻塞IO，因为拷贝数据的过程，线程是阻塞的。</p><p>严格来讲，在IO的概念上，同步和非阻塞是不可能搭配的，因为它们是一对相悖的概念。</p><p>同步IO意味着必须拿到IO的数据，才可以继续执行。因为后续操作依赖IO数据，所以它必须是阻塞的。</p><p>非阻塞IO意味着发起IO请求后，可以继续往下执行。说明后续执行不依赖于IO数据，所以它肯定不是同步的。</p><p>因此，在IO上，同步和非阻塞是互斥的，所以不存在同步非阻塞IO。但同步非阻塞是存在的，那不叫IO，叫操作数据了。</p><p>所以，同步IO一定是阻塞IO，同步IO也就是同步阻塞IO。</p><p><strong>异步IO和异步阻塞/非阻塞IO</strong></p><p>按照上文中对异步的理解，异步IO是指发起IO请求后，不用拿到IO的数据就可以继续执行。</p><p>用户线程的继续执行，和操作系统准备IO数据的过程是同时进行的，因此才叫做异步IO。</p><p>按照IO数据的两个过程，又可以分为两种：</p><p>在等待数据的过程中，用户线程继续执行，在拷贝数据的过程中，线程在阻塞，这就是异步阻塞IO。</p><p>在等待数据的过程中，和拷贝数据的过程中，用户线程都在继续执行，这就是异步非阻塞IO。</p><p>第一种情况是，用户线程没有参与数据等待的过程，所以它是异步的。但用户线程参与了数据拷贝的过程，所以它又是阻塞的。合起来就是异步阻塞IO。</p><p>第二种情况是，用户线程既没有参与等待过程也没有参与拷贝过程，所以它是异步的。当它接到通知时，数据已经准备好了，它没有因为IO数据而阻塞过，所以它又是非阻塞的。合起来就是异步非阻塞IO。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Network</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 阿里云terway源码分析 </title>
    <link href="/2020/01/09/2020-01-09-aliyun-terway/"/>
    <url>/2020/01/09/2020-01-09-aliyun-terway/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>随着公司业务的发展，底层容器环境也需要在各个区域部署，实现多云架构， 使用各个云厂商提供的CNI插件是k8s多云环境下网络架构的一种高效的解法。我们在阿里云的方案中，便用到了阿里云提供的CNI插件terway。terway所提供的VPC互通的网络方案，方便对接已有的基础设施，同时没有overlay网络封包解包的性能损耗，简单易用，出现网络问题方便诊断。本文对该插件做简单的代码分析，理解其原理，以便后期诊断问题和维护。</p><h1 id="功能划分"><a href="#功能划分" class="headerlink" title="功能划分"></a>功能划分</h1><p>阿里云开源的terway代码有三部分组成:</p><ul><li>CNI plugin： 即CNI插件，实现<code>ADD、DEL、VERSION</code>三个接口来供kubelet调用， 该插件将kubelet传递的参数进行简单处理后，会通过gRPC调用terwayBackendServer来实现具体的逻辑，例如申请网络设备等。同步调用terwayBackendServer将网络设备分配完毕之后，会通过<code>ipvlanDriver.Driver</code>进行pod sandbox network namespace的<code>Setup</code>操作，同时还会通过TC进行流控。该插件会通过daemonSet中initContainer安装到所有node上。</li><li>backend server： terway中主要的执行逻辑， 会进行IPAM管理，并申请对应的网络设备， 这部分是本次着重分析的对象。该程序以daemonSet的方式运行在每个节点上。</li><li>networkPolicy： 该部分是借助calico felix实现， 完全与上面两部分解耦。我们看到terway创建的网络设备是以cali为前缀的， 其实就是为了兼容calico的schema。</li></ul><h1 id="TerwayBackendServer"><a href="#TerwayBackendServer" class="headerlink" title="TerwayBackendServer"></a>TerwayBackendServer</h1><p>在terway的main函数中会启动gRPC server监听请求，同时会创建一个<code>TerwayBackendServer</code>， TerwayBackendServer封装全部操作逻辑，在<code>newNetworkService</code>函数中会依次初始化各个子模块实例，具体包括：</p><ul><li>ECS client　用来操作ECS client, 所有创建删除更新操作最后都会通过该client进行处理，简单封装了一层alicloud的SKD</li><li>kubernetes pod 管理模块，用来同步kubernetes pod信息</li><li>resouceDB 用来存储状态信息，便于重启等操作后恢复状态</li><li>resourceManager 管理资源分配的实例，terway会根据不同的配置生成不同的resourceManager，此处我们使用的是<code>ENIMultiIP</code>这种模式，对应的就是<code>newENIIPResourceManager</code></li></ul><p>ENIMultiIP模式会申请阿里云弹性网卡并配置多个辅助VPC的IP地址，将这些辅助IP地址映射和分配到Pod中，这些Pod的网段和宿主机网段是一致的，能够实现VPC网络互通。</p><p>整个架构如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-09/terway.png" srcset="/img/loading.gif" lazyload alt="twrway.png"></p><p>首先我们理解一下kubernetes pod管理模块，该模块用于获取kubernetes pod状态。terway为了支持一些高级的特性，例如流控等，有一些信息无法通过CNI调用传递过来，　还是得去kubernetes中去查询这些信息。此外CNI调用在一些异常情况下可能无法准确回调CNI插件， 例如用户直接<code>kubectl delete pod --force --graceperiod=0</code>，此时就需要kubernetes作为唯一的<code>single source of truth</code>， 保证最后网络设备在pod删除时肯定能够被释放掉。 它内部主要的方法就是<code>GetPod</code>与<code>GetLocalPod</code>。<code>GetPod</code>方法会请求apiserver返回pod信息，如果该pod已经在apiserver中删除，就会从本地的storage中获取。该storage是用boltDB做为底层存储的一个本地文件，每个被处理过的pod都会在该storage中保存一份信息，且该pod副本并不会随着apiserver中pod的删除而删除，这样后面程序如果需要该pod信息可以从该storage中获取。同时该pod副本会通过异步清理goroutine在pod删除一小时后删除。<code>GetLocalPod</code>是从apiserver获取该node上所有的pod信息，该过程是调用kubernetes最多的地方，目前两个清理goroutine会每5min调用一次，调用量相对较小，对apiserver的负载影响不大。该模块也会在本地DB里缓存一份数据，便于在kubernetes pod删除后还可以拿到用户信息。</p><p>其次是resourceDB模块，该模块是用来持久化状态信息，该DB中记录了当前已分配的pod及其网络设备(networkResource)信息。每次请求/释放设备都会更新该DB。程序重新启动初始化完成之后，也会从resouceDB中恢复上次运行的数据。<br>除了基本的分配删除操作会更新该DB, terway还启动异步goroutine定期清理，保证异常情况下的最终一致性，该goroutine会从apiserve中获取所有pod信息和当前DB中的信息进行对比，如果对应的pod已经删除会先释放对应的网络设备，然后从DB中删除该记录。同时延迟清理可以实现Statefulset的Pod在更新过程中IP地址保持不变，</p><p>最重要的是<code>resouceManager</code>模块，该iterface封装了具体网络设备的操作，如下所示:</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// ResourceManager Allocate/Release/Pool/Stick/GC pod resource</span><br><span class="hljs-comment">// managed pod and resource relationship</span><br>type ResourceManager <span class="hljs-class"><span class="hljs-keyword">interface</span> </span>&#123;<br>    Allocate(context *networkContext, prefer string) (types.NetworkResource, error)<br>    Release(context *networkContext, resID string) error<br>    GarbageCollection(inUseResList map[string]<span class="hljs-class"><span class="hljs-keyword">interface</span></span>&#123;&#125;, expireResList map[string]<span class="hljs-class"><span class="hljs-keyword">interface</span></span>&#123;&#125;) error<br>&#125;<br></code></pre></div></td></tr></table></figure><p>从其中三个method可以很明显的看出可以执行的的动作，每次CNI插件调用backendServer时， 就会调用ResoueceManager进行具体的分配释放操作。对于<code>ENIMultiIP</code>这种模式来说，具体的实现类是<code>eniIPResourceManager</code>：</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java">type eniIPResourceManager struct &#123;<br>    pool pool.ObjectPool<br>&#125;<br></code></pre></div></td></tr></table></figure><p>其中只有pool一个成员函数，具体的实现类型是<code>simpleObjectPool</code>, 该pool维护了当前所有的ENI信息。当resouceManager进行分配释放网络设备的时候其实是从该pool中进行存取即可：</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java">func (m *eniIPResourceManager) Allocate(ctx *networkContext, prefer string) (types.NetworkResource, error) &#123;<br>    <span class="hljs-keyword">return</span> m.pool.Acquire(ctx, prefer)<br>&#125;<br><br>func (m *eniIPResourceManager) Release(context *networkContext, resID string) error &#123;<br>    <span class="hljs-keyword">if</span> context != nil &amp;&amp; context.pod != nil &#123;<br>        <span class="hljs-keyword">return</span> m.pool.ReleaseWithReverse(resID, context.pod.IPStickTime)<br>    &#125;<br>    <span class="hljs-keyword">return</span> m.pool.Release(resID)<br>&#125;<br><br>func (m *eniIPResourceManager) GarbageCollection(inUseSet map[string]<span class="hljs-class"><span class="hljs-keyword">interface</span></span>&#123;&#125;, expireResSet map[string]<span class="hljs-class"><span class="hljs-keyword">interface</span></span>&#123;&#125;) error &#123;<br>    <span class="hljs-keyword">for</span> expireRes := range expireResSet &#123;<br>        <span class="hljs-keyword">if</span> err := m.pool.Stat(expireRes); err == nil &#123;<br>            err = m.Release(nil, expireRes)<br>            <span class="hljs-keyword">if</span> err != nil &#123;<br>                <span class="hljs-keyword">return</span> err<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> nil<br>&#125;<br></code></pre></div></td></tr></table></figure><p>由上述代码可见，resouceManager实际操作的都是simpleObjectPool这个对象。　我们看看这个pool到底做了那些操作。首先初始化该pool:</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// NewSimpleObjectPool return an object pool implement</span><br><span class="hljs-function">func <span class="hljs-title">NewSimpleObjectPool</span><span class="hljs-params">(cfg Config)</span> <span class="hljs-params">(ObjectPool, error)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> cfg.MinIdle &gt; cfg.MaxIdle &#123;<br>        <span class="hljs-keyword">return</span> nil, ErrInvalidArguments<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> cfg.MaxIdle &gt; cfg.Capacity &#123;<br>        <span class="hljs-keyword">return</span> nil, ErrInvalidArguments<br>    &#125;<br><br>    pool := &amp;simpleObjectPool&#123;<br>        factory:  cfg.Factory,<br>        inuse:    make(map[string]types.NetworkResource),<br>        idle:     newPriorityQueue(),<br>        maxIdle:  cfg.MaxIdle,<br>        minIdle:  cfg.MinIdle,<br>        capacity: cfg.Capacity,<br>        notifyCh: make(chan <span class="hljs-class"><span class="hljs-keyword">interface</span></span>&#123;&#125;),<br>        tokenCh:  make(chan struct&#123;&#125;, cfg.Capacity),<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> cfg.Initializer != nil &#123;<br>        <span class="hljs-keyword">if</span> err := cfg.Initializer(pool); err != nil &#123;<br>            <span class="hljs-keyword">return</span> nil, err<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> err := pool.preload(); err != nil &#123;<br>        <span class="hljs-keyword">return</span> nil, err<br>    &#125;<br><br>    log.Infof(<span class="hljs-string">"pool initial state, capacity %d, maxIdle: %d, minIdle %d, idle: %s, inuse: %s"</span>,<br>        pool.capacity,<br>        pool.maxIdle,<br>        pool.minIdle,<br>        queueKeys(pool.idle),<br>        mapKeys(pool.inuse))<br><br>    go pool.startCheckIdleTicker()<br><br>    <span class="hljs-keyword">return</span> pool, nil<br>&#125;<br></code></pre></div></td></tr></table></figure><p>可以看到在创建的时候会根据传入的config依次初始化各成员变量，　其中</p><ul><li>factory 成员用来分配网络设备，会调用ECS SDK进行分配资源，分配之后将信息存储在pool之中，具体的实现是<code>eniIPFactory</code>。</li><li>inuse 存储了当前所有正在使用的networkResource</li><li>idle 存储了当前所有空闲的networkResource, 即已经通过factory分配好，但是还未被某个pod实际使用。如果某个network resouce不再使用，也会归还到该idle之中。　通过这种方式，pool具备一定的缓充能力，避免频繁调用factory进行分配释放。idle为<code>priorityQeueu</code>类型，即所有空闲的networkResouce通过优先级队列排列，优先级队列的比较函数会比较<code>reverse</code>字段，<code>reverse</code>默认是入队时间，也就是该networkResouce的释放的时间，这样做能够尽量使一个IP释放之后不会被立马被复用。<code>reverse</code>字段对于一些statueSet的resouce也会进行一些特殊处理，因为statufulSet是有状态workload, 对于IP的释放也会特殊处理，保证其尽可能复用。</li><li>maxIdle, minIdle 分别表示上述idle队列中允许的最大和最小个数，　minIdle是为了提供有一定的缓冲能力，但该值并不保证，最大是为了防止缓存过多，如果空闲的networkResouce太多没有被使用就会释放一部分，IP地址不止是节点级别的资源，也会占用整个vpc/vswitch/安全组的资源，太多的空闲可能会导致其他节点或者云产品分配不出IP。</li><li>capacity 是该pool的容量，最大能分配的networkResouce的个数。该值可以自己指定， 但如果超过该ECS能允许的最大个数就会被设置成允许的最大个数。</li><li>tokenCh 是个buffered channel, 容量大小即为上面capacity的值，被做token bucket。 pool初始化的时候会将其中放满元素，后面运行过程中中，只要能从该channel中读取到元素则意味着该pool还没有满。每次调用factory申请networkResouce之前会从该channel中读取一个元素，　每次调用factory释放networkDevice会从该channel中放入一个元素。</li></ul><p>成员变量初始化完成之后会调用<code>Initializer</code>, 该函数会回调一个闭包函数，定义在<code>newENIIPResourceManager</code>中： 当程序启动时，resouceManager通过读取存储在本地磁盘也就是resouceDB中的信息获取当前正在使用的networkResouce，然后通过ecs获取当前所有eni设备及其ip, 依次遍历所有ip判断当前是否在使用，分别来初始化inuse和idle。这样可以保证程序重启之后可以重构内存中的pool数据信息。</p><p>然后会调用<code>preload</code>,该函数确保pool(idle)中有minIdle个空闲元素, 防止启动时大量调用factory。<br>最后会进行<code>go pool.startCheckIdleTicker()</code>　异步来goroutine中调用<code>checkIdle</code>定期查询pool(idle)中的元素是否超过maxIdle个元素，　如果超过则会调用factory进行释放。同时每次调用factory也会通过<code>notifyCh</code>来通知该goroutine执行检查操作。</p><p>pool结构初始化完成之后，resouceManager中所有对于networkResource的操作都会通过该pool进行，该pool在必要条件下再调用factory进行分配释放。</p><p>factory的具体实现是<code>eniIPFactory</code>, 用来调用ecs SDK进行申请释放eniIP, 并维护对应的数据结构。不同于直接使用eni设备，<code>ENIMultiIP</code>模式会为每个eni设备会有多个eniIP。eni设备是通过<code>ENI</code>结构体标识， eniIP通过<code>ENIIP</code>结构体标识。terway会为每个<code>ENI</code>创建一个goroutine, 该ENI上所有eniIP的分配释放都会在goroutine内进行，factory通过channel与该groutine通信， 每个goroutine对应一个接受channel <code>ipBacklog</code>，用于传递分配请求到该goroutine。 每次factory 需要创建(eniIPFactory.Create)一个eniIP时， 会一次遍历当前已经存在的<code>ENI</code>设备，如果该设备还有空闲的eniIP，就会通过该<code>ipBacklog</code> channel发送一个元素到该ENI设备的goroutine进行请求分配， 当goroutine将eniIP分配完毕之后通过factory 的<code>resultChan</code>通知factory, 这样factory就成功完成一次分配。 如果所有的ENI的eniIP都分配完毕，会首先创建ENI设备及其对应goroutine。因为每个ENI设备会有个主IP， 所以首次分配ENI不需要发送请求到<code>ipBacklog</code>, 直接将该主ip返回即可。对应的释放(Dispose)就是先释放eniIP， 等到只剩最后一个eniIP(主eniIP)时会释放整个ENI设备。对于所有ecs调用都会通过buffer channel进行流控，防止瞬间调用过大。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总之，terway的整个实现，逻辑比较清晰，并且扩展性也较高。后期，可以比较方便地在此基础上做一些定制和运维支持，从而很好地融入公司的基础架构设施。</p>]]></content>
    
    
    
    <tags>
      
      <tag>阿里云</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> sonarqube 搭配gitlab-ci </title>
    <link href="/2020/01/07/2020-01-07-sonarqube-and-gitlab/"/>
    <url>/2020/01/07/2020-01-07-sonarqube-and-gitlab/</url>
    
    <content type="html"><![CDATA[<p>1、项目文件中创建sonar-project.properties 文件</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#项目的key</span><br>sonar.projectKey=admin<br><span class="hljs-comment">#sonarqube的主机地址</span><br>sonar.host.url=https://192.168.1.6:9000<br><span class="hljs-comment">#项目的名字（这个名字在sonar界面显示的,此处根据项目名称修改）</span><br>sonar.projectName=sonar-test<br><span class="hljs-comment">#项目的版本（这个名字在sonar界面显示的,根据项目版本修改）</span><br>sonar.projectVersion=1.0<br><span class="hljs-comment">#需要分析源码的目录，多个目录用英文逗号隔开（根据需要修改）</span><br>sonar.sources=./<br><span class="hljs-comment">#编码格式</span><br><span class="hljs-comment">#sonar.sourceEncoding=UTF-8</span><br><span class="hljs-comment">#项目所用语言</span><br>sonar.language=java<br><span class="hljs-comment">#登录账号</span><br>sonar.login=admin<br><span class="hljs-comment">#登录密码</span><br>sonar.password=admin<br><span class="hljs-comment">#包含与源文件对应的已编译字节码文件 (如果没编译可以不写,默认创建target/sonar目录)</span><br>sonar.java.binaries=target/sonar<br></code></pre></div></td></tr></table></figure><p>例如：如下图</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-07/1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>2、修改项目.gitlab-ci.yml文件，在首部添加如下：</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">sonar_preview:</span><br>  <span class="hljs-attr">stage:</span> <span class="hljs-string">test</span><br>  <span class="hljs-attr">script:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">/usr/local/sonar-scanner/bin/sonar-scanner</span><br>  <span class="hljs-attr">except:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">master</span><br>  <span class="hljs-attr">tags:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">sonar</span><br></code></pre></div></td></tr></table></figure><p>例如：如下图</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-07/2.png" srcset="/img/loading.gif" lazyload alt=""></p><p>3、修改完成后，分支用户每次commit都会触发进行代码检测（没有触发请手动）</p>]]></content>
    
    
    
    <tags>
      
      <tag>Gitlab</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Docker安装sonarqube </title>
    <link href="/2020/01/06/2020-01-06-sonarqube-install/"/>
    <url>/2020/01/06/2020-01-06-sonarqube-install/</url>
    
    <content type="html"><![CDATA[<p><strong>Sonarqube</strong>，是一种自动代码审查工具，可检测代码中的错误，漏洞和代码异常。它可以与您现有的工作流程集成，以实现跨项目分支和请求请求的连续代码检查。</p><p>1、拉取镜像</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">docker pull soanrqube <br>docker pull postgres<br></code></pre></div></td></tr></table></figure><p>2、启动postgres</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">docker run -d --name postgresql --restart=always \<br>-p 5432:5432 \<br>-e POSTGRES_USER=sonarqube \<br>-e POSTGRES_PASSWORD=sonarqube \<br>-e POSTGRES_DB=sonarqube \<br>postgres<br></code></pre></div></td></tr></table></figure><p>POSTGRES_DB：如果未指定此参数，那么第一次启动容器时创建的默认数据库将使用POSTGRES_USER的值</p><p>3、启动soanrqube</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">docker run -d --name sonarqube --restart=always \<br>-p 9000:9000 \<br>-v /opt/sonarqube/conf:/opt/sonarqube/conf \<br>-v /opt/sonarqube/data:/opt/sonarqube/data \<br>-v /opt/sonarqube/logs:/opt/sonarqube/logs \<br>-v /opt/sonarqube/extensions:/opt/sonarqube/extensions \<br>-e sonar.jdbc.username=sonarqube \<br>-e sonar.jdbc.password=sonarqube \<br>-e sonar.jdbc.url=jdbc:postgresql://192.168.1.6:5432/sonarqube \<br>sonarqube<br></code></pre></div></td></tr></table></figure><p>4、浏览器打开192.168.1.6:9000 账号:admin 密码:admin</p><p>5、安装中文插件，configuration–market–搜索Chinese Pack</p><p>6、安装soanr-scanner（安装在gitlab-runner服务器上，可以搭配gitlab-ci）</p><p><a href="https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/" target="_blank" rel="noopener">官网下载</a></p><p>解压放入/usr/local/目录下</p><p>7、项目文件根目录中创建sonar-project.properties 文件</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#项目的key</span><br>sonar.projectKey=admin<br><span class="hljs-comment">#sonarqube的主机地址</span><br>sonar.host.url=https://192.168.1.6:9000<br><span class="hljs-comment">#项目的名字（这个名字在sonar界面显示的,此处根据项目名称修改）</span><br>sonar.projectName=sonar-test<br><span class="hljs-comment">#项目的版本（这个名字在sonar界面显示的,根据项目版本修改）</span><br>sonar.projectVersion=1.0<br><span class="hljs-comment">#需要分析源码的目录，多个目录用英文逗号隔开（根据需要修改）</span><br>sonar.sources=./<br><span class="hljs-comment">#编码格式</span><br><span class="hljs-comment">#sonar.sourceEncoding=UTF-8</span><br><span class="hljs-comment">#项目所用语言</span><br>sonar.language=java<br><span class="hljs-comment">#登录账号</span><br>sonar.login=admin<br><span class="hljs-comment">#登录密码</span><br>sonar.password=admin<br><span class="hljs-comment">#包含与源文件对应的已编译字节码文件 (如果没编译可以不写,默认创建target/sonar目录)</span><br>sonar.java.binaries=target/sonar<br></code></pre></div></td></tr></table></figure><p>8、cd 到项目文件中，执行/usr/local/sonar-scanner/bin/sonar-scanner</p><p>9、再次进入web界面，可以看到分析结果</p>]]></content>
    
    
    
    <tags>
      
      <tag>Gitlab</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Gitlab-CI 流程 </title>
    <link href="/2020/01/03/2020-01-03-gitlab-ci/"/>
    <url>/2020/01/03/2020-01-03-gitlab-ci/</url>
    
    <content type="html"><![CDATA[<p><strong>持续集成(Continuous Integration)</strong></p><p>持续集成指的是频繁的将代码集成到主干，每次集成都通过自动化的构建（包括编译、发布、自动化测试）来验证，它的好处主要有两个：</p><ul><li>快速发现错误。每完成一点更新，就集成到主干，可以快速发现错误，定位错误也比较容易；</li><li>防止分支大幅偏离主干。如果不经常集成，很容易导致集成难度变大，以至于难以集成。</li></ul><h2 id="一、GitLab-CI-CD"><a href="#一、GitLab-CI-CD" class="headerlink" title="一、GitLab CI/CD"></a><strong>一、GitLab CI/CD</strong></h2><p>从<code>8.0</code>版开始，<code>GitLab</code>持续集成(CI)完全集成到<code>GitLab</code>本身，它还具有持续部署和持续交付功能，可用于构建、测试和部署你的应用程序。下面是<code>GitLab CI/CD</code>流程图。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-03/1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>那么怎样让<code>GitLab CI</code>工作起来呢？总结起来就两条：</p><ol><li>将<code>.gitlab-ci.yml</code>文件添加到远程仓库的根目录；</li><li>将<code>GitLab</code>项目配置为使用<code>Runner</code></li></ol><p>设置好这些后，你每次<code>push</code>代码到<code>Git</code>仓库，<code>Runner</code>都会自动触发<code>CI pipeline</code>，你可以在项目的<code>Pipelines</code>页面下。如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-03/2.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如果一切运行正常，你可以看到绿色复选标记，这样你就可以在查看代码之前轻松查看任何提交是否导致测试失败。</p><h2 id="二、什么是-gitlab-ci-yml"><a href="#二、什么是-gitlab-ci-yml" class="headerlink" title="二、什么是 .gitlab-ci.yml"></a><strong>二、什么是 .gitlab-ci.yml</strong></h2><p>1、.gitlab-ci.yml文件配置CI对项目执行的操作，它告诉GitLab runner该做什么。</p><p>2、它位于存储库的根目录中，你代码的每次提交，GitLab都会查找.gitlab-ci.yml这个文件，并根据这个文件的内容，在Runner上启动你提交的工作。</p><p>3、默认情况下，它运行一个包含三个stage的管道：build，test，deploy。你不需要使用所有三个stage，没有工作的stage将会被忽略。</p><p>注意： .gitlab-ci.yml是一个YAML文件，因此您必须特别注意缩进。始终使用空格键，而不是Tab键。</p><p>你需要在你仓库的根目录下创建一个名为<code>.gitlab-ci.yml</code>的文件，下面是一个工程示例。它是最简单的配置。</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">`before_script:``</span> <span class="hljs-string">``-</span> <span class="hljs-string">hostname``</span> <span class="hljs-string">``-</span> <span class="hljs-string">ip</span> <span class="hljs-string">addr`</span> <span class="hljs-string">`stages:``</span> <span class="hljs-string">``-</span> <span class="hljs-string">test``</span> <span class="hljs-string">``-</span> <span class="hljs-string">deploy-app``</span> <span class="hljs-string">`</span> <span class="hljs-string">`sonar_analyze:``</span> <span class="hljs-string">``stage:</span> <span class="hljs-string">test``</span> <span class="hljs-string">``script:``</span>   <span class="hljs-string">``-</span> <span class="hljs-string">/usr/local/sonar-scanner/bin/sonar-scanner``</span> <span class="hljs-string">``except:``</span>  <span class="hljs-string">``-</span> <span class="hljs-string">master``</span> <span class="hljs-string">``tags:``</span>  <span class="hljs-string">``-</span> <span class="hljs-string">sonar`</span> <span class="hljs-string">`deploy-app-to-test:``</span> <span class="hljs-string">``stage:</span> <span class="hljs-string">deploy-app``</span> <span class="hljs-string">``only:``</span>  <span class="hljs-string">``-</span> <span class="hljs-string">master``</span> <span class="hljs-string">``script:``</span>  <span class="hljs-string">``-</span> <span class="hljs-string">hostname``</span>  <span class="hljs-string">``-</span> <span class="hljs-string">ls``</span> <span class="hljs-string">``tags:``</span>  <span class="hljs-string">``-</span> <span class="hljs-string">sonar`</span><br></code></pre></div></td></tr></table></figure><p>上面的配置主要做了两件事：</p><ol><li>执行了两个job（名称是任意的）；</li><li>在每个<code>job</code>之前，执行<code>before_script</code>定义的命令。 </li></ol><p>关于<code>.gitlab-ci.yml</code>的语法讲解，可以查看<a href="https://docs.gitlab.com/ee/ci/yaml/" target="_blank" rel="noopener">官网的介绍</a>，然后根据项目的具体需求，使用这些语法，创建自己的脚本。</p><h2 id="三、配置Runner"><a href="#三、配置Runner" class="headerlink" title="三、配置Runner"></a><strong>三、配置Runner</strong></h2><p><strong>runner简单介绍</strong></p><p>GitLab Runner是一个开源项目，用于运行您的作业并将结果发送回GitLab。它与GitLab CI一起使用，GitLab CI是GitLab随附的开源持续集成服务，用于协调作业。</p><p>要求</p><ul><li>GitLab Runner是用Go编写的，可以作为单个二进制文件运行，不需要语言特定的要求。</li><li>它运行在GNU / Linux，macOS和Windows操作系统上。只要您可以在其上编译Go二进制文件，它就可以正常工作。</li><li>如果要使用Docker，请安装最新版本。GitLab Runner至少需要的Docker v1.13.0。</li><li>建议使用和gitlab相同版本</li></ul><p><strong>1、Runner安装</strong></p><p>请参考官方文档，这里不再详细说明   <a href="https://docs.gitlab.com/runner/" target="_blank" rel="noopener">https://docs.gitlab.com/runner/</a></p><p><strong>2、Runner注册</strong></p><p>要求<br>在注册Runner之前，您需要先：</p><ul><li>将其安装在与安装GitLab的位置不同的服务器上</li><li>通过GitLab的界面获取共享或特定Runner的令牌</li></ul><p>如下图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-03/3.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>GNU / Linux</strong></p><p>1、运行以下命令：<br>gitlab-runner register</p><p>2、输入您的GitLab实例URL：<br>Please enter the gitlab-ci coordinator URL (e.g. <a href="https://gitlab.com" target="_blank" rel="noopener">https://gitlab.com</a> ):</p><p><a href="https://gitlab.xxx.xxx" target="_blank" rel="noopener">https://gitlab.xxx.xxx</a></p><p>3、输入您获得的令牌以注册Runner：<br>Please enter the gitlab-ci token for this runner:</p><p>xxx</p><p>4、输入Runner的描述，您可以稍后在GitLab的UI中更改：（根据需求更改）<br>Please enter the gitlab-ci description for this runner:</p><p>my-runner</p><p>5、输入与Runner关联的标签，您可以稍后在GitLab的UI中更改：（根据需求更改）<br>Please enter the gitlab-ci tags for this runner (comma separated):</p><p>my-tag</p><p>6、输入Runner执行程序：(每个执行程序的作用，详情请点击<a href="https://docs.gitlab.com/runner/executors/README.html" target="_blank" rel="noopener">runner执行程序</a>，请根据需要选择执行器)<br>Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:</p><p>docker</p><p>7、如果您选择Docker作为执行程序，您将被要求为没有在.gitlab-ci.yml中定义映像的项目使用默认映像（根据需要设置默认镜像）</p><p>Please enter the Docker image (eg. ruby:2.1):</p><p>maven:latest</p><p><strong>3、查看注册是否成功</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-03/4.png" srcset="/img/loading.gif" lazyload alt=""></p>]]></content>
    
    
    
    <tags>
      
      <tag>Gitlab</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 阿里云搭建shadowsocks-vpn </title>
    <link href="/2020/01/02/2020-01-02-aliyun-vpn/"/>
    <url>/2020/01/02/2020-01-02-aliyun-vpn/</url>
    
    <content type="html"><![CDATA[<p><strong>脚本可能已不可用，未测试</strong> 2020-5-29</p><p>阿里云服务器购买国外节点，建议香港、日本、新加坡</p><p>系统选择linux，脚本支持centos、debian、ubuntu</p><p>1、下载脚本文件，并执行</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ wget --no-check-certificate -O shadowsocks-all.sh<br>https://github.com/ILIKETWICE/shadowsocks-install/blob/master/shadowsocks-all.sh<br>chmod +x shadowsocks-all.sh<br>$ ./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log<br></code></pre></div></td></tr></table></figure><p>2、选择脚本（Python、R、Go、libev），任选一个：(这里我选择的是Go)</p><figure class="highlight plain"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bahs">Which Shadowsocks server you&#39;d select:<br>1.Shadowsocks-Python<br>2.ShadowsocksR<br>3.Shadowsocks-Go<br>4.Shadowsocks-libev<br>Please enter a number (default 1):3<br></code></pre></div></td></tr></table></figure><p>3、我选择的是<code>Shadowsocks-Go</code>，输入3……然后，输入密码和端口，笔者直接回车用默认：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">You choose = Shadowsocks-Go<br> <br>Please enter password <span class="hljs-keyword">for</span> Shadowsocks-Go<br>(default password: teddysun.com):  <span class="hljs-comment"># 输入你的密码</span><br> <br>password = teddysun.com<br> <br>Please enter a port <span class="hljs-keyword">for</span> Shadowsocks-Go [1-65535]<br>(default port: 8989):   <span class="hljs-comment"># 输入端口</span><br> <br>port = 8989<br> <br> <br>Press any key to start...or Press Ctrl+C to cancel  <span class="hljs-comment"># 回车</span><br></code></pre></div></td></tr></table></figure><p>4、安装成功后，命令行出现：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">Congratulations, Shadowsocks-Go server install completed!<br>Your Server IP        :  xx.xx.xx.xx<br>Your Server Port      :  8989<br>Your Password         :  teddysun.com<br>Your Encryption Method:  aes-256-cfb<br> <br>Welcome to visit: https://teddysun.com/486.html<br>Enjoy it!<br></code></pre></div></td></tr></table></figure><p>5、注意阿里云ECS主机要打开“安全组”，添加入口规则</p>]]></content>
    
    
    
    <tags>
      
      <tag>阿里云</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> mesos 以容器方式启动,拉取镜像失败问题 </title>
    <link href="/2020/01/01/2020-01-01-mesos-pull-images-error/"/>
    <url>/2020/01/01/2020-01-01-mesos-pull-images-error/</url>
    
    <content type="html"><![CDATA[<p>为了方便快速部署,将 mesos、marathon进行了容器化部署, 但是容器化完后发现在<code>marathon</code> 上创建应用一直创建不成功</p><p><strong>分析过程</strong></p><p>因为是容器化部署的mesos-slave和marathon,是不是因为没有找到证书和登录信息导致的,随后在mesos-salve容器手动的进行<code>docker login</code> 操作并将证书进行挂载到对应目录,手工执行命令docker -H unix:///var/run/docker.sock pull registry.cn-beijing.aliyuncs.com/xxxx/xxxxx-service:12984 能正常下载仓库镜像,但通过marathon创建应用问题依旧,此时我们查看了一下日志发现一些踪迹</p><p><strong>mesos-slave 错误信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">Failed to launch container: Failed to run <span class="hljs-string">'docker -H unix:///var/run/docker.sock pull registry.cn-beijing.aliyuncs.com/xxxx/xxxxx-service:12984'</span>: exited with status 1; stderr=<span class="hljs-string">'Error response from daemon: pull access denied for registry.cn-beijing.aliyuncs.com/xxxxx/xxxxx-service, repository does not exist or may require '</span>docker login<span class="hljs-string">': denied: requested access to the resource is denied '</span><br></code></pre></div></td></tr></table></figure><p>镜像仓库报错很明显,认证不通过,通过查找<code>marathon</code> 官方文档,我们发现官方说明在使用<code>Private Docker Registry</code> 时候需要额外做一些配置,参考<a href="https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html" target="_blank" rel="noopener">marathon使用私有仓库配置</a> ,配置简单的步骤如下,所有<code>slave</code>节点和<code>marathon</code>节点都需要配置</p><ul><li>宿主机手工进行docker login</li></ul><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">docker login<br></code></pre></div></td></tr></table></figure><ul><li>登录信息会保存在/root/.docker 目录下,将其进行打包</li></ul><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /root<br>tar -cvf docker.tar.gz .docker/<br></code></pre></div></td></tr></table></figure><ul><li>将打包的文件复制到所有节点目录,<strong>注意:</strong> 放置在一个公共目录,因为marathon和mesos-slave都需要调用到</li></ul><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">scp  docker.tar.gz  所有节点:/一个公共目录<br></code></pre></div></td></tr></table></figure><ul><li>容器启动marathon 和mesos-slave时候进行挂载对应公共目录</li></ul><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#mesos-slave</span><br>docker run -v /tmp/docker.tar.gz:/tmp/docker.tar.gz  .....  mesos-salve<br><span class="hljs-comment">#marathon</span><br>docker run -v /tmp/docker.tar.gz:/tmp/docker.tar.gz  .....  marathon<br></code></pre></div></td></tr></table></figure><ul><li>创建应用时候,配置urls参数</li></ul><figure class="highlight"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs json">"fetch": [<br>  &#123;<br>    <span class="hljs-attr">"uri"</span>: <span class="hljs-string">"file:///etc/docker.tar.gz"</span><br>  &#125;<br>]<br></code></pre></div></td></tr></table></figure><p>应用启动后,我们登录到mesos-slave 容器上查看资源stderr日志可以发现,资源节点如何下载和使用docker.tar.gz 包，这里就不贴出日志信息啦。</p><p>因为我使用的图形化界面配置，mesos版本为1.5.0，配置图如下</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-01/1.png" srcset="/img/loading.gif" lazyload alt=""></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-01/2.png" srcset="/img/loading.gif" lazyload alt=""></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2020-01-01/3.png" srcset="/img/loading.gif" lazyload alt=""></p>]]></content>
    
    
    
    <tags>
      
      <tag>Mesos</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> TCP 超时与重传 </title>
    <link href="/2019/12/31/2019-12-31-tcp-timeout-and-retransmission/"/>
    <url>/2019/12/31/2019-12-31-tcp-timeout-and-retransmission/</url>
    
    <content type="html"><![CDATA[<p>我们都知道 TCP 协议具有重传机制，也就是说，如果发送方认为发生了丢包现象，就重发这些数据包。很显然，我们需要一个方法来「<strong>猜测</strong>」是否发生了丢包。最简单的想法就是，接收方每收到一个包，就向发送方返回一个 <strong>ACK</strong>，表示自己已经收到了这段数据，反过来，如果发送方一段时间内没有收到 ACK，就知道<strong>很可能</strong>是数据包丢失了，紧接着就重发该数据包，直到收到 ACK 为止。</p><p>你可能注意到我用的是「猜测」，因为即使是超时了，这个数据包也可能并没有丢，它只是绕了一条远路，来的很晚而已。毕竟 TCP 协议是位于<strong>传输层</strong>的协议，不可能明确知道数据链路层和物理层发生了什么。但这并不妨碍我们的超时重传机制，因为接收方会自动忽略重复的包。</p><p>超时和重传的概念其实就是这么简单，但内部的细节却是很多，我们最先想到的一个问题就是，<strong>到底多长时间才能算超时呢</strong>？</p><h2 id="超时是怎么确定的？"><a href="#超时是怎么确定的？" class="headerlink" title="超时是怎么确定的？"></a>超时是怎么确定的？</h2><p>一刀切的办法就是，我<strong>直接把超时时间设成一个固定值</strong>，比如说 200ms，但这样肯定是有问题的，我们的电脑和很多服务器都有交互，这些服务器位于天南海北，国内国外，延迟差异巨大，打个比方：</p><ul><li>我的个人博客搭在国内，延迟大概 30ms，也就是说正常情况下的数据包，60ms 左右就已经能收到 ACK 了，但是按照我们的方法，200ms 才能确定丢包（正常可能是 90 到 120 ms），这<strong>效率实在是有点低</strong>。</li><li>假设你访问某国外网站，延迟有 130 ms，这就麻烦了，<strong>正常的数据包都可能被认为是超时，导致大量数据包被重发，可以想象，重发的数据包也很容易被误判为超时。。。雪崩效应的感觉</strong></li></ul><p>所以设置固定值是很不可靠的，<strong>我们要根据网络延迟，动态调整超时时间</strong>，延迟越大，超时时间越长。</p><p>在这里先引入两个概念：</p><ul><li>RTT（Round Trip Time）：往返时延，也就是<strong>数据包从发出去到收到对应 ACK 的时间。</strong>RTT 是针对连接的，每一个连接都有各自独立的 RTT。</li><li>RTO（Retransmission Time Out）：重传超时，也就是前面说的超时时间。</li></ul><p>比较标准的 RTT 定义：</p><blockquote><p>Measure the elapsed time between sending a data octet with a particular sequence number and <strong>receiving an acknowledgment that covers that sequence number</strong> (segments sent do not have to match segments received). This measured elapsed time is the Round Trip Time (RTT).</p></blockquote><h3 id="经典方法"><a href="#经典方法" class="headerlink" title="经典方法"></a>经典方法</h3><p>最初的规范「RFC0793」采用了下面的公式来得到平滑的 RTT 估计值（称作 SRTT）：</p><p><strong>SRTT  &lt;-  α·SRTT +（1 - α）·RTT</strong></p><p>RTT 是指最新的样本值，这种估算方法叫做「指数加权移动平均」，名字听起来比较高大上，但整个公式比较好理解，就是利用现存的 SRTT 值和最新测量到的 RTT 值取一个加权平均。</p><p>有了 SRTT，就该设置对应的 RTO 的值了，「RFC0793」是这么算的：</p><p><strong>RTO = min(ubound, max(lbound, (SRTT)·β))</strong></p><p>这里面的 <strong>ubound</strong> 是 RTO 的<strong>上边界</strong>，<strong>lbound</strong> 为 RTO 的<strong>下边界</strong>，β 称为<strong>时延离散因子</strong>，推荐值为 1.3 ~ 2.0。这个计算公式就是将  (SRTT)·β 的值作为 RTO，只不过另外<strong>限制了 RTO 的上下限</strong>。</p><p>这个计算方法，初看是没有什么问题（至少我是这么感觉的），但是实际应用起来，有两个缺陷：</p><blockquote><p>There were two known problems with the RTO calculations specified in RFC-793. First, the accurate measurement of RTTs is difficult <strong>when there are retransmissions</strong>. Second, the algorithm to compute the smoothed round-trip time is inadequate [TCP:7], <strong>because it incorrectly assumed that the variance in RTT values would be small and constant</strong>. These problems were solved by <strong>Karn’s and Jacobson’s algorithm</strong>, respectively.</p></blockquote><p>这段话摘自「RFC1122」，我来解释一下：</p><ul><li>当<strong>出现数据包重传的情况</strong>下，RTT 的计算就会很“麻烦”，我画了张图来说明这些情况：</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-31/rtt.png" srcset="/img/loading.gif" lazyload alt=""></p><ul><li><p>图上列了两种情况，这两种情况下计算 RTT 的方法是不一样的（这就是所谓的重传二义性）：</p><p>但是对于客户端来说，它不知道发生了哪种情况，选错情况的结果就是 RTT 偏大/偏小，影响到 RTO 的计算。（最简单粗暴的解决方法就是<strong>忽略有重传的数据包，只计算那些没重传过的</strong>，但这样会导致其他问题。。详见 Karn’s algorithm）</p></li><li><ul><li>情况一：RTT = t2 - t0</li><li>情况二：RTT = t2 - t1</li></ul></li><li><p>另一个问题是，<strong>这个算法假设 RTT 波动比较小</strong>，因为这个加权平均的算法又叫<strong>低通滤波器</strong>，对突然的网络波动不敏感。如果网络时延突然增大导致实际 RTT 值远大于估计值，会导致不必要的重传，增大网络负担。（ RTT 增大已经表明网络出现了过载，这些不必要的重传会进一步加重网络负担）。</p></li></ul><h3 id="标准方法"><a href="#标准方法" class="headerlink" title="标准方法"></a>标准方法</h3><p>说实话这个标准方法比较，，，麻烦，我就直接贴公式了：</p><p><strong>SRTT  &lt;-  (1 - α)·SRTT  + α·RTT</strong>  //跟基本方法一样，<strong>求 SRTT 的加权平均</strong></p><p><strong>rttvar  &lt;- (1 - h)·rttvar + h·(|RTT - SRTT |)</strong>  //计算 <strong>SRTT 与真实值的差距</strong>（称之为绝对误差|Err|），同样用到<strong>加权平均</strong></p><p><strong>RTO = SRTT  + 4·rttvar</strong> //估算出来的新的 RTO，rttvar 的系数 4 是调参调出来的</p><p>这个算法的整体思想就是结合<strong>平均值</strong>（就是基本方法）和<strong>平均偏差</strong>来进行估算，一波玄学调参得到不错的效果。如果想更深入了解这个算法，参考「RFC6298」。</p><h2 id="重传——TCP的重要事件"><a href="#重传——TCP的重要事件" class="headerlink" title="重传——TCP的重要事件"></a>重传——TCP的重要事件</h2><h3 id="基于计时器的重传"><a href="#基于计时器的重传" class="headerlink" title="基于计时器的重传"></a>基于计时器的重传</h3><p>这种机制下，<strong>每个数据包都有相应的计时器</strong>，一旦超过 RTO 而没有收到 ACK，就重发该数据包。没收到 ACK 的数据包都会存在重传缓冲区里，等到 ACK 后，就从缓冲区里删除。</p><p>首先明确一点，对 TCP 来说，超时重传是<strong>相当重要</strong>的事件（RTO 往往大于两倍的 RTT，超时往往意味着拥塞），一旦发生这种情况，<strong>TCP 不仅会重传对应数据段，还会降低当前的数据发送速率</strong>，因为TCP 会认为当前网络发生了拥塞。</p><p>简单的超时重传机制往往比较低效，如下面这种情况：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-31/transfer.png" srcset="/img/loading.gif" lazyload alt=""></p><p>假设数据包5丢失，数据包 6,7,8,9 都已经到达接收方，这个时候客户端就只能等服务器发送 ACK，注意对于包 6,7,8,9，服务器都不能发送 ACK，这是滑动窗口机制决定的，因此对于客户端来说，他完全不知道丢了几个包，可能就悲观的认为，5 后面的数据包也都丢了，就重传这 5 个数据包，这就比较浪费了。</p><h3 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h3><p>快速重传机制「RFC5681」基于接收端的反馈信息来引发重传，而非重传计时器超时。</p><p>刚刚提到过，基于计时器的重传往往要等待很长时间，而快速重传使用了很巧妙的方法来解决这个问题：<strong>服务器如果收到乱序的包，也给客户端回复 ACK</strong>，只不过是重复的 ACK。就拿刚刚的例子来说，收到乱序的包 6,7,8,9 时，服务器全都发 ACK = 5。这样，客户端就知道 5 发生了空缺。一般来说，如果客户端连续三次收到重复的 ACK，就会重传对应包，而不需要等到计时器超时。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-31/fast-transfer.png" srcset="/img/loading.gif" lazyload alt=""></p><p>但快速重传仍然没有解决第二个问题：到底该重传多少个包？</p><h3 id="带选择确认的重传"><a href="#带选择确认的重传" class="headerlink" title="带选择确认的重传"></a>带选择确认的重传</h3><p>改进的方法就是 SACK（Selective Acknowledgment），简单来讲就是在快速重传的基础上，<strong>返回最近收到的报文段的序列号范围</strong>，这样客户端就知道，哪些数据包已经到达服务器了。</p><p>来几个简单的示例：</p><ul><li><p>case 1：第一个包丢失，剩下的 7 个包都被收到了。</p><p>当收到 7 个包的<strong>任何一个</strong>的时候，接收方会返回一个带 SACK 选项的 ACK，告知发送方自己收到了哪些乱序包。注：<strong>Left Edge，Right Edge 就是这些乱序包的左右边界</strong>。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">Triggering    ACK      Left Edge   Right Edge<br>Segment<br><br>5000         (lost)<br>5500         5000     5500       6000<br>6000         5000     5500       6500<br>6500         5000     5500       7000<br>7000         5000     5500       7500<br>7500         5000     5500       8000<br>8000         5000     5500       8500<br>8500         5000     5500       9000<br></code></pre></div></td></tr></table></figure><ul><li><p>case 2：第 2, 4, 6, 8 个数据包丢失。</p></li><li><ul><li>收到第一个包时，没有乱序的情况，正常回复 ACK。</li><li>收到第 3, 5, 7 个包时，由于出现了乱序包，回复带 SACK 的 ACK。</li><li>因为这种情况下有很多碎片段，所以相应的 Block 段也有很多组，当然，因为选项字段大小限制， Block 也有上限。</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">Triggering  ACK    First Block   2nd Block     3rd Block<br>Segment            Left   Right  Left   Right  Left   Right<br>                   Edge   Edge   Edge   Edge   Edge   Edge<br><br>5000       5500<br>5500       (lost)<br>6000       5500    6000   6500<br>6500       (lost)<br>7000       5500    7000   7500   6000   6500<br>7500       (lost)<br>8000       5500    8000   8500   7000   7500   6000   6500<br>8500       (lost)<br></code></pre></div></td></tr></table></figure><p>不过 SACK 的规范「RFC2018」有点坑爹，接收方可能会在提供一个 SACK 告诉发送方这些信息后，又「食言」，也就是说，接收方可能把这些（乱序的）数据包删除掉，然后再通知发送方。以下摘自「RFC2018」：</p><blockquote><p>Note that the data receiver is permitted to discard data in its queue that has not been acknowledged to the data sender, even if the data has already been reported in a SACK option. <strong>Such discarding of SACKed packets is discouraged, but may be used if the receiver runs out of buffer space.</strong></p></blockquote><p>最后一句是说，<strong>当接收方缓冲区快被耗尽时</strong>，可以采取这种措施，当然并不建议这种行为。。。</p><p>由于这个操作，发送方在收到 SACK 以后，也不能直接清空重传缓冲区里的数据，一直到接收方发送普通的，ACK 号大于其最大序列号的值的时候才能清除。另外，重传计时器也收到影响，重传计时器应该忽略 SACK 的影响，毕竟接收方把数据删了跟丢包没啥区别。</p><h3 id="DSACK-扩展"><a href="#DSACK-扩展" class="headerlink" title="DSACK 扩展"></a>DSACK 扩展</h3><p>DSACK，即重复 SACK，这个机制是在 SACK 的基础上，额外携带信息，<strong>告知发送方有哪些数据包自己重复接收了</strong>。DSACK 的目的是帮助发送方判断，是否发生了包失序、ACK 丢失、包重复或伪重传。让 TCP 可以更好的做网络流控。</p><p>关于 DSACK，「RFC2883」里举了很多例子，有兴趣的读者可以去阅读一下，我这里就不讲那么细了。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> TCP 协议，握手挥手不是你想的那么简单 </title>
    <link href="/2019/12/30/2019-12-30-tcp-handshake/"/>
    <url>/2019/12/30/2019-12-30-tcp-handshake/</url>
    
    <content type="html"><![CDATA[<h2 id="TCP-报文段结构"><a href="#TCP-报文段结构" class="headerlink" title="TCP 报文段结构"></a>TCP 报文段结构</h2><p>一谈到 TCP 协议，大家最先想到的词就是「<strong>面向连接</strong>」和「<strong>可靠</strong>」。没错，TCP 协议的设计就是为了能够在客户端和服务器之间建立起一个可靠连接。</p><p>在讲连接过程之前，我们先来看看 TCP 的报文段结构，通过这个结构，我们可以知道 TCP 能够提供什么信息：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/tcp-message.png" srcset="/img/loading.gif" lazyload alt="TCP报文结构"></p><p>这里有几点是需要注意的：</p><ul><li>TCP 协议需要一个<strong>四元组</strong>（源IP，源端口，目的IP，目的端口）来确定连接，这要和 UDP 协议区分开。多说一句，IP 地址位于 IP 报文段，TCP 报文段是不含 IP 地址信息的。</li><li><strong>基本 TCP 头部</strong>的长度是 20 字节，但是由于「<strong>选项</strong>」的长度是不确定的，所以需要「<strong>首部长度</strong>」字段明确给出头部长度。这里要注意的是，首部长度字段的单位是 32bit，也就是 4 字节，所以该字段的最小值是 5。</li><li>标橙色的字段（<strong>确认序号，接收窗口大小，ECE，ACK</strong>）用于「回复」对方，举个例子，服务器收到对方的数据包后，不单独发一个数据包来回应，而是稍微等一下，把确认信息附在<strong>下一个</strong>发往<strong>客户端</strong>的数据帧上，也就是<strong>捎带</strong>技术。</li><li>窗口大小是一个 16 位无符号数，也就是说窗口被限制在了 65535 字节，也就限制了 TCP 的吞吐量性能，这对一些高速以及高延迟的网络不太友好（可以想想为什么）。所幸 TCP 额外提供了<strong>窗口缩放</strong>（Window Scale）选项，允许对这个值进行缩放。</li></ul><p>下面是 8 个标志位的含义，有的协议比较旧，可能没有前两个标志位：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/8flag.png" srcset="/img/loading.gif" lazyload alt="8个标志位的含义"></p><p>标志位虽然很多，但是如果放到具体场景里来看的话，就很容易理解他们的作用了。</p><h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p>三次握手就是为了在客户端和服务器间建立连接，这个过程并不复杂，但里面有很多细节需要注意。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/three-handshake.png" srcset="/img/loading.gif" lazyload alt="三次握手"></p><p>这张图就是握手的过程，可以看到客户端与服务器之间一共传递了三次消息，这三次握手其实就是两台机器之间互相确认状态，我们来一点一点看。</p><p><strong>第一次握手</strong></p><p>首先是<strong>客户端发起连接</strong>，第一个数据包将 SYN 置位（也就是 SYN = 1），表明这个数据包是 SYN 报文段（也被称为<strong>段 1</strong>）。这一次发送的目的是告诉服务器，自己的<strong>初始序列号</strong>是 <code>client_isn</code> ，还有一个隐含的信息在图里没有表现出来，那就是告知服务端自己想连接的<strong>端口号</strong>。除了这些，客户端还会发送一些<strong>选项</strong>，不过这跟三次握手没多大关系，暂且按下不表。</p><p>段 1 里最需要注意的就是这个<code>client_isn</code> ，也就是初始序列号。「RFC0793^1」指出:</p><blockquote><p>When new connections are created, an initial sequence number (ISN) generator is employed which selects a new 32 bit ISN. The generator is bound to a (possibly fictitious) 32 bit clock whose low order bit is incremented roughly every 4 microseconds.  Thus, the ISN cycles approximately every 4.55 hours.</p></blockquote><p>翻译过来就是，初始序列号是一个 32 位的（虚拟）计数器，而且这个计数器每 4 微秒加 1，也就是说，ISN 的值<strong>每 4.55 小时循环一次</strong>。这个举措是为了<strong>防止序列号重叠</strong>。</p><p>但即使这样还是会有安全隐患——因为初始 ISN 仍然是可预测的，恶意程序可能会分析 ISN ，然后根据先前使用的 ISN <strong>预测</strong>后续 TCP 连接的 ISN，然后进行攻击，一个著名的例子就是「The Mitnick attack^2」 。这里摘一段原文：</p><blockquote><p>Mitnick sent SYN request to X-Terminal and received SYN/ACK response.  Then he sent RESET response to keep the X-Terminal from being filled up. He repeated this for twenty times. He found there is a pattern between  two successive TCP sequence numbers. It turned out that the numbers were not random at all. The latter number was greater than the previous one  by 128000.</p></blockquote><p>所以为了让初始序列号<strong>更难预测</strong>，现代系统常常使用<strong>半随机</strong>的方法选择初始序列号，详细的方法就不在这里展开了。</p><p><strong>第二次握手</strong></p><p>当服务器接收到客户端的连接请求后，就会向客户端发送 <strong>ACK</strong> 表示自己收到了连接请求，而且，服务器还得<strong>把自己的初始序列号告诉客户端</strong>，这其实是两个步骤，但是发送<strong>一个数据包</strong>就可以完成，用的就是前面说的<strong>捎带</strong>技术。图里的 <code>ACK = client_isn + 1</code> 是指<strong>确认号字段</strong>的值，要注意和 <strong>ACK 标志位</strong>区分开。</p><p>ACK 字段其实也有不少需要注意的点，不过这个跟滑动窗口一块讲比较直观，这里就先不提了。</p><p>这里重点强调一下，当一个 SYN 报文段到达的时候，<strong>服务器会检查处于 SYN_RCVD 状态的连接数目是否超过了 <code>tcp_max_syn_backlog</code> 这个参数，如果超过了，服务器就会拒绝连接</strong>。当然，这个也会被黑客所利用，「SYN Flood」就是个很好的例子。因为服务器在回复 SYN-ACK 后，会等待客户端的 ACK ，如果一定时间内没有收到，认为是丢包了，就重发 SYN-ACK，重复几次后才会断开这个连接，linux 可能要一分钟才会断开，所以攻击者如果制造一大批 SYN 请求而不回复，服务器的 SYN 队列很快就被耗尽，这一段时间里，正常的连接也会得不到响应。</p><p>服务器的这种状态称为<strong>静默</strong>（muted）。为了抵御 SYN Flood 攻击，服务器可以采用「SYN cookies」，这种思想是，当 SYN 到达时，<strong>并不直接为其分配内存</strong>，而是把这条连接的信息编码并保存在 SYN-ACK 报文段的<strong>序列号</strong>字段，如果客户端回复了，服务器再<strong>从 ACK 字段里解算出 SYN 报文的重要信息</strong>（有点黑魔法的感觉了），验证成功后才为该连接分配内存。这样，服务器不会响应攻击者的请求，正常连接则不会受到影响。</p><p>但 SYN cookies 本身有一些限制，并不适合作为默认选项，有兴趣可以自行 Google。</p><p><strong>第三次握手</strong></p><p>这是建立 TCP 连接的最后一步，经过前两次握手，客户端（服务器）已经知道对方的<strong>滑动窗口大小</strong>，<strong>初始序列号</strong>等信息了，这不就完了吗？为什么还要第三次握手？</p><p>这是因为服务器虽然把数据包发出去了，但他<strong>还不知道客户端是否收到了这个包</strong>，所以服务器需要等待客户端返回一个 ACK，表明客户端收到了数据，至此，连接完成。</p><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p>有了三次握手的基础，四次挥手就比较容易理解了：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/four-breakup.png" srcset="/img/loading.gif" lazyload alt="四次挥手"></p><p>四次挥手的过程其实很简单，就是服务器和客户端互相发送 FIN 和 ACK 报文段，告知对方要断开连接。</p><p>四次挥手里值得关注的一点就是 <strong>TIME_WAIT</strong> 状态，也就是说主动关闭连接的一方，即使收到了对方的 FIN 报文，也还要等待 2<strong>MSL</strong> 的时间才会彻底关闭这条连接。（这里面的 MSL 指的是<strong>最大段生成期</strong>，指的是报文段<strong>在网络中</strong>被允许存在的最长时间。）可<strong>为什么不直接关闭连接呢</strong>？</p><p>一个原因是，<strong>第四次挥手的 ACK 报文段不一定到达了服务器</strong>，为了不让服务器一直处于 LAST_ACK 状态（服务器会重发 FIN，<strong>直到收到 ACK</strong>），客户端还得等一会儿，看看是否需要重发。假如真的丢包了，服务器发送 FIN ，这个 FIN 报文到达客户端时不会超过 2MSL（一来一回最多 2MSL），这时候客户端这边的 TCP 还没关掉，还能重发 ACK。</p><p>另一个原因是，<strong>经过 2MSL 之后，网络中与该连接相关的包都已经消失</strong>了，不会干扰新连接。我们来看一个例子：假如客户端向服务器建立了<strong>新的连接</strong>，<strong>旧连接中某些延迟的数据坚持到了新连接建立完毕，而且序列号刚好还在滑动窗口内，服务器就误把它当成新连接的数据包接收</strong>，如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-30/example.png" srcset="/img/loading.gif" lazyload alt="四次挥手"></p><p>2MSL 机制就避免了这种情况。</p>]]></content>
    
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 浅谈 TCP 的三次握手和四次挥手 </title>
    <link href="/2019/12/27/2019-12-27-talk-tcp/"/>
    <url>/2019/12/27/2019-12-27-talk-tcp/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是OSI-七层模型"><a href="#什么是OSI-七层模型" class="headerlink" title="什么是OSI 七层模型?"></a>什么是OSI 七层模型?</h2><blockquote><p>开放式系统互联通信参考模型（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为 OSI 模型（OSI model），一种概念模型，由国际标准化组织（ISO）提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于 ISO/IEC 7498-1。</p></blockquote><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-27/osi7.png" srcset="/img/loading.gif" lazyload alt="OSI七层模型"></p><ul><li>第 7 层应用层 ( Application Layer )</li></ul><p><strong>主要功能：</strong> 为应用软件提供接口，使应用程序能够使用网络服务<br><strong>典型设备：</strong> 网关<br><strong>典型协议、标准和应用：</strong> http(80)、ftp(20/21)、smtp(25)、pop3(110)、telnet(23)、dns(53)</p><ul><li>第 6 层表示层 ( Presentation Layer )</li></ul><p><strong>主要功能：</strong> 数据的解码和编码，数据的加密和解密，数据的压缩和解压缩<br><strong>典型设备：</strong> 网关<br><strong>典型协议、标准和应用：</strong> ASCLL、PICT、TIFF、JPEG、 MIDI、MPEG</p><ul><li>第 5 层会话层 ( Session Layer )</li></ul><p><strong>主要功能：</strong> 建立、维护、管理应用程序之间的会话<br><strong>典型设备：</strong> 网关<br><strong>典型协议、标准和应用：</strong> RPC、SQL、NFS 、X WINDOWS、ASP</p><ul><li>第 4 层传输层 (Transport Layer)</li></ul><p><strong>主要功能：</strong> 负责建立端到端的链接，保证保温在端到端之间的传输<br><strong>典型设备：</strong> 网关<br><strong>典型协议、标准和应用：</strong> TCP、UDP、SPX</p><ul><li>第 3 层网络层 (Network Layer)</li></ul><p><strong>主要功能：</strong> 负责将分组数据从源端传输到目的端，网络层的主要作用就是路由和寻址<br><strong>典型设备：</strong> 路由器<br><strong>典型协议、标准和应用：</strong> IP、IPX、APPLETALK、ICMP</p><ul><li>第 2 层数据链接层 (Data Link Layer)</li></ul><p><strong>主要功能：</strong> 在不可靠的物理链路上，提供可靠的数据传输服务<br><strong>典型设备：</strong> 交换机、网桥、网卡<br><strong>典型协议、标准和应用：</strong> 802.2、802.3ATM、HDLC、FRAME RELAY</p><ul><li>第 1 层物理层 (Physical Layer)</li></ul><p><strong>主要功能：</strong> 利用传输介质为数据链路层提供物理连接，实现比特流的透明传输<br><strong>典型设备：</strong> 集线器、中继器<br><strong>典型协议、标准和应用：</strong> V.35、EIA/TIA-232</p><ul><li>TCP/IP 协议族常用协议</li></ul><p><strong>应用层：</strong> TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet 等等<br><strong>传输层：</strong> TCP，UDP<br><strong>网络层：</strong> IP，ICMP，OSPF，EIGRP，IGMP<br><strong>数据链路层：</strong> SLIP，CSLIP，PPP，MTU</p><h2 id="什么是-TCP-IP"><a href="#什么是-TCP-IP" class="headerlink" title="什么是  TCP/IP ?"></a>什么是  TCP/IP ?</h2><blockquote><p>互联网协议族（英语：Internet Protocol Suite，缩写为 IPS），是一个网络通信模型，以及一整个网络传输协议家族，为互联网的基础通信架构。它常被通称为 TCP/IP 协议族（英语：TCP/IP Protocol Suite，或 TCP/IP Protocols），简称 TCP/IP 。</p><p>因为这个协议家族的两个核心协议，包括TCP（传输控制协议）和 IP（网际协议），为这个家族中最早通过的标准。由于在网络通讯协议普遍采用分层的结构，当多个层次的协议共同工作时，类似计算机科学中的堆栈，因此又被称为 TCP/IP 协议栈（英语：TCP/IP Protocol Stack） 。</p><p>这些协议最早发源于美国国防部（缩写为 DoD）的ARPA 网项目，因此也被称作 DoD 模型（DoD Model）。这个协议套组由互联网工程任务组负责维护。</p><p>TCP/IP 提供点对点的链接机制，将数据应该如何封装、定址、传输、路由以及在目的地如何接收，都加以标准化。它将软件通信过程抽象化为四个抽象层，采取协议堆栈的方式，分别实现出不同通信协议。协议套组下的各种协议，依其功能不同，被分别归属到这四个层次结构之中，常被视为是简化的七层 OSI 模型。</p></blockquote><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-27/7-4-model.png" srcset="/img/loading.gif" lazyload alt="七层/四层模型"></p><p>在建立 TCP 连接之前需要进行三次握手，以便于链接到服务器，如果要断开服务器需要进行四次挥手，具体流程如下。</p><h2 id="TCP-IP-三次握手"><a href="#TCP-IP-三次握手" class="headerlink" title="TCP/IP 三次握手"></a>TCP/IP 三次握手</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-27/handshake.png" srcset="/img/loading.gif" lazyload alt="三次握手"></p><ol><li><p><strong>第一次握手：</strong> Client 将标志位 SYN 设置为 1，随机产生一个 Number 值 SEQ=100，并将数据发送给 Server，Client 进入 SYN_SENT 状态，等待 Server 确认；</p></li><li><p><strong>第二次握手：</strong> Server 收到数据包后 Client 设置的标志位 SYN=1 知道 Client 要求建立连接，Server 将标志位 SYN 和 ACK 都置为 1，并且发送一个确认序号 ACK=100+1，然后随机产生一个值 SEQ=130，并将该数据包发送给 Client 以确认连接请求，Server 进入 SYN_RCVD 状态。</p></li><li><p><strong>第三次握手：</strong> Client 收到确认后，检查 ACK 状态是否为 100+1，ACK 是否为 1，如果正确则将标志位 ACK 置为 1，ACK=130+1，并将该数据包发送给 Server，Server 检查 ACK 是否为 130+1，ACK 是否为1，如果正确则连接建立成功，Client 和 Server 进入 ESTABLISHED 状态，完成三次握手，随后 Client 与 Server 之间可以开始传输数据了。</p></li></ol><p>一个完整的三次握手也就是<strong>请求—应答—再次确认</strong></p><h2 id="TCP-IP-四次挥手"><a href="#TCP-IP-四次挥手" class="headerlink" title="TCP/IP 四次挥手"></a>TCP/IP 四次挥手</h2><p>为什么要挥手，简单点来说就是既然建立了链接，那么肯定还要断开连接吖，连接总不能一直占用吧，这样多浪费系统该资源，下面让我们来看看四次挥手的流程。</p><ol><li><p><strong>第一次挥手：</strong> Client 发送一个 FIN，用来关闭 Client 到 Server 的数据传送，Client 进入 FIN_WAIT_1 状态。</p></li><li><p><strong>第二次挥手：</strong> Server 收到 FIN 后，发送一个 ACK 给 Client，确认序号为 ACK=100+1（与 SYN 相同，一个 FIN 占用一个序号），Server 进入 CLOSE_WAIT 状态。</p></li><li><p><strong>第三次挥手：</strong> Server 发送一个 FIN，用来关闭 Server 到 Client 的数据传送，Server 进入 LAST_ACK 状态。</p></li><li><p><strong>第四次挥手：</strong> Client 收到 FIN 后，Client 进入 TIME_WAIT 状态，接着发送一个 ACK 给 Server，确认序号为 131+1，Server 进入 CLOSED 状态，完成四次挥手。</p></li></ol><h2 id="Q-A"><a href="#Q-A" class="headerlink" title="Q/A"></a>Q/A</h2><ul><li>为什么建立连接是三次握手，而关闭连接却是四次挥手呢？</li></ul><p>这是因为服务端在 LISTEN 状态下，收到建立连接请求的 SYN 报文后，把 ACK 和 SYN 放在一个报文里发送给客户端。而关闭连接时，当收到对方的 FIN 报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即 Close，也可以发送一些数据给对方后，再发送 FIN 报文给对方来表示同意现在关闭连接，因此，己方 ACK 和 FIN一般都会分开发送。</p><ul><li>为什么建立连接要三次握手？</li></ul><p><strong>目的：</strong> 防止已经失效的连接请求到达服务端，创建无效的连接，浪费资源。</p><p><strong>说明：</strong> 当客户端发出的第一个连接请求在网络上的某个节点被滞留了（网络会存在许多不可靠的因素），过一段时间后突然又到达了服务端，服务端误以为这是一个新的建立连接的请求，于是就会向客户端发出确认包并建立连接。</p><p>实际上客户端当前并没有发出创建连接的请求，就会丢弃服务端的确认包。而服务端却创建了连接并等待客户端发送数据，浪费了相关的资源。</p><ul><li>SYN 攻击</li></ul><p>在三次握手过程中，服务器<code>发送 SYN-ACK 之后，收到客户端的 ACK 之前</code>的 TCP 连接称为半连接 (half-open connect)。此时服务器处于 SYN_RECV 状态，当收到 ACK 后，服务器转入 ESTABLISHED 状态.</p><p>SYN 攻击就是：攻击客户端在短时间内伪造大量不存在的 IP 地址，向服务器不断地发送 SYN 包，服务器回复 ACK 确认包，并等待客户的确认从而建立连接。由于源地址是不存在的，不会再发送 ACK 确认包，所以服务器需要不断的重发直至超时，这些伪造的 SYN 包将长时间占用未连接队列，正常的 SYN 请求被丢弃，目标系统运行缓慢，严重者引起网络堵塞甚至系统瘫痪。</p><p>SYN 攻击是一个典型的 DDOS 攻击。检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击</p><ul><li>为什么 TIME_WAIT 状态需要经过 2MSL (最大报文段生存时间)才能返回到 CLOSE 状态？</li></ul><p>虽然按道理，四个报文都发送完毕，我们可以直接进入 CLOSE 状态了，但是我们必须假象网络是不可靠的，有可以最后一个 ACK 丢失。所以 TIME_WAIT 状态就是用来重发可能丢失的 ACK 报文。</p>]]></content>
    
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Nginx 中 reload 流程 </title>
    <link href="/2019/12/26/2019-12-26-nginx-reload/"/>
    <url>/2019/12/26/2019-12-26-nginx-reload/</url>
    
    <content type="html"><![CDATA[<p>今天这篇文章主要来介绍下 Nginx 的 reload 流程。实际上在之前文章中，在更改了 nginx 配置文件时，我们都会执行 nginx -s reload 命令，我们执行这条命令的原因是希望 nginx 不停止服务始终在处理新的请求的同时把 nginx 的配置文件平滑的把旧的 nginx.conf 配置更新为新的 nginx.conf 配置。</p><p>这样一个功能对于 nginx 非常有必要，但是有时候我们会发现在执行 <code>nginx -s reload</code> 命令后，worker 子进程的数量会变多了，这是因为老的配置运行的 worker 进程长时间没有退出，当使用 stream 做四层反向代理的时候，可能这种场景会更多。</p><p>那么下面我们通过分析 nginx 的 reload 流程，来探究下 nginx 到底做了些什么？所谓优雅的退出和立即退出有什么区别？</p><h2 id="reload-流程"><a href="#reload-流程" class="headerlink" title="reload 流程"></a>reload 流程</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-26/reload1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>第一步在修改好 nginx 的配置文件 nginx.conf 后，向 master 进程发送 HUP 信号，这实际上和我们在命令行执行 <code>nginx -s reload</code> 命令效果是一样的。</p><p>那么 master 进程在收到 HUP 信号以后，会在第二步检查我们的配置文件语法是否正确，也就是说我们并不一定非要在 nginx -s reload 前执行 nginx -t 检验下语法是否正确，因为在第二步 nginx 的 master 进程一定会执行这个步骤。</p><p>在 nginx 的配置语法全部正确以后，master 进程会打开新的监听端口，为什么要在 master 进程中打开新的监听端口？因为我们可能在 nginx.conf 中会引入新的例如 443 或者之前我们没有打开的的监听端口，而所有 worker 进程是 master 进程 的子进程，子进程会继承父进程所有已经打开的端口，这是 linux 操作系统定义的，所以第三步，我们 master 进程打开了可能引入的新的监听端口。</p><p>接下来 mster 进程会用新的 nginx.conf 配置文件来启动新的 worker 子进程，那么老的 worker 子进程会怎么样呢？</p><p>我们会在第五步在启动新的 worker 子进程以后，由 master 进程再向老 worker 子进程发送 QUIT 信号，QUIT 信号和 TERM，INT 信号是不一样的，QUIT 信号是请优雅地关闭子进程，这时候需要关注顺序，因为 nginx 需要保证平滑，所以要先启动新的 worker 子进程，再向老的 worker 子进程发送 QUIT 信号。</p><p>那么老的 master 子进程收到 QUIT 信号后，首先关闭监听句柄，也就是说这个时候新的连接只会到新的 worker 子进程，所以虽然他们之间有时间差，但是时间是非常快速的，那么关闭监听句柄后，处理完当前连接后就结束进程。</p><p>下面看 reload 不停机载入新配置的图示。</p><h2 id="reload-不停机载入新配置"><a href="#reload-不停机载入新配置" class="headerlink" title="reload 不停机载入新配置"></a>reload 不停机载入新配置</h2><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-26/reload2.png" srcset="/img/loading.gif" lazyload alt=""></p><p>master 进程上原先有四个绿色的 worker 子进程，它们使用了老的配置，当我们更改了 nginx.conf 配置文件后，向 master 发送 SIGHUP 信号或者执行 reload 命令， 然后 master 会用新的配置文件启动四个新的黄色 worker 子进程，此时是四个老的绿色 worker 子进程和四个新的黄色的 worker 子进程是并存的。那么老的 worker 子进程在正常的情况下会在处理已经建立好的连接上的请求之后关闭这个连接，哪怕这个连接是 keeplive 请求也会正常关闭。</p><p>但是异常情况，如果有一些请求出现问题，客户端长时间无法处理，那么就会导致这个请求长时间停留在这个 worker 子进程当中，那么这个 worker 子进程会长时间存在，因为新的连接已经跑在黄色的 worker 子进程中，所以影响并不会很大，唯一会影响的就是绿色的 worker 子进程会长时间存在，但也只影响已存在的连接，不会影响新的连接。</p><p>我们有什么办法处理呢？在新版本中提供了一个新的配置 worker_shutdown_timeout，也就是说最长等待多长时间，这样 master 进程启动新的黄色 worker 进程之后，如果老的 worker 进程一直没有退出，时间到了之后会强制把老的 worker 进程退出掉。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> linux中inode包含什么内容？ </title>
    <link href="/2019/12/25/2019-12-25-linux-inode/"/>
    <url>/2019/12/25/2019-12-25-linux-inode/</url>
    
    <content type="html"><![CDATA[<h2 id="1、inode是什么"><a href="#1、inode是什么" class="headerlink" title="1、inode是什么"></a>1、inode是什么</h2><p>理解inode，要从文件储存说起。</p><p>文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。</p><p>操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。</p><p>文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。</p><h2 id="2、inode内容"><a href="#2、inode内容" class="headerlink" title="2、inode内容"></a>2、inode内容</h2><p>inode包含文件的元信息，具体来说有以下内容：</p><p>* 文件的字节数</p><p>* 文件拥有者的User ID</p><p>* 文件的Group ID</p><p>* 文件的读、写、执行权限</p><p>* 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。</p><p>* 链接数，即有多少文件名指向这个inode</p><p>* 文件数据block的位置</p><p>可以用stat命令，查看某个文件的inode信息：</p><p>stat example.txt</p><p>总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。</p><h2 id="3、inode的大小"><a href="#3、inode的大小" class="headerlink" title="3、inode的大小"></a>3、inode的大小</h2><p>inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。</p><p>每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。</p><p>查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">df -i<br></code></pre></div></td></tr></table></figure><p>查看每个inode节点的大小，可以用如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">sudo dumpe2fs -h /dev/hda | grep <span class="hljs-string">"Inode size"</span><br></code></pre></div></td></tr></table></figure><p>由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。</p><h2 id="4、inode号码"><a href="#4、inode号码" class="headerlink" title="4、inode号码"></a>4、inode号码</h2><p>每个inode都有一个号码，操作系统用inode号码来识别不同的文件。</p><p>这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。</p><p>使用ls -i命令，可以看到文件名对应的inode号码：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">ls -i example.txt<br></code></pre></div></td></tr></table></figure><h2 id="5、目录文件"><a href="#5、目录文件" class="headerlink" title="5、目录文件"></a>5、目录文件</h2><p>Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。</p><p>目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。</p><p>ls命令只列出目录文件中的所有文件名：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">ls /etc<br></code></pre></div></td></tr></table></figure><p>ls -i命令列出整个目录文件，即文件名和inode号码：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">ls -i /etc<br></code></pre></div></td></tr></table></figure><p>如果要查看文件的详细信息，就必须根据inode号码，访问inode节点，读取信息。ls -l命令列出文件的详细信息。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">ls -l /etc<br></code></pre></div></td></tr></table></figure><h2 id="6、硬链接"><a href="#6、硬链接" class="headerlink" title="6、硬链接"></a>6、硬链接</h2><p>一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。</p><p>ln命令可以创建硬链接：</p><p>ln 源文件 目标文件</p><p>运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。</p><p>这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）,这里的2是父目录对其的“硬链接”和当前目录下的”.硬链接“。</p><h2 id="7、软连接"><a href="#7、软连接" class="headerlink" title="7、软连接"></a>7、软连接</h2><p>除了硬链接以外，还有一种特殊情况。文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。</p><p>这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。</p><p>ln -s命令可以创建软链接。</p><p>ln -s 源文文件或目录 目标文件或目录</p><h2 id="8、inode的特殊作用"><a href="#8、inode的特殊作用" class="headerlink" title="8、inode的特殊作用"></a>8、inode的特殊作用</h2><p>由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。</p><p>\1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。</p><p>\2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。</p><p>\3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。</p><p>第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。</p><h2 id="9、实际问题"><a href="#9、实际问题" class="headerlink" title="9、实际问题"></a>9、实际问题</h2><p>在一台配置较低的Linux服务器（内存、硬盘比较小）的/data分区内创建文件时，系统提示磁盘空间不足，用df -h命令查看了一下磁盘使用情况，发现/data分区只使用了66%，还有12G的剩余空间，按理说不会出现这种问题。 后来用df -i查看了一下/data分区的索引节点(inode)，发现已经用满(IUsed=100%)，导致系统无法创建新目录和文件。</p><p><strong>查找原因：</strong></p><p>/data/cache目录中存在数量非常多的小字节缓存文件，占用的Block不多，但是占用了大量的inode。</p><p><strong>解决方案：</strong></p><p>1、删除/data/cache目录中的部分文件，释放出/data分区的一部分inode。<br>2、用软连接将空闲分区/opt中的newcache目录连接到/data/cache，使用/opt分区的inode来缓解/data分区inode不足的问题：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">ln -s /opt/newcache /data/cache<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> HTTPS 原理分析 </title>
    <link href="/2019/12/24/2019-12-24-https-principle/"/>
    <url>/2019/12/24/2019-12-24-https-principle/</url>
    
    <content type="html"><![CDATA[<p>随着 HTTPS 建站的成本下降，现在大部分的网站都已经开始用上 HTTPS 协议。大家都知道 HTTPS 比 HTTP 安全，也听说过与 HTTPS 协议相关的概念有 SSL 、非对称加密、 CA证书等，但对于以下灵魂三拷问可能就答不上了：</p><ol><li>为什么用了 HTTPS 就是安全的？</li><li>HTTPS 的底层原理如何实现？</li><li>用了 HTTPS 就一定安全吗？</li></ol><p>本文将层层深入，从原理上把 HTTPS 的安全性讲透。</p><h2 id="HTTPS-的实现原理"><a href="#HTTPS-的实现原理" class="headerlink" title="HTTPS 的实现原理"></a>HTTPS 的实现原理</h2><p>大家可能都听说过 HTTPS 协议之所以是安全的是因为 HTTPS 协议会对传输的数据进行加密，而加密过程是使用了非对称加密实现。但其实，HTTPS 在内容传输的加密上使用的是对称加密，非对称加密只作用在证书验证阶段。</p><p>HTTPS的整体过程分为证书验证和数据传输阶段，具体的交互过程如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>1、证书验证阶段</p><ul><li>浏览器发起 HTTPS 请求</li><li>服务端返回 HTTPS 证书</li><li>客户端验证证书是否合法，如果不合法则提示告警</li></ul><p>2、数据传输阶段</p><ul><li>当证书验证合法后，在本地生成随机数</li><li>通过公钥加密随机数，并把加密后的随机数传输到服务端</li><li>服务端通过私钥对随机数进行解密</li><li>服务端通过客户端传入的随机数构造对称加密算法，对返回结果内容进行加密后传输</li></ul><h2 id="为什么数据传输是用对称加密？"><a href="#为什么数据传输是用对称加密？" class="headerlink" title="为什么数据传输是用对称加密？"></a>为什么数据传输是用对称加密？</h2><p>首先，非对称加密的加解密效率是非常低的，而 http 的应用场景中通常端与端之间存在大量的交互，非对称加密的效率是无法接受的；</p><p>另外，在 HTTPS 的场景中只有服务端保存了私钥，一对公私钥只能实现单向的加解密，所以 HTTPS 中内容传输加密采取的是对称加密，而不是非对称加密。</p><h2 id="为什么需要-CA-认证机构颁发证书？"><a href="#为什么需要-CA-认证机构颁发证书？" class="headerlink" title="为什么需要 CA 认证机构颁发证书？"></a>为什么需要 CA 认证机构颁发证书？</h2><p>HTTP 协议被认为不安全是因为传输过程容易被监听者勾线监听、伪造服务器，而 HTTPS 协议主要解决的便是网络传输的安全性问题。</p><p>首先我们假设不存在认证机构，任何人都可以制作证书，这带来的安全风险便是经典的“中间人攻击”问题。“中间人攻击”的具体过程如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/2.png" srcset="/img/loading.gif" lazyload alt=""></p><p>过程原理：</p><ol><li>本地请求被劫持（如DNS劫持等），所有请求均发送到中间人的服务器</li><li>中间人服务器返回中间人自己的证书</li><li>客户端创建随机数，通过中间人证书的公钥对随机数加密后传送给中间人，然后凭随机数构造对称加密对传输内容进行加密传输</li><li>中间人因为拥有客户端的随机数，可以通过对称加密算法进行内容解密</li><li>中间人以客户端的请求内容再向正规网站发起请求</li><li>因为中间人与服务器的通信过程是合法的，正规网站通过建立的安全通道返回加密后的数据</li><li>中间人凭借与正规网站建立的对称加密算法对内容进行解密</li><li>中间人通过与客户端建立的对称加密算法对正规内容返回的数据进行加密传输</li><li>客户端通过与中间人建立的对称加密算法对返回结果数据进行解密</li></ol><p>由于缺少对证书的验证，所以客户端虽然发起的是 HTTPS 请求，但客户端完全不知道自己的网络已被拦截，传输内容被中间人全部窃取。</p><h2 id="浏览器是如何确保-CA-证书的合法性？"><a href="#浏览器是如何确保-CA-证书的合法性？" class="headerlink" title="浏览器是如何确保 CA 证书的合法性？"></a>浏览器是如何确保 CA 证书的合法性？</h2><p>1、证书包含什么信息？<br>颁发机构信息 公钥 公司信息 域名 有效期 指纹 ……</p><p>2、证书的合法性依据是什么？<br>首先，权威机构是要有认证的，不是随便一个机构都有资格颁发证书，不然也不叫做权威机构。另外，证书的可信性基于信任制，权威机构需要对其颁发的证书进行信用背书，只要是权威机构生成的证书，我们就认为是合法的。所以权威机构会对申请者的信息进行审核，不同等级的权威机构对审核的要求也不一样，于是证书也分为免费的、便宜的和贵的。</p><p>3、浏览器如何验证证书的合法性？<br>浏览器发起 HTTPS 请求时，服务器会返回网站的 SSL 证书，浏览器需要对证书做以下验证：</p><ul><li>验证域名、有效期等信息是否正确。证书上都有包含这些信息，比较容易完成验证；</li><li>判断证书来源是否合法。每份签发证书都可以根据验证链查找到对应的根证书，操作系统、浏览器会在本地存储权威机构的根证书，利用本地根证书可以对对应机构签发证书完成来源验证；</li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/3.png" srcset="/img/loading.gif" lazyload alt=""></p><ul><li>判断证书是否被篡改。需要与 CA 服务器进行校验；</li><li>判断证书是否已吊销。通过CRL（Certificate Revocation List 证书注销列表）和 OCSP（Online Certificate Status Protocol 在线证书状态协议）实现，其中 OCSP 可用于第3步中以减少与 CA 服务器的交互，提高验证效率</li></ul><p>以上任意一步都满足的情况下浏览器才认为证书是合法的。</p><blockquote><p>这里插一个我想了很久的但其实答案很简单的问题：</p><p>既然证书是公开的，如果要发起中间人攻击，我在官网上下载一份证书作为我的服务器证书，那客户端肯定会认同这个证书是合法的，如何避免这种证书冒用的情况？</p><p>其实这就是非加密对称中公私钥的用处，虽然中间人可以得到证书，但私钥是无法获取的，一份公钥是不可能推算出其对应的私钥，中间人即使拿到证书也无法伪装成合法服务端，因为无法对客户端传入的加密数据进行解密。</p></blockquote><p>4、只有认证机构可以生成证书吗？</p><p>如果需要浏览器不提示安全风险，那只能使用认证机构签发的证书。但浏览器通常只是提示安全风险，并不限制网站不能访问，所以从技术上谁都可以生成证书，只要有证书就可以完成网站的 HTTPS 传输。例如早期的 12306 采用的便是手动安装私有证书的形式实现 HTTPS 访问。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/4.png" srcset="/img/loading.gif" lazyload alt=""></p><h2 id="本地随机数被窃取怎么办？"><a href="#本地随机数被窃取怎么办？" class="headerlink" title="本地随机数被窃取怎么办？"></a>本地随机数被窃取怎么办？</h2><p>证书验证是采用非对称加密实现，但是传输过程是采用对称加密，而其中对称加密算法中重要的随机数是由本地生成并且存储于本地的，HTTPS 如何保证随机数不会被窃取？</p><p>其实 HTTPS 并不包含对随机数的安全保证，HTTPS 保证的只是传输过程安全，而随机数存储于本地，本地的安全属于另一安全范畴，应对的措施有安装杀毒软件、反木马、浏览器升级修复漏洞等。</p><h2 id="用了-HTTPS-会被抓包吗？"><a href="#用了-HTTPS-会被抓包吗？" class="headerlink" title="用了 HTTPS 会被抓包吗？"></a>用了 HTTPS 会被抓包吗？</h2><p>HTTPS 的数据是加密的，常规下抓包工具代理请求后抓到的包内容是加密状态，无法直接查看。</p><p>但是，正如前文所说，浏览器只会提示安全风险，如果用户授权仍然可以继续访问网站，完成请求。因此，只要客户端是我们自己的终端，我们授权的情况下，便可以组建中间人网络，而抓包工具便是作为中间人的代理。通常 HTTPS 抓包工具的使用方法是会生成一个证书，用户需要手动把证书安装到客户端中，然后终端发起的所有请求通过该证书完成与抓包工具的交互，然后抓包工具再转发请求到服务器，最后把服务器返回的结果在控制台输出后再返回给终端，从而完成整个请求的闭环。</p><p>既然 HTTPS 不能防抓包，那 HTTPS 有什么意义？</p><p>HTTPS 可以防止用户在不知情的情况下通信链路被监听，对于主动授信的抓包操作是不提供防护的，因为这个场景用户是已经对风险知情。要防止被抓包，需要采用应用级的安全防护，例如采用私有的对称加密，同时做好移动端的防反编译加固，防止本地算法被破解。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以下用简短的 Q&amp;A 形式进行全文总结：</p><ul><li>Q: HTTPS 为什么安全？</li></ul><p>​    A: 因为 HTTPS 保证了传输安全，防止传输过程被监听、防止数据被窃取，可以确认网站的真实性。</p><ul><li>Q: HTTPS 的传输过程是怎样的？</li></ul><p>​    A: 客户端发起 HTTPS 请求，服务端返回证书，客户端对证书进行验证，验证通过后本地生成用于改造对称加密算法的随机数，通过证书中的公钥对随机数进行加密传输到服务端，服务端接收后通过私钥解密得到随机数，之后的数据交互通过对称加密算法进行加解密。</p><ul><li>Q: 为什么需要证书？</li></ul><p>​    A: 防止”中间人“攻击，同时可以为网站提供身份证明。</p><ul><li>Q: 使用 HTTPS 会被抓包吗？</li></ul><p>​    A: 会被抓包，HTTPS 只防止用户在不知情的情况下通信被监听，如果用户主动授信，是可以构建“中间人”网络，代理软件可以对传输内容进行解密。</p><p>最后顺手分享一张学习 HTTPS  的过程图。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-24/5.png" srcset="/img/loading.gif" lazyload alt=""></p>]]></content>
    
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 云原生云景高清大图 </title>
    <link href="/2019/12/23/2019-12-23-cloudnativemap/"/>
    <url>/2019/12/23/2019-12-23-cloudnativemap/</url>
    
    <content type="html"><![CDATA[<p><strong>云原生地图</strong></p><p>Cloud Native Trail Map ，是由CNCF发布的云原生云景大图，为企业拥抱云原生指明方向，地图涵盖：容器Registry，存储，容器运行时，网络，编排系统，服务发现，服务代理，API网关，服务网格，数据库，CI/CD等。（地图最后更新时间：2019.12.29）</p><p>图片较大，加载速度较为缓慢，请耐心等待。。。</p><p>图片下载地址：链接: <a href="https://pan.baidu.com/s/1m8Gqt3Rw974P42Hcy3_jnw" target="_blank" rel="noopener">https://pan.baidu.com/s/1m8Gqt3Rw974P42Hcy3_jnw</a> 提取码: 7bc3    </p><p>(含PDF和PNG格式)</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-23/landscape.png" srcset="/img/loading.gif" lazyload alt=""></p>]]></content>
    
    
    
    <tags>
      
      <tag>CloudNative</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Nginx 原理和架构 </title>
    <link href="/2019/12/22/2019-12-22-nginx-principle/"/>
    <url>/2019/12/22/2019-12-22-nginx-principle/</url>
    
    <content type="html"><![CDATA[<h1 id="1、Nginx-的整体架构"><a href="#1、Nginx-的整体架构" class="headerlink" title="1、Nginx 的整体架构"></a>1、Nginx 的整体架构</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-22/191222principle1.png" srcset="/img/loading.gif" lazyload alt=""></p><p>Nginx 里有一个 master 进程和多个 worker 进程。master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。worker 进程负责处理网络请求与响应。</p><p><strong>1.1. 主进程</strong></p><p>master进程主要用来管理worker进程，具体包括如下4个主要功能：</p><ol><li>接收来自外界的信号。</li><li>向各worker进程发送信号。</li><li>监控woker进程的运行状态。</li><li>当woker进程退出后（异常情况下），会自动重新启动新的woker进程。</li></ol><p><strong>1.2. 工作进程</strong></p><p>woker进程主要用来处理基本的网络事件：</p><ol><li>多个worker进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。</li><li>一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</li><li>worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致。同时，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。</li></ol><p><strong>1.3. 模块化设计</strong></p><p>Nginx的worker进程，包括核心和功能性模块，核心模块负责维持一个运行循环 （ run-loop ），执行网络请求处理的 不同阶段 的模块功能。</p><p>比如： 网络读写 、 存储读写、 内容传输 、 外出过滤 ，以及将请求发往上游服务器等。</p><p>而其代码的模块化设计 ，也使得我们可以根据需要对 功能模块 进行适当的 选择 和 修改 ，编译成具有 特定功能的服务器。</p><p><strong>1.4. 事件驱动模型</strong></p><p>基于 异步及非阻塞的事件驱动模型 ，可以说是 Nginx 得以获得高并发、高性能的关键因素，同时也得益于对 Linux 、 Solaris 及类 BSD 等操作系统内核中 事件通知 及 I/O 性能增强功能 的采用，如 kqueue 、 epoll 及 event ports 。</p><p><strong>1.5. 代理（proxy）设计</strong></p><p>代理设计，可以说是 Nginx 深入骨髓的设计，无论是对于 HTTP ，还是对于 FastCGI 、 Memcache 、 Redis 等的网络请求或响应，本质上都采用了 代理机制 。所以， Nginx 天生就是高性能的 代理服务器 。</p><h1 id="2、Nginx的模块化设计"><a href="#2、Nginx的模块化设计" class="headerlink" title="2、Nginx的模块化设计"></a>2、Nginx的模块化设计</h1><p>高度模块化的设计是 Nginx 的架构基础。Nginx 服务器被分解为多个模块 ，每个模块就是一个功能模块 ，只负责自身的功能，模块之间严格遵循 “高内聚，低耦合” 的原则。</p><p>如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-22/191222principle2.png" srcset="/img/loading.gif" lazyload alt=""></p><p><strong>2.1. 核心模块</strong></p><p>核心模块是 Nginx 服务器正常运行 必不可少的模块，提供错误日志记录 、 配置文件解析 、 事件驱动机制 、 进程管理 等核心功能。</p><p><strong>2.2. 标准HTTP模块</strong></p><p>标准 HTTP 模块提供 HTTP 协议解析相关的功能，比如： 端口配置 、 网页编码设置 、 HTTP响应头设置 等等。</p><p><strong>2.3. 可选HTTP模块</strong></p><p>可选 HTTP 模块主要用于 扩展 标准的 HTTP 功能，让 Nginx 能处理一些特殊的服务，比如：Flash 多媒体传输 、解析 GeoIP 请求、 网络传输压缩 、 安全协议 SSL 支持等。</p><p><strong>2.4. 邮件服务模块</strong></p><p>邮件服务模块主要用于支持 Nginx 的 邮件服务 ，包括对 POP3 协议、 IMAP 协议和 SMTP协议的支持。</p><p><strong>2.5. 第三方模块</strong></p><p>第三方模块是为了扩展 Nginx 服务器应用，完成开发者自定义功能，比如：Json 支持、 Lua 支持等。</p><h1 id="3、Nginx的请求方式处理"><a href="#3、Nginx的请求方式处理" class="headerlink" title="3、Nginx的请求方式处理"></a>3、Nginx的请求方式处理</h1><p>Nginx 是一个 高性能 的 Web 服务器，能够同时处理大量的并发请求 。它结合多进程机制和 异步机制 ，异步机制使用的是 异步非阻塞方式 ，接下来就给大家介绍一下 Nginx 的 多线程机制 和 异步非阻塞机制 。</p><p><strong>3.1. 多进程机制</strong></p><p>服务器每当收到一个客户端时，就有 服务器主进程 （ master process ）生成一个 子进程（ worker process ）出来和客户端建立连接进行交互，直到连接断开，该子进程就结束了。</p><p>使用 进程 的好处是 各个进程之间相互独立 ， 不需要加锁 ，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发成本。</p><p>其次，采用独立的进程，可以让 进程互相之间不会影响 ，如果一个进程发生异常退出时，其它进程正常工作， master 进程则很快启动新的 worker 进程，确保服务不会中断，从而将风险降到最低。</p><p>缺点是操作系统生成一个 子进程 需要进行 内存复制 等操作，在 资源 和 时间 上会产生一定的开销。当有 大量请求 时，会导致 系统性能下降 。</p><p><strong>3.2. 异步非阻塞机制</strong></p><p>每个 工作进程 使用 异步非阻塞方式 ，可以处理多个客户端请求 。</p><p>当某个 工作进程 接收到客户端的请求以后，调用 IO 进行处理，如果不能立即得到结果，就去处理其他请求 （即为非阻塞 ），而客户端在此期间也无需等待响应 ，可以去处理其他事情（即为异步 ）</p><p>当 IO 返回时，就会通知此工作进程，该进程得到通知，暂时挂起当前处理的事务去 响应客户端请求 。</p><h1 id="4、Nginx事件驱动模型"><a href="#4、Nginx事件驱动模型" class="headerlink" title="4、Nginx事件驱动模型"></a>4、Nginx事件驱动模型</h1><p>在 Nginx 的 异步非阻塞机制 中， 工作进程在调用 IO 后，就去处理其他的请求，当 IO 调用返回后，会通知该工作进程 。</p><p>对于这样的系统调用，主要使用 Nginx 服务器的<strong>事件驱动模型</strong>来实现，如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-22/191222principle3.png" srcset="/img/loading.gif" lazyload alt=""></p><p>如上图所示， Nginx 的 事件驱动模型 由 事件收集器 、 事件发送器 和 事件处理器 三部分基本单元组成。</p><ul><li><strong>事件收集器</strong>：负责收集 worker 进程的各种 IO 请求；</li><li><strong>事件发送器</strong>：负责将 IO 事件发送到 事件处理器 ；</li><li><strong>事件处理器</strong>：负责各种事件的 响应工作 。</li></ul><p>事件发送器将每个请求放入一个 待处理事件列表 ，使用非阻塞 I/O 方式调用 事件处理器来处理该请求。</p><p>其处理方式称为 “多路 IO 复用方法” ，常见的包括以下三种：select 模型、 poll模型、 epoll 模型。</p><h1 id="5、Nginx进程处理模型"><a href="#5、Nginx进程处理模型" class="headerlink" title="5、Nginx进程处理模型"></a>5、Nginx进程处理模型</h1><p>Nginx 服务器使用 <strong>master/worker</strong> 多进程模式，多线程启动和执行的流程如下：</p><ol><li>主程序Master process启动后，通过一个 for 循环来接收和处理外部信号</li></ol><ol start="2"><li>主进程通过 fork() 函数产生 worker 子进程 ，每个 子进程 执行一个 for 循环来实现 Nginx 服务器 对事件的接收 和 处理 </li></ol><p>一般推荐 worker 进程数 与 CPU 内核数 一致，这样一来不存在 大量的子进程 生成和管理任务，避免了进程之间 竞争 CPU 资源 和 进程切换 的开销。</p><p>而且 Nginx 为了更好的利用 多核特性 ，提供了 CPU 亲缘性 的绑定选项，我们可以将某 一个进程绑定在某一个核上，这样就不会因为 进程的切换 带来 Cache 的失效。</p><p>对于每个请求，有且只有一个 工作进程 对其处理。首先，每个 worker 进程都是从 master进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket（listenfd） 之后，然后再 fork 出多个 worker 进程。</p><p>所有 worker 进程的 listenfd 会在 新连接 到来时变得 可读 ，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢占 accept_mutex </p><p>抢到 互斥锁 的那个进程注册 listenfd 读事件 ，在读事件里调用 accept 接受该连接。</p><p>当一个 worker 进程在 accept 这个连接之后，就开始读取请求 ， 解析请求 ， 处理请求，产生数据后，再返回给客户端 ，最后才断开连接 ，一个完整的请求就是这样。</p><p>我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。</p><p>如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-22/191222principle4.png" srcset="/img/loading.gif" lazyload alt=""></p><p>在 Nginx 服务器的运行过程中， 主进程 和 工作进程 需要进程交互。交互依赖于 Socket 实现的管道来实现。</p><p><strong>5.1. 主进程与工作进程交互</strong></p><p>这条管道与普通的管道不同，它是由 主进程 指向 工作进程 的单向管道 ，包含主进程向工作进程发出的指令工，作进程 ID 等。同时主进程与外界通过信号通信 ；每个子进程具备接收信号 ，并处理相应的事件的能力。</p><p><strong>5.2. 工作进程与工作进程交互</strong></p><p>这种交互和 主进程-工作进程 交互基本一致，但是会通过主进程间接完成，工作进程之间是相互隔离的。</p><p>所以当工作进程 W1 需要向工作进程 W2 发指令时，首先找到 W2 的 进程ID ，然后将正确的指令写入指向 W2 的 通道，W2 收到信号采取相应的措施。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 运维工程师必知必会的一些定律 </title>
    <link href="/2019/12/21/2019-12-21-operation-law/"/>
    <url>/2019/12/21/2019-12-21-operation-law/</url>
    
    <content type="html"><![CDATA[<h1 id="墨菲定律"><a href="#墨菲定律" class="headerlink" title="墨菲定律"></a>墨菲定律</h1><p><strong>墨菲定律</strong>，指的是小概率事情，只要某件事情发生概率不为0，如果样本数足够多，那么这个事情最终会发生。</p><h1 id="海恩法则"><a href="#海恩法则" class="headerlink" title="海恩法则"></a>海恩法则</h1><p><strong>海恩法则</strong>，每一起严重事故的背后，必然有29次轻微事故和300起未遂先兆以及1000起事故隐患。法则强调两点：一是事故的发生是量的积累的结果；二是再好的技术，再完美的规章，在实际操作层面，也无法取代人自身的素质和责任心。</p><p>结合上面的墨菲定律，是不是所有的事故隐患都需要立即处理，都需要当做非常重要的事情呢？答案是否定的，有如下两点考虑：</p><ul><li>不是所有轻微事故的原因都能导致严重事故，因此需要对事故原因进行深入分析，重点放在可能导致严重事故的那部分上。</li><li>事不过三，如果一个问题已经发生了两次，不论概率大小，一定会发生第三次时，那么不管是否为轻微事故，都需要着手处理。</li></ul><h1 id="因果连锁理论"><a href="#因果连锁理论" class="headerlink" title="因果连锁理论"></a>因果连锁理论</h1><p><strong>因果连锁理论</strong>，伤亡事故的发生不是一个孤立的事件，尽管伤害可能在某瞬间突然发生，却是一系列事件相继发生的结果。也称为多米诺骨牌理论。</p><p>从因果连锁理论我们也可以引申出运维的两点内容，首先运维是整个系统可用性保障的最后一道门槛，如果这道门槛不轻易倒下，那么系统的可用性就能够得到保障；其次，需要更宏观的来看系统的可用性保障，不仅仅是运维，还有测试，研发，只要有一个环节能够拦截故障，那么故障就不会真正的发生。所以，我们既要加强自身的能力建设，同时，也需要和研发，测试更好的合作，从而降低最后一道门槛的压力。</p><h1 id="二八定律"><a href="#二八定律" class="headerlink" title="二八定律"></a>二八定律</h1><p><strong>二八定律</strong>，在任何一组东西中，最重要的只占其中一小部分，约20%，其余80%尽管是多数，却是次要的，也成为关键少数法则。</p><p>二八定律在运维中是非常重要的，举几个例子，大家举一反三，多找找运维领域中符合二八定律的场景。</p><ul><li>80%的广告收入由20%的业务贡献，那么在资源有限的情况下，通过保证这20%的业务可用性，就可以确保收入不会出现较大损失</li><li>80%的报警由少数无效策略导致，那么只要优化这些策略，就可以大幅减少报警数量</li></ul><h1 id="帕金森定律和布鲁克斯法则"><a href="#帕金森定律和布鲁克斯法则" class="headerlink" title="帕金森定律和布鲁克斯法则"></a>帕金森定律和布鲁克斯法则</h1><p><strong>帕金森定理 ：</strong>只要还有时间，工作就会不断扩展，直到用完所有的时间</p><p><strong>布鲁克斯法则 ：</strong>向进度落后的项目中增加人手，只会使项目更加落后</p><p>基于上面的两个法则，留给大家的一个思考题，在实际的工作中，如果基础运维出现较大问题，作为团队的负责人，你应该怎么办？笔者列举了几种不太认可的方法：</p><ul><li>将一二线运维分离，确保基础运维工作不会扩散到二线运维团队中，一线运维确保其人员规模在一定范围，及时补充，然后看一线运维中是否有人能够脱颖而出</li><li>暂停各类项目，全员投入到基础运维中</li><li>给基础运维团队足够的HC，快速招人来解决问题</li></ul><h1 id="一万小时定律"><a href="#一万小时定律" class="headerlink" title="一万小时定律"></a>一万小时定律</h1><p><strong>一万小时定律</strong>，要成为某个领域的专家，需要10000小时。按比例计算就是：如果每天工作八个小时，一周工作五天，那么成为一个领域的专家需要五年。不管你信不信，反正有人是相信了，日复一日的重复着枯燥乏味的工作，幻想着自己只要坚持一万小时，就能够成为这个领域的专家。</p><h1 id="根因分析法"><a href="#根因分析法" class="headerlink" title="根因分析法"></a>根因分析法</h1><p><strong>根因分析法</strong>，也称为5why分析法，在故障复盘中，对于我个人始终强调的“一次性的投入，持续彻底的解决一类问题”是非常有用的，通过不断的提问，寻找出真正的根因，才有彻底解决问题的可能。</p><p>所谓5why分析法，又称“5问法”，也就是对一个问题点连续以5个“为什么”来自问，以追究其根本原因。虽为5个为什么，但使用时不限定只做“5次为什么的探讨”，主要是必须找到根本原因为止，有时可能只要3次，有时也许要10次，如古话所言：打破砂锅问到底。5why法的关键所在：鼓励解决问题的人要努力避开主观或自负的假设和逻辑陷阱，从结果着手，沿着因果关系链条，顺藤摸瓜，直至找出原有问题的根本原因。</p>]]></content>
    
    
    
    <tags>
      
      <tag>运维定律</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Linux find命令教程：15个find命令用法 </title>
    <link href="/2019/12/20/2019-12-20-linux-find/"/>
    <url>/2019/12/20/2019-12-20-linux-find/</url>
    
    <content type="html"><![CDATA[<h1 id="查找目录"><a href="#查找目录" class="headerlink" title="查找目录"></a>查找目录</h1><p>您可以使用-type d选项告诉find命令专门查找目录。这将使find命令仅搜索匹配的目录名，而不搜索文件名。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> d -name <span class="hljs-string">"name-of-dir"</span><br></code></pre></div></td></tr></table></figure><p>#查找隐藏文件</p><p>由于Linux中的隐藏文件和目录以句点开头，因此我们可以在搜索字符串中指定此搜索模式，以便递归列出隐藏的文件和目录。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -name <span class="hljs-string">".*"</span><br></code></pre></div></td></tr></table></figure><p>#查找特定大小或大于X的文件</p><p>find的-size选项允许我们搜索特定大小的文件。它可用于查找确切大小的文件，大于或小于特定大小的文件或适合指定大小范围的文件。以下有些例子：<br>搜索大于10MB的文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -size +10M<br></code></pre></div></td></tr></table></figure><p>搜索小于10MB的文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -size -10M<br></code></pre></div></td></tr></table></figure><p>搜索大小恰好为10MB的文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -size 10M<br></code></pre></div></td></tr></table></figure><p>搜索大小在100MB到1GB之间的文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -size +100M -size -1G<br></code></pre></div></td></tr></table></figure><h1 id="从文件列表中查找"><a href="#从文件列表中查找" class="headerlink" title="从文件列表中查找"></a>从文件列表中查找</h1><p>如果您有需要搜索的文件列表（例如，在.txt文件中），则可以使用find和grep命令的组合来搜索文件列表。为了使此命令起作用，只需确保要搜索的每个模式之间都用换行符隔开。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search | grep -f filelist.txt<br></code></pre></div></td></tr></table></figure><p>grep的-f选项表示“file”，并允许我们指定要匹配的字符串文件。这导致find命令返回与列表中的文件或目录名称匹配的任何文件或目录名称。</p><h1 id="不在列表中查找"><a href="#不在列表中查找" class="headerlink" title="不在列表中查找"></a>不在列表中查找</h1><p>使用上一个示例中提到的相同文件列表，您还可以使用find来搜索与文本文件内的模式不符的任何文件。再一次，我们将结合使用find和grep命令；我们只需要用grep指定一个附加选项：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search | grep -f filelist.txt<br></code></pre></div></td></tr></table></figure><p>grep的-v选项表示“逆向匹配”，并且将返回与文件列表中指定的任何模式都不匹配的文件列表。</p><h1 id="设置maxdepth"><a href="#设置maxdepth" class="headerlink" title="设置maxdepth"></a>设置maxdepth</h1><p>find命令默认将进行递归搜索。这意味着它将在指定的目录中搜索您指定的模式，以及您告诉它要搜索的目录中的所有子目录。<br>例如，如果告诉find搜索Linux（/）的根目录，则无论存在多少个子目录，它都会搜索整个硬盘。您可以使用-maxdepth选项来规避此行为。<br>在-maxdepth之后指定一个数字，以指示查找应递归搜索的子目录数。<br>仅搜索当前目录中的文件，而不递归搜索：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find . -maxdepth 0 -name <span class="hljs-string">"myfile.txt"</span><br></code></pre></div></td></tr></table></figure><p>仅在当前目录和更深的一个子目录中搜索文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find . -maxdepth 1 -name <span class="hljs-string">"myfile.txt"</span><br></code></pre></div></td></tr></table></figure><h1 id="查找空文件（零长度）"><a href="#查找空文件（零长度）" class="headerlink" title="查找空文件（零长度）"></a>查找空文件（零长度）</h1><p>要使用find搜索空文件，可以使用-empty标志。搜索所有空文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -empty<br></code></pre></div></td></tr></table></figure><p>搜索所有空目录：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> d -empty<br></code></pre></div></td></tr></table></figure><p>如果希望自动删除find返回的空文件或目录，那么将此命令与-delete选项结合使用也非常方便。<br>删除目录（和子目录）中的所有空文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -empty -delete<br></code></pre></div></td></tr></table></figure><h1 id="查找最大的目录或文件"><a href="#查找最大的目录或文件" class="headerlink" title="查找最大的目录或文件"></a>查找最大的目录或文件</h1><p>如果您想快速确定系统上哪些文件或目录占用了最多的空间，则可以使用find进行递归搜索，并按文件和目录的大小输出排序的列表。<br>如何显示目录中最大的文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -<span class="hljs-built_in">printf</span> <span class="hljs-string">"%s\t%p\n"</span> | sort -n | tail -1<br></code></pre></div></td></tr></table></figure><p>请注意，find命令已被排序到另外两个方便的Linux实用程序：sort和tail。 Sort将按文件的大小顺序排列文件列表，而tail将仅输出列表中的最后一个文件，该文件也是最大的。<br>如果您要输出例如最大的前5个文件，则可以调整tail命令。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -<span class="hljs-built_in">printf</span> <span class="hljs-string">"%s\t%p\n"</span> | sort -n | tail -5<br></code></pre></div></td></tr></table></figure><p>或者，您可以使用head命令来确定最小的文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -<span class="hljs-built_in">printf</span> <span class="hljs-string">"%s\t%p\n"</span> | sort -n | head -5<br></code></pre></div></td></tr></table></figure><p>如果要搜索目录而不是文件，只需在类型选项中指定“ d”即可。如何显示最大目录：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> d -<span class="hljs-built_in">printf</span> <span class="hljs-string">"%s\t%p\n"</span> | sort -n | tail -1<br></code></pre></div></td></tr></table></figure><h1 id="查找setuid设置文件"><a href="#查找setuid设置文件" class="headerlink" title="查找setuid设置文件"></a>查找setuid设置文件</h1><p>Setuid是“set user ID on execution”的缩写，它是一种文件权限，允许普通用户运行具有升级特权（例如root）的程序。<br>出于明显的原因，这可能是一个安全问题，但是可以使用find命令和一些选项轻松隔离这些文件。<br>find命令有两个选项可帮助我们搜索具有特定权限的文件：-user和-perm。要查找普通用户能够以root特权执行的文件，可以使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -user root -perm /4000<br></code></pre></div></td></tr></table></figure><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-20/setuid.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>在上面的屏幕截图中，我们包含了-exec选项，以便显示有关查找返回文件的更多输出。整个命令如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -user root -perm /4000 -<span class="hljs-built_in">exec</span> ls -l &#123;&#125; \;<br></code></pre></div></td></tr></table></figure><p>您也可以在此命令中用“ root”代替您要作为所有者搜索的任何其他用户。或者，您可以搜索具有SUID权限的所有文件，而根本不指定一个用户：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -perm /4000<br></code></pre></div></td></tr></table></figure><h1 id="查找sgid设置文件"><a href="#查找sgid设置文件" class="headerlink" title="查找sgid设置文件"></a>查找sgid设置文件</h1><p>查找具有SGID设置的文件与查找具有SUID的文件几乎相同，只是需要将4000的权限更改为2000：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -perm /2000<br></code></pre></div></td></tr></table></figure><p>您还可以通过在perms选项中指定6000来搜索，同时设置了SUID和SGID的文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -perm /6000<br></code></pre></div></td></tr></table></figure><h1 id="列出文件未经允许被拒绝"><a href="#列出文件未经允许被拒绝" class="headerlink" title="列出文件未经允许被拒绝"></a>列出文件未经允许被拒绝</h1><p>使用find命令搜索文件时，您必须对要搜索的目录和子目录具有读取权限。如果您没有找到，find将输出一条错误消息，但会继续浏览您确实拥有权限的目录。<br>没有权限尽管这可能发生在许多不同的目录中，但在搜索根目录时肯定会发生。<br>这意味着，当您尝试在整个硬盘上搜索文件时，find命令将产生大量错误消息。<br>为避免看到这些错误，您可以将find的stderr输出重定向到stdout，并将其通过管道传递到grep。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find / -name <span class="hljs-string">"myfile.txt"</span> 2&gt;%1 | grep -v <span class="hljs-string">"Permission denied"</span><br></code></pre></div></td></tr></table></figure><p>此命令使用grep的-v（反向）选项来显示所有输出，除了显示“拒绝权限”之外的所有输出。</p><h1 id="在最近X天内查找修改过的文件"><a href="#在最近X天内查找修改过的文件" class="headerlink" title="在最近X天内查找修改过的文件"></a>在最近X天内查找修改过的文件</h1><p>使用find命令上的-mtime选项搜索最近X天内被修改的文件或目录。它也可以用于搜索X天之前的文件，或X天之前被完全修改过的的文件。<br>以下是一些如何在find命令上使用-mtime选项的示例：<br>搜索最近30天内修改过的所有文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -mtime -30<br></code></pre></div></td></tr></table></figure><p>搜索超过30天之前已修改的所有文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -mtime +30<br></code></pre></div></td></tr></table></figure><p>搜索30天前刚修改过的所有文件：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -mtime 30<br></code></pre></div></td></tr></table></figure><p>如果希望find命令输出有关找到的文件的更多信息，例如修改日期，则可以使用-exec选项并包含ls命令：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">type</span> f -mtime -30 -<span class="hljs-built_in">exec</span> ls -l &#123;&#125; \;<br></code></pre></div></td></tr></table></figure><h1 id="按时间排序"><a href="#按时间排序" class="headerlink" title="按时间排序"></a>按时间排序</h1><p>要按文件的修改时间对查找结果进行排序，您可以使用-printf选项以可排序的方式列出时间，然后将其输出到sort实用程序。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">printf</span> <span class="hljs-string">"%T+\t%p\n"</span> | sort<br></code></pre></div></td></tr></table></figure><p>此命令将对旧的文件进行排序。如果您希望较新的文件首先显示，只需传递-r（反向）选项即可进行排序。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ find /path/to/search -<span class="hljs-built_in">printf</span> <span class="hljs-string">"%T+\t%p\n"</span> | sort -r<br></code></pre></div></td></tr></table></figure><h1 id="定位和查找之间的区别"><a href="#定位和查找之间的区别" class="headerlink" title="定位和查找之间的区别"></a>定位和查找之间的区别</h1><p>Linux上的locate命令是搜索系统上文件的另一种好方法。它没有像find命令那样包含过多的搜索选项，因此它的灵活性较差，但仍然很方便。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ locate myfile.txt<br></code></pre></div></td></tr></table></figure><p>locate命令通过搜索包含系统上所有文件名的数据库来工作。搜索到的数据库已使用upatedb命令进行更新。<br>由于locate命令不必实时搜索系统上的所有文件，因此它比find命令效率更高。但是，除了缺少选项之外，还有另一个缺点：文件数据库每天仅更新一次。<br>您可以通过运行updatedb命令手动更新此文件数据库：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ updatedb<br></code></pre></div></td></tr></table></figure><p>当您需要在整个硬盘驱动器中搜索文件时，locate命令特别有用，因为find命令自然需要更长的时间，因为它必须实时遍历每个目录。<br>如果搜索一个特定目录（已知其中不包含大量子目录），则最好坚持使用find命令。</p><h1 id="find命令的CPU负载"><a href="#find命令的CPU负载" class="headerlink" title="find命令的CPU负载"></a>find命令的CPU负载</h1><p>在搜索大量目录时，find命令可能会占用大量资源。它本来应该允许更重要的系统进程具有优先级，但是如果需要确保find命令占用生产服务器上的较少资源，则可以使用ionice或nice命令。<br>监视find命令的CPU使用情况：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ top<br></code></pre></div></td></tr></table></figure><p>降低find命令的输入/输出优先级：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ ionice -c3 -n7 find /path/to/search -name <span class="hljs-string">"myfile.txt"</span><br></code></pre></div></td></tr></table></figure><p>降低find命令的CPU优先级：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ nice -n 19 find /path/to/search -name <span class="hljs-string">"myfile.txt"</span><br></code></pre></div></td></tr></table></figure><p>或结合使用这两个实用程序以真正确保低I / O和低CPU优先级：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ nice -n ionice -c2 -n7 find /path/to/search -name <span class="hljs-string">"myfile.txt"</span><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Nginx的这些妙用，你肯定有不知道的 </title>
    <link href="/2019/12/19/2019-12-19-nginx-usage/"/>
    <url>/2019/12/19/2019-12-19-nginx-usage/</url>
    
    <content type="html"><![CDATA[<h1 id="Nginx-简介"><a href="#Nginx-简介" class="headerlink" title="Nginx 简介"></a>Nginx 简介</h1><p>Nginx 是一个免费、开源、高性能、轻量级的 HTTP 和反向代理服务器，也是一个电子邮件（IMAP/POP3）代理服务器，其特点是占有内存少，并发能力强。</p><p>Nginx 由内核和一系列模块组成，内核提供 Web 服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。</p><p>Nginx 的各种功能和操作都由模块来实现。Nginx 的模块从结构上分为：</p><ul><li><strong>核心模块：</strong>HTTP 模块、EVENT 模块和 MAIL 模块。</li><li><strong>基础模块：</strong>HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite 模块。</li><li><strong>第三方模块：</strong>HTTP Upstream Request Hash 模块、Notice 模块和 HTTP Access Key 模块及用户自己开发的模块。</li></ul><p>这样的设计使 Nginx 方便开发和扩展，也正因此才使得 Nginx 功能如此强大。</p><p>Nginx 的模块默认编译进 Nginx 中，如果需要增加或删除模块，需要重新编译 Nginx，这一点不如 Apache 的动态加载模块方便。</p><p>如果有需要动态加载模块，可以使用由淘宝网发起的 Web 服务器 Tengine，在 Nginx 的基础上增加了很多高级特性，完全兼容 Nginx，已被国内很多网站采用。</p><p>Nginx 有很多扩展版本：</p><ul><li><p><strong>开源版 nginx.org</strong></p></li><li><p><strong>商业版 NGINX Plus</strong></p></li><li><p><strong>淘宝网发起的 Web 服务器 Tengine</strong></p></li><li><p><strong>基于 Nginx 和 Lua 的 Web 平台 OpenResty</strong></p></li></ul><h1 id="Nginx-作为-Web-服务器"><a href="#Nginx-作为-Web-服务器" class="headerlink" title="Nginx 作为 Web 服务器"></a>Nginx 作为 Web 服务器</h1><p>Web 服务器也称为 WWW（World Wide Web）服务器，主要功能是提供网上信息浏览服务，常常以 B/S（Browser/Server）方式提供服务：</p><ul><li><strong>应用层使用 HTTP 协议。</strong></li><li><strong>HTML 文档格式。</strong></li><li><strong>浏览器统一资源定位器(URL)。</strong></li></ul><p>Nginx 可以作为静态页面的 Web 服务器，同时还支持 CGI 协议的动态语言，比如 Perl、PHP 等，但是不支持 Java。</p><p>Java 程序一般都通过与 Tomcat 配合完成。作为一名 Java 程序员，肯定要理解下 Nginx 和 Tomcat 的区别了。</p><p>Nginx、Apache 和 Tomcat：</p><ul><li><p><strong>Nginx：</strong>由俄罗斯程序员 Igor Sysoev 所开发的轻量级、高并发 HTTP 服务器。</p></li><li><p><strong>Apache HTTP Server Project：</strong>一个 Apache 基金会下的 HTTP 服务项目，和 Nginx 功能类似。</p></li><li><p><strong>Apache Tomcat：</strong>是 Apache 基金会下的另外一个项目，是一个 Application Server。</p><p>更准确的说是一个 Servlet 应用容器，与 Apache HTTP Server 和 Nginx 相比，Tomcat 能够动态的生成资源并返回到客户端。</p></li></ul><p>Apache HTTP Server 和 Nginx 本身不支持生成动态页面，但它们可以通过其他模块来支持（例如通过 Shell、PHP、Python 脚本程序来动态生成内容）。</p><p>一个 HTTP Server 关心的是 HTTP 协议层面的传输和访问控制，所以在 Apache/Nginx 上你可以看到代理、负载均衡等功能。</p><p>客户端通过 HTTP Server 访问服务器上存储的资源（HTML 文件、图片文件等等）。</p><p>通过 CGI 技术，也可以将处理过的内容通过 HTTP Server 分发，但是一个 HTTP Server 始终只是把服务器上的文件如实的通过 HTTP 协议传输给客户端。</p><p>而应用服务器，则是一个应用执行的容器。它首先需要支持开发语言的运行（对于 Tomcat 来说，就是 Java），保证应用能够在应用服务器上正常运行。</p><p>其次，需要支持应用相关的规范，例如类库、安全方面的特性。对于 Tomcat 来说，就是需要提供 JSP/Sevlet 运行需要的标准类库、Interface 等。</p><p>为了方便，应用服务器往往也会集成 HTTP Server 的功能，但是不如专业的 HTTP Server 那么强大。</p><p>所以应用服务器往往是运行在 HTTP Server 的背后，执行应用，将动态的内容转化为静态的内容之后，通过 HTTP Server 分发到客户端。</p><h2 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h2><p><strong>正向代理：</strong>如果把局域网外的 Internet 想象成一个巨大的资源库，则局域网中的客户端要访问 Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。</p><p>正向代理“代理”的是客户端。比如你想去 Google 看个“动作片”，可国内不允许呀，就需要找翻墙代理，这个就是所谓的“正向代理”。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/1.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h2 id="反向代理与负载均衡"><a href="#反向代理与负载均衡" class="headerlink" title="反向代理与负载均衡"></a>反向代理与负载均衡</h2><p>反向代理正好与正向代理相反，反向代理是指以代理服务器来接收 Internet 上的连接请求，然后将请求转发到内部网络上的服务器，并将服务器上得到的结果返回给客户端。</p><p>此时代理服务器对外表现就是一个服务器，客户端对代理是无感知的。反向代理“代理”的是服务端。</p><p>再比如，你想本本分分的在“优酷”上看个“爱情片”，youku.com 会把你的请求分发到存放片片的那台机器上，这个就是所谓的“反向代理”。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>为什么使用反向代理，原因如下：</p><ul><li><strong>保护和隐藏原始资源服务器</strong></li><li><strong>加密和 SSL 加速</strong></li><li><strong>通过缓存静态资源，加速 Web 请求</strong></li><li><strong>实现负载均衡</strong></li></ul><p><strong>负载均衡：</strong>TODO: 留一个负载均衡详细介绍传送门。</p><p><strong>地址重定向：</strong>Nginx 的 Rewrite 主要的功能就是实现 URL 重写，比如输入 360.com  跳转到了 360.cn，baidu.cn 跳转到了 baidu.com。</p><h2 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h2><p>为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。</p><p>这里指的就是让动态程序（Java、PHP）去访问应用服务器，让缓存、图片、JS、CSS 等去访问 Nginx。</p><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>nginx.conf 配置文件主要分为三部分：</p><ul><li><strong>全局块</strong></li><li><strong>Events 块</strong></li><li><strong>HTTPS 块</strong></li></ul><p>Nginx 配置语法：</p><ul><li>配置文件由指令和指令块构成</li><li>每条指令以分号（;）结尾，指令和参数间以空格符分隔</li><li>指令块以大括号{}将多条指令组织在一起</li><li>include 语句允许组合多个配置文件以提高可维护性</li><li>使用 # 添加注释</li><li>使用 $ 定义变量</li><li>部分指令的参数支持正则表达式</li></ul><h3 id="全局块"><a href="#全局块" class="headerlink" title="全局块"></a>全局块</h3><p>全局配置部分用来配置对整个 Server 都有效的参数。主要会设置一些影响 Nginx 服务器整体运行的配置指令，包括配置运行 Nginx 服务器的用户（组）、允许生成的 Worker Process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。</p><p>示例如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">user nobody;<br>worker_processes  4;<br>error_log  /data/nginx/logs/error.log  notice;<br></code></pre></div></td></tr></table></figure><h3 id="Events-块"><a href="#Events-块" class="headerlink" title="Events 块"></a>Events 块</h3><p>Events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 Work Process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 Word Process 可以同时支持的最大连接数等。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">events &#123;<br>    <span class="hljs-comment">#每个 work process 支持的最大连接数为 1024.</span><br>    worker_connections  1024;<br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="HTTP-块"><a href="#HTTP-块" class="headerlink" title="HTTP 块"></a>HTTP 块</h3><p>这算是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 需要注意的是：HTTP 块也可以包括 HTTP 全局块、Server 块。</p><p><strong>①HTTP 全局块</strong></p><p>HTTP 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">http &#123;<br>    include       mime.types;<br>    default_type  application/octet-stream;<br>    sendfile        on;<br>    keepalive_timeout  65;<br></code></pre></div></td></tr></table></figure><p><strong>②Server 块</strong></p><p>这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。</p><p>每个 HTTP 块可以包括多个 Server 块，而每个 Server 块就相当于一个虚拟主机。</p><p>而每个 Server 块也分为全局 Server 块，以及可以同时包含多个 Locaton 块。</p><p><strong>全局 Server 块：</strong>也被叫做“虚拟服务器”部分，它描述的是一组根据不同server_name指令逻辑分割的资源，这些虚拟服务器响应 HTTP 请求，因此都包含在 HTTP 部分。</p><p>最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">server &#123;<br>  listen       80;<br>  <span class="hljs-comment">#server_name也支持通配符，*.example.com、www.example.*、.example.com</span><br>  server_name  localhost;<br>  <span class="hljs-comment">#charset koi8-r;</span><br>  <span class="hljs-comment">#access_log  logs/host.access.log  main;</span><br></code></pre></div></td></tr></table></figure><p><strong>Location 块：</strong>一个 Server 块可以配置多个 Location 块。</p><p>这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称 （也可以是 IP 别名）之外的字符串（例如前面的 /uri-string）进行匹配，对特定的请求进行处理。</p><p>地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。</p><p><strong>Location 指令说明：</strong>该指令用于匹配 URL。</p><p>语法如下：</p><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">location</span> [ = | <span class="hljs-regexp">~ |</span> <span class="hljs-regexp">~* |</span><span class="hljs-regexp"> ^~]</span> uri&#123;&#125;<br></code></pre></div></td></tr></table></figure><ul><li><strong>= ：</strong>该修饰符使用精确匹配并且终止搜索。</li><li><strong>~：</strong>该修饰符使用区分大小写的正则表达式匹配。</li><li><strong>~*：</strong>该修饰符使用不区分大小写的正则表达式匹配。</li><li><strong>^~：</strong>用于不含正则表达式的 URI 前，要求 Nginx 服务器找到标识 URI 和请求字符串匹配度最高的 Location 后，立即使用此 Location 处理请求，而不再使用 Location 块中的正则 URI 和请求字符串做匹配。</li></ul><p>?&gt;Tip 注意：如果 URI 包含正则表达式，则必须要有 ~ 或者 ~* 标识。</p><p>当一个请求进入时，URI 将会被检测匹配一个最佳的 Location：</p><ul><li>没有正则表达式的 Location 被作为最佳的匹配，独立于含有正则表达式的 Location 顺序。</li><li>在配置文件中按照查找顺序进行正则表达式匹配。在查找到第一个正则表达式匹配之后结束查找。由这个最佳的 Location 提供请求处理。</li></ul><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">location / &#123;<br>    root   html;<br>   index  index.html index.htm;<br>   &#125;<br><br> <span class="hljs-comment">#error_page  404              /404.html;</span><br><br> <span class="hljs-comment"># redirect server error pages to the static page /50x.html</span><br> <span class="hljs-comment">#</span><br> error_page   500 502 503 504  /50x.html;<br> location = /50x.html &#123;<br>     root   html;<br> &#125;<br> location / &#123;<br>     <span class="hljs-comment">#try_files指令将会按照给定的参数顺序进行匹配尝试</span><br>     try_files <span class="hljs-variable">$uri</span> <span class="hljs-variable">$uri</span>/ /index.html;<br> &#125;<br></code></pre></div></td></tr></table></figure><p>nginx.conf 详细配置如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#定义Nginx运行的用户和用户组</span><br>user www www; <br><br><span class="hljs-comment">#nginx进程数，通常设置成和cpu的数量相等</span><br>worker_processes 4; <br><br><span class="hljs-comment">#全局错误日志定义类型，[debug | info | notice | warn | error | crit]</span><br><span class="hljs-comment">#error_log  /data/nginx/logs/error.log;</span><br><span class="hljs-comment">#error_log  /data/nginx/logs/error.log  notice;</span><br><br><span class="hljs-comment">#日志文件存放路径 access_log path [format [buffer=size | off]]</span><br>access_log /data/nginx/logs/lazyegg.com/web/access.log combinedio;<br><br><span class="hljs-comment">#进程pid文件</span><br><span class="hljs-comment">#pid        logs/nginx.pid;</span><br><br><span class="hljs-comment">#指定进程可以打开的最大描述符：数目</span><br><span class="hljs-comment">#工作模式与连接数上限</span><br><span class="hljs-comment">##这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。</span><br><span class="hljs-comment">#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。</span><br>worker_rlimit_nofile 65535;<br><br><span class="hljs-comment">#################################  events  ###############################</span><br>events &#123;<br>    <span class="hljs-comment">#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型</span><br>    use epoll<br>    <span class="hljs-comment">#单个进程最大连接数（最大连接数=连接数+进程数）</span><br>    worker_connections  1024;<br><br>    <span class="hljs-comment">#keepalive 超时时间</span><br>    keepalive_timeout 60;<br><br>    <span class="hljs-comment">#客户端请求头部的缓冲区大小。</span><br>    client_header_buffer_size 4k;<br><br>    <span class="hljs-comment">#这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。</span><br>    open_file_cache max=65535 inactive=60s;<br>    <span class="hljs-comment">#这个是指多长时间检查一次缓存的有效信息。</span><br>    open_file_cache_valid 80s;<br>        <span class="hljs-comment">#open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。</span><br>    open_file_cache_min_uses 1;<br><br>    <span class="hljs-comment">#语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误.</span><br>    open_file_cache_errors on;<br>&#125;<br><br><span class="hljs-comment">##############################   http    ##################################</span><br><br><span class="hljs-comment">#设定http服务器，利用它的反向代理功能提供负载均衡支持</span><br>http&#123;<br>    <span class="hljs-comment">#文件扩展名与文件类型映射表</span><br>    include mime.types;<br><br>    <span class="hljs-comment">#默认文件类型</span><br>    default_type application/octet-stream;<br><br>    <span class="hljs-comment">#默认编码</span><br>    charset utf-8;<br><br>    <span class="hljs-comment">#服务器名字的hash表大小</span><br>    server_names_hash_bucket_size 128;<br><br>    <span class="hljs-comment">#客户端请求头部的缓冲区大小。</span><br>    client_header_buffer_size 32k;<br><br>    <span class="hljs-comment">#客户请求头缓冲大小。</span><br>    large_client_header_buffers 4 64k;<br><br>    <span class="hljs-comment">#允许客户端请求的最大单个文件字节数</span><br>    client_max_body_size 8m;<br><br>    <span class="hljs-comment">#开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。</span><br>    sendfile on;<br><br>    <span class="hljs-comment">#开启目录列表访问，适合下载服务器，默认关闭。</span><br>    autoindex on;<br><br>    <span class="hljs-comment">#此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用</span><br>    tcp_nopush on;<br><br>    tcp_nodelay on;<br><br>    <span class="hljs-comment">#长连接超时时间，单位是秒</span><br>    keepalive_timeout 120;<br><br>    <span class="hljs-comment">#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。</span><br>    fastcgi_connect_timeout 300;<br>    fastcgi_send_timeout 300;<br>    fastcgi_read_timeout 300;<br>    fastcgi_buffer_size 64k;<br>    fastcgi_buffers 4 64k;<br>    fastcgi_busy_buffers_size 128k;<br>    fastcgi_temp_file_write_size 128k;<br><br>    <span class="hljs-comment">#gzip模块设置</span><br>    gzip on; <span class="hljs-comment">#开启gzip压缩输出</span><br>    gzip_min_length 1k;    <span class="hljs-comment">#最小压缩文件大小</span><br>    gzip_buffers 4 16k;    <span class="hljs-comment">#压缩缓冲区</span><br>    gzip_http_version 1.0; <span class="hljs-comment">#压缩版本（默认1.1，前端如果是squid2.5请使用1.0）</span><br>    gzip_comp_level 2;     <span class="hljs-comment">#压缩等级</span><br>    gzip_types text/plain application/x-javascript text/css application/xml;    <span class="hljs-comment">#压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。</span><br>    gzip_vary on;<br><br>    <span class="hljs-comment">#开启限制IP连接数的时候需要使用</span><br>    <span class="hljs-comment">#limit_zone crawler $binary_remote_addr 10m;</span><br><br>        <span class="hljs-comment">#负载均衡配置</span><br>    upstream lazyegg.net &#123;<br><br>        <span class="hljs-comment">#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。</span><br>        server 192.168.80.121:80 weight=3;<br>        server 192.168.80.122:80 weight=2;<br>        server 192.168.80.123:80 weight=3;<br><br>        <span class="hljs-comment">#nginx的upstream目前支持4种方式的分配</span><br>        <span class="hljs-comment">#1、轮询（默认）</span><br>        <span class="hljs-comment">#每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</span><br>        <span class="hljs-comment">#2、weight</span><br>        <span class="hljs-comment">#指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</span><br>        <span class="hljs-comment">#例如：</span><br>        <span class="hljs-comment">#upstream bakend &#123;</span><br>        <span class="hljs-comment">#    server 192.168.0.14 weight=10;</span><br>        <span class="hljs-comment">#    server 192.168.0.15 weight=10;</span><br>        <span class="hljs-comment">#&#125;</span><br>        <span class="hljs-comment">#2、ip_hash</span><br>        <span class="hljs-comment">#每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</span><br>        <span class="hljs-comment">#例如：</span><br>        <span class="hljs-comment">#upstream bakend &#123;</span><br>        <span class="hljs-comment">#    ip_hash;</span><br>        <span class="hljs-comment">#    server 192.168.0.14:88;</span><br>        <span class="hljs-comment">#    server 192.168.0.15:80;</span><br>        <span class="hljs-comment">#&#125;</span><br>        <span class="hljs-comment">#3、fair（第三方）</span><br>        <span class="hljs-comment">#按后端服务器的响应时间来分配请求，响应时间短的优先分配。</span><br>        <span class="hljs-comment">#upstream backend &#123;</span><br>        <span class="hljs-comment">#    server server1;</span><br>        <span class="hljs-comment">#    server server2;</span><br>        <span class="hljs-comment">#    fair;</span><br>        <span class="hljs-comment">#&#125;</span><br>        <span class="hljs-comment">#4、url_hash（第三方）</span><br>        <span class="hljs-comment">#按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</span><br>        <span class="hljs-comment">#例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法</span><br>        <span class="hljs-comment">#upstream backend &#123;</span><br>        <span class="hljs-comment">#    server squid1:3128;</span><br>        <span class="hljs-comment">#    server squid2:3128;</span><br>        <span class="hljs-comment">#    hash $request_uri;</span><br>        <span class="hljs-comment">#    hash_method crc32;</span><br>        <span class="hljs-comment">#&#125;</span><br><br>        <span class="hljs-comment">#tips:</span><br>        <span class="hljs-comment">#upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123;</span><br>        <span class="hljs-comment">#    ip_hash;</span><br>        <span class="hljs-comment">#    server 127.0.0.1:9090 down;</span><br>        <span class="hljs-comment">#    server 127.0.0.1:8080 weight=2;</span><br>        <span class="hljs-comment">#    server 127.0.0.1:6060;</span><br>        <span class="hljs-comment">#    server 127.0.0.1:7070 backup;</span><br>        <span class="hljs-comment">#&#125;</span><br>        <span class="hljs-comment">#在需要使用负载均衡的server中增加 proxy_pass http://bakend/;</span><br><br>        <span class="hljs-comment">#每个设备的状态设置为:</span><br>        <span class="hljs-comment">#1.down表示单前的server暂时不参与负载</span><br>        <span class="hljs-comment">#2.weight为weight越大，负载的权重就越大。</span><br>        <span class="hljs-comment">#3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误</span><br>        <span class="hljs-comment">#4.fail_timeout:max_fails次失败后，暂停的时间。</span><br>        <span class="hljs-comment">#5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</span><br><br>        <span class="hljs-comment">#nginx支持同时设置多组的负载均衡，用来给不用的server来使用。</span><br>        <span class="hljs-comment">#client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug</span><br>        <span class="hljs-comment">#client_body_temp_path设置记录文件的目录 可以设置最多3层目录</span><br>        <span class="hljs-comment">#location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡</span><br>    &#125;<br><br>       <span class="hljs-comment">#虚拟主机的配置</span><br>    server &#123;<br>        <span class="hljs-comment">#监听端口</span><br>        listen 80;<br><br>        <span class="hljs-comment">#域名可以有多个，用空格隔开</span><br>        server_name lazyegg.net;<br>        <span class="hljs-comment">#默认入口文件名称</span><br>        index index.html index.htm index.php;<br>        root /data/www/lazyegg;<br><br>        <span class="hljs-comment">#对******进行负载均衡</span><br>        location ~ .*.(php|php5)?$<br>        &#123;<br>            fastcgi_pass 127.0.0.1:9000;<br>            fastcgi_index index.php;<br>            include fastcgi.conf;<br>        &#125;<br><br>        <span class="hljs-comment">#图片缓存时间设置</span><br>        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$<br>        &#123;<br>            expires 10d;<br>        &#125;<br><br>        <span class="hljs-comment">#JS和CSS缓存时间设置</span><br>        location ~ .*.(js|css)?$<br>        &#123;<br>            expires 1h;<br>        &#125;<br><br>        <span class="hljs-comment">#日志格式设定</span><br>        <span class="hljs-comment">#$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；</span><br>        <span class="hljs-comment">#$remote_user：用来记录客户端用户名称；</span><br>        <span class="hljs-comment">#$time_local： 用来记录访问时间与时区；</span><br>        <span class="hljs-comment">#$request： 用来记录请求的url与http协议；</span><br>        <span class="hljs-comment">#$status： 用来记录请求状态；成功是200，</span><br>        <span class="hljs-comment">#$body_bytes_sent ：记录发送给客户端文件主体内容大小；</span><br>        <span class="hljs-comment">#$http_referer：用来记录从那个页面链接访问过来的；</span><br>        <span class="hljs-comment">#$http_user_agent：记录客户浏览器的相关信息；</span><br>        <span class="hljs-comment">#通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。</span><br>        log_format access <span class="hljs-string">'$remote_addr - $remote_user [$time_local] "$request" '</span><br>        <span class="hljs-string">'$status $body_bytes_sent "$http_referer" '</span><br>        <span class="hljs-string">'"$http_user_agent" $http_x_forwarded_for'</span>;<br><br>        <span class="hljs-comment">#定义本虚拟主机的访问日志</span><br>        access_log  /usr/<span class="hljs-built_in">local</span>/nginx/logs/host.access.log  main;<br>        access_log  /usr/<span class="hljs-built_in">local</span>/nginx/logs/host.access.404.log  log404;<br><br>        <span class="hljs-comment">#对 "/connect-controller" 启用反向代理</span><br>        location /connect-controller &#123;<br>            proxy_pass http://127.0.0.1:88; <span class="hljs-comment">#请注意此处端口号不能与虚拟主机监听的端口号一样（也就是server监听的端口）</span><br>            proxy_redirect off;<br>            proxy_set_header X-Real-IP <span class="hljs-variable">$remote_addr</span>;<br><br>            <span class="hljs-comment">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span><br>            proxy_set_header X-Forwarded-For <span class="hljs-variable">$proxy_add_x_forwarded_for</span>;<br><br>            <span class="hljs-comment">#以下是一些反向代理的配置，可选。</span><br>            proxy_set_header Host <span class="hljs-variable">$host</span>;<br><br>            <span class="hljs-comment">#允许客户端请求的最大单文件字节数</span><br>            client_max_body_size 10m;<br><br>            <span class="hljs-comment">#缓冲区代理缓冲用户端请求的最大字节数，</span><br>            <span class="hljs-comment">#如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。</span><br>            <span class="hljs-comment">#无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误</span><br>            client_body_buffer_size 128k;<br><br>            <span class="hljs-comment">#表示使nginx阻止HTTP应答代码为400或者更高的应答。</span><br>            proxy_intercept_errors on;<br><br>            <span class="hljs-comment">#后端服务器连接的超时时间_发起握手等候响应超时时间</span><br>            <span class="hljs-comment">#nginx跟后端服务器连接超时时间(代理连接超时)</span><br>            proxy_connect_timeout 90;<br><br>            <span class="hljs-comment">#后端服务器数据回传时间(代理发送超时)</span><br>            <span class="hljs-comment">#后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据</span><br>            proxy_send_timeout 90;<br><br>            <span class="hljs-comment">#连接成功后，后端服务器响应时间(代理接收超时)</span><br>            <span class="hljs-comment">#连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）</span><br>            proxy_read_timeout 90;<br><br>            <span class="hljs-comment">#设置代理服务器（nginx）保存用户头信息的缓冲区大小</span><br>            <span class="hljs-comment">#设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小</span><br>            proxy_buffer_size 4k;<br><br>            <span class="hljs-comment">#proxy_buffers缓冲区，网页平均在32k以下的设置</span><br>            <span class="hljs-comment">#设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k</span><br>            proxy_buffers 4 32k;<br><br>            <span class="hljs-comment">#高负荷下缓冲大小（proxy_buffers*2）</span><br>            proxy_busy_buffers_size 64k;<br><br>            <span class="hljs-comment">#设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长</span><br>            <span class="hljs-comment">#设定缓存文件夹大小，大于这个值，将从upstream服务器传</span><br>            proxy_temp_file_write_size 64k;<br>        &#125;<br><br>        <span class="hljs-comment">#本地动静分离反向代理配置</span><br>        <span class="hljs-comment">#所有jsp的页面均交由tomcat或resin处理</span><br>        location ~ .(jsp|jspx|<span class="hljs-keyword">do</span>)?$ &#123;<br>            proxy_set_header Host <span class="hljs-variable">$host</span>;<br>            proxy_set_header X-Real-IP <span class="hljs-variable">$remote_addr</span>;<br>            proxy_set_header X-Forwarded-For <span class="hljs-variable">$proxy_add_x_forwarded_for</span>;<br>            proxy_pass http://127.0.0.1:8080;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="Nginx-配置：负载均衡"><a href="#Nginx-配置：负载均衡" class="headerlink" title="Nginx 配置：负载均衡"></a>Nginx 配置：负载均衡</h2><p>随着互联网信息的爆炸性增长，负载均衡（Load Balance）已经不再是一个很陌生的话题。</p><p>顾名思义，负载均衡即是将负载分摊到不同的服务单元，既保证服务的可用性，又保证响应足够快，给用户很好的体验。</p><p>快速增长的访问量和数据流量催生了各式各样的负载均衡产品，很多专业的负载均衡硬件提供了很好的功能，但却价格不菲。</p><p>这使得负载均衡软件大受欢迎，Nginx 就是其中的一个，在 Linux 下有 Nginx、LVS、Haproxy 等等服务可以提供负载均衡服务。</p><p>Nginx 的负载均衡是 Proxy 模块和 Upstream 模块搭配实现的。Upstream模块将会启用一个新的配置区段，在该区段定义了一组上游服务器。</p><p><strong>实现效果：配置负载均衡。</strong></p><p>①同时启动两个 Tomcat（为了方便验证效果，修改 Tomcat 端口号的同时，顺便将 Tomcat 默认欢迎页面 apache-tomcat-9.0.29/webapps/ROOR 目录下的 index.jsp 修改下，看下 8081 欢迎页的“蛋蛋”没）：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/3.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>②修改 nginx.conf：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">http &#123;<br>    upstream myserver &#123;<br>        server localhost:8080;<br>        server localhost:8081;<br>    &#125;<br>    server &#123;<br>        listen 80;<br>        location / &#123;<br>            proxy_pass http://myserver;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>③重启 Nginx，验证效果（默认轮询的方式，每次打开新窗口，8080 和 8081 会交替出现，同一个窗口的话需要关闭浏览器缓存)。</p><p>Nginx 分配策略：</p><ul><li>轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 Down 掉，能自动剔除。</li><li>Weight 代表权重，默认为 1，权重越高被分配的客户端越多，指定轮询几率，Weight 和访问比率成正比，用于后端服务器性能不均的情况。</li></ul><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">upstream server_pool&#123; <br>   server 192.168.5.21 weight=10; <br>   server 192.168.5.22 weight=10; &#125;<br></code></pre></div></td></tr></table></figure><p>ip_hash 每个请求按访问 IP 的 Hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 Session 的问题。 </p><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">upstream server_pool&#123;<br>    ip_hash; server 192.168.5.21:80; <br>    server 192.168.5.22:80; <br>&#125;<br></code></pre></div></td></tr></table></figure><p>Fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">upstream server_pool&#123; <br>    server 192.168.5.21:80;<br>    server 192.168.5.22:80; fair;<br> &#125;<br></code></pre></div></td></tr></table></figure><h2 id="Nginx-配置：动静分离"><a href="#Nginx-配置：动静分离" class="headerlink" title="Nginx 配置：动静分离"></a>Nginx 配置：动静分离</h2><p>Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。</p><p>严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。</p><p>动静分离从目前实现角度来讲大致分为两种：</p><ul><li>纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案； </li><li>动态跟静态文件混合在一起发布，通过 Nginx 来分开。 </li></ul><p>通过 Location 指定不同的后缀名实现不同的请求转发。通过 Expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。</p><p><strong>具体 Expires 定义：</strong>是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可， 所以不会产生额外的流量。</p><p>此种方法非常适合不经常变动的资源（如果经常更新的文件， 不建议使用 Expires 来缓存）。</p><p>我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重新下载，返回状态码 200。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/4.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>①服务器找个目录存放自己的静态文件：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/12.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>②修改 nginx.conf：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">server &#123;<br>    listen       80;<br>    server_name  localhost;<br>    location /static/ &#123;<br>        root   /usr/data/www;<br>    &#125;<br>    location /image/ &#123;<br>         root /usr/data/;<br>         autoindex on;<br>    &#125;<br></code></pre></div></td></tr></table></figure><p>③./nginx -s reload，验证效果：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/5.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>添加监听端口、访问名字重点是添加 Location，最后检查 Nginx 配置是否正确即可，然后测试动静分离是否成功，只需要删除后端 Tomcat 服务器上的某个静态文件，查看是否能访问，如果可以访问说明静态资源 Nginx 直接返回了，不走后端 Tomcat 服务器。</p><h2 id="Nginx-的-Rewrite"><a href="#Nginx-的-Rewrite" class="headerlink" title="Nginx 的 Rewrite"></a>Nginx 的 Rewrite</h2><p>Rewrite 是 Nginx 服务器提供的一个重要的功能，它可以实现 URL 重写和重定向功能。</p><p>场景如下：</p><ul><li>URL 访问跳转，支持开发设计。页面跳转、兼容性支持（新旧版本更迭）、展示效果（网址精简）等</li><li>SEO 优化（Nginx 伪静态的支持）</li><li>后台维护、流量转发等</li><li>安全（动态界面进行伪装）</li></ul><p>该指令是通过正则表达式的使用来改变 URI。可以同时存在一个或多个指令。需要按照顺序依次对 URL 进行匹配和处理。</p><p>该指令可以在 Server 块或 Location 块中配置，其基本语法结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">rewrite regex replacement [flag];<br></code></pre></div></td></tr></table></figure><p>①采用反向代理 Demo2 中的例子，修改 nginx.conf（只多加了一行 Rewrite）：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">server &#123;<br>        listen       80;<br>        server_name  localhost;<br><br>        location /java/ &#123;<br>            proxy_pass http://127.0.0.1:8080;<br>            rewrite ^/java /egg/ redirect;<br>        &#125;<br><br>        location /egg/ &#123;<br>            proxy_pass http://127.0.0.1:8081;<br>        &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>②./nginx -s reload，验证效果（输入 ip/java/ 被重定向到了 egg）：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/6.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>Rewrite 指令可以在 Server 块或 Location 块中配置，其基本语法结构如下：</p><figure class="highlight abnf"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs abnf">rewrite regex replacement [flag]<span class="hljs-comment">;</span><br></code></pre></div></td></tr></table></figure><ul><li><strong>rewrite 的含义：</strong>该指令是实现 URL 重写的指令。</li><li><strong>regex 的含义：</strong>用于匹配 URI 的正则表达式。</li><li><strong>replacement：</strong>将 regex 正则匹配到的内容替换成 replacement。</li><li><strong>flag：</strong>flag 标记。</li></ul><p>flag 有如下值：</p><ul><li><strong>last：</strong>本条规则匹配完成后，继续向下匹配新的 Location URI 规则。(不常用)</li><li><strong>break：</strong>本条规则匹配完成即终止，不再匹配后面的任何规则(不常用)。</li><li><strong>redirect：</strong>返回 302 临时重定向，浏览器地址会显示跳转新的 URL 地址。</li><li><strong>permanent：</strong>返回 301 永久重定向。浏览器地址会显示跳转新的 URL 地址。</li></ul><figure class="highlight nginx"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs nginx"><span class="hljs-attribute">rewrite</span><span class="hljs-regexp"> ^/(.*)</span> http://www.360.cn/<span class="hljs-variable">$1</span> <span class="hljs-literal">permanent</span>;<br></code></pre></div></td></tr></table></figure><h2 id="Nginx-高可用"><a href="#Nginx-高可用" class="headerlink" title="Nginx 高可用"></a>Nginx 高可用</h2><p>如果将 Web 服务器集群当做一个城池，那么负载均衡服务器就相当于城门。如果“城门”关闭了，与外界的通道就断了。</p><p>如果只有一台 Nginx 负载服务器，当故障宕机的时候，就会导致整个网站无法访问。</p><p>所以我们需要两台以上 Nginx 来实现故障转移和高可用：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/7.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong>那么如何配置高可用?</strong></p><p><strong>①双机热备方案</strong></p><p>这种方案是国内企业中最为普遍的一种高可用方案，双机热备其实就是指一台服务器在提供服务，另一台为某服务的备用状态，当一台服务器不可用另外一台就会顶替上去。</p><p>Keepalived 是什么？Keepalived 软件起初是专为 LVS 负载均衡软件设计的，用来管理并监控 LVS 集群系统中各个服务节点的状态。</p><p>后来又加入了可以实现高可用的 VRRP (Virtual Router Redundancy Protocol ，虚拟路由器冗余协议）功能。</p><p>因此，Keepalived 除了能够管理 LVS 软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL 等）的高可用解决方案软件。</p><p><strong>②故障转移机制</strong></p><p>Keepalived 高可用服务之间的故障切换转移，是通过 VRRP 来实现的。</p><p>在 Keepalived服务正常工作时，主 Master 节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备 Backup 节点自己还活着。</p><p>当主 Master 节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主  Master 节点的心跳了，于是调用自身的接管程序，接管主 Master 节点的 IP 资源及服务。</p><p>而当主 Master节点恢复时，备 Backup 节点又会释放主节点故障时自身接管的 IP 资源及服务，恢复到原来的备用角色。</p><p>实现方法如下：</p><p>①准备两台安装 Nginx 和 Keepaliver(yum install keepalived -y)的服务器</p><p>②修改两台服务器上的 /etc/keepalived/keepalived.conf</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#主机</span><br><span class="hljs-comment">#检测脚本</span><br>vrrp_script chk_http_port &#123;<br>    script <span class="hljs-string">"/usr/local/src/check_nginx.sh"</span> <span class="hljs-comment">#心跳执行的脚本，检测nginx是否启动</span><br>    interval 2                          <span class="hljs-comment">#（检测脚本执行的间隔，单位是秒）</span><br>    weight 2                            <span class="hljs-comment">#权重</span><br>&#125;<br><span class="hljs-comment">#vrrp 实例定义部分</span><br>vrrp_instance VI_1 &#123;<br>    state MASTER            <span class="hljs-comment"># 指定keepalived的角色，MASTER为主，BACKUP为备</span><br>    interface ens33         <span class="hljs-comment"># 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡</span><br>    virtual_router_id 66    <span class="hljs-comment"># 虚拟路由编号，主从要一直</span><br>    priority 100            <span class="hljs-comment"># 优先级，数值越大，获取处理请求的优先级越高</span><br>    advert_int 1            <span class="hljs-comment"># 检查间隔，默认为1s(vrrp组播周期秒数)</span><br>    <span class="hljs-comment">#授权访问</span><br>    authentication &#123;<br>        auth_type PASS <span class="hljs-comment">#设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信</span><br>        auth_pass 1111<br>    &#125;<br>    track_script &#123;<br>        chk_http_port            <span class="hljs-comment">#（调用检测脚本）</span><br>    &#125;<br>    virtual_ipaddress &#123;<br>        192.168.16.150            <span class="hljs-comment"># 定义虚拟ip(VIP)，可多设，每行一个</span><br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 备机</span><br><span class="hljs-comment">#检测脚本</span><br>vrrp_script chk_http_port &#123;<br>    script <span class="hljs-string">"/usr/local/src/check_nginx.sh"</span> <span class="hljs-comment">#心跳执行的脚本，检测nginx是否启动</span><br>    interval 2                          <span class="hljs-comment">#（检测脚本执行的间隔）</span><br>    weight 2                            <span class="hljs-comment">#权重</span><br>&#125;<br><span class="hljs-comment">#vrrp 实例定义部分</span><br>vrrp_instance VI_1 &#123;<br>    state BACKUP                        <span class="hljs-comment"># 指定keepalived的角色，MASTER为主，BACKUP为备</span><br>    interface ens33                      <span class="hljs-comment"># 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡</span><br>    virtual_router_id 66                <span class="hljs-comment"># 虚拟路由编号，主从要一直</span><br>    priority 99                         <span class="hljs-comment"># 优先级，数值越大，获取处理请求的优先级越高</span><br>    advert_int 1                        <span class="hljs-comment"># 检查间隔，默认为1s(vrrp组播周期秒数)</span><br>    <span class="hljs-comment">#授权访问</span><br>    authentication &#123;<br>        auth_type PASS <span class="hljs-comment">#设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信</span><br>        auth_pass 1111<br>    &#125;<br>    track_script &#123;<br>        chk_http_port                   <span class="hljs-comment">#（调用检测脚本）</span><br>    &#125;<br>    virtual_ipaddress &#123;<br>        192.168.16.150                   <span class="hljs-comment"># 定义虚拟ip(VIP)，可多设，每行一个</span><br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>③新建检测脚本(chmod 775 check_nginx.sh)：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-comment">#检测nginx是否启动了</span><br>A=`ps -C nginx --no-header |wc -l`        <br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$A</span> -eq 0 ];<span class="hljs-keyword">then</span>    <span class="hljs-comment">#如果nginx没有启动就启动nginx                        </span><br>      systemctl start nginx                <span class="hljs-comment">#重启nginx</span><br>      <span class="hljs-keyword">if</span> [ `ps -C nginx --no-header |wc -l` -eq 0 ];<span class="hljs-keyword">then</span>    <span class="hljs-comment">#nginx重启失败，则停掉keepalived服务，进行VIP转移</span><br>              killall keepalived                    <br>      <span class="hljs-keyword">fi</span><br><span class="hljs-keyword">fi</span><br></code></pre></div></td></tr></table></figure><p>④启动 Nginx 和 Keepalived（systemctl start keepalived.service）</p><p>⑤模拟 Nginx 故障（关闭主服务器 Nginx），验证，仍可以通过配置的虚拟 IP 访问，OK。</p><h1 id="Nginx-原理与优化参数配置"><a href="#Nginx-原理与优化参数配置" class="headerlink" title="Nginx 原理与优化参数配置"></a>Nginx 原理与优化参数配置</h1><p>Nginx 默认采用多进程工作方式，Nginx 启动后，会运行一个 Master 进程和多个 Worker 进程。</p><p>其中 Master 充当整个进程组与用户的交互接口，同时对进程进行监护，管理 Worker 进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。</p><p>Worker 用来处理基本的网络事件，Worker 之间是平等的，他们共同竞争来处理来自客户端的请求。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/8.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong>master-workers 的机制的好处：</strong></p><ul><li>可以使用 nginx-s reload 热部署。</li><li>每个 Worker 是独立的进程，不需要加锁，省掉了锁带来的开销。采用独立的进程，可以让互相之间不会影响，一个进程退出后，其他进程还在工作，服务不会中断，Master 进程则很快启动新的 Worker 进程。</li></ul><p><strong>需要设置多少个 Worker？</strong>Nginx 同 Redis 类似都采用了 IO 多路复用机制，每个 Worker 都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求，即使是成千上万个请求也不在话下。</p><p>每个 Worker 的线程可以把一个 CPU 的性能发挥到极致。所以 Worker 数和服务器的 CPU 数相等是最为适宜的。设少了会浪费 CPU，设多了会造成 CPU 频繁切换上下文带来的损耗。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#设置 worker 数量。</span><br> worker_processes 4 <br><span class="hljs-comment">#work 绑定 cpu(4 work 绑定 4cpu)。 </span><br> worker_cpu_affinity 0001 0010 0100 1000 <br><span class="hljs-comment">#work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。 </span><br> worker_cpu_affinity 0000001 00000010 00000100 00001000<br></code></pre></div></td></tr></table></figure><p><strong>连接数 worker_connection：</strong>这个值是表示每个 Worker 进程所能建立连接的最大值。</p><p>所以，一个 Nginx 能建立的最大连接数，应该是 worker_connections*worker_processes。</p><p>当然，这里说的是最大连接数，对于 HTTP 请 求 本 地 资 源 来 说 ， 能 够 支 持 的 最 大 并 发 数 量 是 worker_connections*worker_processes，如果是支持 http1.1 的浏览器每次访问要占两个连接。</p><p>所以普通的静态访问最大并发数是：worker_connections*worker_processes /2。</p><p>而如果是 HTTP 作为反向代理来说，最大并发数量应该是 worker_connections*worker_processes/4。</p><p>因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。</p><p><strong>Nginx 请求处理流程如下图：</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/9.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="Nginx-模块开发"><a href="#Nginx-模块开发" class="headerlink" title="Nginx 模块开发"></a>Nginx 模块开发</h1><p>由于 Nginx 的模块化特性，所以可以支持模块配置，也可以自定义模块，Nginx 的模块开发，程序员目前还不需要太深入。</p><p>Nginx 模块分类如下图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/10.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong>Nginx配置选项，解压 Nginx 后的配置操作示例：</strong></p><figure class="highlight jboss-cli"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs jboss-cli"><span class="hljs-string">./configure</span> <span class="hljs-params">--prefix=/usr/local/nginx</span> <span class="hljs-params">--with-http_stub_status_module</span> <span class="hljs-params">--with-pcre</span>  <span class="hljs-params">--with-http_ssl_module</span><br></code></pre></div></td></tr></table></figure><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-19/11.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="Nginx-面试题"><a href="#Nginx-面试题" class="headerlink" title="Nginx 面试题"></a>Nginx 面试题</h1><p>①Nginx 功能，你们项目中用到的 Nginx？</p><ul><li><strong>反向代理服务器</strong></li><li><strong>实现负载均衡</strong></li><li><strong>做静态资源服务器</strong></li><li><strong>作为 HTTP Server</strong></li></ul><p>②Nginx 常用命令有哪些？</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">启动nginx    ./sbin/nginx<br>停止nginx    ./sbin/nginx -s stop   ./sbin/nginx -s quit<br>重载配置      ./sbin/nginx -s reload(平滑重启) service nginx reload<br>重载指定配置文件    ./sbin/nginx -c  /usr/<span class="hljs-built_in">local</span>/nginx/conf/nginx.conf<br>查看nginx版本  ./sbin/nginx -v<br>检查配置文件是否正确  ./sbin/nginx -t<br>显示帮助信息  ./sbin/nginx  -h<br></code></pre></div></td></tr></table></figure><p>③Nginx 常用配置？</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">worker_processes 4;   <span class="hljs-comment">#工作进程数</span><br>work_connections 65535; <span class="hljs-comment">#每个进程的并发能力</span><br>error_log  /data/nginx/logs/error.log;  <span class="hljs-comment">#错误日志</span><br></code></pre></div></td></tr></table></figure><p>④Nginx 是如何实现高并发的？</p><p>Nginx 采用的是多进程（单线程）&amp;多路 IO 复用模型，异步，非阻塞。</p><p>一个主进程 Master，多个工作进程 Worker，每个工作进程可以处理多个请求 ，Master 进程主要负责收集、分发请求。</p><p>每当一个请求过来时，Master 就拉起一个 Worker 进程负责处理这个请求。同时 Master 进程也负责监控 Woker 的状态，保证高可靠性。</p><p>在 Nginx 中的 Work 进程中，为了应对高并发场景，采取了 Reactor 模型（也就是 I/O 多路复用，NIO）。</p><p><strong>I/O 多路复用模型：</strong>在 I/O 多路复用模型中，最重要的系统调用函数就是 Select（其他的还有 epoll 等）。</p><p>该方法能够同时监控多个文件描述符的可读可写情况（每一个网络连接其实都对应一个文件描述符），当其中的某些文件描述符可读或者可写时，Select 方法就会返回可读以及可写的文件描述符个数。</p><p>Nginx Work 进程使用 I/O 多路复用模块同时监听多个 FD（文件描述符），当 Accept、Read、Write 和 Close 事件产生时，操作系统就会回调 FD 绑定的事件处理器。</p><p>这时候 Work 进程再去处理相应事件，而不是阻塞在某个请求连接上等待。</p><p>这样就可以实现一个进程同时处理多个连接。每一个 Worker 进程通过 I/O 多路复用处理多个连接请求。</p><p>为了减少进程切换（需要系统调用）的性能损耗，一般设置 Worker 进程数量和 CPU 数量一致。</p><p>⑤Nginx 和 Apache 的区别？</p><p>轻量级，同样起 Web 服务，比 Apache 占用更少的内存及资源抗并发，Nginx 处理请求是异步非阻塞的，而 Apache 则是阻塞型的。</p><p>在高并发下 Nginx 能保持低资源低消耗高性能高度模块化的设计，编写模块相对简单，最核心的区别在于 Apache 是同步多进程模型，一个连接对应一个进程；Nginx是异步的，多个连接（万级别）可以对应一个进程。</p><p>⑥Nginx 的 Upstream 支持的负载均衡方式？</p><ul><li><strong>轮询（默认）</strong></li><li><strong>weight：</strong>指定权重</li><li><strong>ip_hash：</strong>每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器</li><li><strong>第三方：</strong>fair、url_hash</li></ul><p>⑦Nginx 常见的优化配置有哪些?</p><ul><li><strong>调整 worker_processes：</strong>指 Nginx 要生成的 Worker 数量，最佳实践是每个 CPU 运行 1 个工作进程。</li><li><strong>最大化 worker_connections。</strong></li><li><strong>启用 Gzip 压缩：</strong>压缩文件大小，减少了客户端 HTTP 的传输带宽，因此提高了页面加载速度。</li><li><strong>为静态文件启用缓存。</strong></li><li><strong>禁用 access_logs：</strong>访问日志记录，它记录每个 Nginx 请求，因此消耗了大量 CPU 资源，从而降低了 Nginx 性能。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Prometheus 部署架构选择 </title>
    <link href="/2019/12/18/2019-12-18-prometheus1-architecture/"/>
    <url>/2019/12/18/2019-12-18-prometheus1-architecture/</url>
    
    <content type="html"><![CDATA[<p>本次 Prometheus 实践采用的是 Prometheus Sever + Kube-state-metrics + Grafana 的架构，每一个组件的作用如下:</p><p><strong>Promethues：</strong>提供强大的数据采集、数据存储、数据展示、告警等，天生完美支持 kubernetes，CNCF 基金会的第二个成员，第一个是 Kubernetes。而且 Prometheus 里面很多思想都来源于Google 内部的监控系统 Borgmon，可以说是 Google 的干儿子。</p><p><strong>kube-state-metrics：</strong>在这里作为 prometheus 的一个 exporter 来使用，提供 deployment、daemonset、cronjob 等服务的监控数据，由 kubernestes 官方提供，与 prometheus 紧密结合。因为prometheus 不能获取集群中 Deployment, Job, CronJob 的监控信息。 更多关于 kube-state-metrics 的信息可以参考：<a href="https://github.com/kubernetes/kube-state-metrics" target="_blank" rel="noopener">https://github.com/kubernetes/kube-state-metrics</a> </p><p><strong>Grafana</strong>: 开源 dashboard，后端支持多种数据库，如：Influxdb、Prometheus…，插件也比较多，功能强大。非常适合用于做展示。</p><p>基本架构图可以参考下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-18/191218.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>需要说明的是本次实践是单集群部署，Prometheus 的联邦机制暂且不考虑。本次的单集群规格信息如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 ~]<span class="hljs-comment"># kubectl get nodes</span><br>NAME                    STATUS   ROLES    AGE   VERSION<br>master-10.200.100.216   Ready    master   7d    v1.15.3<br>node-10.200.100.214     Ready    &lt;none&gt;   7d    v1.15.3<br>node-10.200.100.215     Ready    &lt;none&gt;   7d    v1.15.3<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Prometheus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Prometheus Server组件安装 </title>
    <link href="/2019/12/18/2019-12-18-prometheus2-server/"/>
    <url>/2019/12/18/2019-12-18-prometheus2-server/</url>
    
    <content type="html"><![CDATA[<p>这里 Prometheus Server 使用一个带 RBAC 权限的账号采集集群中现有监控信息（其实是从 cadvisor 获取）和节点信息。本次部署是基于比较新的 v2.11.1 版本，网上的一些教程还停留在比较早的版本，所以有些东西改动还是比较大的。</p><p>yaml文件地址：<a href="https://github.com/ILIKETWICE/prometheus-k8s" target="_blank" rel="noopener">https://github.com/ILIKETWICE/prometheus-k8s</a></p><p>具体配置清单文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bahs">├── prometheus-cm-alerts.yaml<br>├── prometheus-cm-config.yaml<br>├── prometheus-deploy.yaml<br>├── prometheus-ingress.yaml<br>├── prometheus-rbac.yaml<br>└── prometheus-svc.yaml<br></code></pre></div></td></tr></table></figure><p>各个配置文件的作用如下：</p><p><strong>prometheus-cm-alerts.yaml：</strong>该配置文件主要是针对 Alertmanager 定制的一些告警策略，这里暂时不需要 apply <strong>；</strong></p><p><strong>prometheus-cm-config.yaml：</strong> 该配置文件主要是 prometheus 主要的配置文件，prometheus 的配置基本都在此文件中定义；</p><p><strong>prometheus-rbac.yaml</strong>：该文件主要定义了 Prometheus 容器访问 k8s apiserver 所需的 ServiceAccount、ClusterRole 以及 ClusterRoleBinding；</p><p><strong>prometheus-deploy.yaml</strong>：该文件是 Prometheus 的主要的部署文件，里面定义了一些具体参数，可以根据实际集群的规格做相应的调整，个人建议 Prometheus 不要在业务机器上做部署，可以通过节点亲和等特性实现；</p><p><strong>prometheus-svc.yaml</strong>：该文件定义了 Prometheus 的 Service，为了方便服务的暴露方式我选择了 NodePort 的方式，可以根据自己需求做相应的更改；</p><p><strong>prometheus-ingress.yaml</strong>：该文件主要定义了 prometheus 服务的 Ingress 规则，可选；</p><p>配置清单文件准备好后就可以 apply 了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 prometheus-server]<span class="hljs-comment"># kubectl apply -f . --dry-run</span><br>configmap/prometheus-rule-config configured (dry run)<br>configmap/prometheus-config configured (dry run)<br>deployment.apps/prometheus-server configured (dry run)<br>ingress.extensions/prometheus-server-ingress configured (dry run)<br>serviceaccount/prometheus configured (dry run)<br>clusterrole.rbac.authorization.k8s.io/prometheus configured (dry run)<br>clusterrolebinding.rbac.authorization.k8s.io/prometheus configured (dry run)<br>service/prometheus configured (dry run)<br></code></pre></div></td></tr></table></figure><p>部署完成后就可以看到对应的 pod 运行起来了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 prometheus-server]<span class="hljs-comment"># kubectl get pods -n prometheus-huang</span><br>NAME                                 READY   STATUS    RESTARTS   AGE<br>alertmanager-59577dc4bf-qcnvw        1/1     Running   0          19h<br>kube-state-metrics-c8b4bcf8-jstlr    2/2     Running   0          43h<br>node-exporter-l4228                  1/1     Running   0          42h<br>node-exporter-qhqf2                  1/1     Running   0          42h<br>node-exporter-vjtdn                  1/1     Running   0          41h<br>prometheus-grafana-6d8676fb6-w8cvl   1/1     Running   0          24h<br>prometheus-server-784595847-kqznb    1/1     Running   0          19h<br></code></pre></div></td></tr></table></figure><p>需要注意的是上述信息是部署完成各个组件的部署信息，这里只关注 prometheus-server pod 即可；</p><p>Prometheus Server 到现在就可以说部署好了，当然我这里用的是 Deployment 在正式生产环境下还是建议用 SatefulSet ,保证后端存储的可靠性。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Prometheus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> kube-state-metrics 组件安装 </title>
    <link href="/2019/12/18/2019-12-18-prometheus3-kube-state-metrics/"/>
    <url>/2019/12/18/2019-12-18-prometheus3-kube-state-metrics/</url>
    
    <content type="html"><![CDATA[<p>在这里 kube-state-metrics 是作为 prometheus 的一个 exporter 来使用，主要用来提供集群中的 deployment、daemonset、cronjob 等服务的监控数据。</p><p>yaml文件地址：<a href="https://github.com/ILIKETWICE/prometheus-k8s" target="_blank" rel="noopener">https://github.com/ILIKETWICE/prometheus-k8s</a></p><p>具体配置清单文件如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">├── kube-state-metrics-deploy.yaml<br>├── kube-state-metrics-rbac.yaml<br>└── kube-state-metrics-svc.yaml<br></code></pre></div></td></tr></table></figure><p>各个配置文件的作用如下：</p><p><strong>kube-state-metrics-rbac.yaml：</strong>该文件主要定义了 kube-state-metrics 容器访问 k8s apiserver 所需的 ServiceAccount、ClusterRole 以及 ClusterRoleBinding；</p><p><strong>prometheus-deploy.yaml</strong>：该文件是 kube-state-metrics 的主要的部署文件，里面定义了一些具体参数，可以根据实际集群的规格做相应的调整；</p><p><strong>prometheus-svc.yaml</strong>：该文件定义了 kube-state-metrics 的 Service，可以根据自己需求做相应的更改，这里只需要使用默认的 ClusterIP 就可以了，因为它只提供给集群内部的 promethes 访问；</p><p>配置清单文件准备好后就可以 apply 了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 kube-state-metrics]<span class="hljs-comment"># kubectl apply -f . --dry-run</span><br>deployment.apps/kube-state-metrics configured (dry run)<br>serviceaccount/kube-state-metrics configured (dry run)<br>clusterrole.rbac.authorization.k8s.io/kube-state-metrics configured (dry run)<br>role.rbac.authorization.k8s.io/kube-state-metrics-resizer configured (dry run)<br>clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics configured (dry run)<br>rolebinding.rbac.authorization.k8s.io/kube-state-metrics configured (dry run)<br>service/kube-state-metrics configured (dry run)<br></code></pre></div></td></tr></table></figure><p>部署完成后就可以看到对应的 pod 运行起来了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 prometheus-server]<span class="hljs-comment"># kubectl get pods -n prometheus-huang</span><br>NAME                                 READY   STATUS    RESTARTS   AGE<br>alertmanager-59577dc4bf-qcnvw        1/1     Running   0          19h<br>kube-state-metrics-c8b4bcf8-jstlr    2/2     Running   0          43h<br>node-exporter-l4228                  1/1     Running   0          42h<br>node-exporter-qhqf2                  1/1     Running   0          42h<br>node-exporter-vjtdn                  1/1     Running   0          41h<br>prometheus-grafana-6d8676fb6-w8cvl   1/1     Running   0          24h<br>prometheus-server-784595847-kqznb    1/1     Running   0          19h<br></code></pre></div></td></tr></table></figure><p>需要注意的是上述信息是部署完成各个组件的部署信息，这里只关注 kube-state-metrics-c8b4bcf8-jstlr pod 即可.</p>]]></content>
    
    
    
    <tags>
      
      <tag>Prometheus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Node-Expoter 组件安装 </title>
    <link href="/2019/12/18/2019-12-18-prometheus4-node-expoter/"/>
    <url>/2019/12/18/2019-12-18-prometheus4-node-expoter/</url>
    
    <content type="html"><![CDATA[<p>node-exporter 这里主要用来提供集群节点本身的信息的，包括 CPU、内存、硬盘、IO 等等信息。</p><p>yaml文件地址：<a href="https://github.com/ILIKETWICE/prometheus-k8s" target="_blank" rel="noopener">https://github.com/ILIKETWICE/prometheus-k8s</a></p><p>具体配置清单文件如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">├── node-exporter-ds.yaml<br>├── node-exporter-rbac.yaml<br>└── node-exporter-svc.yaml<br></code></pre></div></td></tr></table></figure><p>各个配置文件的作用如下：</p><p><strong>node-exporter-rbac.yaml：</strong>该文件主要定义了 node-exporter 容器访问 k8s apiserver 所需的 ServiceAccount、ClusterRole 以及 ClusterRoleBinding；</p><p><strong>node-exporter-ds.yaml</strong>：该文件是 <strong>node-exporter</strong> 的主要的部署文件，里面定义了一些具体参数，可以根据实际集群的规格做相应的调整,这里用 DaemonSet,保证可以提供每个节点的信息；</p><p><strong>node-exporter-svc.yaml</strong>：该文件定义了 <strong>node-exporter</strong> 的 Service，可以根据自己需求做相应的更改；</p><p>配置清单文件准备好后就可以 apply 了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 node-exporter]<span class="hljs-comment"># kubectl apply -f . --dry-run</span><br>daemonset.extensions/node-exporter configured (dry run)<br>serviceaccount/node-exporter configured (dry run)<br>service/node-exporter configured (dry run)<br></code></pre></div></td></tr></table></figure><p>部署完成后就可以看到对应的 pod 运行起来了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 prometheus-server]<span class="hljs-comment"># kubectl get pods -n prometheus-huang</span><br>NAME                                 READY   STATUS    RESTARTS   AGE<br>alertmanager-59577dc4bf-qcnvw        1/1     Running   0          19h<br>kube-state-metrics-c8b4bcf8-jstlr    2/2     Running   0          43h<br>node-exporter-l4228                  1/1     Running   0          42h<br>node-exporter-qhqf2                  1/1     Running   0          42h<br>node-exporter-vjtdn                  1/1     Running   0          41h<br>prometheus-grafana-6d8676fb6-w8cvl   1/1     Running   0          24h<br>prometheus-server-784595847-kqznb    1/1     Running   0          19h<br></code></pre></div></td></tr></table></figure><p>需要注意的是上述信息是部署完成各个组件的部署信息，这里只关注 node-exporter pod 即可；还有就是默认 pod 不会调度到 master 节点上的，需要添加容忍度才可以，具体如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">spec:<br>      ...<br>      tolerations:<br>        - key: node-role.kubernetes.io/master<br>          effect: NoSchedule<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Prometheus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Grafana 可视化组件安装 </title>
    <link href="/2019/12/18/2019-12-18-prometheus5-grafana/"/>
    <url>/2019/12/18/2019-12-18-prometheus5-grafana/</url>
    
    <content type="html"><![CDATA[<p>Grafana 是一个开源的 dashboard，支持用 prometheus 作为数据源，部署起来也比较简单，这里我用的是 ConfigMap 做配置，所以看起来比较复杂。</p><p>yaml文件地址：<a href="https://github.com/ILIKETWICE/prometheus-k8s" target="_blank" rel="noopener">https://github.com/ILIKETWICE/prometheus-k8s</a></p><p>具体配置清单文件如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">├── grafana-cm.yaml<br>├── grafana-dashboard.yaml<br>├── grafana-deploy.yaml<br>├── grafana-ingress.yaml<br>├── grafana-sa.yaml<br>├── grafana-secret.yaml<br>└── grafana-svc.yaml<br></code></pre></div></td></tr></table></figure><p>文件有点多，其实这样做也是在 Kubernetes 集群部署 Grafana 的比较规范的方式，所有的配置都是通过 ConfigMap 做配置，上述每个文件的具体用途如下：</p><p><strong>grafana-cm.yaml：</strong>该配置文件主要是 grafana 的一些配置文件，包括数据源的配置以及数据保存的位置等等<strong>；</strong></p><p><strong>grafana-dashboard.yaml：</strong> 该配置文件主要是 grafana 导入的 dashboard 模板，其实这些模板可以在部署完成后自己导入的；</p><p><strong>grafana-deploy.yaml</strong>：该文件主要定义了 Grafana 的部署信息，可以根据自己实际情况做修改，生产环境建议做持久化存储；</p><p><strong>grafana-ingress.yaml</strong>：该文件主要是定义 grafana 服务的 Ingress 的规则，通过 Ingress 暴露服务；</p><p><strong>grafana-sa.yaml</strong>：该文件主要定义了 grafana 在集群中的 ServiceAccount；</p><p><strong>grafana-secret.yaml</strong>：该文件主要定义了登录 Grafana 的默认账号密码，通过挂载到部署文件生效；</p><p><strong>grafana-svc.yaml</strong>：该文件主要定义了 Grafana 的服务；</p><p>配置清单文件准备好后就可以 apply 了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 grafana]<span class="hljs-comment"># kubectl apply -f . --dry-run</span><br>configmap/grafana-ini configured (dry run)<br>configmap/grafana-datasources configured (dry run)<br>configmap/grafana-dashboardproviders configured (dry run)<br>configmap/dashboards configured (dry run)<br>deployment.apps/prometheus-grafana configured (dry run)<br>ingress.extensions/prometheus-grafana-ingress configured (dry run)<br>serviceaccount/grafana configured (dry run)<br>secret/grafana configured (dry run)<br>service/grafana configured (dry run)<br></code></pre></div></td></tr></table></figure><p>部署完成后就可以看到对应的 pod 运行起来了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 prometheus-server]<span class="hljs-comment"># kubectl get pods -n prometheus-huang</span><br>NAME                                 READY   STATUS    RESTARTS   AGE<br>alertmanager-59577dc4bf-qcnvw        1/1     Running   0          19h<br>kube-state-metrics-c8b4bcf8-jstlr    2/2     Running   0          43h<br>node-exporter-l4228                  1/1     Running   0          42h<br>node-exporter-qhqf2                  1/1     Running   0          42h<br>node-exporter-vjtdn                  1/1     Running   0          41h<br>prometheus-grafana-6d8676fb6-w8cvl   1/1     Running   0          24h<br>prometheus-server-784595847-kqznb    1/1     Running   0          19h<br></code></pre></div></td></tr></table></figure><p>需要注意的是上述信息是部署完成各个组件的部署信息，这里只关注 grafana pod 即可；</p><p>部署完成后直接访问就可以，因为之前 ConfigMap 已经做过配置，所以不需要单独配置数据源什么的，默认账号密码如下：</p><table><thead><tr><th align="center">账号</th><th align="left">密码</th></tr></thead><tbody><tr><td align="center">admin</td><td align="left">admin</td></tr></tbody></table><table><thead><tr><th align="center">Kubernetes 版本</th><th align="center">v 1.9</th><th align="center">v 1.10</th><th align="center">v 1.11</th><th align="center">v 1.12</th><th align="center">v 1.13</th><th align="center">v 1.14</th><th align="center">v 1.15</th></tr></thead><tbody><tr><td align="center">版本兼容性</td><td align="center">x</td><td align="center">？</td><td align="center">？</td><td align="center">？</td><td align="center">？</td><td align="center">？</td><td align="center">✓</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>Prometheus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> AlertManager 组件安装 </title>
    <link href="/2019/12/18/2019-12-18-prometheus6-alertmanager/"/>
    <url>/2019/12/18/2019-12-18-prometheus6-alertmanager/</url>
    
    <content type="html"><![CDATA[<p>在 Prometheus 监控中， AlertManager 主要是用来除了告警信息和发送告警的。</p><p>yaml文件地址：<a href="https://github.com/ILIKETWICE/prometheus-k8s" target="_blank" rel="noopener">https://github.com/ILIKETWICE/prometheus-k8s</a></p><p>具体配置清单文件如下：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">├── alertmanager-cm.yaml<br>├── alertmanager-deploy.yaml<br>├── alertmanager-ingress.yaml<br>├── alertmanager-operated-svc.yaml<br>├── alertmanager-pvc.yaml<br>├── alertmanager-rbac.yaml<br>└── alertmanager-svc.yaml<br></code></pre></div></td></tr></table></figure><p>各个配置文件的作用如下：</p><p><strong>alertmanager-cm.yaml：</strong>该配置文件主要是针对 Alertmanager 做的一些基础配置以及一些告警途径，包括邮箱、企业微信以及Slack <strong>；</strong></p><p><strong>alertmanager-deploy.yaml：</strong> 该配置文件主要定义 alertmanager 的部署文件,真正生产环境需要考虑后端存储的可靠性；</p><p><strong>alertmanager-ingress.yaml</strong>：该文件主要定义了 alertmanager 的 Ingress 规则，可选，非必须；</p><p><strong>alertmanager-operated-svc.yaml</strong>：该文件主要定义<strong>alertmanager-operated服务，服务地址会在部署文件中用到；</strong></p><p><strong>alertmanager-svc.yaml</strong>：该文件主要用来定义 alertmanager 服务；</p><p><strong>alertmanager-rbac.yaml</strong>：该文件主要定义了部署文件用到的 ServiceAccount；</p><p>配置清单文件准备好后就可以 apply 了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 alertmanager]<span class="hljs-comment"># kubectl apply -f . --dry-run</span><br>configmap/alertmanager-config configured (dry run)<br>deployment.apps/alertmanager configured (dry run)<br>ingress.extensions/prometheus-alert-ingress configured (dry run)<br>service/alertmanager-operated configured (dry run)<br>persistentvolumeclaim/alertmanager configured (dry run)<br>serviceaccount/alertmanager configured (dry run)<br>service/alertmanager configured (dry run)<br></code></pre></div></td></tr></table></figure><p>部署完成后就可以看到对应的 pod 运行起来了：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">[root@master-10 prometheus-server]<span class="hljs-comment"># kubectl get pods -n prometheus-huang</span><br>NAME                                 READY   STATUS    RESTARTS   AGE<br>alertmanager-59577dc4bf-qcnvw        1/1     Running   0          19h<br>kube-state-metrics-c8b4bcf8-jstlr    2/2     Running   0          43h<br>node-exporter-l4228                  1/1     Running   0          42h<br>node-exporter-qhqf2                  1/1     Running   0          42h<br>node-exporter-vjtdn                  1/1     Running   0          41h<br>prometheus-grafana-6d8676fb6-w8cvl   1/1     Running   0          24h<br>prometheus-server-784595847-kqznb    1/1     Running   0          19h<br></code></pre></div></td></tr></table></figure><p>需要注意的是上述信息是部署完成各个组件的部署信息，这里只关注 alertmanager pod 即可；</p><p>到这里基本整个 prometheus 就部署完成了，告警及其规则也配置好了，这里只是配置了微信企业告警，需要其他方式告警可以参考<a href="https://aeric.io/post/prometheus-alertmanager-config/" target="_blank" rel="noopener">https://aeric.io/post/prometheus-alertmanager-config/</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Prometheus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> Prometheus架构原理及其组成 </title>
    <link href="/2019/12/17/2019-12-17-prometheus-introduction/"/>
    <url>/2019/12/17/2019-12-17-prometheus-introduction/</url>
    
    <content type="html"><![CDATA[<h1 id="Prometheus-系统介绍"><a href="#Prometheus-系统介绍" class="headerlink" title="Prometheus 系统介绍"></a><a href="https://confluence.qingclass.cn/pages/viewpage.action?pageId=27755014#prometheus-系统介绍" target="_blank" rel="noopener">Prometheus 系统介绍</a></h1><p>首先，Prometheus 受启发于 Google 的 Brogmon 监控系统，相似的 Kubernetes 是从 Google 的 Brog 系统演变而来，从 2012 年开始由前 Google 工程师在 Soundcloud 以开源软件的形式进行研发，并且于 2015 年早期对外发布早期版本。2016 年 5 月继 Kubernetes 之后成为第二个正式加入 CNCF 基金会的项目，同年 6 月正式发布 1.0 版本。2017 年底发布了基于全新存储层的 2.0 版本，能更好地与容器平台、云平台配合。</p><p>Prometheus 的发展简史如下图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-17/191217-1.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>作为新一代监控系统，Prometheus 可以说是彻底颠覆了传统的监控系统，作为监控系统，一般都离不开以下监控<strong>目标：</strong></p><p><strong>长期趋势分析</strong>：通过对监控样本数据的持续收集和统计，对监控指标进行长期趋势分析。例如，通过对磁盘空间增长率的判断，我们可以提前预测在未来什么时间节点上需要对资源进行扩容。</p><p><strong>对照分析</strong>：两个版本的系统运行资源使用情况的差异如何？在不同容量情况下系统的并发和负载变化如何？通过监控能够方便的对系统进行跟踪和比较。</p><p><strong>告警</strong>：当系统出现或者即将出现故障时，监控系统需要迅速反应并通知管理员，从而能够对问题进行快速的处理或者提前预防问题的发生，避免出现对业务的影响。</p><p><strong>故障分析与定位</strong>：当问题发生后，需要对问题进行调查和处理。通过对不同监控监控以及历史数据的分析，能够找到并解决根源问题。</p><p><strong>数据可视化：</strong>通过可视化仪表盘能够直接获取系统的运行状态、资源使用情况、以及服务运行状态等直观的信息。</p><p>与传统监控系统相比， Prometheus 是一个开源的完整监控解决方案，其对传统监控系统的测试和告警模型进行了彻底的颠覆，形成了基于中央化的规则计算、统一分析和告警的新模型。Prometheus 具有许多独特的优势：</p><p><strong>易于管理</strong>: Prometheus 核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。Prometheus 基于 Pull 模型的架构方式，可以在任何地方（本地电脑，开发环境，测试环境）搭建我们的监控系统。对于一些复杂的情况，还可以使用Prometheus 服务发现 (Service Discovery) 的能力动态管理监控目标。<br>监控服务的内部运行状态: Pometheus 鼓励用户监控服务的内部状态，基于 Prometheus 丰富的 Client 库，用户可以轻松的在应用程序中添加对 Prometheus 的支持，从而让用户可以获取服务和应用内部真正的运行状态。<br><strong>数据模型</strong>: Prometheus 所有采集的监控数据均以指标 (metric) 的形式保存在内置的时间序列数据库当中(TSDB)。所有的样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签。每一条时间序列由指标名称(Metrics Name)以及一组标签(Labels)唯一标识。每条时间序列按照时间的先后顺序存储一系列的样本值。<br><strong>查询语言PromQL</strong>: Prometheus 内置了一个强大的数据查询语言 PromQL。 通过 PromQL 可以实现对监控数据的查询、聚合。同时 PromQL 也被应用于数据可视化(如Grafana)以及告警当中。<br><strong>高效、可扩展、易于集成</strong>: Prometheus 对于联邦集群的支持，可以让多个 Prometheus 实例产生一个逻辑集群，当单实例 Prometheus Server 处理的任务量过大时，通过使用功能分区(sharding)+联邦集群(federation)可以对其进行扩展。使用Prometheus可以快速搭建监控服务，并且可以非常方便地在应用程序中进行集成。<br>Prometheus 还有许多特性，这里不再一一赘述，详细信息可以查阅<a href="https://prometheus.io/docs/introduction/overview/" target="_blank" rel="noopener">官方文档</a></p><h1 id="Prometheus-核心组件"><a href="#Prometheus-核心组件" class="headerlink" title="Prometheus 核心组件"></a><a href="https://confluence.qingclass.cn/pages/viewpage.action?pageId=27755014#prometheus-核心组件" target="_blank" rel="noopener">Prometheus 核心组件</a></h1><p>Prometheus 的基本架构图如下图所示：（图片来源于官方网站）</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-17/191217-2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h2 id="Prometheus-Server"><a href="#Prometheus-Server" class="headerlink" title="Prometheus Server"></a><a href="https://confluence.qingclass.cn/pages/viewpage.action?pageId=27755014#prometheus-server" target="_blank" rel="noopener">Prometheus Server</a></h2><p>Prometheus Server 是 Prometheus 组件中的核心部分，负责实现对监控数据的获取，存储以及查询。 Prometheus Server 可以通过静态配置管理监控目标，也可以配合使用 Service Discovery 的方式动态管理监控目标，并从这些监控目标中获取数据。其次 Prometheus Server 需要对采集到的监控数据进行存储，Prometheus Server 本身就是一个时序数据库，将采集到的监控数据按照时间序列的方式存储在本地磁盘当中。最后 Prometheus Server 对外提供了自定义的 PromQL 语言，实现对数据的查询以及分析。</p><p>Prometheus Server 内置的 Express Browser UI，通过这个 UI 可以直接通过 PromQL 实现数据的查询以及可视化。</p><p>Prometheus Server 的联邦集群能力可以使其从其他的 Prometheus Server 实例中获取数据，因此在大规模监控的情况下，可以通过联邦集群以及功能分区的方式对 Prometheus Server 进行扩展。</p><h2 id="Exporters"><a href="#Exporters" class="headerlink" title="Exporters"></a><a href="https://confluence.qingclass.cn/pages/viewpage.action?pageId=27755014#exporters" target="_blank" rel="noopener">Exporters</a></h2><p>Exporter 将监控数据采集的端点通过 HTTP 服务的形式暴露给 Prometheus Server，然后 Prometheus Server 通过访问该 Exporter 提供的 Endpoint 端点，即可获取到需要采集的监控数据。</p><p>一般来说可以将 Exporter 分为 2 类：</p><ul><li>直接采集：这一类 Exporter 直接内置了对 Prometheus 监控的支持，比如 cAdvisor，Kubernetes，Etcd，Gokit等，都直接内置了用于向 Prometheus 暴露监控数据的端点；</li><li>间接采集：间接采集，原有监控目标并不直接支持 Prometheus，因此我们需要通过 Prometheus 提供的 Client Library 编写该监控目标的监控采集程序。例如: Mysql Exporter，JMX Exporter，Consul Exporter等。</li></ul><h2 id="AlertManager"><a href="#AlertManager" class="headerlink" title="AlertManager"></a><a href="https://confluence.qingclass.cn/pages/viewpage.action?pageId=27755014#alertmanager" target="_blank" rel="noopener">AlertManager</a></h2><p>在 Prometheus Server 中支持基于 PromQL 创建告警规则，如果满足 PromQL 定义的规则，则会产生一条告警，而告警的后续处理流程则由 AlertManager 进行管理。在 AlertManager 中我们可以与邮件，Slack 等等内置的通知方式进行集成，也可以通过 Webhook 自定义告警处理方式。AlertManager 即 Prometheus 体系中的告警处理中心。</p><h2 id="PushGateway"><a href="#PushGateway" class="headerlink" title="PushGateway"></a><a href="https://confluence.qingclass.cn/pages/viewpage.action?pageId=27755014#pushgateway" target="_blank" rel="noopener">PushGateway</a></h2><p>由于 Prometheus 数据采集基于 Pull 模型进行设计，因此在网络环境的配置上必须要让 Prometheus Server 能够直接与 Exporter 进行通信。 当这种网络需求无法直接满足时，就可以利用 PushGateway 来进行中转。可以通过PushGateway 将内部网络的监控数据主动 Push 到 Gateway 当中。而 Prometheus Server 则可以采用同样 Pull 的方式从 PushGateway 中获取到监控数据。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Prometheus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> GitLab 连接 K8S 集群 </title>
    <link href="/2019/12/16/2019-12-16-gitlab-k8s/"/>
    <url>/2019/12/16/2019-12-16-gitlab-k8s/</url>
    
    <content type="html"><![CDATA[<p>用 <code>GitLab</code> 连接 <code>Kubernetes</code> 需要明确以下几点内容：</p><ul><li>目标集群的 API 连接地址；</li><li>集群的 CA 证书；</li><li>基于RBAC 的特定 ServiceAccount 的 Token；</li><li>需要部署 pod 到哪个 NameSpace；</li></ul><p><strong>获取集群的 API 连接地址</strong></p><p>获取集群的 API 连接地址可以用如下命令查看：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl cluster-info<br>Kubernetes master is running at https://59.110.217.141:6443<br>metrics-server is running at https://59.110.217.141:6443/api/v1/namespaces/kube-system/services/heapster/proxy<br>KubeDNS is running at https://59.110.217.141:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy<br></code></pre></div></td></tr></table></figure><figure class="highlight groovy"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs groovy">命令输出内容可以很快知道集群的连接地址是：<span class="hljs-string">https:</span><span class="hljs-comment">//59.110.217.141:6443</span><br></code></pre></div></td></tr></table></figure><blockquote><p>需要注意的是，有时候集群的连接地址分为公网地址和内网地址，这个时候可以根据需求自己做取舍，轻课的 GitLab 和阿里云的 Kubernetes 集群没有打通，一般用的是公网地址</p></blockquote><p><strong>集群 CA 证书</strong></p><p>一般一个集群的 CA 证书是唯一的，所以只需弄一次即可，以后就可以重复利用。</p><p>比如说，我们要在某个集群中的 <code>gatlin</code> 命名空间中部署我们的微服务应用，我们需要创建一个 <code>ServiceAccount</code> 并绑定某个 <code>Role</code> 来获取该命名空间的特定权限。</p><p>一般情况下，在 <code>kubernetes</code> 集群中创建某个 <code>sa</code> 会对应生成该<code>sa</code> 的 <code>secret</code>，我们可以通过该 <code>secret</code> 的具体信息获取整个集群的 <code>CA</code> 证书和对应 <code>sa</code> 的 <code>token</code></p><p><strong>创建对应命名空间的 ServiceAccount</strong></p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n gatlin create sa gatlin-admin<br>为了规范管理，以后所用 ns 的 sa 统一格式为 &lt;NS-NAME&gt;-admin<br></code></pre></div></td></tr></table></figure><p><strong>查看对应命名空间的 ServiceAccount</strong></p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n gatlin get serviceaccounts<br>NAME                     SECRETS   AGE<br>default                  1         20h<br>gatlin-admin             1         103m<br></code></pre></div></td></tr></table></figure><p><strong>给新建的 SA 绑定 Role</strong></p><p>对于权限这块，我一般都是直接绑定名称为 admin 的集群角色，这样该 sa 就获得了该 ns 的管理员权限，而这个 sa 对其他 ns 是没有任何权限的，符合 ci 流程。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n gatlin create clusterrolebinding gatlin-ns-admin --clusterrole=admin --serviceaccount=gatlin:gatlin-admin<br></code></pre></div></td></tr></table></figure><p><strong>查看自动生成的 secret</strong></p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl get secrets -n gatlin<br>NAME                                 TYPE                                  DATA   AGE<br>default-token-fgw4s                  kubernetes.io/service-account-token   3      20h<br>gatlin-admin-token-78pqk             kubernetes.io/service-account-token   3      108m<br>gatlin-service-account-token-nwhh2   kubernetes.io/service-account-token   3      88m<br>gatlin-token                         kubernetes.io/service-account-token   3      88m<br>然后用自动生成的 secret 查看集群 CA 证书就可以了：<br>$ kubectl -n gatlin get secrets gatlin-admin-token-78pqk -o jsonpath=<span class="hljs-string">"&#123;['data']['ca\.crt']&#125;"</span> | base64 -d<br>-----BEGIN CERTIFICATE-----<br>MIIDGjCCAgKgAwIBAgIBADANBgkqhkiG9w0BAQsFADA+MScwFAYDVQQKEw1hbGli<br>YWJhIGNsb3VkMA8GA1UEChMIaGFuZ3pob3UxEzARBgNVBAMTCmt1YmVybmV0ZXMw<br>HhcNMTkwNDIzMDkyMjI5WhcNMjkwNDIwMDkyMjI5WjA+MScwFAYDVQQKEw1hbGli<br>YWJhIGNsb3VkMA8GA1UEChMIaGFuZ3pob3UxEzARBgNVBAMTCmt1YmVybmV0ZXMw<br>ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCrNkXt3CB9HewGw6FLorrm<br>rpYqLxsNhouv61d5nbyD1mxcIQAlK879yFmEfvs6Mo1kp0X/BalTBR6tLvXnQrv6<br>t89n8sflmK5eaw4XVi+bpvVxyG2EyI0VBMzI77y5XYVkg0dD90lTfVyuLYx0h5e7<br>g5/SQmXBvSFotN6+ci3eZDDHluOr72QPLnRukWZNfJfQa5njTb53AxyHEV/qk35N<br>TfI7Er4GEAHniRjbg3zBHypIGc2XQlBROvON/CGehUI20agi+LZ6cNwDeYMQvbMa<br>Vc3hMlQRrscfwKWwiHumdCv1B6ALoF6dtqJp3ry+MS4VTnMc5ZdCsBRa64aaA61/<br>AgMBAAGjIzAhMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTADAQH/MA0GCSqG<br>SIb3DQEBCwUAA4IBAQAetfaOvLN7eklSZRnWBOqZN30ohgN9na/q+vsdtrFSqpRi<br>qeWCE0IIb0G8188J8ITLczgT3h3BrMOvh3KTrIre1+P6zH2bRdfhFD4upbYQRIpL<br>WYaEPxsEihjQFGhpOrvgJVdYpMC1/m09Ili9C82f1hZQp1S0+a0lvRXfR/ox76mv<br>Z2CKoXcP7n2uoh4cVbta8B1r4RSLwdBybWNAkD6NMPZ53LphRLdNaN1KvQJmAkOG<br>X7MiAZeupX+jz0mW+m+cWN0ftiUAuqsaPAfMOg6JgxHpM44WU+wu2aduFxKXzzud<br>Xns1hh44sDQ5vg5JhNd/06tyy2NiaqZRDRJ+ie1ewrwerjewrewj<br>-----END CERTIFICATE-----<br></code></pre></div></td></tr></table></figure><p>然后就可以看到神奇的 CA 证书了，哈哈。</p><p><strong>获取特定 ServiceAccount 的 Token</strong></p><p>获取 token 的时候直接用上面的 secret 即可：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n gatlin get secrets gatlin-admin-token-78pqk -o jsonpath=&#123;.data.token&#125; | base64 -d<br></code></pre></div></td></tr></table></figure><p>记得将上述命令输出的 token 保存一下就可以，因为 token 太长而且没有自动换行，这里就不贴了。</p><p><strong>配置 GitLab</strong></p><p>上面的工作做完了，配置 GitLab 连接 Kubernetes 集群就简单多了，『运维』–『Kubernetes』–『Add existing cluster』,然后直接把上述信息复制粘贴到对应框框里就行了</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-16/gitlab-k8s.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong><em>需要注意的是每个命名空间对应的 token 都不一样，不要盲目复制粘贴，还有就是如果配置错误需要将添加的集群删掉重建，有时候可能因为缓存的问题导致连接集群失败，这是重点，切记！！！</em></strong></p>]]></content>
    
    
    
    <tags>
      
      <tag>Gitlab</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 阿里云子账号权限策略 </title>
    <link href="/2019/12/15/2019-12-15-aliyun-policy/"/>
    <url>/2019/12/15/2019-12-15-aliyun-policy/</url>
    
    <content type="html"><![CDATA[<h1 id="1、OSS读写权限"><a href="#1、OSS读写权限" class="headerlink" title="1、OSS读写权限"></a>1、OSS读写权限</h1><figure class="highlight json"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs json">&#123;<br>    <span class="hljs-attr">"Version"</span>: <span class="hljs-string">"1"</span>,<br>    <span class="hljs-attr">"Statement"</span>: [<br>        &#123;<br>            <span class="hljs-attr">"Effect"</span>: <span class="hljs-string">"Allow"</span>,<br>            <span class="hljs-attr">"Action"</span>: [<br>                <span class="hljs-string">"oss:ListBuckets"</span>,<br>                <span class="hljs-string">"oss:GetBucketStat"</span>,<br>                <span class="hljs-string">"oss:GetBucketInfo"</span>,<br>                <span class="hljs-string">"oss:GetBucketTagging"</span>,<br>                <span class="hljs-string">"oss:GetBucketAcl"</span><br>            ],<br>            <span class="hljs-attr">"Resource"</span>: <span class="hljs-string">"acs:oss:*:*:*"</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-attr">"Effect"</span>: <span class="hljs-string">"Allow"</span>,<br>            <span class="hljs-attr">"Action"</span>: [<br>                <span class="hljs-string">"oss:Get*"</span>,<br>                <span class="hljs-string">"oss:List*"</span><br>            ],<br>            <span class="hljs-attr">"Resource"</span>: <span class="hljs-string">"acs:oss:*:*:oss名称"</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-attr">"Effect"</span>: <span class="hljs-string">"Allow"</span>,<br>            <span class="hljs-attr">"Action"</span>: [<br>                <span class="hljs-string">"oss:Get*"</span>,<br>                <span class="hljs-string">"oss:List*"</span>,<br>                <span class="hljs-string">"oss:Put*"</span>,<br>                <span class="hljs-string">"oss:AbortMultipartUpload"</span><br>            ],<br>            <span class="hljs-attr">"Resource"</span>: <span class="hljs-string">"acs:oss:*:*:oss名称/*"</span><br>        &#125;<br>    ]<br>&#125;<br></code></pre></div></td></tr></table></figure><h1 id="2、日志服务查看指定Project-只能创建，不能删除"><a href="#2、日志服务查看指定Project-只能创建，不能删除" class="headerlink" title="2、日志服务查看指定Project (只能创建，不能删除)"></a>2、日志服务查看指定Project (只能创建，不能删除)</h1><figure class="highlight json"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs json">&#123;<br>    <span class="hljs-attr">"Version"</span>: <span class="hljs-string">"1"</span>,<br>    <span class="hljs-attr">"Statement"</span>: [<br>        &#123;<br>            <span class="hljs-attr">"Action"</span>: [<br>                <span class="hljs-string">"log:ListProject"</span><br>            ],<br>            <span class="hljs-attr">"Resource"</span>: [<br>                <span class="hljs-string">"acs:log:*:*:project/*"</span><br>            ],<br>            <span class="hljs-attr">"Effect"</span>: <span class="hljs-string">"Allow"</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-attr">"Action"</span>: [<br>                <span class="hljs-string">"log:Get*"</span>,<br>                <span class="hljs-string">"log:List*"</span>,<br>                <span class="hljs-string">"log:Create*"</span>,<br>                <span class="hljs-string">"log:Update*"</span>,<br>                <span class="hljs-string">"log:Post*"</span><br>            ],<br>            <span class="hljs-attr">"Resource"</span>: <span class="hljs-string">"acs:log:*:*:project/project名称/*"</span>,<br>            <span class="hljs-attr">"Effect"</span>: <span class="hljs-string">"Allow"</span><br>        &#125;<br>    ]<br>&#125;<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>阿里云</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 执行力，才是拉开人与人差距的关键 </title>
    <link href="/2019/12/14/2019-12-14-execution/"/>
    <url>/2019/12/14/2019-12-14-execution/</url>
    
    <content type="html"><![CDATA[<h1 id="01-如果你想变得更好-首先要学会执行"><a href="#01-如果你想变得更好-首先要学会执行" class="headerlink" title="01 如果你想变得更好 首先要学会执行"></a>01 如果你想变得更好 首先要学会执行</h1><p>我们常常慨叹，为什么都是吃五谷杂粮长大的，人与人之间的差距怎么就那么大呢？</p><p>为什么毕业于同一个学校的人，几年后的差距也会变得那么大呢？</p><p>这其中有一个很重要的因素——<strong>执行力。</strong></p><p>那些能够超越同龄人的人，往往都有这样一个优点，他们除了有远见外，还特别肯吃苦，他们的勤奋和执行力往往能甩出同龄人几条街。</p><p>缺乏执行力，人就会焦虑、迷茫。</p><p>执行力是改变人生最直接有效的方法，没有之一。</p><p>当我们哀叹老板一直没有给自己涨工资，现在的工作不适合自己发展时，我们付出了多少行动？</p><p>一个人在舒适的环境待久了，无论他多么想改变，如果他不去执行，最终都很难取得大的成就。</p><p>马云有一句非常经典的名言：</p><p><strong>“晚上想想千条路，早上起来走原路。**</strong>”**</p><p><strong>说的就是一群人不去执行，只是空想，最终就只能是黄粱一梦。</strong></p><p>所以，想要变得更好，首先，你要学会去执行。</p><p>写出文章最好的办法，不是搜集资料，而是马上在键盘上敲下第一个字。提升演讲能力，突破演讲恐惧，最好的办法是，先冲上台再说。</p><p>等待、默默发力不是最好的准备，只有跨出第一步才叫执行。</p><p>我们常常看到很多曾经淡出人们视野的明星在某段时间后又重新成为人们谈论的话题，人们慨叹他们在年华逝去后还能保持美好的容颜，匀称的身材，仿佛岁月这把杀猪刀已经将他们遗忘。</p><p>其实，岁月并没有饶过谁，只是他们出色的自律力和执行力，让他们能够坚持自我锻炼，将自己塑造成了人们期待的样子。</p><h1 id="02-如何提升执行力？"><a href="#02-如何提升执行力？" class="headerlink" title="02  如何提升执行力？"></a>02  如何提升执行力？</h1><p>有人会说，如何才能练就这样的执行力呢？</p><p>最好的执行者从来都是自己主动去做，不是被动等待别人安排工作，自己才去做的人，而是能根据需求，主动去找事情做的人。</p><p>我们来看看香港的“珠宝大王”郑裕彤是怎么做的。</p><p>郑裕彤出身贫寒，为了养家糊口，小学毕业后，郑裕彤便到父亲的朋友周至元所开的“周大福金铺”去当学徒。</p><p>尽管做的是最底层的工作，但他丝毫不懈怠，每天都早早的赶到金铺，将金铺收拾打扫得干干净净。</p><p>往往是等他收拾完了之后，大伙计们才姗姗来迟。</p><p>店里的伙计，大多只知道埋头做本分事，而郑裕彤，除了做好本分事外，还特别爱动脑筋，经常琢磨和研究怎样做才能更有利于金铺的发展。</p><p>一天，老板让他到码头接一位亲戚。这时他看到有一位南洋侨商上了码头，并向人打听哪里可以兑换港币。</p><p>郑裕彤灵机一动，立即走上前去，说周大福金铺可以兑换，价格也最公道，并立即带路，将这位侨商带进了周大福，之后又马不停蹄地赶回码头接那位亲戚。</p><p>郑裕彤的这一做法，让周老板大为赞赏。</p><p>还有一次，伙计们开工好一会儿了，郑裕彤才气喘吁吁地跑进来。老板很生气，问他到哪里去了。</p><p>郑裕彤回答说，自己看别人家珠宝行做生意去了。</p><p>老板不禁有些好奇，于是问他看出了什么名堂没有。</p><p>“我看别家的生意，比我们店里做得精明，只要客人一踏进店门，店里老板、伙计总是笑脸相迎，有问必答；无论生意大小，一视同仁。</p><p>即使这回生意做不成，给人家留下一个好印象，下回他们自然还会光顾！”</p><p>“另外，店铺一定要开在做生意的旺地，门面装修也要讲究，特别是做珠宝生意，一定要显得十分气派。”</p><p><strong>郑裕彤的回答让老板不禁对这个小伙计有些刮目相看，他没想到这些经商诀窍能够从这个小学徒的口中总结出来。</strong></p><p>自那以后，老板开始有意识地培养他，还将女儿嫁给了他。</p><p>后来，他成为香港金行龙头老大“周大福”的掌门人。在郑裕彤的经营下，“周大福”已经成为了珠宝行和金铺的代名词。</p><p>假如郑裕彤面对那位兑换港元的南洋侨商，是这么想的：</p><p>“金铺又没多给我工钱，我主动去管什么闲事，多一事不如少一事。”</p><p>假如他不主动去琢磨怎么做生意，而是想：</p><p>“我一个小伙计，就算操这份心又有什么用？”</p><p>那么，结果又会怎样呢？</p><p><strong>一流的执行者，他首先会觉得那些问题就是自己的问题，要主动地创造性地去解决；</strong></p><p><strong>他会觉得好机会是单位的机会，也是自己的机会。</strong></p><p>无论这件事情与自己有没有直接关系，也无论自己的职位多么普通，他们都会当仁不让地去做。</p><p>而机会，往往就会因此而产生。</p><h1 id="03-执行力-拉开人与人差距的关键"><a href="#03-执行力-拉开人与人差距的关键" class="headerlink" title="03  执行力   拉开人与人差距的关键"></a>03  执行力   拉开人与人差距的关键</h1><p>皇明太阳能集团创始人、总裁黄鸣，就是一个非常典型的拥有超强执行力的人。</p><p>黄鸣大学毕业后被分到了石油钻井技术研究所，在技术装备室工作。工作两年后，地矿部有一个斥资几十亿元的“七五”大型设备改造项目，即为了提升钻井勘探的技术水平而要把所有的钻机都改造一遍。</p><p>当时部里把这个课题交给了比黄鸣所在装备室的级别和规模更高一级的装备研究所，为此还专门召开了钻机改造方案的评审会，黄鸣当时抱着学习的心态参加了评审会。</p><p>当时有几位年龄比较大的高工（高级工程师）在会上介绍方案，黄鸣听得非常仔细。</p><p>但听着听着，他觉得方案有问题。</p><p><strong>一是方案中有很多理论依据、设计计算跟大学的专业教科书和他所看到的国内外相关文献不符；</strong></p><p><strong>二是实施方案缺乏可操作性，设备改造方案与现场情况有很多不符之处。</strong></p><p>在大学期间，黄鸣的专业课程学得非常深入，每门都是优，实习期间，他又把整个井架、钻台、动力系统等摸得一清二楚，写了厚厚的实习报告，工作两年，他特别关注专业动态，写过几篇专业的文章，发表后引起了很大的关注。</p><p>正因为有对专业技术的深度把握，黄鸣快速捕捉到了方案的不足。</p><p>于是，他把自己认为不妥的地方逐条记下来，共列出了二十几条。等几位高工讲完方案让大家提意见的时候，黄鸣鼓起勇气一下讲了十几条。</p><p>讲的时候一气呵成，但讲完之后，他开始忐忑不安起来，毕竟在座的都是专家、司长、总工，自己不知深浅地提建议，会不会让别人感觉这个初出茅庐的小伙子太不知天高地厚了？</p><p>当天晚上，领导就把他叫到了办公室。当时他忐忑不安的心情可想而知。然而，让他没有想到的是，领导告诉他，听了他的意见之后，大家都很重视，为此特意开会进行讨论，认为他提的很多建议很重要，数据也很翔实，说明现在方案不成熟，存在漏洞，需要调整。</p><p>经过慎重考虑，领导决定把设备改造项目的任务分一半给他们科室，由他牵头，与另一科室共同完成，并正式通知他加入“七五”设备领导改造五人小组。</p><p>就这样，刚刚毕业两年的黄鸣获得了这个很多人想都不敢想的机会，他不负重托，带领课题小组顺利完成了任务，并获得了部里的科技进步二等奖。</p><p>从此，他不断承揽科研课题，年纪轻轻就当上了科研室副主任，成为所里的科研主力。这也为他以后的创业打下了坚实的基础。</p><p>黄鸣的做法，正是让执行力与创新力结合的典范。他的过人之处表现在以下两点：</p><p><strong>第一，不迷信权威，即使是众多专家的方案，如果有漏洞，他也敢于大胆说出自己的想法。</strong></p><p><strong>第二，虽然项目和自己无关，但还是主动去想创新的方案。</strong></p><p>工作中，很多人就像机器人一样，执行中很死板，被动地遵守常规。</p><p>其实，最好的执行者往往能够主动打破条条框框，并把创新力落实到执行中，主动为单位做出贡献。</p><p>只要你时刻围绕“如何将工作做得更好”去思考和琢磨，即使在平凡的岗位上，你也能做出有价值的创新。</p><p>这正是在更高的层面上去完善执行力。</p><p>所以，决定人生高度的，从来不是你的高谈阔论，而是你说做就做的执行力，没有执行力一切都是零。</p><p>执行力的不同，人与人的差距自然就拉开了，从开始的一点点到最后的相差甚远，最后会让你悔不当初。</p>]]></content>
    
    
    
    <tags>
      
      <tag>执行力</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title> 一行 Python 代码能实现这么多丧心病狂的功能？</title>
    <link href="/2019/12/13/2019-12-13-one-line-of-python-code/"/>
    <url>/2019/12/13/2019-12-13-one-line-of-python-code/</url>
    
    <content type="html"><![CDATA[<h1 id="一行代码打印乘法口诀"><a href="#一行代码打印乘法口诀" class="headerlink" title="一行代码打印乘法口诀"></a>一行代码打印乘法口诀</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">print(<span class="hljs-string">'\n'</span>.join([<span class="hljs-string">' '</span>.join([<span class="hljs-string">"%2s x%2s = %2s"</span>%(j,i,i*j) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,i+<span class="hljs-number">1</span>)]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)]))<br></code></pre></div></td></tr></table></figure><h1 id="一行代码打印迷宫"><a href="#一行代码打印迷宫" class="headerlink" title="一行代码打印迷宫"></a>一行代码打印迷宫</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">print(<span class="hljs-string">''</span>.join(__import__(<span class="hljs-string">'random'</span>).choice(<span class="hljs-string">'\u2571\u2572'</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">50</span>*<span class="hljs-number">24</span>)))<br></code></pre></div></td></tr></table></figure><h1 id="一行代码表白爱情"><a href="#一行代码表白爱情" class="headerlink" title="一行代码表白爱情"></a>一行代码表白爱情</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">print(<span class="hljs-string">'\n'</span>.join([<span class="hljs-string">''</span>.join([(<span class="hljs-string">'Love'</span>[(x-y) % len(<span class="hljs-string">'Love'</span>)] <span class="hljs-keyword">if</span> ((x*<span class="hljs-number">0.05</span>)**<span class="hljs-number">2</span>+(y*<span class="hljs-number">0.1</span>)**<span class="hljs-number">2</span><span class="hljs-number">-1</span>)**<span class="hljs-number">3</span>-(x*<span class="hljs-number">0.05</span>)**<span class="hljs-number">2</span>*(y*<span class="hljs-number">0.1</span>)**<span class="hljs-number">3</span> &lt;= <span class="hljs-number">0</span><span class="hljs-keyword">else</span><span class="hljs-string">' '</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">-30</span>, <span class="hljs-number">30</span>)]) <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(<span class="hljs-number">30</span>, <span class="hljs-number">-30</span>, <span class="hljs-number">-1</span>)]))！<br></code></pre></div></td></tr></table></figure><h1 id="一行代码打印小龟龟"><a href="#一行代码打印小龟龟" class="headerlink" title="一行代码打印小龟龟"></a>一行代码打印小龟龟</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">print(<span class="hljs-string">'\n'</span>.join([<span class="hljs-string">''</span>.join([<span class="hljs-string">'*'</span> <span class="hljs-keyword">if</span> abs((<span class="hljs-keyword">lambda</span> a:<span class="hljs-keyword">lambda</span> z,c,n:a(a,z,c,n))(<span class="hljs-keyword">lambda</span> s,z,c,n:z <span class="hljs-keyword">if</span> n==<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> s(s,z*z+c,c,n<span class="hljs-number">-1</span>))(<span class="hljs-number">0</span>,<span class="hljs-number">0.02</span>*x+<span class="hljs-number">0.05j</span>*y,<span class="hljs-number">40</span>))&lt;<span class="hljs-number">2</span> <span class="hljs-keyword">else</span> <span class="hljs-string">' '</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">-80</span>,<span class="hljs-number">20</span>)]) <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(<span class="hljs-number">-20</span>,<span class="hljs-number">20</span>)]))<br></code></pre></div></td></tr></table></figure><h1 id="一行代码实现-1-100-的和"><a href="#一行代码实现-1-100-的和" class="headerlink" title="一行代码实现 1 - 100 的和"></a>一行代码实现 1 - 100 的和</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">sum(range(<span class="hljs-number">1</span>,<span class="hljs-number">101</span>))<br></code></pre></div></td></tr></table></figure><h1 id="一行代码实现数值交换"><a href="#一行代码实现数值交换" class="headerlink" title="一行代码实现数值交换"></a>一行代码实现数值交换</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">a = <span class="hljs-number">1</span><br>b = <span class="hljs-number">2</span><br>a,b = b,a<br>print(a,b)<br></code></pre></div></td></tr></table></figure><h1 id="一行代码求奇偶数"><a href="#一行代码求奇偶数" class="headerlink" title="一行代码求奇偶数"></a>一行代码求奇偶数</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">[x <span class="hljs-keyword">for</span>  x <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>) <span class="hljs-keyword">if</span> x % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>]<br></code></pre></div></td></tr></table></figure><h1 id="一行代码展开列表"><a href="#一行代码展开列表" class="headerlink" title="一行代码展开列表"></a>一行代码展开列表</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">list = [[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>]]<br>[j <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> list <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> i]<br></code></pre></div></td></tr></table></figure><h1 id="一行代码打乱列表"><a href="#一行代码打乱列表" class="headerlink" title="一行代码打乱列表"></a>一行代码打乱列表</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br>lst = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>]<br>random.shuffle(lst)<br>lst<br></code></pre></div></td></tr></table></figure><h1 id="一行代码反转字符串"><a href="#一行代码反转字符串" class="headerlink" title="一行代码反转字符串"></a>一行代码反转字符串</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">name = <span class="hljs-string">'byf4963cg'</span><br>name = [::<span class="hljs-number">-1</span>]<br></code></pre></div></td></tr></table></figure><h1 id="一行代码查看目录下所有文件"><a href="#一行代码查看目录下所有文件" class="headerlink" title="一行代码查看目录下所有文件"></a>一行代码查看目录下所有文件</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br>os.listdir(<span class="hljs-string">'.'</span>)<br></code></pre></div></td></tr></table></figure><h1 id="一行代码去除字符串间的空格"><a href="#一行代码去除字符串间的空格" class="headerlink" title="一行代码去除字符串间的空格"></a>一行代码去除字符串间的空格</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">des = <span class="hljs-string">'My name is master123'</span><br>des.replace(<span class="hljs-string">""</span>,<span class="hljs-string">""</span>)<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">des = <span class="hljs-string">'My name is master123'</span><br><span class="hljs-string">""</span>.join(des.split(<span class="hljs-string">" "</span>))<br></code></pre></div></td></tr></table></figure><h1 id="一行代码实现字符串整数列表变成整数列表"><a href="#一行代码实现字符串整数列表变成整数列表" class="headerlink" title="一行代码实现字符串整数列表变成整数列表"></a>一行代码实现字符串整数列表变成整数列表</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">a = [<span class="hljs-string">'1'</span>,<span class="hljs-string">'2'</span>,<span class="hljs-string">'3'</span>,<span class="hljs-string">'4'</span>,<span class="hljs-string">'5'</span>]<br>list(map(<span class="hljs-keyword">lambda</span> a : int (a),[<span class="hljs-string">'1'</span>,<span class="hljs-string">'2'</span>,<span class="hljs-string">'3'</span>,<span class="hljs-string">'4'</span>,<span class="hljs-string">'5'</span>]))<br></code></pre></div></td></tr></table></figure><h1 id="一行代码删除列表中重复的值"><a href="#一行代码删除列表中重复的值" class="headerlink" title="一行代码删除列表中重复的值"></a>一行代码删除列表中重复的值</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">lst = [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>]<br>list(set(lst))<br></code></pre></div></td></tr></table></figure><h1 id="一行代码找出两个列表中相同的元素"><a href="#一行代码找出两个列表中相同的元素" class="headerlink" title="一行代码找出两个列表中相同的元素"></a>一行代码找出两个列表中相同的元素</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">a = [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>]<br>b = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>]<br>set(a) &amp; set(b)<br></code></pre></div></td></tr></table></figure><h1 id="一行代码找出两个列表中不同的元素"><a href="#一行代码找出两个列表中不同的元素" class="headerlink" title="一行代码找出两个列表中不同的元素"></a>一行代码找出两个列表中不同的元素</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">a = [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>]<br>b = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>]<br>set(a) ^ set(b)<br></code></pre></div></td></tr></table></figure><h1 id="一行代码合并两个字典"><a href="#一行代码合并两个字典" class="headerlink" title="一行代码合并两个字典"></a>一行代码合并两个字典</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">des = &#123;<span class="hljs-string">'name'</span>: <span class="hljs-string">'john'</span>&#125;<br>age = &#123;<span class="hljs-string">'age'</span>: <span class="hljs-string">'25'</span>&#125;<br>des.update(age)<br>des<br></code></pre></div></td></tr></table></figure><h1 id="一行代码实现字典键从小到大排序"><a href="#一行代码实现字典键从小到大排序" class="headerlink" title="一行代码实现字典键从小到大排序"></a>一行代码实现字典键从小到大排序</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">des = &#123;<span class="hljs-string">'name'</span>: <span class="hljs-string">'john'</span>,<span class="hljs-string">'age'</span>: <span class="hljs-string">'25'</span>,<span class="hljs-string">'like'</span>: <span class="hljs-string">'python'</span>&#125;<br>sorted(des.items(), key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>])<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Nginx 配置参数中文说明 </title>
    <link href="/2019/12/12/2019-12-12-nginx-chinese/"/>
    <url>/2019/12/12/2019-12-12-nginx-chinese/</url>
    
    <content type="html"><![CDATA[<h1 id="Nginx-配置参数中文详细说明："><a href="#Nginx-配置参数中文详细说明：" class="headerlink" title="Nginx 配置参数中文详细说明："></a>Nginx 配置参数中文详细说明：</h1><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#定义Nginx运行的用户和用户组</span><br>user www www;<br><span class="hljs-comment">#</span><br><span class="hljs-comment">#nginx进程数,建议设置为等于CPU总核心数.</span><br>worker_processes 8;<br><span class="hljs-comment">#</span><br><span class="hljs-comment">#全局错误日志定义类型,[ debug | info | notice | warn | error | crit ]</span><br>error_log /var/<span class="hljs-built_in">log</span>/nginx/error.log info;<br><span class="hljs-comment">#</span><br><span class="hljs-comment">#进程文件</span><br>pid /var/run/nginx.pid;<br><span class="hljs-comment">#</span><br><span class="hljs-comment">#一个nginx进程打开的最多文件描述符数目,理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除,但是nginx分配请求并不均匀,所以建议与ulimit -n的值保持一致.</span><br>worker_rlimit_nofile 65535;<br><span class="hljs-comment">#</span><br><span class="hljs-comment">#工作模式与连接数上限</span><br>events<br>&#123;<br>    <span class="hljs-comment">#参考事件模型,use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型,如果跑在FreeBSD上面,就用kqueue模型.</span><br>    use epoll;<br>    <span class="hljs-comment">#单个进程最大连接数（最大连接数=连接数*进程数）</span><br>    worker_connections 65535;<br>&#125;<br><span class="hljs-comment">#</span><br><span class="hljs-comment">#设定http服务器</span><br>http<br>&#123;<br>    include mime.types; <span class="hljs-comment">#文件扩展名与文件类型映射表</span><br>    default_type application/octet-stream; <span class="hljs-comment">#默认文件类型</span><br>    <span class="hljs-comment">#charset utf-8; #默认编码</span><br>    server_names_hash_bucket_size 128; <span class="hljs-comment">#服务器名字的hash表大小</span><br>    client_header_buffer_size 32k; <span class="hljs-comment">#上传文件大小限制</span><br>    large_client_header_buffers 4 64k; <span class="hljs-comment">#设定请求缓</span><br>    client_max_body_size 8m; <span class="hljs-comment">#设定请求缓</span><br>    <br>    <span class="hljs-comment"># 开启目录列表访问,合适下载服务器,默认关闭.</span><br>    autoindex on; <span class="hljs-comment"># 显示目录</span><br>    autoindex_exact_size on; <span class="hljs-comment"># 显示文件大小 默认为on,显示出文件的确切大小,单位是bytes 改为off后,显示出文件的大概大小,单位是kB或者MB或者GB</span><br>    autoindex_localtime on; <span class="hljs-comment"># 显示文件时间 默认为off,显示的文件时间为GMT时间 改为on后,显示的文件时间为文件的服务器时间</span><br>    <br>    sendfile on; <span class="hljs-comment"># 开启高效文件传输模式,sendfile指令指定nginx是否调用sendfile函数来输出文件,对于普通应用设为 on,如果用来进行下载等应用磁盘IO重负载应用,可设置为off,以平衡磁盘与网络I/O处理速度,降低系统的负载.注意：如果图片显示不正常把这个改成off.</span><br>    tcp_nopush on; <span class="hljs-comment"># 防止网络阻塞</span><br>    tcp_nodelay on; <span class="hljs-comment"># 防止网络阻塞</span><br>    <br>    keepalive_timeout 120; <span class="hljs-comment"># (单位s)设置客户端连接保持活动的超时时间,在超过这个时间后服务器会关闭该链接</span><br>    <br>    <span class="hljs-comment"># FastCGI相关参数是为了改善网站的性能：减少资源占用,提高访问速度.下面参数看字面意思都能理解.</span><br>    fastcgi_connect_timeout 300;<br>    fastcgi_send_timeout 300;<br>    fastcgi_read_timeout 300;<br>    fastcgi_buffer_size 64k;<br>    fastcgi_buffers 4 64k;<br>    fastcgi_busy_buffers_size 128k;<br>    fastcgi_temp_file_write_size 128k;<br>    <br>    <span class="hljs-comment"># gzip模块设置</span><br>    gzip on; <span class="hljs-comment">#开启gzip压缩输出</span><br>    gzip_min_length 1k; <span class="hljs-comment">#允许压缩的页面的最小字节数,页面字节数从header偷得content-length中获取.默认是0,不管页面多大都进行压缩.建议设置成大于1k的字节数,小于1k可能会越压越大</span><br>    gzip_buffers 4 16k; <span class="hljs-comment">#表示申请4个单位为16k的内存作为压缩结果流缓存,默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果</span><br>    gzip_http_version 1.1; <span class="hljs-comment">#压缩版本（默认1.1,目前大部分浏览器已经支持gzip解压.前端如果是squid2.5请使用1.0）</span><br>    gzip_comp_level 2; <span class="hljs-comment">#压缩等级.1压缩比最小,处理速度快.9压缩比最大,比较消耗cpu资源,处理速度最慢,但是因为压缩比最大,所以包最小,传输速度快</span><br>    gzip_types text/plain application/x-javascript text/css application/xml;<br>    <span class="hljs-comment">#压缩类型,默认就已经包含text/html,所以下面就不用再写了,写上去也不会有问题,但是会有一个warn.</span><br>    gzip_vary on;<span class="hljs-comment">#选项可以让前端的缓存服务器缓存经过gzip压缩的页面.例如:用squid缓存经过nginx压缩的数据</span><br>    <br>    <span class="hljs-comment">#开启限制IP连接数的时候需要使用</span><br>    <span class="hljs-comment">#limit_zone crawler $binary_remote_addr 10m;</span><br>    <br>    <span class="hljs-comment">##upstream的负载均衡,四种调度算法(下例主讲)##</span><br>    <br>    <span class="hljs-comment">#虚拟主机的配置</span><br>    server<br>    &#123;<br>        <span class="hljs-comment"># 监听端口</span><br>        listen 80;<br>        <span class="hljs-comment"># 域名可以有多个,用空格隔开</span><br>        server_name ably.com;<br>        <span class="hljs-comment"># HTTP 自动跳转 HTTPS</span><br>        rewrite ^(.*) https://<span class="hljs-variable">$server_name</span><span class="hljs-variable">$1</span> permanent;<br>    &#125;<br>    <br>    server<br>    &#123;<br>        <span class="hljs-comment"># 监听端口 HTTPS</span><br>        listen 443 ssl;<br>        server_name ably.com;<br>        <br>        <span class="hljs-comment"># 配置域名证书</span><br>        ssl_certificate      C:\WebServer\Certs\certificate.crt;<br>        ssl_certificate_key  C:\WebServer\Certs\private.key;<br>        ssl_session_cache    shared:SSL:1m;<br>        ssl_session_timeout  5m;<br>        ssl_protocols SSLv2 SSLv3 TLSv1;<br>        ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;<br>        ssl_prefer_server_ciphers  on;<br>    <br>        index index.html index.htm index.php;<br>        root /data/www/;<br>        location ~ .*\.(php|php5)?$<br>        &#123;<br>            fastcgi_pass 127.0.0.1:9000;<br>            fastcgi_index index.php;<br>            include fastcgi.conf;<br>        &#125;<br>        <br>        <span class="hljs-comment"># 配置地址拦截转发，解决跨域验证问题</span><br>        location /oauth/&#123;<br>            proxy_pass https://localhost:13580/oauth/;<br>            proxy_set_header HOST <span class="hljs-variable">$host</span>;<br>            proxy_set_header X-Real-IP <span class="hljs-variable">$remote_addr</span>;<br>            proxy_set_header X-Forwarded-For <span class="hljs-variable">$proxy_add_x_forwarded_for</span>;<br>        &#125;<br>        <br>        <span class="hljs-comment"># 图片缓存时间设置</span><br>        location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ &#123;<br>            expires 10d;<br>        &#125;<br>        <br>        <span class="hljs-comment"># JS和CSS缓存时间设置</span><br>        location ~ .*\.(js|css)?$ &#123;<br>            expires 1h;<br>        &#125;<br><br>        <span class="hljs-comment"># 日志格式设定</span><br>        log_format access <span class="hljs-string">'$remote_addr - $remote_user [$time_local] "$request" '</span><br>        <span class="hljs-string">'$status $body_bytes_sent "$http_referer" '</span><br>        <span class="hljs-string">'"$http_user_agent" $http_x_forwarded_for'</span>;<br>        <span class="hljs-comment"># 定义本虚拟主机的访问日志</span><br>        access_log /var/<span class="hljs-built_in">log</span>/nginx/access.log access;<br>        <br>        <span class="hljs-comment"># 设定查看Nginx状态的地址.StubStatus模块能够获取Nginx自上次启动以来的工作状态，此模块非核心模块，需要在Nginx编译安装时手工指定才能使用</span><br>        location /NginxStatus &#123;<br>            stub_status on;<br>            access_log on;<br>            auth_basic <span class="hljs-string">"NginxStatus"</span>;<br>            auth_basic_user_file conf/htpasswd;<br>            <span class="hljs-comment">#htpasswd文件的内容可以用apache提供的htpasswd工具来产生.</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h1 id="Nginx负载均衡服务器的nginx-conf配置注释"><a href="#Nginx负载均衡服务器的nginx-conf配置注释" class="headerlink" title="Nginx负载均衡服务器的nginx.conf配置注释"></a>Nginx负载均衡服务器的<code>nginx.conf</code>配置注释</h1><p><strong>如下：</strong></p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">events<br>&#123;<br>    use epoll;<br>    worker_connections 65535;<br>&#125;<br>http<br>&#123;<br>    <span class="hljs-comment">##upstream的负载均衡,四种调度算法##</span><br>    <span class="hljs-comment">#调度算法1:轮询.每个请求按时间顺序逐一分配到不同的后端服务器,如果后端某台服务器宕机,故障系统被自动剔除,使用户访问不受影响</span><br>    upstream webhost &#123;<br>        server 192.168.0.5:6666 ;<br>        server 192.168.0.7:6666 ;<br>    &#125;<br>    <span class="hljs-comment">#调度算法2:weight(权重).可以根据机器配置定义权重.权重越高被分配到的几率越大</span><br>    upstream webhost &#123;<br>        server 192.168.0.5:6666 weight=2;<br>        server 192.168.0.7:6666 weight=3;<br>    &#125;<br>    <span class="hljs-comment">#调度算法3:ip_hash. 每个请求按访问IP的hash结果分配,这样来自同一个IP的访客固定访问一个后端服务器,有效解决了动态网页存在的session共享问题</span><br>    upstream webhost &#123;<br>        ip_hash;<br>        server 192.168.0.5:6666 ;<br>        server 192.168.0.7:6666 ;<br>    &#125;<br>    <span class="hljs-comment">#调度算法4:url_hash(需安装第三方插件).此方法按访问url的hash结果来分配请求,使每个url定向到同一个后端服务器,可以进一步提高后端缓存服务器的效率.Nginx本身是不支持url_hash的,如果需要使用这种调度算法,必须安装Nginx 的hash软件包</span><br>    upstream webhost &#123;<br>        server 192.168.0.5:6666 ;<br>        server 192.168.0.7:6666 ;<br>        <span class="hljs-built_in">hash</span> <span class="hljs-variable">$request_uri</span>;<br>    &#125;<br>    <span class="hljs-comment">#调度算法5:fair(需安装第三方插件).这是比上面两个更加智能的负载均衡算法.此种算法可以依据页面大小和加载时间长短智能地进行负载均衡,也就是根据后端服务器的响应时间来分配请求,响应时间短的优先分配.Nginx本身是不支持fair的,如果需要使用这种调度算法,必须下载Nginx的upstream_fair模块</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment">#虚拟主机的配置(采用调度算法3:ip_hash)</span><br>    server<br>    &#123;<br>        listen 80;<br>        server_name mongo.demo.com;<br>        <span class="hljs-comment">#对 "/" 启用反向代理</span><br>        location / &#123;<br>            proxy_pass http://webhost;<br>            proxy_redirect off;<br>            proxy_set_header X-Real-IP <span class="hljs-variable">$remote_addr</span>;<br>            <span class="hljs-comment">#后端的Web服务器可以通过X-Forwarded-For获取用户真实IP</span><br>            proxy_set_header X-Forwarded-For <span class="hljs-variable">$proxy_add_x_forwarded_for</span>;<br>            <span class="hljs-comment">#以下是一些反向代理的配置,可选.</span><br>            proxy_set_header Host <span class="hljs-variable">$host</span>;<br>            client_max_body_size 10m; <span class="hljs-comment">#允许客户端请求的最大单文件字节数</span><br>            client_body_buffer_size 128k; <span class="hljs-comment">#缓冲区代理缓冲用户端请求的最大字节数,</span><br>            proxy_connect_timeout 90; <span class="hljs-comment">#nginx跟后端服务器连接超时时间(代理连接超时)</span><br>            proxy_send_timeout 90; <span class="hljs-comment">#后端服务器数据回传时间(代理发送超时)</span><br>            proxy_read_timeout 90; <span class="hljs-comment">#连接成功后,后端服务器响应时间(代理接收超时)</span><br>            proxy_buffer_size 4k; <span class="hljs-comment">#设置代理服务器（nginx）保存用户头信息的缓冲区大小</span><br>            proxy_buffers 4 32k; <span class="hljs-comment">#proxy_buffers缓冲区,网页平均在32k以下的设置</span><br>            proxy_busy_buffers_size 64k; <span class="hljs-comment">#高负荷下缓冲大小（proxy_buffers*2）</span><br>            proxy_temp_file_write_size 64k;<br>            <span class="hljs-comment">#设定缓存文件夹大小,大于这个值,将从upstream服务器传</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>参考链接：<a href="https://mp.weixin.qq.com/s/T0uXiWtvE9tYijVlEsCKLw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/T0uXiWtvE9tYijVlEsCKLw</a></p><p>​                  <a href="http://www.cnblogs.com/xcloudbiz/articles/5234373.html" target="_blank" rel="noopener">http://www.cnblogs.com/xcloudbiz/articles/5234373.html</a></p><p>​                  <a href="http://wangying.sinaapp.com/archives/931" target="_blank" rel="noopener">http://wangying.sinaapp.com/archives/931</a></p><p>​                  <a href="http://www.php100.com/html/program/nginx/2013/0905/5525.html" target="_blank" rel="noopener">http://www.php100.com/html/program/nginx/2013/0905/5525.html</a></p><p>​                  <a href="https://hub.docker.com/_/nginx/" target="_blank" rel="noopener">https://hub.docker.com/_/nginx/</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Nginx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第9篇 网络原理解析</title>
    <link href="/2019/12/11/2019-12-11-kubernetes9-network/"/>
    <url>/2019/12/11/2019-12-11-kubernetes9-network/</url>
    
    <content type="html"><![CDATA[<h1 id="1、Linux网络基础"><a href="#1、Linux网络基础" class="headerlink" title="1、Linux网络基础"></a>1、Linux网络基础</h1><p><strong>Network Namespace(网络命名空间)：</strong></p><p>Linux在网络栈中引入网络命名空间，将独立的网络协议栈隔离到不同的命令空间中，彼此间无法通信；docker利用这一特性，实现不容器间的网络隔离。</p><p><strong>Iptables/Netfilter：</strong></p><p>Netfilter负责在内核中执行各种挂接的规则(过滤、修改、丢弃等)，运行在内核模式中；Iptables模式是在用户模式下运行的进程，负责协助维护内核中Netfilter的各种规则表；通过分析进入主机的网络封包，将封包的表头数据提取出来进行分析，以决定该联机为放行或抵挡的机制。由于这种方式可以直接分析封包表头数据，所以包括硬件地址(MAC), 软件地址 (IP), TCP, UDP, ICMP 等封包的信息都可以进行过滤分析。</p><p><strong>Veth设备对：</strong></p><p>Veth设备对的引入是为了实现在不同网络命名空间的通信。</p><p><strong>Bridge(网桥)：</strong></p><p>网桥是一个二层网络设备，是最简单的CNI网络插件，它首先在Host创建一个网桥，然后再通过veth pair连接该网桥到container netns。另外，Bridge模式下，多主机网络通信需要额外配置主机路由。</p><p><strong>Route(路由)：</strong></p><p>Linux系统包含一个完整的路由功能，当IP层在处理数据发送或转发的时候会使用路由表来决定发往哪里。</p><p><strong>Container Network Interface (CNI) ：</strong></p><p>最早是由CoreOS发起的容器网络规范，是 Kubernetes网络插件的基础。其基本思想为:Container Runtime在创建容器时，先创建好network namespace，然后调用CNI插件为这个netns配置网络，其后再启动容器内的进程。</p><h1 id="2、K8S网络模型"><a href="#2、K8S网络模型" class="headerlink" title="2、K8S网络模型"></a>2、K8S网络模型</h1><p>Kubernetes网络有一个重要的基本设计原则：<strong>每个Pod拥有唯一的IP</strong>。</p><p>这个Pod IP被该Pod内的所有容器共享，并且其它所有Pod都可以路由到该Pod。你可曾注意到，你的Kubernetes节点上运行着一些”pause”容器？它们被称作“沙盒容器（sandbox containers）”，其唯一任务是保留并持有一个网络命名空间（netns），该命名空间被Pod内所有容器共享。通过这种方式，即使一个容器死掉，新的容器创建出来代替这个容器，Pod IP也不会改变。这种IP-per-pod模型的巨大优势是，Pod和底层主机不会有IP或者端口冲突。我们不用担心应用使用了什么端口。</p><p>这点满足后，Kubernetes唯一的要求是，这些Pod IP可被其它所有Pod访问，不管那些Pod在哪个节点。</p><h2 id="2-1-节点内通信"><a href="#2-1-节点内通信" class="headerlink" title="2.1 节点内通信"></a>2.1 节点内通信</h2><p>第一步是确保同一节点上的Pod可以相互通信，然后可以扩展到跨节点通信、internet上的通信，等等。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/2-2-1-a.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>在每个Kubernetes节点（本场景指的是Linux机器）上，都有一个根（root）命名空间（root是作为基准，而不是超级用户）– root netns(root network namespace)。</p><p>主要的网络接口 eth0 就是在这个root netns下。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/2-2-1-b.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>类似的，每个Pod都有其自身的netns(network namespace)，通过一个虚拟的以太网对连接到root netns。这基本上就是一个管道对，一端在root netns内，另一端在Pod的netns内。</p><p>我们把Pod端的网络接口叫 eth0，这样Pod就不需要知道底层主机，它认为它拥有自己的根网络设备。另一端命名成比如 vethxxx。你可以用 ifconfig 或者 ip a 命令列出你的节点上的所有这些接口。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/2-2-1-c.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>节点上的所有Pod都会完成这个过程。这些Pod要相互通信，就要用到linux的以太网桥 cbr0 了。Docker使用了类似的网桥，称为docker0。你可以用 brctl show 命令列出所有网桥。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/2-2-1-d.gif" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>假设一个网络数据包要由pod1到pod2</p><p>1) 它由pod1中netns的eth0网口离开，通过vethxxx进入root netns。</p><p>2) 然后被传到cbr0，cbr0使用ARP请求，说“谁拥有这个IP”，从而发现目标地址。</p><p>3）vethyyy说它有这个IP，因此网桥就知道了往哪里转发这个包。</p><p>4）数据包到达vethyyy，跨过管道对，到达pod2的netns。</p><p>这就是同一节点内容器间通信的流程。当然也可以用其它方式，但是无疑这是最简单的方式，同时也是Docker采用的方式。</p><h2 id="2-2-不同节点间通信"><a href="#2-2-不同节点间通信" class="headerlink" title="2.2 不同节点间通信"></a>2.2 不同节点间通信</h2><p>正如我前面提到，Pod也需要跨节点可达。Kubernetes不关心如何实现。我们可以使用L2（ARP跨节点），L3（IP路由跨节点，就像云提供商的路由表），Overlay网络，或者甚至信鸽。无所谓，只要流量能到达另一个节点的期望Pod就好。每个节点都为Pod IPs分配了唯一的CIDR块（一段IP地址范围），因此每个Pod都拥有唯一的IP，不会和其它节点上的Pod冲突。</p><p>大多数情况下，特别是在云环境上，云提供商的路由表就能确保数据包到达正确的目的地。我们在每个节点上建立正确的路由也能达到同样的目的。许多其它的网络插件通过自己的方式达到这个目的。</p><p>这里我们有两个节点，与之前看到的类似。每个节点有不同的网络命名空间、网络接口以及网桥。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/2-2-2-a.gif" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>假设一个数据包要从pod1到达pod4（在不同的节点上）</p><p>1）它由pod1中netns的eth0网口离开，通过vethxxx进入root netns。</p><p>2）然后被传到cbr0，cbr0通过发送ARP请求来找到目标地址。</p><p>3）本节点上没有Pod拥有pod4的IP地址，根据路由判断数据包由cbr0 传到主网络接口 eth0。</p><p>4）数据包的源地址为pod1，目标地址为pod4，它以这种方式离开node1进入电缆。</p><p>5）路由表有每个节点的CIDR块的路由设定，它把数据包路由到CIDR块包含pod4的IP的节点。</p><p>6）因此数据包到达了node2的主网络接口eth0。现在即使pod4不是eth0的IP，数据包也仍然能转发到cbr0，因为节点配置了IP forwarding enabled。节点的路由表寻找任意能匹配pod4 IP的路由。它发现了 cbr0 是这个节点的CIDR块的目标地址。你可以用route -n命令列出该节点的路由表，它会显示cbr0的路由，类型如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/2-2-2-b.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>7）网桥接收了数据包，发送ARP请求，发现目标IP属于vethyyy。</p><p>8）数据包跨过管道对到达pod4。</p><h1 id="3、覆盖网络"><a href="#3、覆盖网络" class="headerlink" title="3、覆盖网络"></a>3、覆盖网络</h1><p>覆盖⽹络(overlay network)是将TCP数据包装在另⼀种⽹络包⾥⾯进⾏路由转发和通信的技术。Overlay⽹络不是默认必须的，但是它们在特定场景下⾮常有⽤。⽐如当我们没有⾜够的IP空间，或者⽹络⽆法处理额外路由，抑或当我们需要Overlay提供的某些额外管理特性。⼀个常⻅的场景是当云提供商的路由表能处理的路由数是有限制时，例如AWS路由表最多⽀持50条路由才不⾄于影响⽹络性能。因此如果我们有超过50个Kubernetes节点， AWS路由表将不够。这种情况下，使⽤Overlay⽹络将帮到我们。</p><p>本质上来说， Overlay就是在跨节点的本地⽹络上的包中再封装⼀层包。你可能不想使⽤Overlay⽹络，因为它会带来由封装和解封所有报⽂引起的时延和复杂度开销。通常这是不必要的，因此我们应当在知道为什么我们需要它时才使⽤它。</p><p>为了理解Overlay⽹络中流量的流向，我们拿Flannel做例⼦，它是CoreOS 的⼀个开源项⽬。Flannel通过给每台宿主机分配⼀个⼦⽹的⽅式为容器提供虚拟⽹络，它基于Linux TUN/TAP，使⽤UDP封装IP包来创建overlay⽹络，并借助etcd维护⽹络的分配情况。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/3-1.gif" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>这⾥我们注意到它和之前我们看到的设施是⼀样的，只是在root netns中新增了⼀个虚拟的以太⽹设备，称为flannel0。它是虚拟扩展⽹络Virtual Extensible LAN（VXLAN）的⼀种实现，但是在Linux上，它只是另⼀个⽹络接⼝。</p><p>从pod1到pod4（在不同节点）的数据包的流向类似如下：</p><p>1）它由pod1中netns的eth0⽹⼝离开，通过vethxxx进⼊root netns。<br>2）然后被传到cbr0， cbr0通过发送ARP请求来找到⽬标地址。<br>3）数据封装</p><p>  3a. 由于本节点上没有Pod拥有pod4的IP地址，因此⽹桥把数据包发送给了flannel0，因为节点的路由表上flannel0被配成了Pod⽹段的⽬标地址。</p><p>  3b. flanneld daemon和Kubernetes apiserver或者底层的etcd通信，它知道所有的Pod IP，并且知道它们在哪个节点上。因此Flannel创建了Pod IP和Node IP之间的映射（在⽤户空间）。flannel0取到这个包，并在其上再⽤⼀个UDP包封装起来，该UDP包头部的源和⽬的IP分别被改成了对应节点的IP，然后发送这个新包到特定的VXLAN端⼝（通常是8472）。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/3-2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>尽管这个映射发⽣在⽤户空间，真实的封装以及数据的流动发⽣在内核空间，因此仍然是很快的。  </p><p>  3c. 封装后的包通过eth0发送出去，因为它涉及了节点间的路由流量。</p><p>\4. 包带着节点IP信息作为源和⽬的地址离开本节点。<br>\5. 云提供商的路由表已经知道了如何在节点间发送报⽂，因此该报⽂被发送到⽬标地址node2。<br>\6. 数据解包</p><p>  6a. 包到达node2的eth0⽹卡，由于⽬标端⼝是特定的VXLAN端⼝，内核将报⽂发送给了<br>flannel0。<br>  6b. flannel0解封报⽂，并将其发送到 root 命名空间下。从这⾥开始，报⽂的路径和我们之前在Part1 中看到的⾮Overlay⽹络就是⼀致的了。<br>  6c. 由于IP forwarding开启着，内核按照路由表将报⽂转发给了cbr0。</p><p>\7. ⽹桥获取到了包，发送ARP请求，发现⽬标IP属于vethyyy。<br>\8. 包跨过管道对到达pod4</p><p>这就是Kubernetes中Overlay⽹络的⼯作⽅式，虽然不同的实现还是会有细微的差别。<strong>有个常⻅的误区是，当我们使⽤Kubernetes，我们就不得不使⽤Overlay⽹络。事实是，这完全依赖于特定场景。因此请确保在确实需要的场景下才使⽤</strong>。</p><h1 id="4、动态集群"><a href="#4、动态集群" class="headerlink" title="4、动态集群"></a>4、动态集群</h1><p>由于Kubernetes（更通⽤的说法是分布式系统）天⽣具有不断变化的特性，因此它的Pod（以及Pod的IP）总是在改变。变化的原因可以是针对不可预测的Pod或节点崩溃⽽进⾏的滚动升级和扩展。这使得Pod IP不能直接⽤于通信。</p><p>我们看⼀下Kubernetes Service，它是⼀个虚拟IP，并伴随着⼀组Pod IP作为Endpoint（通过标签选择器识别）。它们充当虚拟负载均衡器，其IP保持不变，⽽后端Pod IP可能会不断变化。</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">V1</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">svc2</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">ClusterIP</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">myapp</span><br>  <span class="hljs-attr">ClusterIP:</span> <span class="hljs-number">10.200</span><span class="hljs-number">.100</span><span class="hljs-number">.214</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">http</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">80</span><br></code></pre></div></td></tr></table></figure><p>整个虚拟IP的实现实际上是⼀组iptables（最新版本可以选择使⽤IPVS，但这是另⼀个讨论）规则，由Kubernetes组件kube-proxy管理。这个名字现在实际上是误导性的。它在v 1.0之前确实是⼀个代理，并且由于其实现是内核空间和⽤户空间之间的不断复制，它变得⾮常耗费资源并且速度较慢。现在，它只是⼀个控制器，就像Kubernetes中的许多其它控制器⼀样，它watch api serverendpoint的更改并相应地更新iptables规则。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/4-0-a.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>有了这些iptables规则，每当数据包发往Service IP时，它就进⾏DNAT（DNAT=⽬标⽹络地址转换）操作，这意味着⽬标IP从Service IP更改为其中⼀个Endpoint - Pod IP - 由iptables随机选择。这可确保负载均匀分布在后端Pod中。</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-11/4-0-b.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>当这个DNAT发⽣时，这个信息存储在conntrack中——Linux连接跟踪表（iptables规则5元组转译并完成存储：protocol， srcIP， srcPort， dstIP， dstPort）。这样当请求回来时，它可以un-DNAT，这意味着将源IP从Pod IP更改为Service IP。这样，客户端就不⽤关⼼后台如何处理数据包流。</p><p>因此通过使⽤Kubernetes Service，我们可以使⽤相同的端⼝⽽不会发⽣任何冲突（因为我们可以将端⼝重新映射到Endpoint）。这使服务发现变得⾮常容易。我们可以使⽤内部DNS并对服务主机名进⾏硬编码。</p><p>我们甚⾄可以使⽤Kubernetes提供的service主机和端⼝的环境变量来完成服务发现。</p><p><strong>专家建议：</strong>采取第⼆种⽅法，你可节省不必要的DNS调⽤，但是由于环境变量存在创建顺序的局限性（环境变量中不包含后来创建的服务），推荐使⽤DNS来进⾏服务名解析。</p><h2 id="4-1-出站流量"><a href="#4-1-出站流量" class="headerlink" title="4.1 出站流量"></a>4.1 出站流量</h2><p>到⽬前为⽌我们讨论的Kubernetes Service是在⼀个集群内⼯作。但是，在⼤多数实际情况中，应⽤程序需要访问⼀些外部api/website。</p><p>通常，节点可以同时具有私有IP和公共IP。对于互联⽹访问，这些公共和私有IP存在某种1：1的NAT，特别是在云环境中。</p><p>对于从节点到某些外部IP的普通通信，源IP从节点的专⽤IP更改为其出站数据包的公共IP，⼊站的响应数据包则刚好相反。但是，当Pod发出与外部IP的连接时，源IP是Pod IP，云提供商的NAT机制不知道该IP。因此它将丢弃具有除节点IP之外的源IP的数据包。</p><p>因此你可能也猜对了，我们将使⽤更多的iptables！这些规则也由kube-proxy添加，执⾏SNAT（源⽹络地址转换），即IP MASQUERADE（IP伪装）。它告诉内核使⽤此数据包发出的⽹络接⼝的IP，代替源Pod IP同时保留conntrack条⽬以进⾏反SNAT操作。</p><h2 id="4-2-入站流量"><a href="#4-2-入站流量" class="headerlink" title="4.2 入站流量"></a>4.2 入站流量</h2><p>到⽬前为⽌⼀切都很好。Pod可以互相交谈，也可以访问互联⽹。但我们仍然缺少关键部分 - 为⽤户请求流量提供服务。截⾄⽬前，有两种主要⽅法可以做到这⼀点：</p><ul><li><strong>NodePort /云负载均衡器（L4 - IP和端⼝）</strong></li></ul><p>将服务类型设置为NodePort默认会为服务分配范围为30000-33000d的nodePort。即使在特定节点上没有运⾏Pod，此nodePort也会在每个节点上打开。此NodePort上的⼊站流量将再次使⽤iptables发送到其中⼀个Pod（该Pod甚⾄可能在其它节点上！）。</p><p>云环境中的LoadBalancer服务类型将在所有节点之前创建云负载均衡器（例如ELB），命中相同的nodePort。</p><ul><li><strong>Ingress（L7 - HTTP / TCP）</strong></li></ul><p>许多不同的⼯具，如Nginx， Traefik， HAProxy等，保留了http主机名/路径和各⾃后端的映射。通常这是基于负载均衡器和nodePort的流量⼊⼝点，其优点是我们可以有⼀个⼊⼝处理所有服务的⼊站流量，⽽不需要多个nodePort和负载均衡器。</p><h2 id="4-3-网站策略"><a href="#4-3-网站策略" class="headerlink" title="4.3 网站策略"></a>4.3 网站策略</h2><p>可以把它想象为Pod的安全组/ ACL。NetworkPolicy规则允许/拒绝跨Pod的流量。确切的实现取决于⽹络层/CNI，但⼤多数只使⽤iptables。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第8篇 CI/CD 之全流程实践</title>
    <link href="/2019/12/10/2019-12-10-kubernetes8-cicd-full/"/>
    <url>/2019/12/10/2019-12-10-kubernetes8-cicd-full/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>1）本实践中已经的示例代码及jenkins-agent镜像已经推送归档至github，–&gt;传送门（<a href="https://github.com/Kubernetes-Best-Pratice/）" target="_blank" rel="noopener">https://github.com/Kubernetes-Best-Pratice/）</a></p><p>2）注意本实践中均为内网数据，你测试时一定要改为自己的环境的有效数据。</p><p>3) 由于本实践涉及组件较多，若有操作不明确的话，你可以后台留言，我们一起完善。</p><p>4) 具体操作时若有不清楚，或是错误可以留言，大家一起解决。</p><h1 id="1、准备基础数据"><a href="#1、准备基础数据" class="headerlink" title="1、准备基础数据"></a>1、准备基础数据</h1><p><strong>step1：</strong>配置Gitlab</p><ul><li>创建项目</li><li>上传示例代码</li></ul><p><em>注: 本次示例使用的gitlab项目地址：</em></p><p><em><a href="http://gitlab.hanker.com/colynn/hanker-hello.git" target="_blank" rel="noopener">http://gitlab.hanker.com/colynn/hanker-hello.git</a></em></p><p><strong>step2：</strong>配置Harbor</p><p>创建项目, 用于存储构建的镜像</p><p><em>注: 本次示例使用的harbor地址为</em> </p><p><em>10.0.0.185:5000/hanker/hanker-hello:v1</em></p><p><strong>step3：</strong>Jenkins验证信息</p><ul><li><p>添加 gitlab 帐号信息</p><p><u>操作指引：【Credentials】-&gt; 【System】-&gt; 【Global credentials】-&gt; 【Add Credentials】</u></p></li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/1-3-a.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><ul><li><p>harbor 信息</p><p><u>操作指引：【Credentials】-&gt; 【System】-&gt; 【Global credentials】-&gt; 【Add Credentials】</u></p></li></ul><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/1-3-b.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><ul><li><p>k8s namespace验证信息</p><p>在你的k8s master节点上执行如下操作：</p><p>1) 创建serviceaccount</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n devops create serviceaccount jenkins-robot<br></code></pre></div></td></tr></table></figure><p>命令输出：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">serviceaccount/jenkins-robot created<br></code></pre></div></td></tr></table></figure><p>  2) 角色绑定</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n devops create rolebinding jenkins-robot-binding --clusterrole=cluster-admin --serviceaccount=devops:jenkins-robot<br></code></pre></div></td></tr></table></figure><p>命令输出：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">rolebinding.rbac.authorization.k8s.io/jenkins-robot-binding created<br></code></pre></div></td></tr></table></figure><p>3) 获取 ServiceAccount</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros">$ kubectl -n devops <span class="hljs-builtin-name">get</span> serviceaccount jenkins-robot -o go-template <span class="hljs-attribute">--template</span>=<span class="hljs-string">'&#123;&#123;range .secrets&#125;&#125;&#123;&#123;.name&#125;&#125;&#123;&#123;"\n"&#125;&#125;&#123;&#123;end&#125;&#125;'</span>jenkins-robot-token-n8w6b<br></code></pre></div></td></tr></table></figure><p> 4) 基于base64解码 ServiceToken</p><figure class="highlight jboss-cli"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs jboss-cli">$ kubectl -n devops get secrets jenkins-robot-token-n8w6b -o go-template <span class="hljs-params">--template</span> '&#123;&#123;index <span class="hljs-string">.data</span> <span class="hljs-string">"token"</span>&#125;&#125;' | base64 <span class="hljs-params">--decode</span><br></code></pre></div></td></tr></table></figure><p>命令输出：</p><figure class="highlight smali"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs smali">eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZXZvcHMiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlY3JldC5uYW1lIjoiamVua2lucy1yb2JvdC10b2tlbi1uOHc2YiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJqZW5raW5zLXJvYm90Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiOTcyZTY0OGYtMTYxZC00NmM5LWI0ZjgtYjFkNTdlOWY4NTBjIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50OmRldm9wczpqZW5raW5zLXJvYm90In0.ArQvcaEqCaeU1ZcJ6nOC5rLaTZr_vLDrpLCt87asltMUWj2gSli_mXUTrl09hBnBDXI3A1D4rJXHKLHjIAA4nN8qRIRGbpqSNzDwmqJr-jmmmWWZFrZ3n3Al9-13KJnNOK8pcWr70rt3Rsigt4B6CIQ0-ZLK8BZhvROJSifeOfJ6xe2KBqdXBv1ccZZZfEhPLgGbaR5yWm5jLvOMr2MQiPDrZoHOEkcMt-C0xipytOp4sJCJ4bQhb-UoMu1owYydxbd6O7xO71fvqP_bMDpZXC601nA2ggK7h-vi6CJffHv5MM59q8X_DWe1NnZS6KXiMmkXqAmBn10Yu20PNj-kjg<br></code></pre></div></td></tr></table></figure><p> 5) 添加 Secret text验证信息</p><p><u>操作指引：【首页】-&gt;【Credentials】-&gt; 【System】-&gt; 【Global credentials】-&gt; 【Add Credentials】-&gt; 选择【Secret text】类型</u></p><p>然后将上一步 解码的结果 更新至 Secret, Pipeline 中</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/1-5.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="2、如何创建Jenkins-pipline"><a href="#2、如何创建Jenkins-pipline" class="headerlink" title="2、如何创建Jenkins pipline"></a>2、如何创建Jenkins pipline</h1><p><strong>step1：</strong>创建jenkins pipeline item</p><p><u>操作指引：【首页】-&gt;【New Item】</u></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/2-1.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong>step2:</strong> pipeline script 步骤说明</p><p><em>注: pipeline主要包含三个阶段（检出代码、制作镜像、部署服务），下面跟大家解释下，如何编写pipeline， 借助Pipeline Syntax生成的只是部分代码，你可以根据语言规范将其完善。</em></p><p>阶段1: 检出代码</p><p><u>操作指引：【首页】-&gt;【hanker-hello-demo】-&gt; 【Pipeline Syntax】</u></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/2-2-a.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><em>注: 本实践中选取的 git: Git 类型，当然你也可以选择 checkout: Check out from version control</em></p><p>获取到该步骤的脚本</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">git credentialsId: <span class="hljs-string">'gitlab-project-auth'</span>, url: <span class="hljs-string">'http://gitlab.hanker.com/colynn/hanker-hello.git'</span><br></code></pre></div></td></tr></table></figure><p>阶段2：构建建镜像操作指引,类似于阶段1</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/2-2-b.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>完善获取该步骤脚本</p><figure class="highlight"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs json">script &#123;<br>    withDockerRegistry(credentialsId: 'harbor-auth', url: 'http://10.0.0.185:5000') &#123;<br>        def customImage =  docker.build("10.0.0.185:5000/devops/hanker-hello:v1")<br>        customImage.push()<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p><em>注: 支持本阶段需要jenkins-agent镜像里包含docker命令。</em></p><p> 阶段3. 部署服务</p><p>参考: jenkins kubernetes cli plugin</p><p><a href="https://github.com/jenkinsci/kubernetes-cli-plugin/blob/master/README.md" target="_blank" rel="noopener">https://github.com/jenkinsci/kubernetes-cli-plugin/blob/master/README.md</a></p><p><em>注: 支持本阶段需要jenkins-agent镜像里包含kubectl命令。</em></p><p>*<em>step3: *</em>设置 pipeline</p><p><em>注:General/ Build Triggers/ Advanced Project Options 这三块你可以根据自己需要设置，将各阶段的脚本合并，更新至 Pipline -&gt; Script内。</em></p><p>合并后的pipeline脚本内容如下：</p><figure class="highlight"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs json">pipeline &#123;<br>    agent any<br>    stages &#123;<br>        stage('checkout') &#123;<br>            steps &#123;<br>                git credentialsId: 'gitlab-project-auth', url: 'http://gitlab.hanker.com/colynn/hanker-hello.git'    <br>            &#125;<br>        &#125;<br><br>        stage('docker-publish') &#123;<br>            steps&#123;<br>                script &#123;<br>                    withDockerRegistry(credentialsId: 'harbor-auth', url: 'http://10.0.0.185:5000') &#123;<br>                        def customImage =  docker.build("10.0.0.185:5000/devops/hanker-hello:v1")<br>                        customImage.push()<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        stage('application-deploy') &#123;<br>            steps &#123;<br>                withKubeConfig([credentialsId: '5a5517f3-3d38-459d-bafc-12b55beeb588', serverUrl: 'https://10.0.0.182:6443']) &#123;<br>                    sh '/usr/bin/kubectl apply -f k8s-setup.yml'<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/2-3.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="3、触发构建"><a href="#3、触发构建" class="headerlink" title="3、触发构建"></a>3、触发构建</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/3-1.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="4、结果确认"><a href="#4、结果确认" class="headerlink" title="4、结果确认"></a>4、结果确认</h1><p>1) 确认 jenkina-agent 启动状态；</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n devops get pods |grep jnlp<br>jnlp-sh8zl                                 1/1     Running   0          14s<br>// 查看jenkins-agent pod日志<br>$ kubectl -n devops logs -f [jenkins-agent-pod-name]<br></code></pre></div></td></tr></table></figure><p><em>注: 如果长时间没有启动jenkins-agent, 可以确认下集群内是否有足够的资源。</em></p><p>2) 确认pipeline 执行状态；</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/4-2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>3) 确认harbor镜像仓库里是否已经有新推送的镜像</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/4-3.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><em>注: harbor里的项目是需要你先创建好的，不然推送时会报错。</em></p><p>4) 确认部署的服务状态</p><p>k8s master节点上执行如下操作:</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n devops get pod,deployment,svc,ingress |grep hanker-hello<br><br>pod/hanker-hello-5b7586f86d-5j7kk              1/1     Running   0          173m<br><br><br>deployment.extensions/hanker-hello              1/1     1            1           3h8m<br>service/hanker-hello-svc          ClusterIP   10.233.22.19    &lt;none&gt;        8080/TCP             3h8m<br>ingress.extensions/hanker-hello-ingress              hanker-hello-demo.dev.hanker.net                   80      3h8m<br></code></pre></div></td></tr></table></figure><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-10/4-4.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="5、附录"><a href="#5、附录" class="headerlink" title="5、附录"></a>5、附录</h1><p><strong>1）自定义jenkins-agent镜像</strong></p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">## 基于 https://github.com/Kubernetes-Best-Pratice/jenkins-jnlp-agent.git</span><br>$ git checkout  https://github.com/Kubernetes-Best-Pratice/jenkins-jnlp-agent.git<br>$ <span class="hljs-built_in">cd</span> jenkins-jnlp-agent<br>$ docker build .<br>$ docker tag tag-name custom-private-repository-addr<br></code></pre></div></td></tr></table></figure><p><em>注: 你也可以基于基础镜像创建自定义的镜像</em></p><p><strong>2）可以做的更完善</strong></p><ol><li>配置webhook, 自动触发jenkins job;</li><li>当前我们实践时构建的镜像版本使用的是固定的, 你是否可以将其替换为依赖pipeline环境变量或是传参的形式，将其变是更有意义；</li><li>上一篇文章（<a href="http://mp.weixin.qq.com/s?__biz=MzU5MTkyNzQ0MQ==&mid=2247483797&idx=1&sn=770557060a5bc4507c2ba9a8d71b1ddb&chksm=fe26c06bc951497d6596a2c9a717bcca04ad130ab8f14097ccd0cc9df9d39bb44adbc4d18768&scene=21#wechat_redirect" target="_blank" rel="noopener">点击这里</a>进入传送门）中在设置【配置Kubernetes Pod Template】时，我们提到可以挂载主机或是网络共享存储，你是否可以通过这个将你的构建快起来；</li><li>我们的示例代码使用的go, 直接是镜像内打包，如何更好的就好的其他语言的构建，你可以参考Using Docker with Pipeline；</li><li>你想过如何下载构建过程中的产物吗，等等</li></ol><p><strong>3）参考链接</strong></p><ol><li><p><a href="https://github.com/jenkinsci/kubernetes-cli-plugin/blob/master/README.md" target="_blank" rel="noopener">https://github.com/jenkinsci/kubernetes-cli-plugin/blob/master/README.md</a></p></li><li><p>下载kubectl:</p><p><a href="https://docs.docker.com/ee/ucp/user-access/kubectl/" target="_blank" rel="noopener">https://docs.docker.com/ee/ucp/user-access/kubectl/</a></p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第7篇 CI/CD 之组件部署</title>
    <link href="/2019/12/09/2019-12-09-kubernetes7-cicd/"/>
    <url>/2019/12/09/2019-12-09-kubernetes7-cicd/</url>
    
    <content type="html"><![CDATA[<h1 id="1、前言"><a href="#1、前言" class="headerlink" title="1、前言"></a>1、前言</h1><p>应对敏捷开发的需求，对CI(持续集成))/CD（持续交付）的提出了更高的标准，今天来讨论下，如何基于开源组件（gitlab/jenkins/harbor/kubernetes）使用CI/CD，赋能团队的开发、运维。</p><h1 id="2、核心组件"><a href="#2、核心组件" class="headerlink" title="2、核心组件"></a>2、核心组件</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-09/2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="3、基本流程"><a href="#3、基本流程" class="headerlink" title="3、基本流程"></a>3、基本流程</h1><p><strong>step1：</strong>在GitLab创建对应的项目。</p><p><strong>step2：</strong>开发者将代码提交到GitLab。</p><p><strong>step3：</strong>Jenkins创建对应的任务（Job），集成该项目的Git地址和Kubernetes集群。</p><p><strong>step4：</strong>如有配置钩子，推送（Push）代码会自动触发Jenkins构建，如没有配置钩子，需要手动构建。</p><p><strong>step5：</strong>Jenkins控制Kubernetes（使用的是Kubernetes插件）创建Jenkins Slave。</p><p><strong>step6：</strong>Jenkins Slave根据流水线（Pipeline）定义的步骤执行构建。</p><p>​    a.检出代码、打包、编译。</p><p>​    b.通过Dockerfile生成镜像。</p><p>​    c.将镜像提送（Push）到私有Harbor。</p><p>​    d.Jenkins再次控制Kubernetes进行最新的镜像部署。</p><p>注:    </p><ul><li><em>上面所述为一般步骤，中间还可能会涉及自动化测试等步骤，可自行根据业务场景添加。</em></li><li><em>上面流水线步骤一般由应用代码库的根目录下Jenkinsfile决定，Jenkins会自动读取该文件；另外如果需要对具体的应用流水线实施强管控，可以独立管理jenkinsfile模板，然后根据jenkins API接口即时生成流水线。</em></li><li><em>默认使用的Dockerfile放置在代码仓库的根目录下。</em></li></ul><h1 id="4、组件部署"><a href="#4、组件部署" class="headerlink" title="4、组件部署"></a>4、组件部署</h1><p><strong>step1：</strong><a href="http://mp.weixin.qq.com/s?__biz=MzU5MTkyNzQ0MQ==&mid=2247483708&idx=1&sn=3efc9ecf7d9c04fd58bfcaf068233ec9&chksm=fe26c0c2c95149d47f8e438bf34f443be745b05d419c0837e20d9245e4df7d5f20589e2a1458&scene=21#wechat_redirect" target="_blank" rel="noopener">kubernetes系列 第3篇 Kubernetes集群安装部署</a></p><p><strong>step2：</strong><a href="http://mp.weixin.qq.com/s?__biz=MzU5MTkyNzQ0MQ==&mid=2247483726&idx=1&sn=ce1b45eb224c936e0173b3dea7786de3&chksm=fe26c0b0c95149a62eafa8aff2d2cc6905389d7bed3ff222a7e5afff0f1ccd08ba89368a0919&scene=21#wechat_redirect" target="_blank" rel="noopener">gitlab 无忌过招:手把手教你搭建自己的GitLab库</a></p><p><strong>step3：</strong>harbor 安装配置指南  <a href="https://github.com/goharbor/harbor/blob/v1.7.4/docs/installation_guide.md" target="_blank" rel="noopener">https://github.com/goharbor/harbor/blob/v1.7.4/docs/installation_guide.md</a></p><p><strong>step4：</strong>jenkins</p><p><em>注: 本文主要说明下jenkins的部署及配置，其他组件如果你部署有问题，欢迎留言。</em></p><h1 id="5、Jenkins部署及配置"><a href="#5、Jenkins部署及配置" class="headerlink" title="5、Jenkins部署及配置"></a>5、Jenkins部署及配置</h1><p><strong>0. 说明:</strong> </p><ul><li><p>以下的yaml文件均在 k8s master节点的 /home/jenkins_deploy目录下。</p></li><li><p>部署示例的depployment.yaml 的注解</p></li><li><ul><li>nodeName ipaddress , ipaddress 请确认其为一个有效的ip。</li><li>示例中jenkins的目录 /var/jenkins_home 是直接挂载到host_path, 如果你有条件，建议替换为共享存储。</li><li>因使用的jenkins-master 的基础镜像来自公网，需要k8s maste 节点也要可以访问外网，或者你可以将 jenkins/jenkins:lts-alpine 推送至自己的内网镜像仓库。</li></ul></li><li><p>部署示例的ingress.yaml 的注解</p></li><li><ul><li>需要你也需要办公网（集群外）访问，请将jenkins.dev.hanker.net, 改为有效的域名地址，或是你也可以通过NodePort的形式声明 service，就可以直接通过ip:port的形式访问jenkins了。</li></ul></li></ul><p><strong>1. 准备部署yaml</strong></p><ul><li>deployment.yaml<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Namespace</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">devops</span><br><br><span class="hljs-comment"># Deployment</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">extensions/v1beta1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">devops</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">1</span><br>  <span class="hljs-attr">revisionHistoryLimit:</span> <span class="hljs-number">3</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">jenkins</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">nodeName:</span> <span class="hljs-number">1.1</span><span class="hljs-number">.1</span><span class="hljs-number">.1</span><br>      <span class="hljs-attr">serviceAccountName:</span> <span class="hljs-string">jenkins-admin</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">jenkins/jenkins:lts-alpine</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins</span><br>        <span class="hljs-attr">volumeMounts:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-volume</span><br>          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/jenkins_home</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-localtime</span><br>          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/etc/localtime</span><br>        <span class="hljs-attr">env:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">JAVA_OPTS</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">'-Xms256m -Xmx1024m -Duser.timezone=Asia/Shanghai'</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">TRY_UPGRADE_IF_NO_MARKER</span><br>            <span class="hljs-attr">value:</span> <span class="hljs-string">'true'</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">http</span><br>          <span class="hljs-attr">containerPort:</span> <span class="hljs-number">8080</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">agent</span><br>          <span class="hljs-attr">containerPort:</span> <span class="hljs-number">50000</span><br>        <span class="hljs-attr">resources:</span><br>          <span class="hljs-attr">requests:</span><br>            <span class="hljs-attr">cpu:</span> <span class="hljs-string">1000m</span><br>            <span class="hljs-attr">memory:</span> <span class="hljs-string">1Gi</span><br>          <span class="hljs-attr">limits:</span><br>            <span class="hljs-attr">cpu:</span> <span class="hljs-string">1200m</span><br>            <span class="hljs-attr">memory:</span> <span class="hljs-string">2Gi</span><br>      <span class="hljs-attr">volumes:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-localtime</span><br>          <span class="hljs-attr">hostPath:</span><br>            <span class="hljs-attr">path:</span> <span class="hljs-string">/etc/localtime</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-volume</span><br>          <span class="hljs-attr">hostPath:</span><br>            <span class="hljs-attr">path:</span> <span class="hljs-string">/home/jenkins/jenkins_home</span><br></code></pre></div></td></tr></table></figure></li><li>配置service, services.yaml<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-service</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">devops</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">http</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">8080</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">8080</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">port:</span> <span class="hljs-number">50000</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">50000</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">agent</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">jenkins</span><br></code></pre></div></td></tr></table></figure></li><li>授权jenkins对k8s的访问 rbac.yaml<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">k8s-app:</span> <span class="hljs-string">jenkins</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-admin</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">devops</span><br><br><span class="hljs-meta">---</span><br><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1beta1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-rbac</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">devops</span><br><span class="hljs-attr">rules:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">apiGroups:</span> <span class="hljs-string">["","extensions","app"]</span><br>    <span class="hljs-attr">resources:</span> <span class="hljs-string">["pods","pods/exec","deployments","replicasets"]</span><br>    <span class="hljs-attr">verbs:</span> <span class="hljs-string">["get","list","watch","create","update","patch","delete"]</span><br><br><span class="hljs-meta">---</span><br><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1beta1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRoleBinding</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-admin</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">devops</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">k8s-app:</span> <span class="hljs-string">jenkins</span><br><span class="hljs-attr">subjects:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-admin</span><br>    <span class="hljs-attr">namespace:</span> <span class="hljs-string">devops</span><br><span class="hljs-attr">roleRef:</span><br>  <span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-rbac</span><br>  <span class="hljs-attr">apiGroup:</span> <span class="hljs-string">rbac.authorization.k8s.io</span><br></code></pre></div></td></tr></table></figure></li><li>为了便于办公网（集群外）访问，ingress.yaml<figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">extensions/v1beta1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Ingress</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">jenkins-ingress</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">devops</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">rules:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">host:</span> <span class="hljs-string">jenkins.dev.hanker.net</span><br>    <span class="hljs-attr">http:</span><br>      <span class="hljs-attr">paths:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">backend:</span><br>          <span class="hljs-attr">serviceName:</span> <span class="hljs-string">jenkins-service</span><br>          <span class="hljs-attr">servicePort:</span> <span class="hljs-number">8080</span><br>        <span class="hljs-attr">path:</span> <span class="hljs-string">/</span><br></code></pre></div></td></tr></table></figure></li></ul><p><strong>2. 应用yaml，部署jenkins</strong></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">pwd</span></span><br><span class="hljs-meta">$</span><span class="bash"> /home/jenkins_deploy</span><br><span class="hljs-meta">$</span><span class="bash"> kubectl apply -f *.yaml</span><br></code></pre></div></td></tr></table></figure><p><strong>3. 确认jenkins 服务状态</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript">[<span class="hljs-symbol">root@</span>node0 jenkins_deploy]# kubectl -n devops <span class="hljs-keyword">get</span> deployment jenkins<br>NAME      READY   UP-TO-DATE   AVAILABLE   AGE<br>jenkins   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">51</span>d<br>[<span class="hljs-symbol">root@</span>node0 jenkins_deploy]#<br></code></pre></div></td></tr></table></figure><p><strong>4. 访问jenkins 安装插件、设置</strong></p><p><em>注: 步骤1 声明的域名 jenkins.dev.hanker.net 已经解析至ingress，故可直接访问；如果你也想通过自定义域名访问jenkins，麻请解析至正确的ingress服务节点，即可。</em></p><p>  <strong>a. 确认你也已经安装了kubernetes/ kubernetes cli 插件</strong></p><p>操作指引：【Manage Jenkins】 -&gt; 【Manage Plugins】</p><p>你应该可以通过类似的指令获取jenkins-master的密码。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">$ kubectl -n devops <span class="hljs-built_in">exec</span> jenkins-pod-name cat /var/jenkins_home/secrets/initialAdminPassword<br></code></pre></div></td></tr></table></figure><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-09/5-4-a.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong>b.配置Kubernetes 插件</strong></p><p>操作指引：【Manage Jenkins】-&gt;【Configure System】</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-09/5-4-b1.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-09/5-4-b2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>图中标注：</p><p>1) 请修改为你所在环境对应的k8s master。</p><p>2) 声明jenkins-agent 的命令空间，也可以根据需要调整。</p><p>3）jenkins-master的访问地址，本示例使用的是 service-name的形式访问。</p><p>4) 测试与k8s分享群的连接情况。如果你获取到『Connection test successful』，恭喜你可以继续。</p><p>5）配置Kubernetes Pod Template</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-09/5-4-b3.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>图中标注：</p><p>1）设置基础的jenkins-agent镜像；</p><p>2）指定工作目录：如果你需要下载、导出或是缓存构建的话，指定一个为共享存储的目录就很有意义了。</p><p>3）设置目录挂载：如步骤2如说，你可以将宿主机的目录或是网络存储挂载至jenkins-agent。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第6篇 Ingress controller - nginx组件介绍</title>
    <link href="/2019/12/08/2019-12-08-kubernetes6-nginx-introduction/"/>
    <url>/2019/12/08/2019-12-08-kubernetes6-nginx-introduction/</url>
    
    <content type="html"><![CDATA[<h1 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h1><p>在上一篇文章中我们介绍了如何通过helm进行安装部署traefik组件（<a href="http://mp.weixin.qq.com/s?__biz=MzU5MTkyNzQ0MQ==&mid=2247483749&idx=1&sn=458f63caa65a8fbd33992b8414830388&chksm=fe26c09bc951498d183b2eb05d2f526e2e701e0432b51574ca932839f2146a94bc1e3a781bb7&scene=21#wechat_redirect" target="_blank" rel="noopener">链接点这里</a>），文中还提到常用的ingress controller除了traefik还有Nginx、HAProxy、Kong等，在本篇文章中我们就介绍如何安装部署Nginx-ingress，只有在经过积累不同组件的使用经验之后，我们才能更好的比较其优劣，形成最佳实践。</p><h1 id="2、安装部署"><a href="#2、安装部署" class="headerlink" title="2、安装部署"></a>2、安装部署</h1><p><strong>2.1 通过helm查找nginx-ingress</strong></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> step1: 通过helm查找nginx-ingress</span><br><span class="hljs-meta">&gt;</span><span class="bash"> helm search nginx-ingress</span><br><span class="hljs-meta">&gt;</span><span class="bash"> helm inspect stable/nginx-ingress</span><br></code></pre></div></td></tr></table></figure><p><strong>2.2 镜像下载及上传</strong></p><p>部分企业由于服务器没有外网访问策略以及防火墙的原因无法获取国外Docker镜像，所以我们事先需要将所需镜像准备好，并上传到企业私有镜像仓库。</p><figure class="highlight angelscript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs angelscript"># step2: 镜像准备<br>&gt; docker pull quay.io/kubernetes-ingress-controller/nginx-ingress-controller:<span class="hljs-number">0.25</span><span class="hljs-number">.1</span><br>&gt; docker tag quay.io/kubernetes-ingress-controller/nginx-ingress-controller:<span class="hljs-number">0.25</span><span class="hljs-number">.1</span> registry.hankercloud.com/ingress-controller/nginx-ingress-controller:<span class="hljs-number">0.25</span><span class="hljs-number">.1</span><br>&gt; docker push registry.hankercloud.com/ingress-controller/nginx-ingress-controller:<span class="hljs-number">0.25</span><span class="hljs-number">.1</span><br>&gt;<br>&gt; docker pull k8s.gcr.io/defaultbackend-amd64:<span class="hljs-number">1.5</span><br>&gt; docker tag k8s.gcr.io/defaultbackend-amd64:<span class="hljs-number">1.5</span> registry.hankercloud.com/google_containers/defaultbackend-amd64:<span class="hljs-number">1.5</span><br>&gt; docker push registry.hankercloud.com/google_containers/defaultbackend-amd64:<span class="hljs-number">1.5</span><br></code></pre></div></td></tr></table></figure><p><strong>2.3 组件部署</strong></p><p>在上一篇博客中，我们是采用Deployment模式部署的traefik组件，这次我们采用DaemonSet的模式来部署nginx-ingress组件。</p><figure class="highlight routeros"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs routeros"><span class="hljs-comment"># step3: 组件部署</span><br>&gt; helm install stable/nginx-ingress --name nginx-ingress <span class="hljs-attribute">--namespace</span>=kube-system \<br>  --<span class="hljs-builtin-name">set</span> <span class="hljs-attribute">fullnameOverride</span>=nginx-ingress \<br>  --<span class="hljs-builtin-name">set</span> controller.<span class="hljs-attribute">kind</span>=DaemonSet \<br>  --<span class="hljs-builtin-name">set</span> controller.daemonset.<span class="hljs-attribute">useHostPort</span>=<span class="hljs-literal">true</span> \<br>  --<span class="hljs-builtin-name">set</span> controller.metrics.<span class="hljs-attribute">enabled</span>=<span class="hljs-literal">true</span> \<br>  --<span class="hljs-builtin-name">set</span> controller.image.<span class="hljs-attribute">repository</span>=registry.hankercloud.com/ingress-controller/nginx-ingress-controller \<br>  --set<br>  defaultBackend.image.<span class="hljs-attribute">repository</span>=registry.hankercloud.com/google_containers/defaultbackend-amd64<br><span class="hljs-comment"># step4: 检查部署是否成功</span><br>&gt; helm list&gt; kubectl <span class="hljs-builtin-name">get</span> all -n kube-system&gt; kubectl logs <span class="hljs-variable">$POD_NAME</span> -n kube-system<br></code></pre></div></td></tr></table></figure><p><strong>2.4 负载均衡配置及域名解析处理</strong></p><p>本次我们采用DaemonSet部署nginx-ingress组件，并且使用了主机的80和443接口用来分别接收http和https请求，我们将相应的域名解析到nginx-ingress Pod所在的主机IP之后，就可以通过域名来进行相应的域名访问了。</p><p>但上述配置方式无法做到高可用，当nginx-ingress的Pod实例故障或者其所在主机发生故障时，会导致相应的域名无法访问，所以建议在公有云购买负载均衡设备并配置相应的后端服务器列表以实现高可用的目的。</p><p><strong>2.5 安装调试</strong></p><p>在上文中我们通过helm部署了一个wordpress应用，本文我们继续通过该应用进行域名访问，在本机控制台输入 </p><figure class="highlight awk"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs awk">&gt; curl -i http:<span class="hljs-regexp">//</span><span class="hljs-number">10.0</span>.<span class="hljs-number">0.182</span> -H <span class="hljs-string">'Host: blog.hankercloud.com'</span><br></code></pre></div></td></tr></table></figure><p>如果看到有正常返回则说明部署成功。</p><h1 id="3、企业场景及解决方案"><a href="#3、企业场景及解决方案" class="headerlink" title="3、企业场景及解决方案"></a>3、企业场景及解决方案</h1><p><strong>3.1 如何做内外网的隔离</strong></p><p><strong>Step1:</strong> 我们首先部署了两个ingress组件，其中之一是接收内网访问请求，另外一个是接收外网访问请求，相应配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># 内网nginx-ingress配置声明：</span><br><span class="hljs-attr">spec:</span><br><span class="hljs-attr">template:</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">args:</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">/nginx-ingress-controller</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">--default-backend-service=kube-system/nginx-ingress-default-backend</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">--election-id=ingress-controller-leader</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">--ingress-class=nginx</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">--configmap=kube-system/nginx-ingress-controller</span><br></code></pre></div></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># 外网nginx-ingress配置声明：</span><br><span class="hljs-attr">spec:</span><br><span class="hljs-attr">template:</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">args:</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">/nginx-ingress-controller</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">--default-backend-service=kube-system/nginx-ingress-external-default-backend</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">--election-id=ingress-controller-leader</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">--ingress-class=nginx-external</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">--configmap=kube-system/nginx-ingress-external-controller</span><br></code></pre></div></td></tr></table></figure><p>两者的主要区别在于参数 –ingress-class 设置的值是不一样的。</p><p><strong>Step2:</strong> 对于需要暴露到公网的域名，修改其ingress的定义，相应配置参考如下：</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">www</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">kubernetes.io/ingress.class:</span> <span class="hljs-string">"nginx-external"</span><br></code></pre></div></td></tr></table></figure><p><strong>Step3:</strong> 检查是否配置成功，执行 </p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">kubectl exec $&#123;POD_NAME&#125; -n kube-system cat /etc/nginx/nginx.conf<br></code></pre></div></td></tr></table></figure><p>查看配置文件中是否已经包含外网域名的相关配置，并在本地进行测试验证。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第5篇 Ingress Controller - Traefik组件介绍</title>
    <link href="/2019/12/07/2019-12-07-kubernetes5-traefik-introduction/"/>
    <url>/2019/12/07/2019-12-07-kubernetes5-traefik-introduction/</url>
    
    <content type="html"><![CDATA[<h1 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h1><p>为了能够让Ingress资源能够工作，在Kubernetes集群中必须至少有一个运行中的ingress controller组件。也就是说如果在kubernetes集群中没有一个ingress controller组件，只是定义了ingress资源，其实并不会实现http、https协议的请求转发、负载均衡等功能。常见的ingress controller组件如下：</p><ul><li>Nginx</li><li>Traefik</li><li>Kong</li><li>Istio</li><li>HAProxy</li></ul><p>关于上述的组件目前并没有详细的对比，后续我们在对每个组件都有一定的了解和使用的基础之上，可以给出一些详细的对比信息。本篇内容将主要介绍traefik组件的安装部署以及会通过一个具体的应用作演示。</p><h1 id="2、Trafeik组件的安装部署"><a href="#2、Trafeik组件的安装部署" class="headerlink" title="2、Trafeik组件的安装部署"></a>2、Trafeik组件的安装部署</h1><h2 id="2-1-通过helm-chart部署traefik"><a href="#2-1-通过helm-chart部署traefik" class="headerlink" title="2.1 通过helm chart部署traefik"></a>2.1 通过helm chart部署traefik</h2><p>helm traefik chart包中包含了部署traefik组件的所需的资源，我们可以通过借助该组件进行快速部署traefik组件，以下是部署命令行信息：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">&gt; helm install --name inner-traefik --namespace kube-system\<br>  --<span class="hljs-built_in">set</span> image=registry.docker.hankercloud.com/ingress-controller/traefik \<br>  --<span class="hljs-built_in">set</span> serviceType=NodePort \<br>  stable/traefik<br></code></pre></div></td></tr></table></figure><p>部署完成后，执行kubectl get pods -n kube-system命令，可以看到在kube-system的命名空间中已经存在名为 inner-traefik 的Pod。</p><h2 id="2-2-RBAC配置"><a href="#2-2-RBAC配置" class="headerlink" title="2.2 RBAC配置"></a>2.2 RBAC配置</h2><p>在kubernetes 1.6版本中引入了RBAC（Role Based Access Control）机制来更好的管理资源和API的访问。如果在集群中配置了RBAC，则需要授权Treafik使用Kubernetes的API，有两种方式来进行设置合适的策略：通过特定的命名空间进行角色绑定（RoleBinding）以及全局角色绑定（ClusterRoleBinding）。现在简单起见，我们直接使用ClusterRoleBinding，资源定义如下：</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1beta1</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">traefik-ingress-controller</span><br><span class="hljs-attr">rules:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">apiGroups:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">""</span><br>    <span class="hljs-attr">resources:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">services</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">endpoints</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">secrets</span><br>    <span class="hljs-attr">verbs:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">get</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">list</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">watch</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">apiGroups:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">extensions</span><br>    <span class="hljs-attr">resources:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ingresses</span><br>    <span class="hljs-attr">verbs:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">get</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">list</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">watch</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRoleBinding</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1beta1</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">traefik-ingress-controller</span><br><span class="hljs-attr">roleRef:</span><br>  <span class="hljs-attr">apiGroup:</span> <span class="hljs-string">rbac.authorization.k8s.io</span><br>  <span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">traefik-ingress-controller</span><br><span class="hljs-attr">subjects:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">traefik-ingress-controller</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kube-system</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">traefik-ingress-controller</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kube-system</span><br></code></pre></div></td></tr></table></figure><p>接下来我们执行如下命令创建资源并修改deployment的资源定义文件。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">kubectl apply -f traefik-rbac.yml<br>kubectl edit deploy inner-traefik -n kube-system<br></code></pre></div></td></tr></table></figure><p>执行完上述的操作之后，我们可以进行校验相关的资源已经正常启动。</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">kubectl logs $(kubectl get pods -n kube-system |grep traefik | awk <span class="hljs-string">'&#123;print $1&#125;'</span>) -n kube-system<br></code></pre></div></td></tr></table></figure><h2 id="2-3-负载均衡配置"><a href="#2-3-负载均衡配置" class="headerlink" title="2.3 负载均衡配置"></a>2.3 负载均衡配置</h2><p>由于我们使用的是Deployment部署的traefik组件，其Service Type为NodePort，通过kubectl get svc -n kube-system|grep traefik，可以看到端口映射关系，接下来我们在阿里云申请一个负载均衡的设备，然后进行相应的配置之后就完成了这一步操作。</p><p>另外一种替代方式是使用DaemonSet的方式部署traefik组件，设置主机端口和Pod实例端口的映射关系，也可以完成这一任务。</p><h1 id="3、创建ingress资源并进行调试"><a href="#3、创建ingress资源并进行调试" class="headerlink" title="3、创建ingress资源并进行调试"></a>3、创建ingress资源并进行调试</h1><p>接下来我们在kubernetes集群中创建一个ingress资源，由于我们之前已经在集群中部署了一个wordpress应用，资源定义文件如下：</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">extensions/v1beta1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Ingress</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">wordpress-ingress</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="hljs-string">/</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">rules:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">host:</span> <span class="hljs-string">blog.hankercloud.com</span><br>    <span class="hljs-attr">http:</span><br>      <span class="hljs-attr">paths:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">path:</span> <span class="hljs-string">/</span><br>        <span class="hljs-attr">backend:</span><br>          <span class="hljs-attr">serviceName:</span> <span class="hljs-string">wordpress-test-wordpress</span><br>          <span class="hljs-attr">servicePort:</span> <span class="hljs-number">80</span><br></code></pre></div></td></tr></table></figure><p>完成上述的操作之后，我们在本地修改/etc/hosts文件，手动配置blog.hankercloud.com的域名解析记录，在浏览器地址栏输入 <a href="http://blog.hankercloud.com" target="_blank" rel="noopener">http://blog.hankercloud.com</a> 就可以看到页面了，到此我们完成了traefik组件的安装部署及调试工作。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第4篇 Kubernetes包管理工具-helm介绍</title>
    <link href="/2019/12/06/2019-12-06-kubernetes4-helm-introduction/"/>
    <url>/2019/12/06/2019-12-06-kubernetes4-helm-introduction/</url>
    
    <content type="html"><![CDATA[<h1 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h1><p>Helm是kubernetes包管理工具，可以方便快捷的安装、管理、卸载kubernetes应用，类似于Linux操作系统中yum或apt-get软件的作用。其主要的设计目的：</p><ul><li>创建新的chart包</li><li>将charts包文件打包压缩</li><li>同chart仓库进行集成，获取charts文件</li><li>安装及卸载charts到kubernetes集群</li><li>管理通过helm安装的charts应用</li></ul><h1 id="2、概念介绍"><a href="#2、概念介绍" class="headerlink" title="2、概念介绍"></a>2、概念介绍</h1><p><strong>chart:</strong> 一个 Helm 包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含 Kubernetes 集群中的服务定义。</p><p><strong>release：</strong>在 Kubernetes 集群上运行的 Chart 的一个实例。在同一个集群上，一个 Chart 可以安装很多次，每次安装都会创建一个新的 release。</p><p><strong>repository：</strong>用于发布和存储 Chart 的仓库，Helm客户端通过HTTP协议来访问仓库中Chart的索引文件和压缩包。</p><h1 id="3、组件"><a href="#3、组件" class="headerlink" title="3、组件"></a>3、组件</h1><p><strong>helm:</strong> 提供给用户的客户端程序，可以以命令行的形式同服务端-tiller进行通信。</p><p><strong>tiller：</strong>服务端软件，用来同helm客户端进行交互，并同kubernetes api server组件进行交互。</p><p>架构如下：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-06/4-3.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="4、安装部署"><a href="#4、安装部署" class="headerlink" title="4、安装部署"></a>4、安装部署</h1><h2 id="1-helm的安装部署"><a href="#1-helm的安装部署" class="headerlink" title="1. helm的安装部署"></a>1. helm的安装部署</h2><ul><li>版本下载，版本列表 <a href="https://github.com/helm/helm/releases" target="_blank" rel="noopener">https://github.com/helm/helm/releases</a></li><li>解压缩, tar -zxvf helm-v2.0.0-linux-amd64.tgz</li><li>将解压缩后的二进制文件放在可执行目录下 mv linux-amd64/helm /usr/local/bin/helm，然后执行 helm –help查看帮助文档</li></ul><h2 id="2-tiller的安装部署"><a href="#2-tiller的安装部署" class="headerlink" title="2. tiller的安装部署"></a>2. tiller的安装部署</h2><p>控制台执行 &gt; helm init命令，该命令会将从charts仓库中下载charts包，并根据其中的配置部署至kubernetes集群。</p><p>默认的charts仓库为 <a href="https://kubernetes-charts.storage.googleapis.com/index.yaml" target="_blank" rel="noopener">https://kubernetes-charts.storage.googleapis.com/index.yaml</a></p><p>默认使用的tiller镜像为 gcr.io/kubernetes-helm/tiller:v2.13.1 </p><p>国内由于墙的原因无法直接访问，需要我们自行处理可替代的仓库和镜像版本，通过如下命令进行helm服务端的安装部署：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> helm init --tiller-image registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.13.1 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br><br>Creating /root/.helm/repository/repositories.yaml<br>Adding stable repo with URL: https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts<br>Adding local repo with URL: http://127.0.0.1:8879/charts<br><span class="hljs-meta">$</span><span class="bash">HELM_HOME has been configured at /root/.helm.</span><br><br>Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.<br><br>Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users'<br>policy.<br>To prevent this, run `helm init` with the --tiller-tls-verify flag.<br>For more information on securing your installation see:<br>https://docs.helm.sh/using_helm/#securing-your-helm-installationHappy Helming!<br></code></pre></div></td></tr></table></figure><p>稍等一会然后执行如下命令，看到如下输出说明安装成功：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> helm version</span><br>Client: &amp;version.Version&#123;SemVer:"v2.13.1", GitCommit:"618447cbf203d147601b4b9bd7f8c37a5d39fbb4", GitTreeState:"clean"&#125;<br>Server: &amp;version.Version&#123;SemVer:"v2.13.1", GitCommit:"618447cbf203d147601b4b9bd7f8c37a5d39fbb4", GitTreeState:"clean"&#125;<br></code></pre></div></td></tr></table></figure><p>通过执行 helm –help 可以看到常用的命令，说明如下：</p><ul><li>search 在helm仓库进行查找应用</li><li>fetch 从仓库中下载chart包到本地</li><li>list 在该k8s集群的部署的release列表</li><li>status 显示release的具体信息</li><li>install 安装charts</li><li>inspect 描述charts信息</li><li>delete 删除部署的release</li><li>create 创建一个charts</li><li>package 将某一charts进行打包压缩</li><li>repo 显示、添加、移除charts仓库</li></ul><h1 id="5、访问授权"><a href="#5、访问授权" class="headerlink" title="5、访问授权"></a>5、访问授权</h1><p>在上面的步骤中我们将tiller所需的资源部署到了kubernetes集群中，但是由于Deployment tiller-deploy没有定义授权的ServiceAccount导致访问apiserver拒绝，执行如下命令为tiller-deploy进行授权：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> kubectl create serviceaccount --namespace kube-system tiller</span><br><span class="hljs-meta">&gt;</span><span class="bash"> kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller</span><br><span class="hljs-meta">&gt;</span><span class="bash"> kubectl patch deploy --namespace kube-system tiller-deploy -p <span class="hljs-string">'&#123;"spec":&#123;</span></span><br></code></pre></div></td></tr></table></figure><h1 id="6、通过helm部署WordPress"><a href="#6、通过helm部署WordPress" class="headerlink" title="6、通过helm部署WordPress"></a>6、通过helm部署WordPress</h1><p>输入如下命令，我们可以通过helm创建一个WordPress博客网站</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> helm install --name wordpress-test --<span class="hljs-built_in">set</span> <span class="hljs-string">"persistence.enabled=false,mariadb.persistence.enabled=false"</span> stable/wordpress</span><br></code></pre></div></td></tr></table></figure><p>通过如下命令获取登录信息：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> kubectl get svc -o wide</span><br><span class="hljs-meta">&gt;</span><span class="bash"> kubectl get secret --namespace default wordpress-test-wordpress -o jsonpath=<span class="hljs-string">"&#123;.data.wordpress-password&#125;"</span> | base64 --decode</span><br></code></pre></div></td></tr></table></figure><p>在浏览器中打开页面，并输入用户名和密码就可以看到搭建好的WordPress博客网站了。</p><h1 id="7、升级"><a href="#7、升级" class="headerlink" title="7、升级"></a>7、升级</h1><p>当有新的chart包发布时或者想改变已有release的配置时，可以通过 helm upgrade命令实现，比如：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> helm upgrade wordpress-test \</span><br><span class="hljs-meta">&gt;</span><span class="bash"> --<span class="hljs-built_in">set</span> <span class="hljs-string">"persistence.enabled=true,mariadb.persistence.enabled=true"</span> \</span><br><span class="hljs-meta">&gt;</span><span class="bash"> stable/wordpress</span><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第3篇 Kubernetes集群安装部署</title>
    <link href="/2019/12/05/2019-12-05-kubernetes3-cluster-install/"/>
    <url>/2019/12/05/2019-12-05-kubernetes3-cluster-install/</url>
    
    <content type="html"><![CDATA[<p>本文介绍了如何通过Kubespray来进行部署高可用k8s集群，k8s版本为1.12.5。</p><h1 id="1、部署手册"><a href="#1、部署手册" class="headerlink" title="1、部署手册"></a>1、部署手册</h1><p>代码仓库：<a href="https://github.com/kubernetes-sigs/kubespray" target="_blank" rel="noopener">https://github.com/kubernetes-sigs/kubespray</a></p><p>参考文档：<a href="https://kubespray.io/#/" target="_blank" rel="noopener">https://kubespray.io/#/</a></p><h1 id="2、k8s-master机器配置"><a href="#2、k8s-master机器配置" class="headerlink" title="2、k8s master机器配置"></a>2、k8s master机器配置</h1><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-05/2.jpg" srcset="/img/loading.gif" lazyload alt="avatar"></p><h1 id="3、k8s-集群安装步骤"><a href="#3、k8s-集群安装步骤" class="headerlink" title="3、k8s 集群安装步骤"></a>3、k8s 集群安装步骤</h1><p><strong>step1: 设置主机间的免密登录</strong></p><p>由于kubespray是依赖于ansible，ansible通过ssh协议进行主机之间的访问，所以部署之前需要设置主机之间免密登录，步骤如下：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">ssh-keygen -t rsa<br>scp ~/.ssh/id_rsa.pub root@IP:/root/.ssh<br>ssh root@IP<br>cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys<br></code></pre></div></td></tr></table></figure><p><strong>step2: 下载kubespray</strong></p><p>注意：不要通过使用github仓库master分支的代码，我这里使用的是tag v2.8.3进行部署</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">wget https://github.com/kubernetes-sigs/kubespray/archive/v2.8.3.tar.gz<br>tar -xvf v2.8.3<br>cd kubespray-v2.8.3<br></code></pre></div></td></tr></table></figure><p><strong>step3: 配置调整</strong></p><h2 id="3-1-更换镜像"><a href="#3-1-更换镜像" class="headerlink" title="3.1 更换镜像"></a>3.1 更换镜像</h2><p>Kubernetes安装大部分都是使用的国外的镜像，由于防火墙原因没有办法获取到这些镜像，所以需要自己创建镜像仓库并将这些镜像获取到上传到镜像仓库中。</p><p><strong>3.1.1 新建镜像仓库</strong></p><p>镜像仓库我们选用的组件是Harbor，安装步骤参考：</p><p><a href="https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md" target="_blank" rel="noopener">https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md</a></p><p><strong>3.1.2 整理k8s集群部署中需要使用的镜像</strong></p><p>在文件roles/download/defaults/main.yml文件中，可以看到使用的全量镜像列表，注意某些镜像由于功能未使用的原因所以暂时没有用到，我们主要用到有如下镜像：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-05/3-1-2.jpg" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong>3.1.3 下载所需镜像并上传至私有镜像仓库</strong></p><p>使用的镜像列表如下，在这里我申请了一台国外的阿里云主机，在该台主机下载所需镜像然后上传至私有镜像仓库</p><p>例如操作某个镜像时，需要执行如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">docker pull gcr.io/google_containers/kubernetes-dashboard-amd64:v1.10.0<br>docker tag gcr.io/google_containers/kubernetes-dashboard-amd64:v1.10.0 106.14.219.69:5000/google_containers/kubernetes-dashboard-amd64:v1.10.0<br>docker push 106.14.219.69:5000/google_containers/kubernetes-dashboard-amd64:v1.10.0<br></code></pre></div></td></tr></table></figure><p><strong>3.1.4 更改镜像地址并修改Docker配置</strong></p><p>在inventory/testcluster/group_vars/k8s-cluster/k8s-cluster.yml文件中添加如下配置：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> kubernetes image repo define</span><br>kube_image_repo: "10.0.0.183:5000/google_containers"<br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># modified by: robbin</span></span><br><span class="hljs-meta">#</span><span class="bash"> comment: 将使⽤的组件的镜像仓库修改为私有镜像仓库地址</span><br>etcd_image_repo: "10.0.0.183:5000/coreos/etcd"<br>coredns_image_repo: "10.0.0.183:5000/coredns"<br>calicoctl_image_repo: "10.0.0.183:5000/calico/ctl"<br>calico_node_image_repo: "10.0.0.183:5000/calico/node"<br>calico_cni_image_repo: "10.0.0.183:5000/calico/cni"<br>calico_policy_image_repo: "10.0.0.183:5000/calico/kube-controllers"<br>hyperkube_image_repo: "&#123;&#123; kube_image_repo &#125;&#125;/hyperkube-&#123;&#123; image_arch &#125;&#125;"<br>pod_infra_image_repo: "&#123;&#123; kube_image_repo &#125;&#125;/pause-&#123;&#123; image_arch &#125;&#125;"<br>dnsautoscaler_image_repo: "&#123;&#123; kube_image_repo &#125;&#125;/cluster-proportional-autoscaler-&#123;&#123; image_arch &#125;&#125;"<br>dashboard_image_repo: "&#123;&#123; kube_image_repo &#125;&#125;/kubernetes-dashboard-&#123;&#123; image_arch &#125;&#125;"<br></code></pre></div></td></tr></table></figure><p>由于我们的私有镜像仓库未配置https证书，需要在 inventory/testcluster/group_vars/all/docker.yml文件中添加如下配置：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">docker_insecure_registries:<br>- 10.0.0.183:5000<br></code></pre></div></td></tr></table></figure><h2 id="3-2-Docker安装源更改以及执行文件预处理"><a href="#3-2-Docker安装源更改以及执行文件预处理" class="headerlink" title="3.2 Docker安装源更改以及执行文件预处理"></a>3.2 Docker安装源更改以及执行文件预处理</h2><p><strong>3.2.1 Docker安装源更改</strong></p><p>由于默认从Docker官方源安装docker，速度非常慢，这里我们更换为国内阿里源，在inventory/testcluster/group_vars/k8s-cluster/k8s-cluster.yml文件中添加如下配置：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> CentOS/RedHat docker-ce repodocker_rh_repo_base_url: <span class="hljs-string">'https://mirrors.aliyun.com/docker-ce/linux/centos/7/$basearch/stable'</span></span><br>docker_rh_repo_gpgkey: 'https://mirrors.aliyun.com/docker-ce/linux/centos/gpg'<br>dockerproject_rh_repo_base_url: 'https://mirrors.aliyun.com/docker-engine/yum/repo/main/centos/7'<br>dockerproject_rh_repo_gpgkey: 'https://mirrors.aliyun.com/docker-engine/yum/gpg'<br></code></pre></div></td></tr></table></figure><p><strong>3.2.2 可执行文件预处理</strong></p><p>另外由于需要从google以及github下载一些可执行文件，由于防火墙原因无法直接在服务器上下载，我们可以预先将这些执行文件下载好，然后上传到指定的服务器路径中</p><p>可执行文件下载地址可以在roles/download/defaults/main.yml文件中查找到，下载路径如下：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">kubeadm_download_url: "https://storage.googleapis.com/kubernetes-release/release/v1.12.5/bin/linux/amd64/kubeadm"<br>hyperkube_download_url: "https://storage.googleapis.com/kubernetes-release/release/v1.12.5/bin/linux/amd64/hyperkube"<br>cni_download_url: "https://github.com/containernetworking/plugins/releases/download/v0.6.0/cni-plugins-amd64-v0.6.0.tgz"<br></code></pre></div></td></tr></table></figure><p>接下来修改文件权限，并上传到每台服务器的/tmp/releases目录下</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">chmod 755 cni-plugins-amd64-v0.6.0.tgz hyperkube kubeadm<br>scp cni-plugins-amd64-v0.6.0.tgz hyperkube kubeadm root@node1:/tmp/releases<br></code></pre></div></td></tr></table></figure><h2 id="3-3-组件列表"><a href="#3-3-组件列表" class="headerlink" title="3.3 组件列表"></a>3.3 组件列表</h2><p><strong>k8s所需要的组件</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-05/3-3-1.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong>可选插件列表</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-05/3-3-2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h2 id="3-4-DNS方案"><a href="#3-4-DNS方案" class="headerlink" title="3.4 DNS方案"></a>3.4 DNS方案</h2><p>k8s的服务发现依赖于DNS，涉及到两种类型的网络：主机网络和容器网络，所以Kubespray提供了两种配置来进行管理 </p><p><strong>3.4.1 dns_mode</strong></p><p>dns_mode 主要用于集群内的域名解析，有如下几种类型，我们的技术选型是coredns，注意：选择某种dns_mode，可能需要下载安装多个容器镜像，其镜像版本也可能不同</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-05/3-4-1.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p><strong>3.4.2 resolvconf_mode</strong></p><p>resolvconf_mode主要用来解决当容器部署为host网络模式的时候，如何使用k8s的dns，这里我们使用的是docker_dns</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">resolvconf_mode: docker_dns<br></code></pre></div></td></tr></table></figure><h2 id="3-5-网络插件选择"><a href="#3-5-网络插件选择" class="headerlink" title="3.5 网络插件选择"></a>3.5 网络插件选择</h2><p><strong>3.5.1 kube-proxy</strong></p><p>kube-proxy可以选择ipvs或者iptables，在这里我们选择的是ipvs模式，关于这两者的区别可以参考 华为云在 K8S 大规模场景下的 Service 性能优化实践(<a href="https://zhuanlan.zhihu.com/p/37230013" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/37230013</a>)</p><p><strong>3.5.2 网络插件列表</strong></p><p>网络插件列表如下，我们的技术选型是calico，注意：选择某种网络插件，可能需要一个或多个容器镜像，其镜像版本也可能不同</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-12-05/3-5-2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><h2 id="3-6-高可用方案"><a href="#3-6-高可用方案" class="headerlink" title="3.6 高可用方案"></a>3.6 高可用方案</h2><p><strong>step4: 按照如下步骤进行安装部署</strong></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> Install dependencies from ``requirements.txt``</span><br>sudo pip install -r requirements.txt<br><span class="hljs-meta">#</span><span class="bash"> Copy `inventory/sample` as `inventory/mycluster`</span><br>cp -rfp inventory/sample inventory/mycluster<br><span class="hljs-meta">#</span><span class="bash"> Update Ansible inventory file with inventory builder</span><br>declare -a IPS=(10.10.1.3 10.10.1.4 10.10.1.5)<br>CONFIG_FILE=inventory/mycluster/hosts.ini python3 contrib/inventory_builder/inventory.py $&#123;IPS[@]&#125;<br><span class="hljs-meta">#</span><span class="bash"> Review and change parameters under `inventory/mycluster/group_vars`</span><br>cat inventory/mycluster/group_vars/all/all.yml<br>cat inventory/mycluster/group_vars/k8s-cluster/k8s-cluster.yml<br><span class="hljs-meta">#</span><span class="bash"> Deploy Kubespray with Ansible Playbook - run the playbook as root</span><br><span class="hljs-meta">#</span><span class="bash"> The option `-b` is required, as <span class="hljs-keyword">for</span> example writing SSL keys <span class="hljs-keyword">in</span> /etc/,</span><br><span class="hljs-meta">#</span><span class="bash"> installing packages and interacting with various systemd daemons.</span><br><span class="hljs-meta">#</span><span class="bash"> Without -b the playbook will fail to run!</span><br>ansible-playbook -i inventory/mycluster/hosts.ini --become --become-user=root cluster.yml<br></code></pre></div></td></tr></table></figure><p>部署完成，可以登录到k8s-master所在的主机，执行如下命令，可以看到各个组件正常</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">kubectl cluster-info<br>kubectl get node<br>kubectl get pods --all-namespaces<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第2篇 基础概念介绍</title>
    <link href="/2019/12/04/2019-12-04-kubernetes2-introduction-to-basic-concepts/"/>
    <url>/2019/12/04/2019-12-04-kubernetes2-introduction-to-basic-concepts/</url>
    
    <content type="html"><![CDATA[<h1 id="1、Pod-实例"><a href="#1、Pod-实例" class="headerlink" title="1、Pod - 实例"></a>1、Pod - 实例</h1><p>Pod是一组紧密关联的容器集合，支持多个容器在一个Pod中共享网络和文件系统，可以通过进程间通信和文件共享这种简单高效的方式完成服务，是Kubernetes调度的基本单位。Pod的设计理念是 <strong>每个Pod都有一个唯一的IP</strong></p><p>Pod具有如下特征：</p><ul><li>包含多个共享IPC、Network和UTC namespace的容器，可直接通过localhost通信 </li><li>所有Pod内容器都可以访问共享的Volume，可以访问共享数据 </li><li>优雅终止:Pod删除的时候先给其内的进程发送SIGTERM，等待一段时间(grace period)后才强制停止依然还在运行的进程 </li><li>特权容器(通过SecurityContext配置)具有改变系统配置的权限(在网络插件中大量应用)</li><li>支持三种重启策略（restartPolicy），分别是：Always、OnFailure、Never</li><li>支持三种镜像拉取策略（imagePullPolicy），分别是：Always、Never、IfNotPresent</li><li>资源限制，Kubernetes通过CGroup限制容器的CPU以及内存等资源，可以设置request以及limit值</li><li>健康检查，提供两种健康检查探针，分别是livenessProbe和redinessProbe，前者用于探测容器是否存活，如果探测失败，则根据重启策略进行重启操作，后者用于检查容器状态是否正常，如果检查容器状态不正常，则请求不会到达该Pod</li><li>Init container在所有容器运行之前执行，常用来初始化配置</li><li>容器生命周期钩子函数，用于监听容器生命周期的特定事件，并在事件发生时执行已注册的回调函数，支持两种钩子函数：postStart和preStop，前者是在容器启动后执行，后者是在容器停止前执行</li></ul><h1 id="2、Namespace-命名空间"><a href="#2、Namespace-命名空间" class="headerlink" title="2、Namespace - 命名空间"></a>2、Namespace - 命名空间</h1><p>Namespace（命名空间）是对一组资源和对象的抽象集合，比如可以用来将系统内部的对象划分为不同的项目组或者用户组。常见的pod、service、replicaSet和deployment等都是属于某一个namespace的(默认是default)，而node, persistentVolumes等则不属于任何namespace。</p><p>常用namespace操作：</p><figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 查询所有namespaces </span><br>kubectl get namespace<span class="hljs-comment"># </span><br>创建namespace<br>kubectl create namespace ns-name <br><span class="hljs-comment"># 删除namespace</span><br>kubectl delete namespace ns-name<br></code></pre></div></td></tr></table></figure><p>删除命名空间时，需注意以下几点：</p><ol><li>删除一个namespace会自动删除所有属于该namespace的资源。</li><li>default 和 kube-system 命名空间不可删除。</li><li>PersistentVolumes是不属于任何namespace的，但PersistentVolumeClaim是属于某个特定namespace的。</li><li>Events是否属于namespace取决于产生events的对象。</li></ol><h1 id="3、Node-节点"><a href="#3、Node-节点" class="headerlink" title="3、Node 节点"></a>3、Node 节点</h1><p>Node是Pod真正运行的主机，可以是物理机也可以是虚拟机。Node本质上不是Kubernetes来创建的， Kubernetes只是管理Node上的资源。为了管理Pod，每个Node节点上至少需要运行container runtime（Docker）、kubelet和kube-proxy服务。</p><p>常用node操作：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 查询所有node</span><br>kubectl get nodes<br><span class="hljs-meta">#</span><span class="bash"> 将node标志为不可调度</span><br>kubectl cordon $nodename<br><span class="hljs-meta">#</span><span class="bash"> 将node标志为可调度</span><br>kubectl uncordon $nodename<br></code></pre></div></td></tr></table></figure><p><strong>taint(污点)</strong></p><p>使用kubectl taint命令可以给某个Node节点设置污点，Node被设置上污点之后就和Pod之间存在了一种相斥的关系，可以让Node拒绝Pod的调度执行，甚至将Node已经存在的Pod驱逐出去。每个污点的组成：<code>key=value:effect</code>，当前taint effect支持如下三个选项：</p><ul><li>NoSchedule：表示k8s将不会将Pod调度到具有该污点的Node上</li><li>PreferNoSchedule：表示k8s将尽量避免将Pod调度到具有该污点的Node上</li><li>NoExecute：表示k8s将不会将Pod调度到具有该污点的Node上，同时会将Node上已经存在的Pod驱逐出去</li></ul><p>常用命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 为节点node0设置不可调度污点</span><br>kubectl taint node node0 key1=value1:NoShedule<br><span class="hljs-meta">#</span><span class="bash"> 将node0上key值为key1的污点移除</span><br>kubectl taint node node0 key-<br><span class="hljs-meta">#</span><span class="bash"> 为kube-master节点设置不可调度污点</span><br>kubectl taint node node1 node-role.kubernetes.io/master=:NoSchedule<br><span class="hljs-meta">#</span><span class="bash"> 为kube-master节点设置尽量不可调度污点</span><br>kubectl taint node node1 node-role.kubernetes.io/master=PreferNoSchedule<br></code></pre></div></td></tr></table></figure><p><strong>容忍(Tolerations)</strong></p><p>设置了污点的Node将根据taint的effect：NoSchedule、PreferNoSchedule、NoExecute和Pod之间产生互斥的关系，Pod将在一定程度上不会被调度到Node上。 但我们可以在Pod上设置容忍(Toleration)，意思是设置了容忍的Pod将可以容忍污点的存在，可以被调度到存在污点的Node上。</p><h1 id="4、Service-服务"><a href="#4、Service-服务" class="headerlink" title="4、Service 服务"></a>4、Service 服务</h1><p>Service是对一组提供相同功能的Pods的抽象，并为他们提供一个统一的入口，借助 Service 应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。 Service通过标签(label)来选取后端Pod，一般配合ReplicaSet或者Deployment来保证后端容器的正常运行。</p><p>service 有如下四种类型，默认是ClusterIP：</p><ul><li>ClusterIP: 默认类型，自动分配一个仅集群内部可以访问的虚拟IP</li><li>NodePort: 在ClusterIP基础上为Service在每台机器上绑定一个端口，这样就可以通过 <code>NodeIP:NodePort</code> 来访问该服务</li><li>LoadBalancer: 在NodePort的基础上，借助cloud provider创建一个外部的负载均衡器，并将请求转发到 NodeIP:NodePort</li><li>ExternalName: 将服务通过DNS CNAME记录方式转发到指定的域名</li></ul><p>另外，也可以将已有的服务以Service的形式加入到Kubernetes集群中来，只需要在创建 Service 的时候不指定Label selector，而是在Service创建好后手动为其添加endpoint。</p><h1 id="5、Volume-存储卷"><a href="#5、Volume-存储卷" class="headerlink" title="5、Volume 存储卷"></a>5、Volume 存储卷</h1><p>默认情况下容器的数据是非持久化的，容器消亡以后数据也会跟着丢失，所以Docker提供了Volume机制以便将数据持久化存储。Kubernetes提供了更强大的Volume机制和插件，解决了容器数据持久化以及容器间共享数据的问题。</p><p>Kubernetes存储卷的生命周期与Pod绑定</p><ul><li>容器挂掉后Kubelet再次重启容器时，Volume的数据依然还在</li><li>Pod删除时，Volume才会清理。数据是否丢失取决于具体的Volume类型，比如emptyDir的数据会丢失，而PV的数据则不会丢</li></ul><p>目前Kubernetes主要支持以下Volume类型：</p><ul><li>emptyDir：Pod存在，emptyDir就会存在，容器挂掉不会引起emptyDir目录下的数据丢失，但是pod被删除或者迁移，emptyDir也会被删除</li><li>hostPath：hostPath允许挂载Node上的文件系统到Pod里面去</li><li>NFS（Network File System）：网络文件系统，Kubernetes中通过简单地配置就可以挂载NFS到Pod中，而NFS中的数据是可以永久保存的，同时NFS支持同时写操作。</li><li>glusterfs：同NFS一样是一种网络文件系统，Kubernetes可以将glusterfs挂载到Pod中，并进行永久保存</li><li>cephfs：一种分布式网络文件系统，可以挂载到Pod中，并进行永久保存</li><li>subpath：Pod的多个容器使用同一个Volume时，会经常用到</li><li>secret：密钥管理，可以将敏感信息进行加密之后保存并挂载到Pod中</li><li>persistentVolumeClaim：用于将持久化存储（PersistentVolume）挂载到Pod中</li><li>…</li></ul><h1 id="6、PersistentVolume-PV-持久化存储卷"><a href="#6、PersistentVolume-PV-持久化存储卷" class="headerlink" title="6、PersistentVolume(PV) 持久化存储卷"></a>6、PersistentVolume(PV) 持久化存储卷</h1><p>PersistentVolume(PV)是集群之中的一块网络存储。跟 Node 一样，也是集群的资源。PersistentVolume (PV)和PersistentVolumeClaim (PVC)提供了方便的持久化卷: PV提供网络存储资源，而PVC请求存储资源并将其挂载到Pod中。</p><p>PV的访问模式(accessModes)有三种:</p><ul><li>ReadWriteOnce(RWO):是最基本的方式，可读可写，但只支持被单个Pod挂载。</li><li>ReadOnlyMany(ROX):可以以只读的方式被多个Pod挂载。 </li><li>ReadWriteMany(RWX):这种存储可以以读写的方式被多个Pod共享。</li></ul><p>不是每一种存储都支持这三种方式，像共享方式，目前支持的还比较少，比较常用的是 NFS。在PVC绑定PV时通常根据两个条件来绑定，一个是存储的大小，另一个就是 访问模式。</p><p>PV的回收策略(persistentVolumeReclaimPolicy)也有三种</p><ul><li>Retain，不清理保留Volume(需要手动清理)</li><li>Recycle，删除数据，即 rm -rf /thevolume/* (只有NFS和HostPath支持) </li><li>Delete，删除存储资源</li></ul><h1 id="7、Deployment-无状态应用"><a href="#7、Deployment-无状态应用" class="headerlink" title="7、Deployment 无状态应用"></a>7、Deployment 无状态应用</h1><p>一般情况下我们不需要手动创建Pod实例，而是采用更高一层的抽象或定义来管理Pod，针对无状态类型的应用，Kubernetes使用Deloyment的Controller对象与之对应。其典型的应用场景包括：</p><ul><li>定义Deployment来创建Pod和ReplicaSet </li><li>滚动升级和回滚应用</li><li>扩容和缩容</li><li>暂停和继续Deployment</li></ul><p>常用的操作命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 生成一个Deployment对象</span><br>kubectl run www --image=10.0.0.183:5000/hanker/www:0.0.1 --port=8080<br><span class="hljs-meta">#</span><span class="bash"> 查找Deployment</span><br>kubectl get deployment --all-namespaces<br><span class="hljs-meta">#</span><span class="bash"> 查看某个Deployment</span><br>kubectl describe deployment www<br><span class="hljs-meta">#</span><span class="bash"> 编辑Deployment定义</span><br>kubectl edit deployment www<br><span class="hljs-meta">#</span><span class="bash"> 删除某Deployment</span><br>kubectl delete deployment www<br><span class="hljs-meta">#</span><span class="bash"> 扩缩容操作，即修改Deployment下的Pod实例个数</span><br>kubectl scale deployment/www --replicas=2<br><span class="hljs-meta">#</span><span class="bash"> 更新镜像</span><br>kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1<br><span class="hljs-meta">#</span><span class="bash"> 回滚操作</span><br>kubectl rollout undo deployment/nginx-deployment<br><span class="hljs-meta">#</span><span class="bash"> 查看回滚进度</span><br>kubectl rollout status deployment/nginx-deployment<br><span class="hljs-meta">#</span><span class="bash"> 启用水平伸缩（HPA - horizontal pod autoscaling），设置最小、最大实例数量以及目标cpu使用率</span><br>kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80<br><span class="hljs-meta">#</span><span class="bash"> 暂停更新Deployment</span><br>kubectl rollout pause deployment/nginx-deployment<br><span class="hljs-meta">#</span><span class="bash"> 恢复更新Deployment</span><br>kubectl rollout resume deploy nginx<br></code></pre></div></td></tr></table></figure><p><strong>更新策略</strong></p><p><code>.spec.strategy</code> 指新的Pod替换旧的Pod的策略，有以下两种类型</p><ul><li><code>RollingUpdate</code> 滚动升级，可以保证应用在升级期间，对外正常提供服务。</li><li><code>Recreate</code> 重建策略，在创建出新的Pod之前会先杀掉所有已存在的Pod。</li></ul><p><strong>Deployment和ReplicaSet两者之间的关系</strong></p><ul><li>使用Deployment来创建ReplicaSet。ReplicaSet在后台创建pod，检查启动状态，看它是成功还是失败。</li><li>当执行更新操作时，会创建一个新的ReplicaSet，Deployment会按照控制的速率将pod从旧的ReplicaSet移 动到新的ReplicaSet中</li></ul><h1 id="8、StatefulSet-有状态应用"><a href="#8、StatefulSet-有状态应用" class="headerlink" title="8、StatefulSet 有状态应用"></a>8、StatefulSet 有状态应用</h1><p>Deployments和ReplicaSets是为无状态服务设计的，那么StatefulSet则是为了有状态服务而设计，其应用场景包括：</p><ul><li>稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现</li><li>稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service(即没有Cluster IP的Service)来实现 </li><li>有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次进行操作(即从0到N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态)，基于init containers来实现 </li><li>有序收缩，有序删除(即从N-1到0)</li></ul><p>支持两种更新策略：</p><ul><li>OnDelete:当<code>.spec.template</code>更新时，并不立即删除旧的Pod，而是等待用户手动删除这些旧Pod后自动创建新Pod。这是默认的更新策略，兼容v1.6版本的行为 </li><li>RollingUpdate:当 <code>.spec.template</code> 更新时，自动删除旧的Pod并创建新Pod替换。在更新时这些Pod是按逆序的方式进行，依次删除、创建并等待Pod变成Ready状态才进行下一个Pod的更新。</li></ul><h1 id="9、DaemonSet-守护进程集"><a href="#9、DaemonSet-守护进程集" class="headerlink" title="9、DaemonSet 守护进程集"></a>9、DaemonSet 守护进程集</h1><p>DaemonSet保证在特定或所有Node节点上都运行一个Pod实例，常用来部署一些集群的日志采集、监控或者其他系统管理应用。典型的应用包括:</p><ul><li>日志收集，比如fluentd，logstash等</li><li>系统监控，比如Prometheus Node Exporter，collectd等</li><li>系统程序，比如kube-proxy, kube-dns, glusterd, ceph，ingress-controller等</li></ul><p><strong>指定Node节点</strong></p><p>DaemonSet会忽略Node的unschedulable状态，有两种方式来指定Pod只运行在指定的Node节点上:</p><ul><li>nodeSelector:只调度到匹配指定label的Node上 </li><li>nodeAffinity:功能更丰富的Node选择器，比如支持集合操作 </li><li>podAffinity:调度到满足条件的Pod所在的Node上</li></ul><p>目前支持两种策略</p><ul><li>OnDelete: 默认策略，更新模板后，只有手动删除了旧的Pod后才会创建新的Pod </li><li>RollingUpdate: 更新DaemonSet模版后，自动删除旧的Pod并创建新的Pod</li></ul><h1 id="10、Ingress-负载均衡"><a href="#10、Ingress-负载均衡" class="headerlink" title="10、Ingress 负载均衡"></a>10、Ingress 负载均衡</h1><p>Kubernetes中的负载均衡我们主要用到了以下两种机制：</p><ul><li>Service：使用Service提供集群内部的负载均衡，Kube-proxy负责将service请求负载均衡到后端的Pod中</li><li>Ingress Controller：使用Ingress提供集群外部的负载均衡</li></ul><p>Service和Pod的IP仅可在集群内部访问。集群外部的请求需要通过负载均衡转发到service所在节点暴露的端口上，然后再由kube-proxy通过边缘路由器将其转发到相关的Pod，Ingress可以给service提供集群外部访问的URL、负载均衡、HTTP路由等，为了配置这些Ingress规则，集群管理员需要部署一个Ingress Controller，它监听Ingress和service的变化，并根据规则配置负载均衡并提供访问入口。</p><p>常用的ingress controller：</p><ul><li>nginx</li><li>traefik</li><li>Kong</li><li>Openresty</li></ul><h1 id="11、Job-amp-CronJob-任务和定时任务"><a href="#11、Job-amp-CronJob-任务和定时任务" class="headerlink" title="11、Job &amp; CronJob 任务和定时任务"></a>11、Job &amp; CronJob 任务和定时任务</h1><p>Job负责批量处理短暂的一次性任务 (short lived one-off tasks)，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束。</p><p>CronJob即定时任务，就类似于Linux系统的crontab，在指定的时间周期运行指定的任务。</p><h1 id="12、HPA（Horizontal-Pod-Autoscaling）-水平伸缩"><a href="#12、HPA（Horizontal-Pod-Autoscaling）-水平伸缩" class="headerlink" title="12、HPA（Horizontal Pod Autoscaling） 水平伸缩"></a>12、HPA（Horizontal Pod Autoscaling） 水平伸缩</h1><p>Horizontal Pod Autoscaling可以根据CPU、内存使用率或应用自定义metrics自动扩展Pod数量 (支持replication controller、deployment和replica set)。</p><ul><li><p>控制管理器默认每隔30s查询metrics的资源使用情况(可以通过 –horizontal-pod-autoscaler-sync-period 修改)</p></li><li><p>支持三种metrics类型</p></li><li><ul><li>预定义metrics(比如Pod的CPU)以利用率的方式计算 </li><li>自定义的Pod metrics，以原始值(raw value)的方式计算 </li><li>自定义的object metrics</li></ul></li><li><p>支持两种metrics查询方式:Heapster和自定义的REST API </p></li><li><p>支持多metrics</p></li></ul><p>可以通过如下命令创建HPA：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10<br></code></pre></div></td></tr></table></figure><h1 id="13、Service-Account"><a href="#13、Service-Account" class="headerlink" title="13、Service Account"></a>13、Service Account</h1><p>Service account是为了方便Pod里面的进程调用Kubernetes API或其他外部服务而设计的</p><p><strong>授权</strong></p><p>Service Account为服务提供了一种方便的认证机制，但它不关心授权的问题。可以配合RBAC(Role Based Access Control)来为Service Account鉴权，通过定义Role、RoleBinding、ClusterRole、ClusterRoleBinding来对sa进行授权。</p><h1 id="14、-Secret-密钥"><a href="#14、-Secret-密钥" class="headerlink" title="14、 Secret 密钥"></a>14、 Secret 密钥</h1><p>Sercert-密钥解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者Pod Spec中。Secret可以以Volume或者环境变量的方式使用。有如下三种类型：</p><ul><li>Service Account:用来访问Kubernetes API，由Kubernetes自动创建，并且会自动挂载到Pod的 /run/secrets/kubernetes.io/serviceaccount 目录中; </li><li>Opaque:base64编码格式的Secret，用来存储密码、密钥等;</li><li>kubernetes.io/dockerconfigjson: 用来存储私有docker registry的认证信息。</li></ul><h1 id="15、ConfigMap-配置中心"><a href="#15、ConfigMap-配置中心" class="headerlink" title="15、ConfigMap 配置中心"></a>15、ConfigMap 配置中心</h1><p>ConfigMap用于保存配置数据的键值对，可以用来保存单个属性，也可以用来保存配置文件。ConfigMap跟secret很类似，但它可以更方便地处理不包含敏感信息的字符串。ConfigMap可以通过三种方式在Pod中使用，三种分别方式为:设置环境变量、设置容器命令行参数以及在Volume中直接挂载文件或目录。</p><p>可以使用 kubectl create configmap从文件、目录或者key-value字符串创建等创建 ConfigMap。也可以通过 kubectl create -f value.yaml 创建。</p><h1 id="16、Resource-Quotas-资源配额"><a href="#16、Resource-Quotas-资源配额" class="headerlink" title="16、Resource Quotas 资源配额"></a>16、Resource Quotas 资源配额</h1><p>资源配额(Resource Quotas)是用来限制用户资源用量的一种机制。</p><p>资源配额有如下类型：</p><ul><li><p>计算资源，包括cpu和memory</p></li><li><ul><li>cpu, limits.cpu, requests.cpu</li><li>memory, limits.memory, requests.memory</li></ul></li><li><p>存储资源，包括存储资源的总量以及指定storage class的总量 </p></li><li><ul><li>requests.storage:存储资源总量，如500Gi </li><li>persistentvolumeclaims:pvc的个数 </li><li>.storageclass.storage.k8s.io/requests.storage </li><li>.storageclass.storage.k8s.io/persistentvolumeclaims</li></ul></li><li><p>对象数，即可创建的对象的个数</p></li><li><ul><li>pods, replicationcontrollers, configmaps, secrets </li><li>resourcequotas, persistentvolumeclaims</li><li>services, services.loadbalancers, services.nodeports</li></ul></li></ul><p>它的工作原理为:</p><ul><li>资源配额应用在Namespace上，并且每个Namespace最多只能有一个 ResourceQuota 对象 </li><li>开启计算资源配额后，创建容器时必须配置计算资源请求或限制(也可以 用LimitRange设置默认值)</li><li>用户超额后禁止创建新的资源</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【Kubernetes系列】第1篇 架构及组件介绍 </title>
    <link href="/2019/11/29/2019-11-29-kubernetes1-architecture-component/"/>
    <url>/2019/11/29/2019-11-29-kubernetes1-architecture-component/</url>
    
    <content type="html"><![CDATA[<h1 id="1、Kubernetes简介"><a href="#1、Kubernetes简介" class="headerlink" title="1、Kubernetes简介"></a>1、Kubernetes简介</h1><p>Kubernetes是谷歌开源的容器集群管理系统，是Google多年大规模容器管理技术Borg的开源版本，主要功能包括:    </p><ul><li><p>基于容器的应用部署、维护和滚动升级</p></li><li><p>负载均衡和服务发现</p></li><li><p>跨机器和跨地区的集群调度</p></li><li><p>自动伸缩</p></li><li><p>无状态服务和有状态服务 </p></li><li><p>广泛的Volume支持 </p></li><li><p>插件机制保证扩展性</p></li></ul><p>Kubernetes发展非常迅速，已经成为容器编排领域的领导者。</p><h1 id="2、Kubernetes-架构及组件介绍"><a href="#2、Kubernetes-架构及组件介绍" class="headerlink" title="2、Kubernetes 架构及组件介绍"></a>2、Kubernetes 架构及组件介绍</h1><h2 id="2-1-kubernetes-架构"><a href="#2-1-kubernetes-架构" class="headerlink" title="2.1 kubernetes 架构"></a>2.1 kubernetes 架构</h2><p>Kubernetes架构如图所示：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-11-29/2-1.jpg" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>Kubernetes主要由以下几个核心组件构成：</p><ul><li><p>etcd 保存整个集群的状态；</p></li><li><p>apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；</p></li><li><p>controller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；</p></li><li><p>scheduler 负责资源的调度，按照预定的调度策略将实例（Pod）调度到相应的主机上；</p></li><li><p>kubelet 负责维护容器的生命周期，同时也负责存储卷和网络的管理；</p></li><li><p>container runtime 负责镜像管理以及容器的真正执行，在我们系统中指的是Docker</p></li><li><p>kube-proxy 负责为应用提供集群内部的服务发现和负载均衡</p></li><li><p>推荐的插件</p><ul><li><p>helm - kubernetes包管理工具</p></li><li><p>kube-dns/coreDNS 负责为整个集群提供DNS服务</p></li><li><p>Ingress Controller 为服务提供外网入口</p></li><li><p>Heapster 提供资源监控</p></li><li><p>Dashboard 提供GUI</p></li><li><p>Federation 提供跨可用区的集群</p></li><li><p>Fluentd-elasticsearch 提供集群日志采集、存储与查询</p></li></ul></li></ul><h2 id="2-2-Kubernetes组件介绍"><a href="#2-2-Kubernetes组件介绍" class="headerlink" title="2.2 Kubernetes组件介绍"></a>2.2 Kubernetes组件介绍</h2><h3 id="2-2-1-etcd"><a href="#2-2-1-etcd" class="headerlink" title="2.2.1 etcd"></a>2.2.1 etcd</h3><p>etcd是基于Raft一致性算法开发的分布式key-value存储，可用于服务发现、共享配置以及一致性保障（如数据库选主、分布式锁等）</p><p>   <strong>etcd主要功能：</strong></p><ul><li><p>基本的key-value存储</p></li><li><p>监听机制</p></li><li><p>key的过期及续约机制，用于监控和服务发现</p></li><li><p>原子CAS和CAD，用于分布式锁和leader选举</p></li></ul><p> <strong>Etcd基于RAFT的一致性</strong></p><p> <strong>leader节点选举方法</strong></p><ul><li><p>初始启动时，节点处于follower状态并被设定一个election timeout，如果在这一时间周期内没有收到来自leader的心跳检测，节点将发起选举，将自己切换为candidate（候选人）节点之后，向集群中的其他follow节点发送请求，询问其是否选举自己为leader</p></li><li><p>当收到来自集群中过半数节点的接受投票后，节点即成为leader，开始接收保存client的数据并向其他的follower节点同步日志。如果没有达成一致，则candidate节点随机选择一个等待时间（150ms ～ 300ms）再次发起投票，得到集群中半数以上的follower接受的candidate将成为leader</p></li><li><p>leader节点依靠定时向follower节点发送心跳检测来保持其地位</p></li><li><p>任何时候如果其他follower在election timeout期间没有收到来自leader的心跳检测，同样会将自己的状态切换为candidate并发起选举。每成功选举一次，新leader的步进数（Term）都会比之前leader的步进数加1 </p></li></ul><p><strong>失效处理</strong></p><ul><li><p>leader失效：其他没有收到心跳检测的节点将发起新的选举，当leader恢复后由于步进数小自动成为follower（日志会被新leader的日志覆盖）</p></li><li><p>follower节点不可用：follower节点不可用的情况相对比较容易解决。因为集群中的日志内容始终是从leader节点同步，只要这一节点再次加入集群时重新从leader节点处复制日志即可</p></li><li><p>多个候选人（candidate）：冲突后candidate将随机选择一个等待时间（150ms ～ 300ms）再次发起投票，得到集群中半数以上的follower接受的candidate将成为leader  </p></li></ul><p>讲到这里可能有同学发现Etcd和Zookeeper、Consul等一致性协议实现框架有些类似，的确这些中间件是比较类似的，关于其中的异同点，大家可以自行查阅资料。</p><h3 id="2-2-2-kube-apiserver"><a href="#2-2-2-kube-apiserver" class="headerlink" title="2.2.2 kube-apiserver"></a>2.2.2 kube-apiserver</h3><p>kube-apiserver是Kubernetes最重要的核心组件之一，主要提供了如下功能：</p><ul><li><p>提供集群管理的REST API接口，包括认证授权、数据校验以及集群状态变更等</p></li><li><p>提供同其他模块之间的数据交互(其他模块通过API Server查询或修改数据，只有API Server才直接操作etcd)</p></li></ul><h3 id="2-2-3-kube-scheduler"><a href="#2-2-3-kube-scheduler" class="headerlink" title="2.2.3 kube-scheduler"></a>2.2.3 kube-scheduler</h3><p>kube-scheduler负责分配调度Pod到集群内的节点上，它监听kube-<br>apiserver，查询还未分配Node的Pod，然后根据调度策略为这些Pod分配节点</p><p>通过以下三种方式可以指定Pod只运行在特定的Node节点上</p><ul><li><p>nodeSelector:只调度到匹配指定label的Node上 </p></li><li><p>nodeAffinity:功能更丰富的Node选择器，比如支持集合操作 </p></li><li><p>podAffinity:调度到满足条件的Pod所在的Node上</p></li></ul><h3 id="2-2-4-kube-controller-manager"><a href="#2-2-4-kube-controller-manager" class="headerlink" title="2.2.4 kube-controller-manager"></a>2.2.4 kube-controller-manager</h3><p>kube-controller-manager是Kubernetes的大脑，通过kube-<br>apiserver监控整个集群的状态，并确保集群处于预期的工作状态，它由一系列的控制器组成，这些控制器主要包括三组：</p><p> <strong>1. 必须启动的控制器</strong>  </p><ul><li><p>eploymentController</p></li><li><p>DaemonSetController</p></li><li><p>NamesapceController</p></li><li><p>ReplicationController</p></li><li><p>RelicaSet</p></li><li><p>JobController</p></li><li><p>…</p><p><strong>2. 默认启动的控制器</strong>  </p></li><li><p>NodeController</p></li><li><p>ServiceController</p></li><li><p>PVBinderController</p></li><li><p>…</p><p><strong>3. 默认禁止的可选控制器</strong></p></li><li><p>BootstrapSignerController</p></li><li><p>TokenCleanerController</p></li></ul><h3 id="2-2-5-Kubelet"><a href="#2-2-5-Kubelet" class="headerlink" title="2.2.5 Kubelet"></a>2.2.5 Kubelet</h3><p>每个Node节点上都运行一个kubelet守护进程，默认监听10250端口，接收并执行master发来的指令，管理Pod及Pod中的容器。每个kubelet进程会在API<br>Server上注册节点自身信息，定期向master节点汇报节点的资源使用情况</p><p> <strong>节点管理</strong></p><p>主要是节点自注册和节点状态更新:</p><ul><li><p>Kubelet可以通过设置启动参数 –register-node 来确定是否向API Server注册自己; </p></li><li><p>如果Kubelet没有选择自注册模式，则需要用户自己配置Node资源信息，同时需要在Kubelet上配置集群中API Server的信息;</p></li><li><p>Kubelet在启动时通过API Server注册节点信息，并定时向API Server发送节点状态消息，API Server在接收到新消息后，将信息写入etcd  </p><p><strong>容器健康检查</strong></p></li></ul><p>Pod通过两类探针检查容器的健康状态</p><ul><li><p>LivenessProbe 存活探针：通过该探针判断容器是否健康，告诉Kubelet一个容器什么时候处于不健康的状态。如果LivenessProbe探针探测到容器不健康，则kubelet将删除该容器，并根据容器的重启策略做相应的处理。如果一个容器不包含LivenessProbe探针，那么kubelet认为该容器的LivenessProbe探针返回的值永远是“Success”。</p></li><li><p>ReadinessProbe 就绪探针：用于判断容器是否启动完成且准备接收请求。如果 ReadinessProbe 探针探测到失败，则Pod的状态将被修改。Endpoint Controller将从Service的Endpoint中删除包含该容器所在Pod的IP地址的Endpoint条目。</p></li></ul><p>以下是Pod的启动流程：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-11-29/2-2-5.jpg" srcset="/img/loading.gif" lazyload alt="avatar"></p><h3 id="2-2-6-kube-proxy"><a href="#2-2-6-kube-proxy" class="headerlink" title="2.2.6 kube-proxy"></a>2.2.6 kube-proxy</h3><p>每台机器上都运行一个kube-proxy服务，它监听API<br>Server中service和Pod的变化情况，并通过userspace、iptables、ipvs等proxier来为服务配置负载均衡</p><p>代理模式（proxy-mode）提供如下三种类型：</p><p> <strong>1. userspace</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-11-29/2-2-6-1.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>最早的负载均衡方案，它在用户空间监听一个端口，所有请求通过 iptables 转发到这个端口，然后在其内部负载均衡到实际的<br>Pod。service的请求会先从用户空间进入内核iptables，然后再回到用户空间（kube-proxy），由kube-<br>proxy完成后端Endpoints的选择和代理工作，这样流量从用户空间进出内核带来的性能损耗是不可接受的，所以产生了iptables的代理模式</p><p> <strong>2. iptables:</strong></p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-11-29/2-2-6-2.png" srcset="/img/loading.gif" lazyload alt="avatar"></p><p>iptables<br>mode完全使用iptables来完成请求过滤和转发。但是如果集群中存在大量的Service/Endpoint，那么Node上的iptables<br>rules将会非常庞大，添加或者删除iptables规则会引起较大的延迟。  </p><p> <strong>3. ipvs:</strong></p><p>为了解决存在大量iptables规则时的网络延迟的问题，Kubernetes引入了ipvs的模式，（ipvs是LVS - Linux Virtual<br>Server 的重要组成部分，最早是由中国的章文嵩博士推出的一个开源项目，提供软件负载均衡的解决方案），下面是ipvs模式的原理图：</p><p><img src="https://gitee.com/like-ycy/images/raw/master/blog/2019-11-29/2-2-6-3.png" srcset="/img/loading.gif" lazyload alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
